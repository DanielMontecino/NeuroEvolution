{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.codification_cnn import CNNLayer, NNLayer, ChromosomeCNN, FitnessCNN, FitnessCNNParallel\n",
    "from utils.codification_skipc import ChromosomeSkip, FitnessSkip, Connections\n",
    "from utils.datamanager import DataManager\n",
    "from utils.lr_finder import LRFinder\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, PReLU, LeakyReLU, Dropout, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from utils.utils import smooth_labels, WarmUpCosineDecayScheduler, LinearDecayScheduler\n",
    "\n",
    "def show_result(history, metric='acc'):\n",
    "        color = np.array([[31, 119, 180], [255, 127, 14]]) / 255.\n",
    "        try:\n",
    "            epochs = np.linspace(0, len(history.history['acc']) - 1, len(history.history['acc']))\n",
    "            argmax_val = np.argmax(history.history['val_%s' % metric])\n",
    "            plt.plot(epochs, history.history['val_%s' % metric], label='validation', color=color[0], alpha=0.5)\n",
    "            plt.plot(epochs, median_filter(history.history['val_%s' % metric]), color=color[0])\n",
    "            plt.scatter(epochs[argmax_val], history.history['val_%s' % metric][argmax_val],\n",
    "            label='max val_%s %0.4f' % (metric, history.history['val_%s' % metric][argmax_val]), c='r')\n",
    "        except KeyError:\n",
    "            pass\n",
    "        plt.plot(epochs, history.history[metric], label='train', color=color[1], alpha=0.5)\n",
    "        plt.plot(epochs, median_filter(history.history[metric]), color=color[1])\n",
    "\n",
    "\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.xticks([20, 40, 60, 80, 120, 160, 180])\n",
    "        plt.grid()\n",
    "        plt.ylabel(metric)\n",
    "        plt.show()\n",
    "        \n",
    "def median_filter(v, size=5):\n",
    "    stride = (size - 1) // 2\n",
    "    filtered_v = []\n",
    "    for i in range(len(v)):\n",
    "        if i < stride or i + stride == len(v):\n",
    "            filtered_v.append(v[i])\n",
    "        else:\n",
    "            filtered_v.append(np.mean(v[i-stride:i + stride + 1]))\n",
    "    return filtered_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "def get_chromosome_from_file(filename):\n",
    "    cnn_layers = []\n",
    "    nn_layers = []\n",
    "    connections = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            params = line.split('|')            \n",
    "            if 'CNN' == params[0]:\n",
    "                filters = int(params[1].split(':')[1])\n",
    "                kernel = literal_eval(params[2].split(':')[1])\n",
    "                activation = params[3].split(':')[1]\n",
    "                dropout = float(params[4].split(':')[1])\n",
    "                maxpool = bool(int(params[5].split(':')[1]))\n",
    "                cnn_layers.append(CNNLayer(filters, kernel, activation, dropout, maxpool))\n",
    "            elif 'NN' == params[0]:\n",
    "                units = int(params[1].split(':')[1])\n",
    "                activation = params[2].split(':')[1]\n",
    "                dropout = float(params[3].split(':')[1])\n",
    "                nn_layers.append(NNLayer(units, activation, dropout))\n",
    "            else:\n",
    "                try:\n",
    "                    local_connections = [int(el) for el in params[0].split(\"\\n\")[0]]\n",
    "                    if len(local_connections) > 0:\n",
    "                        connections.append(local_connections)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        max_len = np.max([len(e) for e in connections])\n",
    "        matrix = np.array([el + [0] * (max_len - len(el)) for el in connections])\n",
    "        connections = Connections(matrix)\n",
    "    return ChromosomeSkip(cnn_layers, nn_layers, connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset params:\n",
    "data_folder = '/home/daniel/datasets/MNIST_variations'\n",
    "classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600, 28, 28, 1) train samples\n",
      "(2400, 28, 28, 1) validation samples\n",
      "(50000, 28, 28, 1) test samples\n"
     ]
    }
   ],
   "source": [
    "dataset = 'MRDBI'\n",
    "\n",
    "c = get_chromosome_from_file('./models/%s' % dataset)\n",
    "dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder)\n",
    "data = dm.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN|F:57|K:(3,3)|A:prelu|D:0.343|M:0\n",
      "CNN|F:79|K:(3,5)|A:prelu|D:0.137|M:0\n",
      "CNN|F:66|K:(7,7)|A:relu|D:0.189|M:0\n",
      "CNN|F:67|K:(1,1)|A:relu|D:0.220|M:0\n",
      "CNN|F:71|K:(7,7)|A:prelu|D:0.246|M:1\n",
      "CNN|F:72|K:(7,7)|A:leakyreLu|D:0.256|M:1\n",
      "CNN|F:73|K:(7,7)|A:prelu|D:0.247|M:1\n",
      "1\n",
      "11\n",
      "101\n",
      "1001\n",
      "00001\n",
      "000001\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 1)    4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 57)   570         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 28, 28, 57)   44688       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 57)   228         p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 28, 28, 57)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 79)   67624       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 28, 28, 79)   61936       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 28, 28, 79)   316         p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 28, 28, 79)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 136)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 66)   439890      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 28, 28, 66)   264         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 28, 28, 66)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 123)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 67)   8308        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 28, 67)   268         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 28, 28, 67)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 124)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 71)   431467      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 28, 28, 71)   55664       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 71)   284         p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 71)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 14, 14, 71)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 14, 14, 72)   250560      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 72)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 14, 14, 72)   288         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 72)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 72)     0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 7, 73)     257617      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 7, 7, 73)     3577        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 7, 7, 73)     292         p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 73)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 3, 3, 73)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 657)          0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           6580        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,630,425\n",
      "Trainable params: 1,629,453\n",
      "Non-trainable params: 972\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(c)\n",
    "keras.backend.clear_session()\n",
    "f = FitnessSkip()\n",
    "f.input_shape = (28, 28, 1)\n",
    "f.num_clases = 10\n",
    "f.verb = 1\n",
    "model = f.decode(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "warmup_epochs = 0\n",
    "batch_size = 128\n",
    "cosine_decay = True\n",
    "#epochs = 200\n",
    "data_augmentation = False\n",
    "val_data = 0\n",
    "\n",
    "\n",
    "# Create the Learning rate scheduler.\n",
    "total_steps = int(epochs * data[0][1].shape[0] / batch_size)\n",
    "warm_up_steps = int(warmup_epochs * data[0][1].shape[0] /batch_size)\n",
    "base_steps = total_steps * (not cosine_decay)\n",
    "warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base=0.0001,\n",
    "                                        total_steps=total_steps,\n",
    "                                        warmup_learning_rate=0.0,\n",
    "                                        warmup_steps=warm_up_steps,\n",
    "                                        hold_base_rate_steps=base_steps)\n",
    "\n",
    "callbacks = [warm_up_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Epoch 1/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 2/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0226 - acc: 0.9928\n",
      "Epoch 3/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0224 - acc: 0.9922\n",
      "Epoch 4/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0208 - acc: 0.9931\n",
      "Epoch 5/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0156 - acc: 0.9952\n",
      "Epoch 6/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0165 - acc: 0.9947\n",
      "Epoch 7/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0155 - acc: 0.9955\n",
      "Epoch 8/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0128 - acc: 0.9960\n",
      "Epoch 9/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0147 - acc: 0.9952\n",
      "Epoch 10/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0126 - acc: 0.9965\n",
      "Epoch 11/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0109 - acc: 0.9964\n",
      "Epoch 12/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0108 - acc: 0.9968\n",
      "Epoch 13/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0106 - acc: 0.9971\n",
      "Epoch 14/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0096 - acc: 0.9973\n",
      "Epoch 15/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 16/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0081 - acc: 0.9976\n",
      "Epoch 17/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 18/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0101 - acc: 0.9977\n",
      "Epoch 19/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0094 - acc: 0.9968\n",
      "Epoch 20/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0087 - acc: 0.9973\n",
      "Epoch 21/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0067 - acc: 0.9982\n",
      "Epoch 22/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0085 - acc: 0.9977\n",
      "Epoch 23/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0072 - acc: 0.9980\n",
      "Epoch 24/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0062 - acc: 0.9982\n",
      "Epoch 25/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0073 - acc: 0.9977\n",
      "Epoch 26/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0074 - acc: 0.9979\n",
      "Epoch 27/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0076 - acc: 0.9976\n",
      "Epoch 28/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0074 - acc: 0.9978\n",
      "Epoch 29/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0048 - acc: 0.9988\n",
      "Epoch 30/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0054 - acc: 0.9986\n",
      "Epoch 31/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0063 - acc: 0.9983\n",
      "Epoch 32/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0055 - acc: 0.9987\n",
      "Epoch 33/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0069 - acc: 0.9977\n",
      "Epoch 34/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0051 - acc: 0.9985\n",
      "Epoch 35/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0047 - acc: 0.9991\n",
      "Epoch 36/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0057 - acc: 0.9985\n",
      "Epoch 37/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0060 - acc: 0.9983\n",
      "Epoch 38/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0058 - acc: 0.9988\n",
      "Epoch 39/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0051 - acc: 0.9987\n",
      "Epoch 40/100\n",
      "12000/12000 [==============================] - 45s 4ms/step - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 41/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 42/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0048 - acc: 0.9984\n",
      "Epoch 43/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0057 - acc: 0.9980\n",
      "Epoch 44/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0057 - acc: 0.9981\n",
      "Epoch 45/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 46/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0061 - acc: 0.9985\n",
      "Epoch 47/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0039 - acc: 0.9992\n",
      "Epoch 48/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0046 - acc: 0.9987\n",
      "Epoch 49/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0041 - acc: 0.9990\n",
      "Epoch 50/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0046 - acc: 0.9991\n",
      "Epoch 51/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 52/100\n",
      "12000/12000 [==============================] - 44s 4ms/step - loss: 0.0036 - acc: 0.9992\n",
      "Epoch 53/100\n",
      "12000/12000 [==============================] - 46s 4ms/step - loss: 0.0057 - acc: 0.9981\n",
      "Epoch 54/100\n",
      "12000/12000 [==============================] - 46s 4ms/step - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 55/100\n",
      " 2304/12000 [====>.........................] - ETA: 37s - loss: 0.0065 - acc: 0.9974"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0c6dc0346706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                   verbose=1)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using real-time data augmentation.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if val_data:\n",
    "    #validation_data = (x_test[0:10000,...], y_test[0:10000,...])\n",
    "    validation_data = data[2][0], data[2][1]\n",
    "    x_train, y_train = data[0][0], data[0][1]\n",
    "else:\n",
    "    x_train = np.concatenate([data[0][0], data[2][0]], axis=0)\n",
    "    x_test = data[1][0]\n",
    "    y_train = np.concatenate([data[0][1], data[2][1]], axis=0)\n",
    "    y_test = data[1][1]\n",
    "    validation_data = (x_test, y_test)\n",
    "    validation_data = None\n",
    "ti = time()\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    h = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=validation_data,\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks,\n",
    "                  verbose=1)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # preprocessing  and realtime data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (deg 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally\n",
    "        height_shift_range=0.1,  # randomly shift images vertically\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    h = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        validation_data=validation_data,\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# score trained model\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print(\"Elapsed time: %0.2f\" % ((time() - ti) / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 106s 2ms/step\n",
      "Test loss: 0.5999474371919036\n",
      "Test accuracy: 0.89482\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.2320000000000007"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_result(h)\n",
    "100 * (1-0.97768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| dataset | val error | test error | test error+DA   |\n",
    "|---------|-----------|------------|-----------------|\n",
    "|  MB     |  0.50     |    0.90    |     0.68        |\n",
    "|  MBI    |  1.58     |    2.27    |     2.22        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 35s 693us/step\n",
      "Test loss: 0.1026977105951158\n",
      "Test accuracy: 0.9766\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
