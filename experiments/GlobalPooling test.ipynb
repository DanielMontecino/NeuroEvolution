{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the time and the accuracy of adding a global pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.codification_cnn import CNNLayer, NNLayer, ChromosomeCNN, FitnessCNN, FitnessCNNParallel\n",
    "from utils.datamanager import DataManager\n",
    "from utils.lr_finder import LRFinder\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, PReLU, LeakyReLU, Dropout, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from utils.utils import smooth_labels, WarmUpCosineDecayScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset params:\n",
    "data_folder = '/home/daniel/datasets/MNIST_variations'\n",
    "classes = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600, 28, 28, 1) train samples\n",
      "(2400, 28, 28, 1) validation samples\n",
      "(50000, 28, 28, 1) test samples\n"
     ]
    }
   ],
   "source": [
    "dataset = 'MRDBI'\n",
    "dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder)\n",
    "data = dm.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([data[0][0], data[2][0]], axis=0)\n",
    "x_test = data[1][0]\n",
    "y_train = np.concatenate([data[0][1], data[2][1]], axis=0)\n",
    "y_test = data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer(input_, filters, ksize, act, dropout, maxpool, original=False):\n",
    "    if not original:\n",
    "        act = 'relu'\n",
    "        k = min(ksize[0], ksize[1])\n",
    "        ksize = (k, k)\n",
    "        \n",
    "    if act in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
    "        x = Conv2D(filters, ksize, activation=act, padding='same')(input_)\n",
    "    elif act == 'prelu':\n",
    "        x = Conv2D(filters, ksize, padding='same')(input_)\n",
    "        x = PReLU()(x)\n",
    "    else:\n",
    "        x = Conv2D(filters, ksize, padding='same')(input_)\n",
    "        x = LeakyReLU()(x)\n",
    "        \n",
    "    x = BatchNormalization()(x)\n",
    "    if maxpool:\n",
    "        if original:\n",
    "            x = MaxPooling2D()(x)\n",
    "        else:\n",
    "            x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "    if not original:\n",
    "        x = keras.layers.SpatialDropout2D(dropout)(x)\n",
    "    else:\n",
    "        x = Dropout(dropout)(x)\n",
    "    return x\n",
    "    \n",
    "def get_nn_layer(input_, units, act, dropout, original=False):\n",
    "    if not original:\n",
    "        act = 'sigmoid'\n",
    "    if act in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
    "        x = Dense(units, activation=act)(input_)\n",
    "    elif act == 'prelu':\n",
    "        x = Dense(units)(input_)\n",
    "        x = PReLU()(x)\n",
    "    else:\n",
    "        x = Dense(units)(input_)\n",
    "        x = LeakyReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 54)        1404      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 54)        216       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_1 (Spatial (None, 28, 28, 54)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 54)        72954     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 54)        216       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_2 (Spatial (None, 28, 28, 54)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 54)        72954     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 54)        216       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_3 (Spatial (None, 28, 28, 54)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 51)        24837     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 51)        204       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 51)        0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_4 (Spatial (None, 13, 13, 51)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 136)       173536    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 13, 13, 136)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 136)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_5 (Spatial (None, 6, 6, 136)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4896)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 702)               3437694   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 702)               2808      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 702)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                7030      \n",
      "=================================================================\n",
      "Total params: 3,794,617\n",
      "Trainable params: 3,792,513\n",
      "Non-trainable params: 2,104\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import smooth_labels, WarmUpCosineDecayScheduler\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPool2D\n",
    "\n",
    "model = 4\n",
    "o = False\n",
    "keras.backend.clear_session()\n",
    "inp = Input(shape=data[0][0][0].shape)\n",
    "\n",
    "if o:\n",
    "    x = inp\n",
    "else:\n",
    "    x = BatchNormalization()(inp)\n",
    "\n",
    "if model == 0:\n",
    "    x = get_layer(x, 86, (3,5), 'relu', 0.262, 1)\n",
    "    x = get_layer(x, 84, (5,3), 'relu', 0.319, 1)\n",
    "    x = get_layer(x, 243, (1,3), 'relu', 0.322, 1)\n",
    "    #x = GlobalMaxPool2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = get_nn_layer(x, 948, 'sigmoid', 0.467)\n",
    "    x = get_nn_layer(x, 780, 'sigmoid', 0.441)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "elif model == 1:\n",
    "    x = get_layer(x, 99, (7,3), 'leakyreLu', 0.307, 0, o)\n",
    "    x = get_layer(x, 192, (5,5), 'relu', 0.271, 0, o)\n",
    "    x = get_layer(x, 96, (1,7), 'leakyreLu', 0.041, 1, o)\n",
    "    x = get_layer(x, 177, (1,3), 'elu', 0.161, 1, o)\n",
    "    x = get_layer(x, 177, (7,4), 'relu', 0.656, 0, o)\n",
    "    x = Flatten()(x)\n",
    "    x = get_nn_layer(x, 286, 'elu', 0.432, o)\n",
    "    x = get_nn_layer(x, 411, 'sigmoid', 0.527, o)\n",
    "    x = get_nn_layer(x, 621, 'elu', 0.491, o)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "elif model == 2:\n",
    "    x = get_layer(x, 154, (3,7), 'relu', 0.414, 1, o)\n",
    "    x = get_layer(x, 164, (3,7), 'relu', 0.400, 1, o)\n",
    "    x = Flatten()(x)\n",
    "    x = get_nn_layer(x, 329, 'sigmoid', 0.085, o)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "elif model == 3:\n",
    "    x = get_layer(x, 192, (5,7), 'elu', 0.178, 1, o)\n",
    "    x = get_layer(x, 222, (1,5), 'leakyreLu', 0.291, 0, o)\n",
    "    x = get_layer(x, 206, (7,3), 'tanh', 0.419, 0, o)\n",
    "    x = get_layer(x, 132, (3,7), 'leakyreLu', 0.380, 0, o)\n",
    "    x = get_layer(x, 132, (5,7), 'relu', 0.407, 0, o)\n",
    "    x = get_layer(x, 46, (5,1), 'elu', 0.176, 0, o)\n",
    "    x = get_layer(x, 185, (1,3), 'leakyreLu', 0.292, 0, o)\n",
    "    x = Flatten()(x)\n",
    "    x = get_nn_layer(x, 362, 'elu', 0.427, o)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "elif model == 4:\n",
    "    x = get_layer(x, 54, (5,5), 'prelu', 0.166, 0, o)\n",
    "    x = get_layer(x, 54, (5,5), 'prelu', 0.166, 0, o)\n",
    "    x = get_layer(x, 54, (5,5), 'prelu', 0.138, 0, o)\n",
    "    x = get_layer(x, 51, (7,3), 'prelu', 0.277, 1, o)\n",
    "    x = get_layer(x, 136, (5,7), 'elu', 0.525, 1, o)\n",
    "    x = Flatten()(x)\n",
    "    x = get_nn_layer(x, 702, 'sigmoid', 0.301, o)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "elif model == 5:\n",
    "    x = get_layer(x, 121, (3,1), 'prelu', 0.175, 0, o)\n",
    "    x = get_layer(x, 94, (3,3), 'prelu', 0.404, 1, o)\n",
    "    x = get_layer(x, 149, (5,7), 'prelu', 0.326, 1, o)\n",
    "    x = get_layer(x, 190, (3,7), 'prelu', 0.098, 1, o)\n",
    "    x = Conv2D(10, 2, padding='valid', activation='softmax')(x)\n",
    "    x = Flatten()(x)\n",
    "    #x = Dense(10, activation='softmax')(x)\n",
    "    \n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "epochs = 75\n",
    "warmup_epochs = 0\n",
    "batch_size = 128\n",
    "cosine_decay = True\n",
    "#epochs = 200\n",
    "data_augmentation = False\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "# prepare callbacks for model saving and for learning rate reducer\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "\n",
    "# Create the Learning rate scheduler.\n",
    "total_steps = int(epochs * data[0][1].shape[0] / batch_size)\n",
    "warm_up_steps = int(warmup_epochs * data[0][1].shape[0] /batch_size)\n",
    "base_steps = total_steps * (not cosine_decay)\n",
    "warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base=0.001,\n",
    "                                        total_steps=total_steps,\n",
    "                                        warmup_learning_rate=0.0,\n",
    "                                        warmup_steps=warm_up_steps,\n",
    "                                        hold_base_rate_steps=base_steps)\n",
    "\n",
    "callbacks = [warm_up_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 12000 samples, validate on 50000 samples\n",
      "Epoch 1/75\n",
      "  512/12000 [>.............................] - ETA: 42s - loss: 3.2614 - acc: 0.1562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-240962af1938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                   verbose=1)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using real-time data augmentation.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    h = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks,\n",
    "                  verbose=1)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # preprocessing  and realtime data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=360,  # randomly rotate images in the range (deg 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally\n",
    "        height_shift_range=0.1,  # randomly shift images vertically\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    h = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "ti = time()\n",
    "\n",
    "# score trained model\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print(\"Elapsed time: %0.2f\" % ((time() - ti) / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/75\n",
      "9600/9600 [==============================] - 14s 1ms/step - loss: 2.8639 - acc: 0.2046 - val_loss: 1.9589 - val_acc: 0.3029\n",
      "Epoch 2/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 1.8210 - acc: 0.3736 - val_loss: 1.4762 - val_acc: 0.4938\n",
      "Epoch 3/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 1.4281 - acc: 0.5080 - val_loss: 1.1499 - val_acc: 0.6096\n",
      "Epoch 4/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 1.2331 - acc: 0.5828 - val_loss: 1.0296 - val_acc: 0.6650\n",
      "Epoch 5/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 1.1160 - acc: 0.6262 - val_loss: 0.9387 - val_acc: 0.6858\n",
      "Epoch 6/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 1.0177 - acc: 0.6589 - val_loss: 0.8832 - val_acc: 0.7150\n",
      "Epoch 7/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.9295 - acc: 0.6897 - val_loss: 0.8411 - val_acc: 0.7204\n",
      "Epoch 8/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.8684 - acc: 0.7149 - val_loss: 0.7652 - val_acc: 0.7521\n",
      "Epoch 9/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.7867 - acc: 0.7382 - val_loss: 0.7087 - val_acc: 0.7787\n",
      "Epoch 10/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.7538 - acc: 0.7546 - val_loss: 0.7296 - val_acc: 0.7700\n",
      "Epoch 11/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.7126 - acc: 0.7680 - val_loss: 0.6411 - val_acc: 0.7892\n",
      "Epoch 12/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.6904 - acc: 0.7693 - val_loss: 0.6346 - val_acc: 0.7925\n",
      "Epoch 13/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.6760 - acc: 0.7791 - val_loss: 0.6334 - val_acc: 0.7912\n",
      "Epoch 14/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.6241 - acc: 0.7968 - val_loss: 0.6160 - val_acc: 0.8004\n",
      "Epoch 15/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.5967 - acc: 0.8049 - val_loss: 0.5711 - val_acc: 0.8142\n",
      "Epoch 16/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.5697 - acc: 0.8122 - val_loss: 0.5981 - val_acc: 0.8104\n",
      "Epoch 17/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.5442 - acc: 0.8223 - val_loss: 0.5968 - val_acc: 0.8017\n",
      "Epoch 18/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.5407 - acc: 0.8243 - val_loss: 0.5294 - val_acc: 0.8258\n",
      "Epoch 19/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.5069 - acc: 0.8329 - val_loss: 0.5695 - val_acc: 0.8146\n",
      "Epoch 20/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.5027 - acc: 0.8356 - val_loss: 0.5378 - val_acc: 0.8333\n",
      "Epoch 21/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.4748 - acc: 0.8378 - val_loss: 0.5349 - val_acc: 0.8333\n",
      "Epoch 22/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.4781 - acc: 0.8428 - val_loss: 0.5348 - val_acc: 0.8313\n",
      "Epoch 23/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.4340 - acc: 0.8543 - val_loss: 0.5261 - val_acc: 0.8400\n",
      "Epoch 24/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.4280 - acc: 0.8555 - val_loss: 0.5296 - val_acc: 0.8371\n",
      "Epoch 25/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.3979 - acc: 0.8681 - val_loss: 0.5211 - val_acc: 0.8317\n",
      "Epoch 26/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.3995 - acc: 0.8690 - val_loss: 0.5078 - val_acc: 0.8450\n",
      "Epoch 27/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.3708 - acc: 0.8696 - val_loss: 0.5226 - val_acc: 0.8433\n",
      "Epoch 28/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.3782 - acc: 0.8743 - val_loss: 0.5166 - val_acc: 0.8421\n",
      "Epoch 29/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.3558 - acc: 0.8792 - val_loss: 0.4941 - val_acc: 0.8483\n",
      "Epoch 30/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.3400 - acc: 0.8878 - val_loss: 0.5091 - val_acc: 0.8442\n",
      "Epoch 31/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.3255 - acc: 0.8897 - val_loss: 0.4942 - val_acc: 0.8512\n",
      "Epoch 32/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.3119 - acc: 0.8969 - val_loss: 0.4842 - val_acc: 0.8550\n",
      "Epoch 33/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.3007 - acc: 0.9001 - val_loss: 0.4807 - val_acc: 0.8546\n",
      "Epoch 34/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.2869 - acc: 0.9054 - val_loss: 0.4854 - val_acc: 0.8592\n",
      "Epoch 35/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.2807 - acc: 0.9065 - val_loss: 0.4732 - val_acc: 0.8654\n",
      "Epoch 36/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.2711 - acc: 0.9073 - val_loss: 0.4869 - val_acc: 0.8633\n",
      "Epoch 37/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.2602 - acc: 0.9130 - val_loss: 0.4771 - val_acc: 0.8571\n",
      "Epoch 38/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.2551 - acc: 0.9146 - val_loss: 0.4715 - val_acc: 0.8658\n",
      "Epoch 39/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.2327 - acc: 0.9219 - val_loss: 0.4807 - val_acc: 0.8675\n",
      "Epoch 40/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.2377 - acc: 0.9221 - val_loss: 0.4764 - val_acc: 0.8717\n",
      "Epoch 41/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.2193 - acc: 0.9224 - val_loss: 0.4575 - val_acc: 0.8750\n",
      "Epoch 42/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.2059 - acc: 0.9285 - val_loss: 0.4703 - val_acc: 0.8742\n",
      "Epoch 43/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.2135 - acc: 0.9255 - val_loss: 0.4716 - val_acc: 0.8675\n",
      "Epoch 44/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1898 - acc: 0.9336 - val_loss: 0.4682 - val_acc: 0.8708\n",
      "Epoch 45/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1905 - acc: 0.9327 - val_loss: 0.4744 - val_acc: 0.8679\n",
      "Epoch 46/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1762 - acc: 0.9411 - val_loss: 0.4690 - val_acc: 0.8708\n",
      "Epoch 47/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1794 - acc: 0.9366 - val_loss: 0.4663 - val_acc: 0.8767\n",
      "Epoch 48/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1780 - acc: 0.9393 - val_loss: 0.4486 - val_acc: 0.8733\n",
      "Epoch 49/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1681 - acc: 0.9450 - val_loss: 0.4678 - val_acc: 0.8783\n",
      "Epoch 50/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1605 - acc: 0.9453 - val_loss: 0.4574 - val_acc: 0.8733\n",
      "Epoch 51/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1570 - acc: 0.9445 - val_loss: 0.4566 - val_acc: 0.8758\n",
      "Epoch 52/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1498 - acc: 0.9483 - val_loss: 0.4613 - val_acc: 0.8779\n",
      "Epoch 53/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1447 - acc: 0.9530 - val_loss: 0.4592 - val_acc: 0.8754\n",
      "Epoch 54/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1378 - acc: 0.9528 - val_loss: 0.4635 - val_acc: 0.8804\n",
      "Epoch 55/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1322 - acc: 0.9578 - val_loss: 0.4609 - val_acc: 0.8783\n",
      "Epoch 56/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1318 - acc: 0.9560 - val_loss: 0.4607 - val_acc: 0.8754\n",
      "Epoch 57/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1223 - acc: 0.9581 - val_loss: 0.4600 - val_acc: 0.8817\n",
      "Epoch 58/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1272 - acc: 0.9581 - val_loss: 0.4590 - val_acc: 0.8758\n",
      "Epoch 59/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1249 - acc: 0.9592 - val_loss: 0.4581 - val_acc: 0.8842\n",
      "Epoch 60/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1240 - acc: 0.9587 - val_loss: 0.4642 - val_acc: 0.8833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1183 - acc: 0.9619 - val_loss: 0.4675 - val_acc: 0.8829\n",
      "Epoch 62/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1088 - acc: 0.9656 - val_loss: 0.4650 - val_acc: 0.8800\n",
      "Epoch 63/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1181 - acc: 0.9610 - val_loss: 0.4681 - val_acc: 0.8821\n",
      "Epoch 64/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1158 - acc: 0.9611 - val_loss: 0.4658 - val_acc: 0.8812\n",
      "Epoch 65/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1134 - acc: 0.9629 - val_loss: 0.4633 - val_acc: 0.8825\n",
      "Epoch 66/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1039 - acc: 0.9649 - val_loss: 0.4606 - val_acc: 0.8867\n",
      "Epoch 67/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1042 - acc: 0.9651 - val_loss: 0.4588 - val_acc: 0.8854\n",
      "Epoch 68/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1084 - acc: 0.9649 - val_loss: 0.4582 - val_acc: 0.8854\n",
      "Epoch 69/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1086 - acc: 0.9623 - val_loss: 0.4582 - val_acc: 0.8858\n",
      "Epoch 70/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1065 - acc: 0.9639 - val_loss: 0.4590 - val_acc: 0.8854\n",
      "Epoch 71/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1063 - acc: 0.9642 - val_loss: 0.4593 - val_acc: 0.8862\n",
      "Epoch 72/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1055 - acc: 0.9666 - val_loss: 0.4591 - val_acc: 0.8858\n",
      "Epoch 73/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1032 - acc: 0.9656 - val_loss: 0.4588 - val_acc: 0.8850\n",
      "Epoch 74/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.0997 - acc: 0.9670 - val_loss: 0.4587 - val_acc: 0.8850\n",
      "Epoch 75/75\n",
      "9600/9600 [==============================] - 13s 1ms/step - loss: 0.1036 - acc: 0.9652 - val_loss: 0.4586 - val_acc: 0.8850\n",
      "Test: 0.87794\n",
      "Elapsed time: 16.78\n"
     ]
    }
   ],
   "source": [
    "ti = time()\n",
    "h = model.fit(data[0][0], data[0][1],\n",
    "      batch_size=batch_size,\n",
    "      epochs=epochs,\n",
    "      verbose=1,\n",
    "      validation_data=(data[2][0], data[2][1]),\n",
    "             callbacks=callbacks)\n",
    "print(\"Test:\", model.evaluate(data[1][0], data[1][1], verbose=0)[1])\n",
    "print(\"Elapsed time: %0.2f\" % ((time() - ti) / 60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| model id | improved |dataset | val acc | test acc | time (min) | params  |\n",
    "|----------|----------|--------|---------|----------|------------|---------|\n",
    "|    4     | NO       | MRDBI  |  85.96  |  86.32   |   22.88    |5,305,149| \n",
    "|    4     | YES      | MRDBI  |  87.42  |  87.23   |   15.19    |3,589,465|\n",
    "|    4     | YES+ks   | MRDBI  |  87.50  |  87.84   |   16.52    |3,789,465|\n",
    "|    4     | YES+ks+prelu|MRDBI|  88.17  |  87.86   |   20.23    |3,984,593|\n",
    "|    2     | NO       |  MB    |  99.25  |  98.94   |   13.62    |3,183,989|\n",
    "|    2     | YES      |  MB    |  99.37  |  98.96   |   9.90     |2,177,645|\n",
    "|    3     | NO       |  MB    |  99.12  |  99.04   |   43.53    |15,554,109|\n",
    "|    3     | YES      |  MB    |  99.21  |  99.00   |   27.7     |12,658,663|\n",
    "|    5     | YES      |  MBI   |  97.33  |  97.28   |   15.64    |  717,811|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def show_result(history, metric='acc'):\n",
    "        color = np.array([[31, 119, 180], [255, 127, 14]]) / 255.\n",
    "        epochs = np.linspace(0, len(history.history['acc']) - 1, len(history.history['acc']))\n",
    "        argmax_val = np.argmax(history.history['val_%s' % metric])\n",
    "        plt.plot(epochs, history.history['val_%s' % metric], label='validation', color=color[0], alpha=0.5)\n",
    "        plt.plot(epochs, median_filter(history.history['val_%s' % metric]), color=color[0])\n",
    "        plt.plot(epochs, history.history[metric], label='train', color=color[1], alpha=0.5)\n",
    "        plt.plot(epochs, median_filter(history.history[metric]), color=color[1])\n",
    "\n",
    "        plt.scatter(epochs[argmax_val], history.history['val_%s' % metric][argmax_val],\n",
    "                    label='max val_%s %0.4f' % (metric, history.history['val_%s' % metric][argmax_val]), c='r')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(metric)\n",
    "        plt.show()\n",
    "        \n",
    "def median_filter(v, size=5):\n",
    "    stride = (size - 1) // 2\n",
    "    filtered_v = []\n",
    "    for i in range(len(v)):\n",
    "        if i < stride or i + stride == len(v):\n",
    "            filtered_v.append(v[i])\n",
    "        else:\n",
    "            filtered_v.append(np.mean(v[i-stride:i + stride + 1]))\n",
    "    return filtered_v\n",
    "\n",
    "show_result(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/5\n",
      "9600/9600 [==============================] - 5s 499us/step - loss: 0.3220 - acc: 0.8869 - val_loss: 0.6561 - val_acc: 0.8046\n",
      "Epoch 2/5\n",
      "9600/9600 [==============================] - 5s 507us/step - loss: 0.3219 - acc: 0.8871 - val_loss: 0.6560 - val_acc: 0.8042\n",
      "Epoch 3/5\n",
      "9600/9600 [==============================] - 5s 501us/step - loss: 0.3180 - acc: 0.8908 - val_loss: 0.6556 - val_acc: 0.8054\n",
      "Epoch 4/5\n",
      "9600/9600 [==============================] - 5s 504us/step - loss: 0.3264 - acc: 0.8901 - val_loss: 0.6556 - val_acc: 0.8050\n",
      "Epoch 5/5\n",
      "9600/9600 [==============================] - 5s 501us/step - loss: 0.3240 - acc: 0.8897 - val_loss: 0.6555 - val_acc: 0.8054\n",
      "Test: 0.80988\n"
     ]
    }
   ],
   "source": [
    "model.trainable = False\n",
    "h = model.fit(data[0][0], data[0][1],\n",
    "      batch_size=128,\n",
    "      epochs=5,\n",
    "      verbose=1,\n",
    "      validation_data=(data[2][0], data[2][1]))\n",
    "print(\"Test:\", model.evaluate(data[1][0], data[1][1], verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|    1     | NO       | MRDBI  |  85.96  |  85.77   |   48.75    |3,841,215|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
