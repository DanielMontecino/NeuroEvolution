{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import keras\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.utils import smooth_labels, CLRScheduler, LinearDecayScheduler, WarmUpCosineDecayScheduler\n",
    "from utils.codification_cnn import CNNLayer, NNLayer, ChromosomeCNN, FitnessCNN, FitnessCNNParallel\n",
    "\n",
    "from utils.codification_skipc import FitnessSkip, Connections, ChromosomeSkip\n",
    "from utils.datamanager import DataManager\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.layers import Conv2D, PReLU, LeakyReLU, Dropout,SpatialDropout2D\n",
    "from keras.layers import MaxPooling2D, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from keras.layers import SeparableConv2D, DepthwiseConv2D, LocallyConnected2D\n",
    "\n",
    "\n",
    "def get_chromosome_from_file(filename):\n",
    "    cnn_layers = []\n",
    "    nn_layers = []\n",
    "    connections = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            params = line.split('|')            \n",
    "            if 'CNN' == params[0]:\n",
    "                filters = int(params[1].split(':')[1])\n",
    "                kernel = literal_eval(params[2].split(':')[1])\n",
    "                activation = params[3].split(':')[1]\n",
    "                dropout = float(params[4].split(':')[1])\n",
    "                maxpool = bool(int(params[5].split(':')[1]))\n",
    "                cnn_layers.append(CNNLayer(filters, kernel, activation, dropout, maxpool))\n",
    "            elif 'NN' == params[0]:\n",
    "                units = int(params[1].split(':')[1])\n",
    "                activation = params[2].split(':')[1]\n",
    "                dropout = float(params[3].split(':')[1])\n",
    "                nn_layers.append(NNLayer(units, activation, dropout))\n",
    "            else:\n",
    "                try:\n",
    "                    local_connections = [int(el) for el in params[0].split(\"\\n\")[0]]\n",
    "                    if len(local_connections) > 0:\n",
    "                        connections.append(local_connections)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        max_len = np.max([len(e) for e in connections])\n",
    "        matrix = np.array([el + [0] * (max_len - len(el)) for el in connections])\n",
    "        connections = Connections(matrix)\n",
    "    return ChromosomeSkip(cnn_layers, nn_layers, connections)\n",
    "\n",
    "\n",
    "def show_result(history, metric='acc'):\n",
    "        color = np.array([[31, 119, 180], [255, 127, 14]]) / 255.\n",
    "        try:\n",
    "            epochs = np.linspace(0, len(history.history['acc']) - 1, len(history.history['acc']))\n",
    "            argmax_val = np.argmax(history.history['val_%s' % metric])\n",
    "            plt.plot(epochs, history.history['val_%s' % metric], label='validation', color=color[0], alpha=0.5)\n",
    "            plt.plot(epochs, median_filter(history.history['val_%s' % metric]), color=color[0])\n",
    "            plt.scatter(epochs[argmax_val], history.history['val_%s' % metric][argmax_val],\n",
    "            label='max val_%s %0.4f' % (metric, history.history['val_%s' % metric][argmax_val]), c='r')\n",
    "        except KeyError:\n",
    "            pass\n",
    "        plt.plot(epochs, history.history[metric], label='train', color=color[1], alpha=0.5)\n",
    "        plt.plot(epochs, median_filter(history.history[metric]), color=color[1])\n",
    "\n",
    "\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epochs')\n",
    "        #plt.xticks([20, 40, 60, 80, 120, 160, 180])\n",
    "        plt.grid()\n",
    "        plt.ylabel(metric)\n",
    "        plt.show()\n",
    "        \n",
    "def median_filter(v, size=5):\n",
    "    stride = (size - 1) // 2\n",
    "    filtered_v = []\n",
    "    for i in range(len(v)):\n",
    "        if i < stride or i + stride == len(v):\n",
    "            filtered_v.append(v[i])\n",
    "        else:\n",
    "            filtered_v.append(np.mean(v[i-stride:i + stride + 1]))\n",
    "    return filtered_v\n",
    "\n",
    "def select_conv(inp, filters, k_size, type_, act=None):\n",
    "    if type_ == 'sep':\n",
    "        return SeparableConv2D(filters, k_size, activation=act_, padding='same')(inp)\n",
    "    elif type_ == 'depw':\n",
    "        return DepthwiseConv2D(filters, k_size, activation=act_, padding='same')(inp)\n",
    "    elif type_ == 'loc':\n",
    "        return LocallyConnected2D(filters, k_size, activation=act_, padding='same')(inp)\n",
    "    else:\n",
    "        print(\"%s conv type is not defined\" % type_)\n",
    "\n",
    "class FitnessSkip_v2(FitnessSkip):\n",
    "    maxpool_overlap = False\n",
    "    spatial_dropout = False\n",
    "\n",
    "    def decode(self, chromosome, lr=0.001, fp=32, type_conv='sep'):\n",
    "        connections = chromosome.connections.matrix\n",
    "        cnn_layers = chromosome.cnn_layers\n",
    "\n",
    "        if self.maxpool_overlap:\n",
    "            ps = 3\n",
    "            st = 2\n",
    "        else:\n",
    "            ps = 2\n",
    "            st = 2\n",
    "\n",
    "        def decode_layer(layer, inp_):\n",
    "            act_ = layer.activation\n",
    "            filters = layer.filters\n",
    "            k_size = layer.k_size\n",
    "            \n",
    "            act_aux = act_\n",
    "            if act_ in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
    "                act_ = act_\n",
    "            else:\n",
    "                act_ = None\n",
    "            if type_conv == 'sep':\n",
    "                x_ = SeparableConv2D(filters, k_size, activation=act_, padding='same')(inp_)\n",
    "            elif type_conv == 'depw':\n",
    "                x_ = DepthwiseConv2D(kernel_size=k_size,depth_multiplier=2, activation=act_, padding='same')(inp_)\n",
    "            elif type_conv == 'loc':\n",
    "                x_ = LocallyConnected2D(filters, kernel_size=k_size, activation=act_, padding='same')(inp_)\n",
    "            else:\n",
    "                x_ = Conv2D(filters, kernel_size=k_size, activation=act_, padding='same')(inp_)\n",
    "                \n",
    "            if act_aux == 'prelu':\n",
    "                x_ = PReLU()(x_)\n",
    "            elif act_aux == 'leakyreLu':\n",
    "                x_ = LeakyReLU()(x_)\n",
    "\n",
    "            x_ = BatchNormalization()(x_)\n",
    "            if layer.maxpool:\n",
    "                x_ = MaxPooling2D(pool_size=ps, strides=st)(x_)\n",
    "            if self.spatial_dropout:\n",
    "                x_ = SpatialDropout2D(layer.dropout)(x_)\n",
    "            else:\n",
    "                x_ = Dropout(layer.dropout)(x_)\n",
    "\n",
    "            return x_\n",
    "\n",
    "        def count_mp(s1, s2):\n",
    "            n = 0\n",
    "            while True:\n",
    "                if s1 == s2:\n",
    "                    return n\n",
    "                if FitnessSkip.maxpool_overlap:\n",
    "                    s1 = int((s1 + 1) / 2 - 1)\n",
    "                else:\n",
    "                    s1 = int(s1/2)\n",
    "                n += 1\n",
    "\n",
    "        inp = Input(shape=self.input_shape)\n",
    "        x = BatchNormalization()(inp)\n",
    "\n",
    "        layers = []\n",
    "        if len(cnn_layers) > 0:\n",
    "            layers.append(decode_layer(cnn_layers[0], x))\n",
    "\n",
    "        for block in range(connections.shape[0]):\n",
    "            input_connections = []\n",
    "            for input_layer in range(connections.shape[0]):\n",
    "                if connections[block, input_layer] == 1:\n",
    "                    input_connections.append(layers[input_layer])\n",
    "\n",
    "            if len(input_connections) > 1:\n",
    "                shapes = [l._shape_as_list()[1] for l in input_connections]\n",
    "                min_shape = np.min(shapes)\n",
    "                for k in range(len(input_connections)):\n",
    "                    maxpool_size = count_mp(shapes[k], min_shape) + 1\n",
    "                    while maxpool_size > 1:\n",
    "                        input_connections[k] = MaxPooling2D(pool_size=ps, strides=st)(input_connections[k])\n",
    "                        maxpool_size -= 1\n",
    "                x = concatenate(input_connections)\n",
    "            else:\n",
    "                x = input_connections[0]\n",
    "            layers.append(decode_layer(cnn_layers[block + 1], x))\n",
    "\n",
    "        if len(layers) == 0:\n",
    "            x = Flatten()(x)\n",
    "        else:\n",
    "            x = Flatten()(layers[-1])\n",
    "\n",
    "        for i in range(chromosome.n_nn):\n",
    "            act = chromosome.nn_layers[i].activation\n",
    "            if act in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
    "                x = Dense(chromosome.nn_layers[i].units, activation=act)(x)\n",
    "            elif act == 'prelu':\n",
    "                x = Dense(chromosome.nn_layers[i].units)(x)\n",
    "                x = PReLU()(x)\n",
    "            else:\n",
    "                x = Dense(chromosome.nn_layers[i].units)(x)\n",
    "                x = LeakyReLU()(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(chromosome.nn_layers[i].dropout)(x)\n",
    "        x = Dense(self.num_clases, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        if self.verb:\n",
    "            model.summary()\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(lr),\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "data_folder = '/home/daniel/datasets/MNIST_variations'\n",
    "command = 'python ./train_gen.py'\n",
    "verbose = 1\n",
    "experiments_folder = '../super_conv'\n",
    "gpus = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600, 28, 28, 1) train samples\n",
      "(2400, 28, 28, 1) validation samples\n",
      "(50000, 28, 28, 1) test samples\n"
     ]
    }
   ],
   "source": [
    "# dataset params:\n",
    "data_folder = data_folder\n",
    "smooth = 0.1\n",
    "classes = []\n",
    "\n",
    "dataset = 'MRDBI'\n",
    "dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder)\n",
    "(x_train, y_train), (x_test, y_test), (x_val, y_val) = dm.load_data()\n",
    "\n",
    "\n",
    "if smooth > 0:\n",
    "    y_train = smooth_labels(y_train, smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FitnessSkip_v2()\n",
    "f.input_shape = (28, 28, 1)\n",
    "f.num_clases = 10\n",
    "f.verb = 0\n",
    "\n",
    "keras.backend.clear_session()\n",
    "c = get_chromosome_from_file('./models/%s' % dataset)\n",
    "model = f.decode(c, type_conv='sep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 1)    4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 28, 28, 57)   123         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 28, 28, 57)   44688       separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 57)   228         p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 28, 28, 57)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 28, 28, 79)   5437        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 28, 28, 79)   61936       separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 28, 28, 79)   316         p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 28, 28, 79)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 136)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 28, 28, 66)   15706       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 28, 28, 66)   264         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 28, 28, 66)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 123)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 28, 28, 67)   8431        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 28, 67)   268         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 28, 28, 67)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 124)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 28, 28, 71)   14951       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 28, 28, 71)   55664       separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 71)   284         p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 71)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 14, 14, 71)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 14, 14, 72)   8663        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 72)   0           separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 14, 14, 72)   288         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 72)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 72)     0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 7, 7, 73)     8857        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 7, 7, 73)     3577        separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 7, 7, 73)     292         p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 73)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 3, 3, 73)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 657)          0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           6580        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 236,557\n",
      "Trainable params: 235,585\n",
      "Non-trainable params: 972\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with conv2D conv2d\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 1)    4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 57)   570         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 28, 28, 57)   44688       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 57)   228         p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 28, 28, 57)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 79)   67624       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 28, 28, 79)   61936       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 28, 28, 79)   316         p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 28, 28, 79)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 136)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 66)   439890      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 28, 28, 66)   264         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 28, 28, 66)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 123)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 67)   8308        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 28, 67)   268         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 28, 28, 67)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 124)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 71)   431467      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 28, 28, 71)   55664       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 71)   284         p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 13, 13, 71)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 13, 13, 71)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 13, 13, 72)   250560      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 13, 13, 72)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 13, 13, 72)   288         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 72)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 6, 6, 72)     0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 6, 6, 73)     257617      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 6, 6, 73)     2628        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6, 6, 73)     292         p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 73)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 2, 2, 73)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 292)          0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2930        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,625,826\n",
      "Trainable params: 1,624,854\n",
      "Non-trainable params: 972\n",
      "__________________________________________________________________________________________________\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/25\n",
      "9600/9600 [==============================] - 30s 3ms/step - loss: 2.7936 - acc: 0.1790 - val_loss: 1.7685 - val_acc: 0.3983\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 28s 3ms/step - loss: 1.7422 - acc: 0.4499 - val_loss: 1.2339 - val_acc: 0.5771\n",
      "Epoch 3/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 1.3130 - acc: 0.6644 - val_loss: 0.9256 - val_acc: 0.7033\n",
      "Epoch 4/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 1.1154 - acc: 0.7592 - val_loss: 0.7280 - val_acc: 0.7683\n",
      "Epoch 5/25\n",
      "9600/9600 [==============================] - 27s 3ms/step - loss: 1.0161 - acc: 0.8069 - val_loss: 0.5547 - val_acc: 0.8296\n",
      "Epoch 6/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.9415 - acc: 0.8430 - val_loss: 0.5959 - val_acc: 0.8067\n",
      "Epoch 7/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.9109 - acc: 0.8567 - val_loss: 0.8873 - val_acc: 0.7358\n",
      "Epoch 8/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.8624 - acc: 0.8825 - val_loss: 0.6806 - val_acc: 0.7942\n",
      "Epoch 9/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.8134 - acc: 0.9035 - val_loss: 0.5146 - val_acc: 0.8458\n",
      "Epoch 10/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.7909 - acc: 0.9129 - val_loss: 0.6579 - val_acc: 0.8146\n",
      "Epoch 11/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.7606 - acc: 0.9258 - val_loss: 0.7133 - val_acc: 0.8042\n",
      "Epoch 12/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.7326 - acc: 0.9371 - val_loss: 0.5628 - val_acc: 0.8325\n",
      "Epoch 13/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.7182 - acc: 0.9431 - val_loss: 0.8013 - val_acc: 0.7929\n",
      "Epoch 14/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.6743 - acc: 0.9651 - val_loss: 0.5193 - val_acc: 0.8738\n",
      "Epoch 15/25\n",
      "9600/9600 [==============================] - 27s 3ms/step - loss: 0.6405 - acc: 0.9793 - val_loss: 0.4641 - val_acc: 0.8800\n",
      "Epoch 16/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.6117 - acc: 0.9889 - val_loss: 0.4221 - val_acc: 0.8858\n",
      "Epoch 17/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.5913 - acc: 0.9950 - val_loss: 0.4559 - val_acc: 0.8796\n",
      "Epoch 18/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.5799 - acc: 0.9981 - val_loss: 0.4009 - val_acc: 0.8929\n",
      "Epoch 19/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.5725 - acc: 0.9984 - val_loss: 0.4181 - val_acc: 0.8921\n",
      "Epoch 20/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.5626 - acc: 0.9995 - val_loss: 0.4053 - val_acc: 0.8979\n",
      "Epoch 21/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.5578 - acc: 0.9992 - val_loss: 0.4044 - val_acc: 0.8975\n",
      "Epoch 22/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.5541 - acc: 0.9996 - val_loss: 0.4010 - val_acc: 0.9063\n",
      "Epoch 23/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.5509 - acc: 0.9998 - val_loss: 0.4015 - val_acc: 0.9025\n",
      "Epoch 24/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.5486 - acc: 0.9998 - val_loss: 0.4035 - val_acc: 0.9021\n",
      "Epoch 25/25\n",
      "9600/9600 [==============================] - 28s 3ms/step - loss: 0.5463 - acc: 0.9998 - val_loss: 0.3998 - val_acc: 0.9029\n",
      "50000/50000 [==============================] - 44s 871us/step\n",
      "Test loss: 0.404796422290802\n",
      "Test accuracy: 0.8974\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 25\n",
    "w_epochs = epochs // 2\n",
    "total_steps = int(epochs * y_train.shape[0] / batch_size)\n",
    "w_steps = int(w_epochs * y_train.shape[0] / batch_size)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "\n",
    "for conv_type in ['sep', 'depw', 'loc', 'conv2d']:\n",
    "    if conv_type in ['depw', 'loc', 'sep']:\n",
    "        continue\n",
    "    print(\"Training with conv2D %s\" % conv_type)\n",
    "    callbacks = [LinearDecayScheduler(learning_rate_base=0.03,\n",
    "                           total_steps=total_steps,\n",
    "                           warmup_learning_rate=0.00003,\n",
    "                           warmup_steps=w_steps,\n",
    "                           hold_base_rate_steps=0, verbose=0)]\n",
    "    f.spatial_dropout = False\n",
    "    f.maxpool_overlap = True\n",
    "    model = f.decode(c, type_conv=conv_type)\n",
    "    model.summary()\n",
    "    h = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_val, y_val),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks,\n",
    "          verbose=1)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The spatial dimensions of the inputs to  a LocallyConnected2D layer should be fully-defined, but layer received the inputs shape (None, None, None, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-a040abd5a920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocallyConnected2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.7/site-packages/keras/layers/local.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    309\u001b[0m                              \u001b[0;34m' a LocallyConnected2D layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                              \u001b[0;34m'should be fully-defined, but layer received '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                              'the inputs shape ' + str(input_shape))\n\u001b[0m\u001b[1;32m    312\u001b[0m         output_row = conv_utils.conv_output_length(input_row, self.kernel_size[0],\n\u001b[1;32m    313\u001b[0m                                                    self.padding, self.strides[0])\n",
      "\u001b[0;31mValueError\u001b[0m: The spatial dimensions of the inputs to  a LocallyConnected2D layer should be fully-defined, but layer received the inputs shape (None, None, None, 3)"
     ]
    }
   ],
   "source": [
    "i = Input(shape=(224, None,3))\n",
    "x = LocallyConnected2D(64, kernel_size=3, activation='relu', padding='valid')(i)\n",
    "x = MaxPooling2D(3,2)(x)\n",
    "model = Model(i, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeparableConv2D?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
