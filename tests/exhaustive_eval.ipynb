{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.codification_cnn import FitnessCNNParallel\n",
    "from utils.codification_grew import FitnessGrow, Merger, ChromosomeGrow, Concatenation, Sum, IdentityGrow, AvPooling\n",
    "from utils.codification_grew import Inputs, MaxPooling, AvPooling, OperationBlock, CNNGrow, IdentityGrow, HyperParams\n",
    "\n",
    "from utils.datamanager import DataManager\n",
    "from GA.geneticAlgorithm import TwoLevelGA\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../../../../datasets/MNIST_variations' # '../../datasets/MNIST_variations'\n",
    "command = 'python3 ../train_gen.py'\n",
    "verbose = 0\n",
    "\n",
    "gpus = 1 # 4\n",
    "batch = 4 # 50\n",
    "\n",
    "# Fitness params\n",
    "epochs = 18\n",
    "batch_size = 128\n",
    "verbose = verbose\n",
    "redu_plat = True # False\n",
    "early_stop = 0\n",
    "warm_up_epochs = 0\n",
    "base_lr = 0.05\n",
    "smooth = 0.1\n",
    "cosine_dec = False\n",
    "lr_find = False\n",
    "precise_eps = 4 # 54\n",
    "\n",
    "include_time = True\n",
    "test_eps = 90\n",
    "augment = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'MRDBI'\n",
    "experiments_folder = '../../../../evolved_data/test_validation3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ../../../../evolved_data/test_validation3/0/MRDBI/genetic/0_2020-04-18-17:13/GA_experiment\n",
      "\n",
      "\n",
      "Starting exhaustive evaluation.\n",
      "\n",
      "\n",
      "Evaluating 5 model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1aa440570ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_to_eval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             scores = fitness.eval_list(chromosome_list=models_to_eval, test=False, precise_mode=True,\n\u001b[0;32m--> 144\u001b[0;31m                                file_model_list=file_models)\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_to_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mindiv_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_to_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proyectos/Tesis/workspace/branches/server/NeuroEvolution/utils/codification_cnn.py\u001b[0m in \u001b[0;36meval_list\u001b[0;34m(self, chromosome_list, test, precise_mode, file_model_list, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads_waiting\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads_running\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0mthreads_finished\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mthr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads_running\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misAlive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0mthreads_running\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mthr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads_running\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misAlive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proyectos/Tesis/workspace/branches/server/NeuroEvolution/utils/codification_cnn.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads_waiting\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads_running\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0mthreads_finished\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mthr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads_running\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misAlive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0mthreads_running\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mthr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads_running\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misAlive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Softwares/Anaconda/anaconda3/envs/genetic/lib/python3.7/threading.py\u001b[0m in \u001b[0;36misAlive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         warnings.warn('isAlive() is deprecated, use is_alive() instead',\n\u001b[0;32m-> 1113\u001b[0;31m                       PendingDeprecationWarning, stacklevel=2)\n\u001b[0m\u001b[1;32m   1114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Chromosome parameters\n",
    "Merger._projection_type = ['normal', 'extend'][1]\n",
    "\n",
    "HyperParams._GROW_RATE_LIMITS = [2, 4.5]\n",
    "HyperParams._N_CELLS = [1, 2]\n",
    "HyperParams._N_BLOCKS = [2]\n",
    "HyperParams._STEM = [32, 45]\n",
    "HyperParams._MAX_WU = 0.5\n",
    "HyperParams._LR_LIMITS = [-9, -2] # [-9, -3]\n",
    "\n",
    "CNNGrow.filters_mul_range = [0.2, 1.2]\n",
    "CNNGrow.possible_activations = ['relu', 'elu']\n",
    "CNNGrow.dropout_range = [0.0, 0.7]\n",
    "CNNGrow.possible_k = [1, 3, 5]\n",
    "\n",
    "\n",
    "def get_params(gen_list):\n",
    "    params = {}\n",
    "    for gen in gen_list:\n",
    "        if ':' in gen:\n",
    "            name, val = gen.split(':')\n",
    "            if not val.isalpha():\n",
    "                val = float(val) if '.' in val else int(val)\n",
    "            else:\n",
    "                pass\n",
    "            val = np.log(val) / np.log(2) if name == 'LR' else val\n",
    "            params[name] = val\n",
    "    return params\n",
    "    \n",
    "def get_hp_from_line(_line):\n",
    "    params = _line.split('|')    \n",
    "    p_dict = get_params(params)\n",
    "    hp = HyperParams(grow_rate=p_dict['GR'], n_cells=p_dict['CELL'], n_blocks=p_dict['BLOCK'], \n",
    "                     stem=p_dict['STEM'], lr=p_dict['LR'], warmup=p_dict['WU'])\n",
    "    return hp\n",
    "\n",
    "def get_operation_from_line(line):\n",
    "    '||CNN|F:1.2|K:1|A:relu|D:0.05||woCAT||1||'\n",
    "    op, merge, inputs = line.split('||')[1:-1]\n",
    "    \n",
    "    # encoding inputs\n",
    "    inputs = np.array([int(c) for c in inputs])\n",
    "    inputs = Inputs(inputs_array=inputs)\n",
    "    \n",
    "    # encoding merging\n",
    "    merge = Concatenation() if 'CAT' in merge else Sum()\n",
    "    \n",
    "    # encoding operation\n",
    "    op_type = op.split('|')[0]\n",
    "    op_params = op.split('|')[1::]     \n",
    "        \n",
    "    if 'AP' == op_type:\n",
    "        val = op_params[0]\n",
    "        op = AvPooling(size=int(val))\n",
    "    elif 'MP' == op_type:\n",
    "        val = op_params[0]\n",
    "        op = MaxPooling(size=int(val))\n",
    "    elif 'CNN' == op_type:\n",
    "        p_dict = get_params(op_params)\n",
    "        op = CNNGrow(filter_mul=p_dict['F'], kernel_size=p_dict['K'], activation=p_dict['A'], dropout=p_dict['D'])\n",
    "    else:\n",
    "        op = IdentityGrow()\n",
    "                    \n",
    "    ops = [operation.random() if operation._type != op_type else op for operation in OperationBlock._operations]\n",
    "    \n",
    "    final_op = OperationBlock(operation_type=op_type, ops=ops, concatenation=merge, inputs=inputs)\n",
    "    return final_op\n",
    "\n",
    "def str_to_chromosome(string):\n",
    "    lines = string.split('\\n')\n",
    "    nodes = []\n",
    "    hp = None\n",
    "    for line in lines:\n",
    "        if line.replace(' ', '') == '':\n",
    "            continue\n",
    "        if 'HP' in line:\n",
    "            hp = line\n",
    "            break\n",
    "        else:\n",
    "            nodes.append(line)\n",
    "    hp = get_hp_from_line(hp)\n",
    "    ops = [get_operation_from_line(line) for line in nodes]\n",
    "    return ChromosomeGrow(blocks=ops, n_blocks=len(ops), hparams=hp)\n",
    "    \n",
    "\n",
    "exps = os.listdir(experiments_folder)\n",
    "for exp in exps:\n",
    "    exp_folder = os.path.join(experiments_folder, exp, dataset)\n",
    "    folder = os.path.join(exp_folder, 'genetic')\n",
    "    fitness_folder = exp_folder\n",
    "    fitness_file = os.path.join(fitness_folder, 'fitness_example') \n",
    "    \n",
    "    if not os.path.isfile(fitness_file):\n",
    "        dm = DataManager(dataset, clases=[], folder_var_mnist=data_folder, num_clases=10)  #,  max_examples=15000)\n",
    "        data = dm.load_data()\n",
    "        fitness_cnn = FitnessGrow() \n",
    "        fitness_cnn.set_params(data=data, verbose=verbose, batch_size=batch_size, reduce_plateau=redu_plat,\n",
    "                       epochs=epochs, cosine_decay=cosine_dec, early_stop=early_stop, \n",
    "                       warm_epochs=warm_up_epochs, base_lr=base_lr, smooth_label=smooth, find_lr=lr_find,\n",
    "                       precise_epochs=precise_eps, include_time=include_time, test_eps=test_eps,  augment=augment)\n",
    "\n",
    "        fitness_cnn.save(fitness_file)\n",
    "    \n",
    "    models_folder = os.path.join(fitness_folder, 'all_models')\n",
    "    os.makedirs(models_folder, exist_ok=True)\n",
    "    fitness = FitnessCNNParallel()\n",
    "    fitness.set_params(chrom_files_folder=fitness_folder, fitness_file=fitness_file, max_gpus=gpus,\n",
    "                           fp=32, main_line=command)\n",
    "    \n",
    "    try:\n",
    "        generational = TwoLevelGA.load_genetic_algorithm(folder=folder) \n",
    "    except:\n",
    "        print(\"Genetic Model not found!\")\n",
    "        continue\n",
    "    original_filename = generational.filename\n",
    "    filename = original_filename.split('genetic')[-1]\n",
    "    generational.filename = folder + filename\n",
    "    if not hasattr(generational, 'exhaustive_eval'):\n",
    "        generational.exhaustive_eval = {}\n",
    "    \n",
    "    for k, individual in enumerate(generational.history_fitness.keys()):\n",
    "        if not individual in generational.exhaustive_eval.keys():\n",
    "            chromosome = str_to_chromosome(individual)\n",
    "            file_model = os.path.join(models_folder, \"%d.hdf5\" % k)\n",
    "            tmp_dict = {'n':k, 'chromosome':chromosome, 'test':None, 'val':None, 'file_model':file_model}\n",
    "            generational.exhaustive_eval[individual] = tmp_dict\n",
    "            \n",
    "    generational.print_genetic(\"\\n\\nStarting exhaustive evaluation.\\n\\n\")\n",
    "    generational.print_genetic(\"Evaluating %d model\" % len(generational.exhaustive_eval[individual].keys()))\n",
    "    generational.maybe_save_genetic_algorithm()\n",
    "    \n",
    "    ti = time()\n",
    "    models_to_eval = []\n",
    "    file_models = []\n",
    "    ids = []\n",
    "    for individual, tmp_dict in generational.exhaustive_eval.items():\n",
    "        if tmp_dict['val'] is not None and os.path.isfile(tmp_dict['file_model']):\n",
    "            continue\n",
    "        models_to_eval.append(tmp_dict['chromosome'])        \n",
    "        file_models.append(None) #file_models.append(tmp_dict['file_model'])\n",
    "        ids.append(tmp_dict['n'])        \n",
    "        if len(models_to_eval) == batch:\n",
    "            scores = fitness.eval_list(chromosome_list=models_to_eval, test=False, precise_mode=True,\n",
    "                               file_model_list=file_models)\n",
    "            for i in range(len(models_to_eval)):\n",
    "                indiv_i = models_to_eval[i].__repr__()\n",
    "                score_i = scores[i]\n",
    "                generational.exhaustive_eval[indiv_i]['val'] = score_i\n",
    "            generational.print_genetic(\"Elapsed time: %0.2f\" % ((time() - ti) / 60))\n",
    "            generational.maybe_save_genetic_algorithm()\n",
    "            models_to_eval = []\n",
    "            file_models = []\n",
    "            ids = []\n",
    "        \n",
    "    scores = fitness.eval_list(chromosome_list=models_to_eval, test=False, precise_mode=True,\n",
    "                               file_model_list=file_models)\n",
    "    for i in range(len(models_to_eval)):\n",
    "        indiv_i = models_to_eval[i].__repr__()\n",
    "        score_i = scores[i]\n",
    "        generational.exhaustive_eval[indiv_i]['val'] = score_i\n",
    "        \n",
    "    generational.print_genetic(\"Elapsed time: %0.2f\" % ((time() - ti) / 60))\n",
    "    generational.maybe_save_genetic_algorithm()\n",
    "        \n",
    "    # Evaluate test\n",
    "    \n",
    "    fitness = FitnessGrow.load(fitness_file)\n",
    "    for indiv in generational.exhaustive_eval.keys():\n",
    "        tmp_dict = generational.exhaustive_eval[indiv]\n",
    "        file_model = tmp_dict['file_model']\n",
    "        model = load_model(file_model)\n",
    "        score = 1 - model.evaluate(fitness.x_test, fitness.y_test, verbose=0)[1]\n",
    "        generational.exhaustive_eval[indiv]['test'] = score\n",
    "       \n",
    "    generational.print_genetic(\"Finish in time: %0.2f\" % ((time() - ti) / 60))\n",
    "    generational.filename = original_filename\n",
    "    generational.maybe_save_genetic_algorithm()\n",
    "        \n",
    "                \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
