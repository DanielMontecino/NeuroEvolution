{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.codification_cnn import FitnessCNN, FitnessCNNParallel\n",
    "from utils.datamanager import DataManager\n",
    "from utils.codification_grew import ChromosomeOp, OperationBlock, CNN, Inputs, HyperParams, Merger, MaxPooling, AvPooling\n",
    "from GA.geneticAlgorithm import TwoLevelGA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata_folder = '/home/daniel/datasets/MNIST_variations'\\ncommand = 'python ./../train_gen.py'\\nverbose = 1\\nexperiments_folder = '../exps_testing'\\ngpus = 1\\nskip = 1\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chromosome parameters\n",
    "ChromosomeOp._max_initial_blocks = 5\n",
    "ChromosomeOp._grow_prob = 0.15\n",
    "ChromosomeOp._decrease_prob = 0.25\n",
    "\n",
    "Merger._projection_type = ['normal', 'extend'][1]\n",
    "MaxPooling._admited_sizes = [2, 3, 5]\n",
    "AvPooling._admited_sizes = [2, 3, 5]\n",
    "\n",
    "HyperParams._GROW_RATE_LIMITS = [1.5, 3.]\n",
    "HyperParams._N_CELLS = [1, 2, 3]\n",
    "HyperParams._N_BLOCKS = [1, 2, 3]\n",
    "HyperParams. _STEM = [16, 32, 64]\n",
    "\n",
    "OperationBlock._change_op_prob = 0.15\n",
    "OperationBlock._change_concat_prob = 0.15\n",
    "\n",
    "CNN.filters_mul_range = [0.5, 1.2]\n",
    "CNN.possible_activations = ['relu', 'elu', 'prelu']\n",
    "CNN.dropout_range = [0, 0.7]\n",
    "CNN.possible_k = [1, 3, 5]\n",
    "CNN.k_prob = 0.2\n",
    "CNN.drop_prob = 0.2\n",
    "CNN.filter_prob = 0.2\n",
    "CNN.act_prob = 0.2\n",
    "\n",
    "Inputs._mutate_prob = 0.5\n",
    "\n",
    "    \n",
    "data_folder = '../../datasets/MNIST_variations'\n",
    "command = 'python3 ../train_gen.py'\n",
    "verbose = 0\n",
    "experiments_folder = '../../exp_op_coding2'\n",
    "\n",
    "gpus = 2\n",
    "\n",
    "'''\n",
    "data_folder = '/home/daniel/datasets/MNIST_variations'\n",
    "command = 'python ./../train_gen.py'\n",
    "verbose = 1\n",
    "experiments_folder = '../exps_testing'\n",
    "gpus = 1\n",
    "skip = 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_cnn = FitnessCNN()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||CNN|F:0.9|K:1|A:prelu|D:0.40||woCAT||1||\n",
      "||CNN|F:1.2|K:1|A:prelu|D:0.40||woCAT||10||\n",
      "||CNN|F:0.9|K:1|A:relu|D:0.25||SUM||011||\n",
      "HP->|GR:2.82|CELL:1|BLOCK:2|STEM:64|LR:-7.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = ChromosomeOp.random_individual()\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset params:\n",
    "data_folder = data_folder\n",
    "classes = []\n",
    "\n",
    "# genetic algorithm params:\n",
    "generations = -1\n",
    "population_first_level = 20\n",
    "population_second_level = 8\n",
    "training_hours = 24\n",
    "save_progress = True\n",
    "maximize_fitness = False\n",
    "statistical_validation = False\n",
    "frequency_second_level = 3\n",
    "start_level2 = 1\n",
    "\n",
    "\n",
    "# Fitness params\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "verbose = verbose\n",
    "redu_plat = False\n",
    "early_stop = 0\n",
    "warm_up_epochs = 0\n",
    "base_lr = 0.05\n",
    "smooth = 0.1\n",
    "cosine_dec = False\n",
    "lr_find = False\n",
    "precise_eps = 75\n",
    "include_time = True\n",
    "test_eps=200\n",
    "\n",
    "datasets = ['MB', 'MBI', 'MRB', 'MRD', 'MRDBI']\n",
    "datasets = ['cifar10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVOLVING IN DATASET cifar10 ...\n",
      "\n",
      "Loading file ../../exp_cifar10_grow_timefit/cifar10/genetic/0_2020-01-14-20:13/GA_experiment\n",
      "(40000, 32, 32, 3) train samples\n",
      "(10000, 32, 32, 3) validation samples\n",
      "(10000, 32, 32, 3) test samples\n",
      "12\n",
      "10000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-01e666a28432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerational\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerational\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_generations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgenerational\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mgenerational\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_generations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mgenerational\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_hours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Error' is not defined"
     ]
    }
   ],
   "source": [
    "#experiments_folder = '../../exp_cifar10_time'\n",
    "experiments_folder = '../../exp_cifar10_grow_timefit'\n",
    "\n",
    "description = \"Filter grow exponentially respect to grow_rate.\\nCells, blocks and Stem added.\\nTime in fitness calculation\"\n",
    "description += \"\\nWo maxpooling and av pooling.\\nPrecision filter grow of cnn's reduced to 0.1\"\n",
    "experiments_folder = experiments_folder\n",
    "os.makedirs(experiments_folder, exist_ok=True)\n",
    "for dataset in datasets:\n",
    "    print(\"\\nEVOLVING IN DATASET %s ...\\n\" % dataset)\n",
    "    exp_folder = os.path.join(experiments_folder, dataset)\n",
    "    folder = os.path.join(exp_folder, 'genetic')\n",
    "    fitness_folder = exp_folder\n",
    "    fitness_file = os.path.join(fitness_folder, 'fitness_example')   \n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        generational = TwoLevelGA.load_genetic_algorithm(folder=folder)\n",
    "        # Load data\n",
    "        num_clases = 100 if dataset == 'cifar100' else 10\n",
    "        dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder, num_clases=num_clases) #, max_examples=8000)\n",
    "        data = dm.load_data()\n",
    "        fitness_cnn.set_params(data=data, verbose=verbose, batch_size=batch_size, reduce_plateau=redu_plat,\n",
    "                       epochs=epochs, cosine_decay=cosine_dec, early_stop=early_stop, \n",
    "                       warm_epochs=warm_up_epochs, base_lr=base_lr, smooth_label=smooth, find_lr=lr_find,\n",
    "                       precise_epochs=precise_eps, include_time=include_time, test_eps=test_eps)\n",
    "\n",
    "        fitness_cnn.save(fitness_file)\n",
    "    except:\n",
    "        # Load data\n",
    "        num_clases = 100 if dataset == 'cifar100' else 10\n",
    "        dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder, num_clases=num_clases) #, max_examples=8000)\n",
    "        data = dm.load_data()\n",
    "        fitness_cnn.set_params(data=data, verbose=verbose, batch_size=batch_size, reduce_plateau=redu_plat,\n",
    "                       epochs=epochs, cosine_decay=cosine_dec, early_stop=early_stop, \n",
    "                       warm_epochs=warm_up_epochs, base_lr=base_lr, smooth_label=smooth, find_lr=lr_find,\n",
    "                       precise_epochs=precise_eps, include_time=include_time, test_eps=test_eps)\n",
    "\n",
    "        fitness_cnn.save(fitness_file)\n",
    "\n",
    "        del dm, data\n",
    "\n",
    "        fitness = FitnessCNNParallel()\n",
    "        fitness.set_params(chrom_files_folder=fitness_folder, fitness_file=fitness_file, max_gpus=gpus,\n",
    "                       fp=32, main_line=command)\n",
    "        generational = TwoLevelGA(chromosome=c,\n",
    "                                  fitness=fitness,\n",
    "                                  generations=generations,\n",
    "                                  population_first_level=population_first_level,\n",
    "                                  population_second_level=population_second_level,\n",
    "                                  training_hours=training_hours,\n",
    "                                  save_progress=save_progress,\n",
    "                                  maximize_fitness=maximize_fitness,\n",
    "                                  statistical_validation=statistical_validation,\n",
    "                                  folder=folder,\n",
    "                                  start_level2=start_level2,\n",
    "                                  frequency_second_level=frequency_second_level)\n",
    "        generational.print_genetic(description)\n",
    "\n",
    "        \n",
    "    ti_all = time()\n",
    "    print(generational.generation)\n",
    "    print(generational.num_generations)\n",
    "    raise Error\n",
    "    if generational.generation < generational.num_generations:\n",
    "        generational.training_hours = 12\n",
    "        winner, best_fit, ranking = generational.evolve()\n",
    "    print(\"Total elapsed time: %0.3f\" % (time() - ti_all))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "experiments_folder = '../../exp_cifar10_time'\n",
    "dataset = datasets[0]\n",
    "exp_folder = os.path.join(experiments_folder, dataset)\n",
    "folder = os.path.join(exp_folder, 'genetic')\n",
    "\n",
    "\n",
    "generational = TwoLevelGA.load_genetic_algorithm(folder=folder)\n",
    "generational.finishing_evolution(show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||CNN|F:0.6|K:1|A:relu|D:0.10||woCAT||1||\n",
      "||CNN|F:0.9|K:1|A:relu|D:0.05||woCAT||01||\n",
      "||CNN|F:0.8|K:5|A:relu|D:0.35||SUM||011||\n",
      "||CNN|F:0.8|K:5|A:relu|D:0.10||SUM||1001||\n",
      "HP->|GR:2.57|CELL:2|BLOCK:3|STEM:64|LR:0.1\n",
      "\n",
      "0.938193\n",
      "0.9551 0.0449\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "winner = generational.best_individual['winner']\n",
    "fit = generational.best_individual['best_fit']\n",
    "test = generational.best_individual[\"test\"]\n",
    "print(winner)\n",
    "print(1 - fit)\n",
    "print(1 - test, test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3) train samples\n",
      "(10000, 32, 32, 3) validation samples\n",
      "(10000, 32, 32, 3) test samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.codification_cnn.FitnessCNN at 0x7fd7880e04e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "num_clases = 100 if dataset == 'cifar100' else 10\n",
    "dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder, num_clases=num_clases) #, max_examples=8000)\n",
    "data = dm.load_data()\n",
    "fitness_cnn.set_params(data=data, verbose=verbose, batch_size=batch_size, reduce_plateau=redu_plat,\n",
    "               epochs=epochs, cosine_decay=cosine_dec, early_stop=early_stop, \n",
    "               warm_epochs=warm_up_epochs, base_lr=base_lr, smooth_label=smooth, find_lr=lr_find,\n",
    "               precise_epochs=precise_eps, include_time=include_time, test_eps=test_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||CNN|F:0.7|K:3|A:prelu|D:0.10||woCAT||1||\n",
      "||CNN|F:0.9|K:5|A:prelu|D:0.10||woCAT||01||\n",
      "||CNN|F:0.8|K:5|A:relu|D:0.50||woCAT||010||\n",
      "||CNN|F:0.6|K:5|A:relu|D:0.10||CAT||0011||\n",
      "HP->|GR:2.26|CELL:1|BLOCK:1|STEM:32\n",
      "\n",
      "0.9471\n",
      "0.9471\n",
      "Candidate to best:\n",
      "\n",
      "||CNN|F:0.7|K:3|A:prelu|D:0.15||woCAT||1||\n",
      "||CNN|F:0.9|K:5|A:relu|D:0.05||woCAT||01||\n",
      "||CNN|F:0.8|K:3|A:relu|D:0.70||SUM||011||\n",
      "||CNN|F:0.5|K:5|A:elu|D:0.10||SUM||1011||\n",
      "HP->|GR:2.65|CELL:2|BLOCK:2|STEM:64\n",
      "\n",
      "0.089187\n",
      "0.065458\n",
      "\n",
      "The best:\n",
      "\n",
      "||CNN|F:0.7|K:3|A:prelu|D:0.10||woCAT||1||\n",
      "||CNN|F:0.9|K:5|A:prelu|D:0.10||woCAT||01||\n",
      "||CNN|F:0.8|K:5|A:relu|D:0.50||woCAT||010||\n",
      "||CNN|F:0.6|K:5|A:relu|D:0.10||CAT||0011||\n",
      "HP->|GR:2.26|CELL:1|BLOCK:1|STEM:32\n",
      "\n",
      "0.0529\n",
      "0.138766\n",
      "gen 1\n",
      "\n",
      "||CNN|F:0.7|K:3|A:prelu|D:0.15||woCAT||1||\n",
      "||CNN|F:0.9|K:5|A:relu|D:0.05||woCAT||01||\n",
      "||CNN|F:0.8|K:3|A:relu|D:0.70||SUM||011||\n",
      "||CNN|F:0.5|K:5|A:elu|D:0.10||SUM||1011||\n",
      "HP->|GR:2.65|CELL:2|BLOCK:2|STEM:64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "winner = generational.best_individual['winner']\n",
    "fit = generational.best_individual['best_fit']\n",
    "test = generational.best_individual[\"test\"]\n",
    "print(winner)\n",
    "print(1 - fit)\n",
    "print(1 - test)\n",
    "\n",
    "gen1 = \"||CNN|F:0.98|K:1|A:relu|D:0.50||woCAT||1||\\n\\\n",
    "||CNN|F:0.83|K:3|A:relu|D:0.20||SUM||11||\\n\\\n",
    "||CNN|F:0.91|K:5|A:relu|D:0.20||woCAT||001||\\n\\\n",
    "||CNN|F:0.80|K:3|A:relu|D:0.15||CAT||0101||\\n\\\n",
    "||CNN|F:0.76|K:3|A:elu|D:0.15||CAT||00011||\\n\"\n",
    "\n",
    "gen1 = \"||CNN|F:0.7|K:3|A:prelu|D:0.15||woCAT||1||\\n\\\n",
    "||CNN|F:0.9|K:5|A:relu|D:0.05||woCAT||01||\\n\\\n",
    "||CNN|F:0.8|K:3|A:relu|D:0.70||SUM||011||\\n\\\n",
    "||CNN|F:0.5|K:5|A:elu|D:0.10||SUM||1011||\\n\\\n",
    "HP->|GR:2.65|CELL:2|BLOCK:2|STEM:64\\n\"\n",
    "\n",
    "if str(winner) != gen1:\n",
    "\n",
    "    print(\"Candidate to best:\\n\")\n",
    "    print(gen1)\n",
    "    print(generational.history_fitness[gen1])\n",
    "    print(generational.history_precision_fitness[gen1])\n",
    "\n",
    "    print(\"\\nThe best:\\n\")\n",
    "    gen = str(winner)\n",
    "    print(gen)\n",
    "    print(generational.history_fitness[gen])\n",
    "    print(generational.history_precision_fitness[gen])\n",
    "\n",
    "    for p in generational.population_2:\n",
    "        if str(p) == gen1:\n",
    "            print(\"gen 1\\n\")\n",
    "            print(p)\n",
    "            break\n",
    "        elif str(p) == gen:\n",
    "            print(\"gen\\n\")\n",
    "            print(gen)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.138766\n",
      "0.138766\n",
      "WTF\n",
      "\n",
      "0.070199\n",
      "\n",
      "0.072123\n",
      "0.9\n",
      "\n",
      "0.074289\n",
      "0.070199\n",
      "\n",
      "0.077583\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p in generational.population_2\n",
    "for q in generational.population_1:\n",
    "    try:\n",
    "        print(generational.history_fitness[q.__repr__()])\n",
    "        print(generational.history_precision_fitness[q.__repr__()])\n",
    "        if p==q:\n",
    "            print(\"This\")\n",
    "        elif q==winner:\n",
    "            print(\"WTF\")\n",
    "    except:\n",
    "        pass\n",
    "    print()\n",
    "    \n",
    "generational.history_fitness[winner.__repr__()] = 0.138766\n",
    "\n",
    "generational.history_fitness[p.__repr__()] = 0.08919\n",
    "generational.history_precision_fitness[p.__repr__()] = 0.06546\n",
    "\n",
    "generational.best_individual['winner'] = p\n",
    "generational.best_individual['best_fit'] = 0.06546\n",
    "generational.best_individual['test'] = 0.0529\n",
    "\n",
    "generational.maybe_save_genetic_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||CNN|F:0.7|K:3|A:prelu|D:0.15||woCAT||1||\n",
      "||CNN|F:0.9|K:5|A:relu|D:0.05||woCAT||01||\n",
      "||CNN|F:0.8|K:3|A:relu|D:0.70||SUM||011||\n",
      "||CNN|F:0.5|K:5|A:elu|D:0.10||SUM||1011||\n",
      "HP->|GR:2.65|CELL:2|BLOCK:2|STEM:64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate: 0.05\n",
      "Training... No Early stopping\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 8)    520         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 8)    32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 72)   0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 45)   3285        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 45)   180         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 45)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 36)   1656        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 36)   144         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 81)   0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 72)   5904        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 72)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 72)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 46)   2116        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 19)   1387        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 46)   184         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 19)   76          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 91)   0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 91)   0           dropout_2[0][0]                  \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 91)   0           concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 75)   170700      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 75)   300         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 75)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 39)   2535        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 28)   2128        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 39)   156         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 28)   112         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 103)  0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 103)  0           dropout_3[0][0]                  \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 103)  0           concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 81)   208656      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 81)   324         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 81)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 34)   2788        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 34)   136         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 115)  0           dropout_4[0][0]                  \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 72)   8352        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 72)   288         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 72)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 58)   4234        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 58)   232         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 130)  0           dropout_5[0][0]                  \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 117)  15327       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 117)  468         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 117)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 74)   5402        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 29)   3422        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 74)   296         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 29)   116         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 146)  0           dropout_5[0][0]                  \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 146)  0           dropout_6[0][0]                  \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 146)  0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 121)  441771      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 121)  484         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 121)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 83)   6806        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 43)   5246        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 83)   332         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 43)   172         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 164)  0           dropout_4[0][0]                  \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 164)  0           dropout_7[0][0]                  \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 164)  0           concatenate_11[0][0]             \n",
      "                                                                 concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 130)  533130      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 130)  520         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 130)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 130)  0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 55)   7205        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 55)   220         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 185)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 116)  21576       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 116)  464         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 116)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 92)   10764       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 92)   368         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 208)  0           dropout_9[0][0]                  \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 187)  39083       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 187)  748         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 16, 187)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 118)  13806       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 47)   8836        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 118)  472         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 47)   188         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 234)  0           dropout_9[0][0]                  \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 234)  0           dropout_10[0][0]                 \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 234)  0           concatenate_15[0][0]             \n",
      "                                                                 concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 194)  1135094     add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 194)  776         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, 16, 194)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 133)  17423       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 69)   13455       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 133)  532         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 69)   276         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 263)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 263)  0           dropout_11[0][0]                 \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 263)  0           concatenate_17[0][0]             \n",
      "                                                                 concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 209)  1374384     add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 209)  836         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 16, 209)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 87)   18270       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 87)   348         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 296)  0           dropout_12[0][0]                 \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 187)  55539       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 187)  748         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 187)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 146)  27448       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 146)  584         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 333)  0           dropout_13[0][0]                 \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 299)  99866       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 299)  1196        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 299)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 187)  35156       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 75)   22500       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 187)  748         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 75)   300         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 374)  0           dropout_13[0][0]                 \n",
      "                                                                 batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 374)  0           dropout_14[0][0]                 \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 374)  0           concatenate_21[0][0]             \n",
      "                                                                 concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 310)  2898810     add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 310)  1240        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 310)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 212)  44520       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 111)  34521       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 212)  848         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 111)  444         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 421)  0           dropout_12[0][0]                 \n",
      "                                                                 batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 421)  0           dropout_15[0][0]                 \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 421)  0           concatenate_23[0][0]             \n",
      "                                                                 concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 334)  3515684     add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 334)  1336        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 334)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 334)    0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 140)    46900       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 140)    560         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 474)    0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 299)    142025      concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 299)    1196        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 8, 8, 299)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 234)    70200       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 234)    936         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 533)    0           dropout_17[0][0]                 \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 479)    255786      concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 479)    1916        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 8, 8, 479)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 301)    90300       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 121)    58080       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 301)    1204        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 121)    484         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 600)    0           dropout_17[0][0]                 \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 600)    0           dropout_18[0][0]                 \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 600)    0           concatenate_27[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 497)    7455497     add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 497)    1988        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 8, 8, 497)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 341)    114235      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 8, 178)    88644       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 341)    1364        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 178)    712         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 675)    0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 675)    0           dropout_19[0][0]                 \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 675)    0           concatenate_29[0][0]             \n",
      "                                                                 concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 536)    9045536     add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 536)    2144        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 8, 8, 536)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 223)    119751      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 223)    892         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 759)    0           dropout_20[0][0]                 \n",
      "                                                                 batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 479)    364040      concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 479)    1916        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 8, 8, 479)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 375)    180000      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 375)    1500        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 854)    0           dropout_21[0][0]                 \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 768)    656640      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 768)    3072        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 8, 8, 768)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 482)    231360      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 193)    148417      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 482)    1928        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 193)    772         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 961)    0           dropout_21[0][0]                 \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 961)    0           dropout_22[0][0]                 \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 961)    0           concatenate_33[0][0]             \n",
      "                                                                 concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 797)    19148722    add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 797)    3188        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 8, 8, 797)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 545)    292665      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 284)    226632      dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 545)    2180        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 284)    1136        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 1081)   0           dropout_20[0][0]                 \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 8, 8, 1081)   0           dropout_23[0][0]                 \n",
      "                                                                 batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 1081)   0           concatenate_35[0][0]             \n",
      "                                                                 concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 859)    23215334    add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 859)    3436        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 8, 8, 859)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 859)          0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           8600        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 72,830,753\n",
      "Trainable params: 72,805,607\n",
      "Non-trainable params: 25,146\n",
      "__________________________________________________________________________________________________\n",
      "Without Cutout augmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "390/390 [==============================] - 233s 598ms/step - loss: 1.8383 - accuracy: 0.3795 - val_loss: 4.4611 - val_accuracy: 0.1502\n",
      "Epoch 2/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 1.5025 - accuracy: 0.5407 - val_loss: 1.2278 - val_accuracy: 0.5718\n",
      "Epoch 3/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 1.2991 - accuracy: 0.6443 - val_loss: 1.0202 - val_accuracy: 0.6560\n",
      "Epoch 4/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 1.1503 - accuracy: 0.7153 - val_loss: 0.8356 - val_accuracy: 0.7329\n",
      "Epoch 5/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 1.0538 - accuracy: 0.7612 - val_loss: 0.9940 - val_accuracy: 0.6839\n",
      "Epoch 6/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.9845 - accuracy: 0.7909 - val_loss: 0.7704 - val_accuracy: 0.7569\n",
      "Epoch 7/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.9341 - accuracy: 0.8139 - val_loss: 0.6883 - val_accuracy: 0.7974\n",
      "Epoch 8/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.9002 - accuracy: 0.8301 - val_loss: 0.8536 - val_accuracy: 0.7346\n",
      "Epoch 9/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.8656 - accuracy: 0.8447 - val_loss: 0.6766 - val_accuracy: 0.7849\n",
      "Epoch 10/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.8365 - accuracy: 0.8574 - val_loss: 0.6137 - val_accuracy: 0.8103\n",
      "Epoch 11/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.8185 - accuracy: 0.8642 - val_loss: 0.6212 - val_accuracy: 0.8113\n",
      "Epoch 12/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.8013 - accuracy: 0.8724 - val_loss: 0.7533 - val_accuracy: 0.7734\n",
      "Epoch 13/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.7772 - accuracy: 0.8826 - val_loss: 0.5979 - val_accuracy: 0.8113\n",
      "Epoch 14/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.7692 - accuracy: 0.8868 - val_loss: 0.5964 - val_accuracy: 0.8189\n",
      "Epoch 15/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.7545 - accuracy: 0.8935 - val_loss: 0.6785 - val_accuracy: 0.8048\n",
      "Epoch 16/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.7449 - accuracy: 0.8984 - val_loss: 0.4825 - val_accuracy: 0.8571\n",
      "Epoch 17/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.7298 - accuracy: 0.9063 - val_loss: 0.5097 - val_accuracy: 0.8625\n",
      "Epoch 18/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.7237 - accuracy: 0.9073 - val_loss: 0.6388 - val_accuracy: 0.8149\n",
      "Epoch 19/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.7152 - accuracy: 0.9100 - val_loss: 0.4528 - val_accuracy: 0.8637\n",
      "Epoch 20/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.7100 - accuracy: 0.9135 - val_loss: 0.6837 - val_accuracy: 0.7840\n",
      "Epoch 21/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6977 - accuracy: 0.9190 - val_loss: 0.4324 - val_accuracy: 0.8751\n",
      "Epoch 22/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6905 - accuracy: 0.9235 - val_loss: 0.4548 - val_accuracy: 0.8721\n",
      "Epoch 23/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6906 - accuracy: 0.9228 - val_loss: 0.5778 - val_accuracy: 0.8306\n",
      "Epoch 24/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6795 - accuracy: 0.9287 - val_loss: 0.4525 - val_accuracy: 0.8768\n",
      "Epoch 25/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6780 - accuracy: 0.9275 - val_loss: 0.4449 - val_accuracy: 0.8834\n",
      "Epoch 26/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6695 - accuracy: 0.9337 - val_loss: 0.8349 - val_accuracy: 0.7497\n",
      "Epoch 27/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6675 - accuracy: 0.9339 - val_loss: 0.4597 - val_accuracy: 0.8647\n",
      "Epoch 28/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6613 - accuracy: 0.9359 - val_loss: 0.4344 - val_accuracy: 0.8820\n",
      "Epoch 29/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6529 - accuracy: 0.9400 - val_loss: 0.4140 - val_accuracy: 0.8859\n",
      "Epoch 30/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6516 - accuracy: 0.9401 - val_loss: 0.4812 - val_accuracy: 0.8598\n",
      "Epoch 31/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6486 - accuracy: 0.9420 - val_loss: 0.4281 - val_accuracy: 0.8832\n",
      "Epoch 32/200\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6434 - accuracy: 0.9434 - val_loss: 0.4020 - val_accuracy: 0.8907\n",
      "Epoch 33/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.6323 - accuracy: 0.9484 - val_loss: 0.4344 - val_accuracy: 0.8771\n",
      "Epoch 34/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.6297 - accuracy: 0.9502 - val_loss: 0.5398 - val_accuracy: 0.8466\n",
      "Epoch 35/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.6311 - accuracy: 0.9505 - val_loss: 0.3769 - val_accuracy: 0.8924\n",
      "Epoch 36/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.6264 - accuracy: 0.9515 - val_loss: 0.4086 - val_accuracy: 0.8898\n",
      "Epoch 37/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.6210 - accuracy: 0.9541 - val_loss: 0.4619 - val_accuracy: 0.8748\n",
      "Epoch 38/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.6152 - accuracy: 0.9572 - val_loss: 0.3640 - val_accuracy: 0.8987\n",
      "Epoch 39/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.6136 - accuracy: 0.9572 - val_loss: 0.4030 - val_accuracy: 0.8890\n",
      "Epoch 40/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.6089 - accuracy: 0.9597 - val_loss: 0.4556 - val_accuracy: 0.8831\n",
      "Epoch 41/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.6090 - accuracy: 0.9596 - val_loss: 0.3805 - val_accuracy: 0.8964\n",
      "Epoch 42/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.6075 - accuracy: 0.9612 - val_loss: 0.3878 - val_accuracy: 0.9012\n",
      "Epoch 43/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.6041 - accuracy: 0.9616 - val_loss: 0.3697 - val_accuracy: 0.9011\n",
      "Epoch 44/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.6002 - accuracy: 0.9628 - val_loss: 0.3948 - val_accuracy: 0.8934\n",
      "Epoch 45/200\n",
      "390/390 [==============================] - 201s 516ms/step - loss: 0.6024 - accuracy: 0.9626 - val_loss: 0.4228 - val_accuracy: 0.8873\n",
      "Epoch 46/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5962 - accuracy: 0.9661 - val_loss: 0.4775 - val_accuracy: 0.8714\n",
      "Epoch 47/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5908 - accuracy: 0.9679 - val_loss: 0.3783 - val_accuracy: 0.9021\n",
      "Epoch 48/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5876 - accuracy: 0.9695 - val_loss: 0.3795 - val_accuracy: 0.9001\n",
      "Epoch 49/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5874 - accuracy: 0.9696 - val_loss: 0.4579 - val_accuracy: 0.8802\n",
      "Epoch 50/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5876 - accuracy: 0.9697 - val_loss: 0.4838 - val_accuracy: 0.8851\n",
      "Epoch 51/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5859 - accuracy: 0.9691 - val_loss: 0.3219 - val_accuracy: 0.9141\n",
      "Epoch 52/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5807 - accuracy: 0.9721 - val_loss: 0.4746 - val_accuracy: 0.8667\n",
      "Epoch 53/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5831 - accuracy: 0.9708 - val_loss: 0.4507 - val_accuracy: 0.8742\n",
      "Epoch 54/200\n",
      "390/390 [==============================] - 201s 516ms/step - loss: 0.5867 - accuracy: 0.9696 - val_loss: 0.4261 - val_accuracy: 0.8885\n",
      "Epoch 55/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5736 - accuracy: 0.9747 - val_loss: 0.3666 - val_accuracy: 0.9002\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5817 - accuracy: 0.9725 - val_loss: 0.4044 - val_accuracy: 0.8998\n",
      "Epoch 57/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5753 - accuracy: 0.9746 - val_loss: 0.4210 - val_accuracy: 0.8930\n",
      "Epoch 58/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5748 - accuracy: 0.9744 - val_loss: 0.3735 - val_accuracy: 0.9101\n",
      "Epoch 59/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5721 - accuracy: 0.9761 - val_loss: 0.4759 - val_accuracy: 0.8791\n",
      "Epoch 60/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5768 - accuracy: 0.9741 - val_loss: 0.6822 - val_accuracy: 0.8198\n",
      "Epoch 61/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5810 - accuracy: 0.9739 - val_loss: 0.3557 - val_accuracy: 0.9098\n",
      "Epoch 62/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5696 - accuracy: 0.9772 - val_loss: 0.3945 - val_accuracy: 0.8998\n",
      "Epoch 63/200\n",
      "390/390 [==============================] - 201s 516ms/step - loss: 0.5712 - accuracy: 0.9768 - val_loss: 0.3639 - val_accuracy: 0.9083\n",
      "Epoch 64/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5639 - accuracy: 0.9789 - val_loss: 0.3936 - val_accuracy: 0.9032\n",
      "Epoch 65/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5654 - accuracy: 0.9788 - val_loss: 0.3733 - val_accuracy: 0.9048\n",
      "Epoch 66/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5624 - accuracy: 0.9805 - val_loss: 0.3759 - val_accuracy: 0.9145\n",
      "Epoch 67/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5679 - accuracy: 0.9779 - val_loss: 0.3704 - val_accuracy: 0.9088\n",
      "Epoch 68/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5684 - accuracy: 0.9783 - val_loss: 0.3695 - val_accuracy: 0.9098\n",
      "Epoch 69/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5604 - accuracy: 0.9809 - val_loss: 0.4020 - val_accuracy: 0.8966\n",
      "Epoch 70/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5604 - accuracy: 0.9802 - val_loss: 0.3874 - val_accuracy: 0.9028\n",
      "Epoch 71/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5585 - accuracy: 0.9817 - val_loss: 0.3961 - val_accuracy: 0.9018\n",
      "Epoch 72/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5713 - accuracy: 0.9771 - val_loss: 0.3558 - val_accuracy: 0.9124\n",
      "Epoch 73/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5629 - accuracy: 0.9799 - val_loss: 0.4155 - val_accuracy: 0.8919\n",
      "Epoch 74/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5571 - accuracy: 0.9818 - val_loss: 0.4070 - val_accuracy: 0.9004\n",
      "Epoch 75/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5602 - accuracy: 0.9815 - val_loss: 0.3605 - val_accuracy: 0.9078\n",
      "Epoch 76/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5581 - accuracy: 0.9816 - val_loss: 0.3364 - val_accuracy: 0.9177\n",
      "Epoch 77/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5542 - accuracy: 0.9827 - val_loss: 0.3903 - val_accuracy: 0.9053\n",
      "Epoch 78/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5596 - accuracy: 0.9818 - val_loss: 0.3521 - val_accuracy: 0.9105\n",
      "Epoch 79/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5599 - accuracy: 0.9825 - val_loss: 0.4112 - val_accuracy: 0.9003\n",
      "Epoch 80/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5544 - accuracy: 0.9831 - val_loss: 0.3780 - val_accuracy: 0.9050\n",
      "Epoch 81/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5522 - accuracy: 0.9837 - val_loss: 0.4583 - val_accuracy: 0.8808\n",
      "Epoch 82/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5543 - accuracy: 0.9834 - val_loss: 0.3563 - val_accuracy: 0.9131\n",
      "Epoch 83/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5683 - accuracy: 0.9806 - val_loss: 0.4060 - val_accuracy: 0.8981\n",
      "Epoch 84/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5553 - accuracy: 0.9838 - val_loss: 0.3991 - val_accuracy: 0.8990\n",
      "Epoch 85/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5519 - accuracy: 0.9847 - val_loss: 0.3310 - val_accuracy: 0.9197\n",
      "Epoch 86/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.5511 - accuracy: 0.9853 - val_loss: 0.4030 - val_accuracy: 0.9106\n",
      "Epoch 87/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5500 - accuracy: 0.9853 - val_loss: 1.8440 - val_accuracy: 0.9062\n",
      "Epoch 88/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5557 - accuracy: 0.9842 - val_loss: 0.3804 - val_accuracy: 0.9054\n",
      "Epoch 89/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5522 - accuracy: 0.9847 - val_loss: 0.3486 - val_accuracy: 0.9139\n",
      "Epoch 90/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5566 - accuracy: 0.9850 - val_loss: 0.3719 - val_accuracy: 0.9115\n",
      "Epoch 91/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5475 - accuracy: 0.9860 - val_loss: 0.4005 - val_accuracy: 0.9034\n",
      "Epoch 92/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5504 - accuracy: 0.9858 - val_loss: 0.3919 - val_accuracy: 0.9104\n",
      "Epoch 93/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5551 - accuracy: 0.9846 - val_loss: 0.3525 - val_accuracy: 0.9235\n",
      "Epoch 94/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5488 - accuracy: 0.9858 - val_loss: 0.6237 - val_accuracy: 0.9189\n",
      "Epoch 95/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5545 - accuracy: 0.9851 - val_loss: 0.3596 - val_accuracy: 0.9218\n",
      "Epoch 96/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5528 - accuracy: 0.9862 - val_loss: 0.4265 - val_accuracy: 0.9084\n",
      "Epoch 97/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5522 - accuracy: 0.9861 - val_loss: 0.3409 - val_accuracy: 0.9224\n",
      "Epoch 98/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5501 - accuracy: 0.9864 - val_loss: 0.5520 - val_accuracy: 0.9083\n",
      "Epoch 99/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5440 - accuracy: 0.9880 - val_loss: 0.3829 - val_accuracy: 0.9084\n",
      "Epoch 100/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5492 - accuracy: 0.9859 - val_loss: 0.3610 - val_accuracy: 0.9144\n",
      "Epoch 101/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 1.4509 - accuracy: 0.8885 - val_loss: 0.6837 - val_accuracy: 0.8065\n",
      "Epoch 102/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5870 - accuracy: 0.9729 - val_loss: 0.2929 - val_accuracy: 0.9292\n",
      "Epoch 103/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5483 - accuracy: 0.9866 - val_loss: 0.3137 - val_accuracy: 0.9303\n",
      "Epoch 104/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5358 - accuracy: 0.9903 - val_loss: 0.2953 - val_accuracy: 0.9323\n",
      "Epoch 105/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5306 - accuracy: 0.9919 - val_loss: 4.8634 - val_accuracy: 0.9254\n",
      "Epoch 106/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5279 - accuracy: 0.9926 - val_loss: 25.5891 - val_accuracy: 0.9311\n",
      "Epoch 107/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5260 - accuracy: 0.9930 - val_loss: 0.7728 - val_accuracy: 0.9314\n",
      "Epoch 108/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5264 - accuracy: 0.9931 - val_loss: 42.9229 - val_accuracy: 0.9293\n",
      "Epoch 109/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5279 - accuracy: 0.9923 - val_loss: 0.3339 - val_accuracy: 0.9254\n",
      "Epoch 110/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5294 - accuracy: 0.9915 - val_loss: 0.3150 - val_accuracy: 0.9303\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5297 - accuracy: 0.9918 - val_loss: 10.6705 - val_accuracy: 0.9276\n",
      "Epoch 112/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5289 - accuracy: 0.9921 - val_loss: 6.9472 - val_accuracy: 0.9196\n",
      "Epoch 113/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5295 - accuracy: 0.9916 - val_loss: 0.3330 - val_accuracy: 0.9260\n",
      "Epoch 114/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5307 - accuracy: 0.9916 - val_loss: 0.3465 - val_accuracy: 0.9240\n",
      "Epoch 115/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5308 - accuracy: 0.9917 - val_loss: 0.3618 - val_accuracy: 0.9182\n",
      "Epoch 116/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5324 - accuracy: 0.9915 - val_loss: 0.4882 - val_accuracy: 0.9216\n",
      "Epoch 117/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5293 - accuracy: 0.9931 - val_loss: 0.3366 - val_accuracy: 0.9240\n",
      "Epoch 118/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5302 - accuracy: 0.9918 - val_loss: 0.3425 - val_accuracy: 0.9323\n",
      "Epoch 119/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5278 - accuracy: 0.9934 - val_loss: 0.3071 - val_accuracy: 0.9291\n",
      "Epoch 120/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5289 - accuracy: 0.9932 - val_loss: 0.3051 - val_accuracy: 0.9316\n",
      "Epoch 121/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5277 - accuracy: 0.9930 - val_loss: 1.4847 - val_accuracy: 0.9234\n",
      "Epoch 122/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5245 - accuracy: 0.9940 - val_loss: 0.3457 - val_accuracy: 0.9249\n",
      "Epoch 123/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5278 - accuracy: 0.9929 - val_loss: 0.3291 - val_accuracy: 0.9278\n",
      "Epoch 124/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5277 - accuracy: 0.9932 - val_loss: 0.3647 - val_accuracy: 0.9213\n",
      "Epoch 125/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5245 - accuracy: 0.9937 - val_loss: 0.3213 - val_accuracy: 0.9284\n",
      "Epoch 126/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5249 - accuracy: 0.9939 - val_loss: 0.6546 - val_accuracy: 0.8462\n",
      "Epoch 127/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5328 - accuracy: 0.9920 - val_loss: 0.6003 - val_accuracy: 0.9321\n",
      "Epoch 128/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5197 - accuracy: 0.9953 - val_loss: 0.3237 - val_accuracy: 0.9267\n",
      "Epoch 129/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5191 - accuracy: 0.9953 - val_loss: 0.3067 - val_accuracy: 0.9335\n",
      "Epoch 130/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5220 - accuracy: 0.9948 - val_loss: 0.3265 - val_accuracy: 0.9306\n",
      "Epoch 131/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5168 - accuracy: 0.9963 - val_loss: 0.2984 - val_accuracy: 0.9390\n",
      "Epoch 132/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5205 - accuracy: 0.9956 - val_loss: 0.3237 - val_accuracy: 0.9298\n",
      "Epoch 133/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.5222 - accuracy: 0.9949 - val_loss: 0.3073 - val_accuracy: 0.9330\n",
      "Epoch 134/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5209 - accuracy: 0.9952 - val_loss: 0.3123 - val_accuracy: 0.9365\n",
      "Epoch 135/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5177 - accuracy: 0.9959 - val_loss: 0.3152 - val_accuracy: 0.9275\n",
      "Epoch 136/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5202 - accuracy: 0.9953 - val_loss: 0.3167 - val_accuracy: 0.9331\n",
      "Epoch 137/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5184 - accuracy: 0.9959 - val_loss: 510594.8275 - val_accuracy: 0.9274\n",
      "Epoch 138/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5155 - accuracy: 0.9965 - val_loss: 222.5328 - val_accuracy: 0.9313\n",
      "Epoch 139/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5168 - accuracy: 0.9965 - val_loss: 0.3553 - val_accuracy: 0.9304\n",
      "Epoch 140/200\n",
      "390/390 [==============================] - 201s 516ms/step - loss: 0.5150 - accuracy: 0.9967 - val_loss: 55796.1625 - val_accuracy: 0.9302\n",
      "Epoch 141/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5152 - accuracy: 0.9968 - val_loss: 3549.6721 - val_accuracy: 0.9345\n",
      "Epoch 142/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5145 - accuracy: 0.9968 - val_loss: 146849.8279 - val_accuracy: 0.9262\n",
      "Epoch 143/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.5141 - accuracy: 0.9972 - val_loss: 2921.3293 - val_accuracy: 0.9311\n",
      "Epoch 144/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5155 - accuracy: 0.9968 - val_loss: 2957.9363 - val_accuracy: 0.9348\n",
      "Epoch 145/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5132 - accuracy: 0.9971 - val_loss: 0.8839 - val_accuracy: 0.9400\n",
      "Epoch 146/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.5138 - accuracy: 0.9970 - val_loss: 0.2892 - val_accuracy: 0.9388\n",
      "Epoch 147/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5137 - accuracy: 0.9973 - val_loss: 18382.2775 - val_accuracy: 0.9327\n",
      "Epoch 148/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5132 - accuracy: 0.9973 - val_loss: 0.2791 - val_accuracy: 0.9408\n",
      "Epoch 149/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5126 - accuracy: 0.9975 - val_loss: 294.4265 - val_accuracy: 0.9364\n",
      "Epoch 150/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5138 - accuracy: 0.9970 - val_loss: 119.2980 - val_accuracy: 0.9352\n",
      "Epoch 151/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5110 - accuracy: 0.9981 - val_loss: 465.0986 - val_accuracy: 0.9397\n",
      "Epoch 152/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5101 - accuracy: 0.9981 - val_loss: 137.2746 - val_accuracy: 0.9383\n",
      "Epoch 153/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5111 - accuracy: 0.9982 - val_loss: 0.2973 - val_accuracy: 0.9356\n",
      "Epoch 154/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5099 - accuracy: 0.9982 - val_loss: 19066.8266 - val_accuracy: 0.9359\n",
      "Epoch 155/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5113 - accuracy: 0.9979 - val_loss: 0.3312 - val_accuracy: 0.9342\n",
      "Epoch 156/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5112 - accuracy: 0.9976 - val_loss: 649.7648 - val_accuracy: 0.9415\n",
      "Epoch 157/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.5100 - accuracy: 0.9981 - val_loss: 134.7522 - val_accuracy: 0.9397\n",
      "Epoch 158/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5099 - accuracy: 0.9981 - val_loss: 0.8952 - val_accuracy: 0.9388\n",
      "Epoch 159/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5091 - accuracy: 0.9982 - val_loss: 0.2893 - val_accuracy: 0.9380\n",
      "Epoch 160/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5096 - accuracy: 0.9982 - val_loss: 0.2938 - val_accuracy: 0.9422\n",
      "Epoch 161/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5090 - accuracy: 0.9982 - val_loss: 0.3022 - val_accuracy: 0.9346\n",
      "Epoch 162/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5099 - accuracy: 0.9979 - val_loss: 0.2862 - val_accuracy: 0.9396\n",
      "Epoch 163/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5078 - accuracy: 0.9987 - val_loss: 0.4769 - val_accuracy: 0.9409\n",
      "Epoch 164/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5078 - accuracy: 0.9986 - val_loss: 11607.1472 - val_accuracy: 0.9372\n",
      "Epoch 165/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5071 - accuracy: 0.9990 - val_loss: 0.6975 - val_accuracy: 0.9434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5081 - accuracy: 0.9986 - val_loss: 0.5600 - val_accuracy: 0.9409\n",
      "Epoch 167/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5067 - accuracy: 0.9990 - val_loss: 0.2909 - val_accuracy: 0.9408\n",
      "Epoch 168/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5079 - accuracy: 0.9985 - val_loss: 0.2854 - val_accuracy: 0.9426\n",
      "Epoch 169/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5070 - accuracy: 0.9988 - val_loss: 0.3490 - val_accuracy: 0.9410\n",
      "Epoch 170/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5065 - accuracy: 0.9989 - val_loss: 190.5197 - val_accuracy: 0.9419\n",
      "Epoch 171/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5069 - accuracy: 0.9989 - val_loss: 183850.2263 - val_accuracy: 0.9402\n",
      "Epoch 172/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5062 - accuracy: 0.9991 - val_loss: 136.4349 - val_accuracy: 0.9423\n",
      "Epoch 173/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5064 - accuracy: 0.9989 - val_loss: 1.1640 - val_accuracy: 0.9436\n",
      "Epoch 174/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5061 - accuracy: 0.9990 - val_loss: 82.2502 - val_accuracy: 0.9436\n",
      "Epoch 175/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5053 - accuracy: 0.9992 - val_loss: 18374.9405 - val_accuracy: 0.9439\n",
      "Epoch 176/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5058 - accuracy: 0.9991 - val_loss: 152.5033 - val_accuracy: 0.9422\n",
      "Epoch 177/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5053 - accuracy: 0.9993 - val_loss: 2769.7347 - val_accuracy: 0.9449\n",
      "Epoch 178/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.5054 - accuracy: 0.9994 - val_loss: 0.3517 - val_accuracy: 0.9403\n",
      "Epoch 179/200\n",
      "390/390 [==============================] - 201s 516ms/step - loss: 0.5051 - accuracy: 0.9993 - val_loss: 15.1578 - val_accuracy: 0.9445\n",
      "Epoch 180/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5051 - accuracy: 0.9992 - val_loss: 3436.1416 - val_accuracy: 0.9453\n",
      "Epoch 181/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5048 - accuracy: 0.9994 - val_loss: 264.9588 - val_accuracy: 0.9438\n",
      "Epoch 182/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5043 - accuracy: 0.9995 - val_loss: 66.4373 - val_accuracy: 0.9453\n",
      "Epoch 183/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5041 - accuracy: 0.9996 - val_loss: 1.0683 - val_accuracy: 0.9428\n",
      "Epoch 184/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5044 - accuracy: 0.9995 - val_loss: 130.1496 - val_accuracy: 0.9438\n",
      "Epoch 185/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5040 - accuracy: 0.9996 - val_loss: 0.2723 - val_accuracy: 0.9459\n",
      "Epoch 186/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5040 - accuracy: 0.9996 - val_loss: 10.4898 - val_accuracy: 0.9444\n",
      "Epoch 187/200\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.5040 - accuracy: 0.9995 - val_loss: 24.3575 - val_accuracy: 0.9466\n",
      "Epoch 188/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5044 - accuracy: 0.9995 - val_loss: 0.2700 - val_accuracy: 0.9475\n",
      "Epoch 189/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5036 - accuracy: 0.9997 - val_loss: 0.2781 - val_accuracy: 0.9474\n",
      "Epoch 190/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5034 - accuracy: 0.9998 - val_loss: 0.2758 - val_accuracy: 0.9463\n",
      "Epoch 191/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5033 - accuracy: 0.9998 - val_loss: 2.4789 - val_accuracy: 0.9467\n",
      "Epoch 192/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5032 - accuracy: 0.9998 - val_loss: 0.4779 - val_accuracy: 0.9453\n",
      "Epoch 193/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5033 - accuracy: 0.9997 - val_loss: 0.3797 - val_accuracy: 0.9460\n",
      "Epoch 194/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5032 - accuracy: 0.9998 - val_loss: 0.4542 - val_accuracy: 0.9467\n",
      "Epoch 195/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5034 - accuracy: 0.9997 - val_loss: 10.9154 - val_accuracy: 0.9466\n",
      "Epoch 196/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5034 - accuracy: 0.9997 - val_loss: 11.2980 - val_accuracy: 0.9467\n",
      "Epoch 197/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5032 - accuracy: 0.9998 - val_loss: 23.7254 - val_accuracy: 0.9482\n",
      "Epoch 198/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5031 - accuracy: 0.9997 - val_loss: 32.6716 - val_accuracy: 0.9475\n",
      "Epoch 199/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5031 - accuracy: 0.9997 - val_loss: 9.5638 - val_accuracy: 0.9472\n",
      "Epoch 200/200\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.5029 - accuracy: 0.9999 - val_loss: 3.0281 - val_accuracy: 0.9474\n",
      "Acc -> Val acc: 0.0518,Test (best_acc) acc: 0.0518\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0518 in 677.3 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fitness_cnn.verb = True\n",
    "score = fitness_cnn.calc(winner, test=True, precise_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without cutout score (200 eps): 0.05180001258850098\n",
      "Training with 100 eps and cutout\n",
      "Training with learning rate: 0.05\n",
      "Training... No Early stopping\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 8)    520         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 8)    32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 72)   0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 45)   3285        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 45)   180         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 45)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 36)   1656        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 36)   144         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 81)   0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 72)   5904        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 72)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 72)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 46)   2116        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 19)   1387        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 46)   184         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 19)   76          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 91)   0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 91)   0           dropout_2[0][0]                  \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 91)   0           concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 75)   170700      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 75)   300         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 75)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 39)   2535        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 28)   2128        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 39)   156         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 28)   112         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 103)  0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 103)  0           dropout_3[0][0]                  \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 103)  0           concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 81)   208656      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 81)   324         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 81)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 34)   2788        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 34)   136         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 115)  0           dropout_4[0][0]                  \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 72)   8352        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 72)   288         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 72)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 58)   4234        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 58)   232         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 130)  0           dropout_5[0][0]                  \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 117)  15327       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 117)  468         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 117)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 74)   5402        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 29)   3422        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 74)   296         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 29)   116         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 146)  0           dropout_5[0][0]                  \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 146)  0           dropout_6[0][0]                  \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 146)  0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 121)  441771      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 121)  484         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 121)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 83)   6806        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 43)   5246        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 83)   332         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 43)   172         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 164)  0           dropout_4[0][0]                  \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 164)  0           dropout_7[0][0]                  \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 164)  0           concatenate_11[0][0]             \n",
      "                                                                 concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 130)  533130      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 130)  520         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 130)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 130)  0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 55)   7205        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 55)   220         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 185)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 116)  21576       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 116)  464         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 116)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 92)   10764       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 92)   368         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 208)  0           dropout_9[0][0]                  \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 187)  39083       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 187)  748         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 16, 187)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 118)  13806       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 47)   8836        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 118)  472         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 47)   188         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 234)  0           dropout_9[0][0]                  \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 234)  0           dropout_10[0][0]                 \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 234)  0           concatenate_15[0][0]             \n",
      "                                                                 concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 194)  1135094     add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 194)  776         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, 16, 194)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 133)  17423       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 69)   13455       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 133)  532         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 69)   276         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 263)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 263)  0           dropout_11[0][0]                 \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 263)  0           concatenate_17[0][0]             \n",
      "                                                                 concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 209)  1374384     add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 209)  836         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 16, 209)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 87)   18270       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 87)   348         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 296)  0           dropout_12[0][0]                 \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 187)  55539       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 187)  748         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 187)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 146)  27448       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 146)  584         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 333)  0           dropout_13[0][0]                 \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 299)  99866       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 299)  1196        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 299)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 187)  35156       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 75)   22500       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 187)  748         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 75)   300         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 374)  0           dropout_13[0][0]                 \n",
      "                                                                 batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 374)  0           dropout_14[0][0]                 \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 374)  0           concatenate_21[0][0]             \n",
      "                                                                 concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 310)  2898810     add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 310)  1240        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 310)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 212)  44520       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 111)  34521       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 212)  848         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 111)  444         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 421)  0           dropout_12[0][0]                 \n",
      "                                                                 batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 421)  0           dropout_15[0][0]                 \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 421)  0           concatenate_23[0][0]             \n",
      "                                                                 concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 334)  3515684     add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 334)  1336        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 334)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 334)    0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 140)    46900       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 140)    560         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 474)    0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 299)    142025      concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 299)    1196        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 8, 8, 299)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 234)    70200       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 234)    936         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 533)    0           dropout_17[0][0]                 \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 479)    255786      concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 479)    1916        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 8, 8, 479)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 301)    90300       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 121)    58080       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 301)    1204        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 121)    484         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 600)    0           dropout_17[0][0]                 \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 600)    0           dropout_18[0][0]                 \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 600)    0           concatenate_27[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 497)    7455497     add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 497)    1988        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 8, 8, 497)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 341)    114235      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 8, 178)    88644       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 341)    1364        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 178)    712         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 675)    0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 675)    0           dropout_19[0][0]                 \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 675)    0           concatenate_29[0][0]             \n",
      "                                                                 concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 536)    9045536     add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 536)    2144        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 8, 8, 536)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 223)    119751      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 223)    892         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 759)    0           dropout_20[0][0]                 \n",
      "                                                                 batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 479)    364040      concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 479)    1916        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 8, 8, 479)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 375)    180000      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 375)    1500        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 854)    0           dropout_21[0][0]                 \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 768)    656640      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 768)    3072        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 8, 8, 768)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 482)    231360      dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 193)    148417      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 482)    1928        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 193)    772         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 961)    0           dropout_21[0][0]                 \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 961)    0           dropout_22[0][0]                 \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 961)    0           concatenate_33[0][0]             \n",
      "                                                                 concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 797)    19148722    add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 797)    3188        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 8, 8, 797)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 545)    292665      dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 284)    226632      dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 545)    2180        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 284)    1136        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 1081)   0           dropout_20[0][0]                 \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 8, 8, 1081)   0           dropout_23[0][0]                 \n",
      "                                                                 batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 1081)   0           concatenate_35[0][0]             \n",
      "                                                                 concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 859)    23215334    add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 859)    3436        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 8, 8, 859)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 859)          0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           8600        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 72,830,753\n",
      "Trainable params: 72,805,607\n",
      "Non-trainable params: 25,146\n",
      "__________________________________________________________________________________________________\n",
      "Cutout augmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "390/390 [==============================] - 222s 570ms/step - loss: 1.8566 - accuracy: 0.3675 - val_loss: 3.9876 - val_accuracy: 0.1680\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 1.5271 - accuracy: 0.5302 - val_loss: 1.2775 - val_accuracy: 0.5765\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 1.3457 - accuracy: 0.6214 - val_loss: 1.2510 - val_accuracy: 0.5750\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 1.2198 - accuracy: 0.6822 - val_loss: 1.0042 - val_accuracy: 0.6717\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 1.1258 - accuracy: 0.7275 - val_loss: 0.8480 - val_accuracy: 0.7405\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 1.0643 - accuracy: 0.7540 - val_loss: 0.6956 - val_accuracy: 0.7894\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 1.0139 - accuracy: 0.7783 - val_loss: 1.1451 - val_accuracy: 0.6244\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.9715 - accuracy: 0.7962 - val_loss: 0.8166 - val_accuracy: 0.7368\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 201s 515ms/step - loss: 0.9454 - accuracy: 0.8087 - val_loss: 0.6324 - val_accuracy: 0.8037\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.9148 - accuracy: 0.8226 - val_loss: 0.7711 - val_accuracy: 0.7611\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.8960 - accuracy: 0.8311 - val_loss: 0.6880 - val_accuracy: 0.7821\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.8823 - accuracy: 0.8380 - val_loss: 0.5211 - val_accuracy: 0.8568\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.8702 - accuracy: 0.8422 - val_loss: 0.5460 - val_accuracy: 0.8362\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.8558 - accuracy: 0.8508 - val_loss: 0.7137 - val_accuracy: 0.7853\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.8472 - accuracy: 0.8534 - val_loss: 0.6246 - val_accuracy: 0.8075\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.8338 - accuracy: 0.8607 - val_loss: 0.5831 - val_accuracy: 0.8410\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.8211 - accuracy: 0.8655 - val_loss: 0.5200 - val_accuracy: 0.8506\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.8213 - accuracy: 0.8652 - val_loss: 0.5666 - val_accuracy: 0.8345\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.8067 - accuracy: 0.8737 - val_loss: 0.6110 - val_accuracy: 0.8128\n",
      "Epoch 20/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.8004 - accuracy: 0.8761 - val_loss: 0.4674 - val_accuracy: 0.8751\n",
      "Epoch 21/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7928 - accuracy: 0.8797 - val_loss: 0.7091 - val_accuracy: 0.7870\n",
      "Epoch 22/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7866 - accuracy: 0.8812 - val_loss: 0.5089 - val_accuracy: 0.8675\n",
      "Epoch 23/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.7854 - accuracy: 0.8825 - val_loss: 0.5870 - val_accuracy: 0.8270\n",
      "Epoch 24/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7749 - accuracy: 0.8881 - val_loss: 0.4572 - val_accuracy: 0.8702\n",
      "Epoch 25/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7762 - accuracy: 0.8880 - val_loss: 0.5274 - val_accuracy: 0.8535\n",
      "Epoch 26/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7653 - accuracy: 0.8929 - val_loss: 0.4678 - val_accuracy: 0.8589\n",
      "Epoch 27/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7631 - accuracy: 0.8929 - val_loss: 0.4611 - val_accuracy: 0.8737\n",
      "Epoch 28/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7535 - accuracy: 0.8984 - val_loss: 0.5151 - val_accuracy: 0.8569\n",
      "Epoch 29/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7522 - accuracy: 0.8973 - val_loss: 0.5661 - val_accuracy: 0.8265\n",
      "Epoch 30/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7406 - accuracy: 0.9040 - val_loss: 0.5233 - val_accuracy: 0.8606\n",
      "Epoch 31/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7403 - accuracy: 0.9043 - val_loss: 0.5505 - val_accuracy: 0.8344\n",
      "Epoch 32/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7376 - accuracy: 0.9051 - val_loss: 0.4307 - val_accuracy: 0.8841\n",
      "Epoch 33/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7340 - accuracy: 0.9091 - val_loss: 0.4191 - val_accuracy: 0.8818\n",
      "Epoch 34/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.7288 - accuracy: 0.9096 - val_loss: 0.4008 - val_accuracy: 0.8932\n",
      "Epoch 35/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7191 - accuracy: 0.9138 - val_loss: 0.5013 - val_accuracy: 0.8602\n",
      "Epoch 36/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7195 - accuracy: 0.9145 - val_loss: 0.4673 - val_accuracy: 0.8854\n",
      "Epoch 37/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7216 - accuracy: 0.9155 - val_loss: 0.5410 - val_accuracy: 0.8429\n",
      "Epoch 38/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6984 - accuracy: 0.9226 - val_loss: 0.4821 - val_accuracy: 0.8716\n",
      "Epoch 39/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.7146 - accuracy: 0.9188 - val_loss: 0.4741 - val_accuracy: 0.8627\n",
      "Epoch 40/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.7074 - accuracy: 0.9208 - val_loss: 0.4101 - val_accuracy: 0.8862\n",
      "Epoch 41/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6972 - accuracy: 0.9254 - val_loss: 0.4592 - val_accuracy: 0.8739\n",
      "Epoch 42/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6954 - accuracy: 0.9270 - val_loss: 0.4476 - val_accuracy: 0.8859\n",
      "Epoch 43/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6965 - accuracy: 0.9276 - val_loss: 0.4137 - val_accuracy: 0.8968\n",
      "Epoch 44/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6917 - accuracy: 0.9284 - val_loss: 0.4122 - val_accuracy: 0.8795\n",
      "Epoch 45/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6780 - accuracy: 0.9337 - val_loss: 0.3890 - val_accuracy: 0.8965\n",
      "Epoch 46/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6849 - accuracy: 0.9318 - val_loss: 0.3514 - val_accuracy: 0.9037\n",
      "Epoch 47/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6716 - accuracy: 0.9365 - val_loss: 0.4274 - val_accuracy: 0.8857\n",
      "Epoch 48/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6839 - accuracy: 0.9340 - val_loss: 0.4734 - val_accuracy: 0.8729\n",
      "Epoch 49/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6684 - accuracy: 0.9379 - val_loss: 0.4660 - val_accuracy: 0.8811\n",
      "Epoch 50/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6748 - accuracy: 0.9387 - val_loss: 0.3870 - val_accuracy: 0.8917\n",
      "Epoch 51/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6728 - accuracy: 0.9395 - val_loss: 0.4399 - val_accuracy: 0.8829\n",
      "Epoch 52/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6568 - accuracy: 0.9435 - val_loss: 0.3655 - val_accuracy: 0.8951\n",
      "Epoch 53/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6435 - accuracy: 0.9474 - val_loss: 0.3593 - val_accuracy: 0.9169\n",
      "Epoch 54/100\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.6438 - accuracy: 0.9500 - val_loss: 0.3311 - val_accuracy: 0.9142\n",
      "Epoch 55/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6269 - accuracy: 0.9540 - val_loss: 0.3392 - val_accuracy: 0.9104\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6354 - accuracy: 0.9529 - val_loss: 0.3242 - val_accuracy: 0.9198\n",
      "Epoch 57/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6167 - accuracy: 0.9594 - val_loss: 0.3322 - val_accuracy: 0.9249\n",
      "Epoch 58/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.6216 - accuracy: 0.9574 - val_loss: 0.3612 - val_accuracy: 0.9139\n",
      "Epoch 59/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6148 - accuracy: 0.9604 - val_loss: 0.3433 - val_accuracy: 0.9156\n",
      "Epoch 60/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6105 - accuracy: 0.9621 - val_loss: 0.3043 - val_accuracy: 0.9269\n",
      "Epoch 61/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6050 - accuracy: 0.9644 - val_loss: 0.2914 - val_accuracy: 0.9314\n",
      "Epoch 62/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.6074 - accuracy: 0.9642 - val_loss: 0.3605 - val_accuracy: 0.9156\n",
      "Epoch 63/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.5930 - accuracy: 0.9676 - val_loss: 0.3448 - val_accuracy: 0.9096\n",
      "Epoch 64/100\n",
      "390/390 [==============================] - 199s 511ms/step - loss: 0.5970 - accuracy: 0.9669 - val_loss: 0.3412 - val_accuracy: 0.9175\n",
      "Epoch 65/100\n",
      "390/390 [==============================] - 200s 512ms/step - loss: 0.5912 - accuracy: 0.9687 - val_loss: 0.3203 - val_accuracy: 0.9224\n",
      "Epoch 66/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.5797 - accuracy: 0.9731 - val_loss: 0.3131 - val_accuracy: 0.9279\n",
      "Epoch 67/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5772 - accuracy: 0.9732 - val_loss: 0.3148 - val_accuracy: 0.9247\n",
      "Epoch 68/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5783 - accuracy: 0.9735 - val_loss: 0.2714 - val_accuracy: 0.9363\n",
      "Epoch 69/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5776 - accuracy: 0.9744 - val_loss: 0.2976 - val_accuracy: 0.9280\n",
      "Epoch 70/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5728 - accuracy: 0.9755 - val_loss: 0.2881 - val_accuracy: 0.9330\n",
      "Epoch 71/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.5692 - accuracy: 0.9768 - val_loss: 0.2731 - val_accuracy: 0.9351\n",
      "Epoch 72/100\n",
      "390/390 [==============================] - 200s 512ms/step - loss: 0.5677 - accuracy: 0.9768 - val_loss: 0.2856 - val_accuracy: 0.9332\n",
      "Epoch 73/100\n",
      "390/390 [==============================] - 199s 511ms/step - loss: 0.5663 - accuracy: 0.9775 - val_loss: 0.2837 - val_accuracy: 0.9411\n",
      "Epoch 74/100\n",
      "390/390 [==============================] - 199s 512ms/step - loss: 0.5660 - accuracy: 0.9777 - val_loss: 0.2759 - val_accuracy: 0.9334\n",
      "Epoch 75/100\n",
      "390/390 [==============================] - 199s 511ms/step - loss: 0.5609 - accuracy: 0.9803 - val_loss: 0.2732 - val_accuracy: 0.9375\n",
      "Epoch 76/100\n",
      "390/390 [==============================] - 199s 511ms/step - loss: 0.5588 - accuracy: 0.9804 - val_loss: 0.2545 - val_accuracy: 0.9399\n",
      "Epoch 77/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.5554 - accuracy: 0.9815 - val_loss: 0.2606 - val_accuracy: 0.9430\n",
      "Epoch 78/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5563 - accuracy: 0.9812 - val_loss: 0.2599 - val_accuracy: 0.9396\n",
      "Epoch 79/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5538 - accuracy: 0.9824 - val_loss: 0.2557 - val_accuracy: 0.9436\n",
      "Epoch 80/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5492 - accuracy: 0.9833 - val_loss: 0.2555 - val_accuracy: 0.9425\n",
      "Epoch 81/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5473 - accuracy: 0.9841 - val_loss: 0.2627 - val_accuracy: 0.9423\n",
      "Epoch 82/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5472 - accuracy: 0.9842 - val_loss: 0.2602 - val_accuracy: 0.9470\n",
      "Epoch 83/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5458 - accuracy: 0.9843 - val_loss: 0.2719 - val_accuracy: 0.9416\n",
      "Epoch 84/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5458 - accuracy: 0.9851 - val_loss: 0.2563 - val_accuracy: 0.9443\n",
      "Epoch 85/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5427 - accuracy: 0.9854 - val_loss: 0.2396 - val_accuracy: 0.9466\n",
      "Epoch 86/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5397 - accuracy: 0.9867 - val_loss: 0.2331 - val_accuracy: 0.9475\n",
      "Epoch 87/100\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.5401 - accuracy: 0.9865 - val_loss: 0.2385 - val_accuracy: 0.9494\n",
      "Epoch 88/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.5367 - accuracy: 0.9881 - val_loss: 0.2442 - val_accuracy: 0.9502\n",
      "Epoch 89/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5362 - accuracy: 0.9878 - val_loss: 0.2464 - val_accuracy: 0.9463\n",
      "Epoch 90/100\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.5357 - accuracy: 0.9881 - val_loss: 0.2368 - val_accuracy: 0.9498\n",
      "Epoch 91/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5340 - accuracy: 0.9886 - val_loss: 0.2290 - val_accuracy: 0.9492\n",
      "Epoch 92/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5326 - accuracy: 0.9894 - val_loss: 0.2246 - val_accuracy: 0.9512\n",
      "Epoch 93/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5328 - accuracy: 0.9895 - val_loss: 0.2413 - val_accuracy: 0.9497\n",
      "Epoch 94/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5309 - accuracy: 0.9901 - val_loss: 0.2392 - val_accuracy: 0.9494\n",
      "Epoch 95/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5295 - accuracy: 0.9899 - val_loss: 0.2396 - val_accuracy: 0.9499\n",
      "Epoch 96/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5272 - accuracy: 0.9913 - val_loss: 0.2373 - val_accuracy: 0.9503\n",
      "Epoch 97/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5273 - accuracy: 0.9910 - val_loss: 0.2285 - val_accuracy: 0.9516\n",
      "Epoch 98/100\n",
      "390/390 [==============================] - 200s 513ms/step - loss: 0.5268 - accuracy: 0.9907 - val_loss: 0.2335 - val_accuracy: 0.9510\n",
      "Epoch 99/100\n",
      "390/390 [==============================] - 200s 514ms/step - loss: 0.5258 - accuracy: 0.9917 - val_loss: 0.2290 - val_accuracy: 0.9522\n",
      "Epoch 100/100\n",
      "390/390 [==============================] - 201s 514ms/step - loss: 0.5243 - accuracy: 0.9920 - val_loss: 0.2294 - val_accuracy: 0.9527\n",
      "Acc -> Val acc: 0.0473,Test (best_acc) acc: 0.0473\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0473 in 340.3 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fitness_cnn.test_eps = 100\n",
    "fitness_cnn.verb = True\n",
    "print(\"Without cutout score (200 eps):\", score)\n",
    "if float(score) < 0.0449:\n",
    "    fitness_cnn.augment = True\n",
    "    print(\"Training with 100 eps and without cutout\")\n",
    "else:\n",
    "    fitness_cnn.augment = 'cutout'\n",
    "    print(\"Training with 100 eps and cutout\")\n",
    "    \n",
    "score = fitness_cnn.calc(winner, test=True, precise_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3) (10000, 32, 32, 3)\n",
      "(50000, 10) (10000, 10) (10000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(fitness_cnn.x_train.shape, fitness_cnn.x_test.shape, fitness_cnn.x_val.shape)\n",
    "print(fitness_cnn.y_train.shape, fitness_cnn.y_test.shape, fitness_cnn.y_val.shape)\n",
    "\n",
    "\n",
    "x = (fitness_cnn.x_test[1], fitness_cnn.x_train[1], fitness_cnn.x_val[1])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x[0]); plt.show()\n",
    "plt.imshow(x[1]); plt.show()\n",
    "plt.imshow(x[2]); plt.show()\n",
    "\n",
    "for xi in fitness_cnn.x_train:\n",
    "    if np.sum(xi == x) == 32*32*3:\n",
    "        print(\"Puta la wea\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||CNN|F:0.7|K:3|A:prelu|D:0.15||woCAT||1||\n",
      "||CNN|F:0.9|K:5|A:relu|D:0.05||woCAT||01||\n",
      "||CNN|F:0.8|K:3|A:relu|D:0.70||SUM||011||\n",
      "||CNN|F:0.5|K:5|A:elu|D:0.10||SUM||1011||\n",
      "HP->|GR:2.65|CELL:2|BLOCK:2|STEM:64\n",
      "\n",
      "Training... No Early stopping\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 8)    520         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 8)    32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 72)   0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 49)   31801       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 32, 32, 49)   50176       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 49)   196         p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 49)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 33)   1650        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 33)   132         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 82)   0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 69)   141519      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 69)   276         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 69)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 43)   2150        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 23)   1610        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 43)   172         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 23)   92          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 92)   0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 92)   0           dropout_2[0][0]                  \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 92)   0           concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 75)   62175       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 75)   300         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 75)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 40)   2600        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 35)   2450        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 29)   2204        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 40)   160         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 35)   140         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 29)   116         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 104)  0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 104)  0           dropout_2[0][0]                  \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 104)  0           dropout_3[0][0]                  \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 104)  0           concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 55)   143055      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 55)   220         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 55)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 63)   3528        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 63)   252         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 118)  0           dropout_4[0][0]                  \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 80)   85040       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 32, 32, 80)   81920       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 80)   320         p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 80)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 53)   4293        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 53)   212         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 133)  0           dropout_5[0][0]                  \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 113)  375838      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 113)  452         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 113)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 70)   5670        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 37)   4218        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 70)   280         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 37)   148         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 150)  0           dropout_5[0][0]                  \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 150)  0           dropout_6[0][0]                  \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 150)  0           concatenate_10[0][0]             \n",
      "                                                                 concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 122)  164822      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 122)  488         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 122)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 115)  6440        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 57)   6498        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 48)   5904        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 115)  460         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 57)   228         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 48)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 170)  0           dropout_4[0][0]                  \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 32, 32, 170)  0           dropout_6[0][0]                  \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 170)  0           dropout_7[0][0]                  \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 170)  0           concatenate_12[0][0]             \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 90)   382590      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 90)   360         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 90)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 90)   0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 102)  9282        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 102)  408         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 130)  224770      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 16, 16, 130)  33280       conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 130)  520         p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 130)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 87)   11397       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 87)   348         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 217)  0           dropout_9[0][0]                  \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 184)  998384      concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 184)  736         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 16, 184)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 115)  15065       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 61)   11285       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 115)  460         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 61)   244         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 245)  0           dropout_9[0][0]                  \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 245)  0           dropout_10[0][0]                 \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 245)  0           concatenate_17[0][0]             \n",
      "                                                                 concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 199)  438994      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 199)  796         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, 16, 199)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 187)  17017       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 93)   17205       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 78)   15600       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 187)  748         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 93)   372         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 78)   312         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 277)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 277)  0           dropout_10[0][0]                 \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 277)  0           dropout_11[0][0]                 \n",
      "                                                                 batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 277)  0           concatenate_19[0][0]             \n",
      "                                                                 concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 147)  1018122     add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 147)  588         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 16, 147)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 166)  24568       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 166)  664         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 313)  0           dropout_12[0][0]                 \n",
      "                                                                 batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 213)  600234      concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 16, 16, 213)  54528       conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 213)  852         p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 213)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 140)  29960       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 140)  560         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 353)  0           dropout_13[0][0]                 \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 300)  2647800     concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 300)  1200        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 300)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 186)  39804       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 99)   29799       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 186)  744         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 99)   396         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 399)  0           dropout_13[0][0]                 \n",
      "                                                                 batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 16, 16, 399)  0           dropout_14[0][0]                 \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 399)  0           concatenate_24[0][0]             \n",
      "                                                                 concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 325)  1167400     add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 325)  1300        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 325)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 304)  44992       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 151)  45451       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 126)  41076       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 304)  1216        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 151)  604         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 126)  504         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 451)  0           dropout_12[0][0]                 \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 451)  0           dropout_14[0][0]                 \n",
      "                                                                 batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 16, 16, 451)  0           dropout_15[0][0]                 \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 451)  0           concatenate_26[0][0]             \n",
      "                                                                 concatenate_27[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 239)  2694964     add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 239)  956         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 239)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 239)          0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2400        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 11,823,852\n",
      "Trainable params: 11,813,846\n",
      "Non-trainable params: 10,006\n",
      "__________________________________________________________________________________________________\n",
      "Cutout augmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "390/390 [==============================] - 163s 419ms/step - loss: 1.9223 - accuracy: 0.3666 - val_loss: 3.5652 - val_accuracy: 0.1654\n",
      "Epoch 2/200\n",
      "390/390 [==============================] - 142s 365ms/step - loss: 1.6269 - accuracy: 0.5512 - val_loss: 1.2367 - val_accuracy: 0.5861\n",
      "Epoch 3/200\n",
      " 76/390 [====>.........................] - ETA: 1:48 - loss: 1.5109 - accuracy: 0.6201"
     ]
    }
   ],
   "source": [
    "\n",
    "winner = generational.best_individual['winner']\n",
    "fitness_cnn.verb = True\n",
    "print(p)\n",
    "score = fitness_cnn.calc(p, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100, cifar10\n",
    "\n",
    "data = cifar100.load_data()\n",
    "data2 = cifar10.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data), len(data2)\n",
    "len(data[1]), len(data2[1])\n",
    "type(data[0][0]), type(data2[0][0])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        print(data[i][j].shape, data2[i][j].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolve MRDBI 1 cells per block and 1 blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_folder = '../../exp_op_coding_VM3'\n",
    "\n",
    "experiments_folder = experiments_folder\n",
    "os.makedirs(experiments_folder, exist_ok=True)\n",
    "for dataset in datasets:\n",
    "    print(\"\\nEVOLVING IN DATASET %s ...\\n\" % dataset)\n",
    "    exp_folder = os.path.join(experiments_folder, dataset)\n",
    "    folder = os.path.join(exp_folder, 'genetic')\n",
    "    fitness_folder = exp_folder\n",
    "    fitness_file = os.path.join(fitness_folder, 'fitness_example')   \n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        generational = TwoLevelGA.load_genetic_algorithm(folder=folder)\n",
    "    except:\n",
    "        # Load data\n",
    "        dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder) #, max_examples=8000)\n",
    "        data = dm.load_data()\n",
    "        fitness_cnn.set_params(data=data, verbose=verbose, batch_size=batch_size, reduce_plateau=redu_plat,\n",
    "                       epochs=epochs, cosine_decay=cosine_dec, early_stop=early_stop, \n",
    "                       warm_epochs=warm_up_epochs, base_lr=base_lr, smooth_label=smooth, find_lr=lr_find,\n",
    "                       precise_epochs=precise_eps)\n",
    "\n",
    "        fitness_cnn.save(fitness_file)\n",
    "\n",
    "        del dm, data\n",
    "\n",
    "        fitness = FitnessCNNParallel()\n",
    "        fitness.set_params(chrom_files_folder=fitness_folder, fitness_file=fitness_file, max_gpus=gpus,\n",
    "                       fp=32, main_line=command)\n",
    "        generational = TwoLevelGA(chromosome=c,\n",
    "                                  fitness=fitness,\n",
    "                                  generations=generations,\n",
    "                                  population_first_level=population_first_level,\n",
    "                                  population_second_level=population_second_level,\n",
    "                                  training_hours=training_hours,\n",
    "                                  save_progress=save_progress,\n",
    "                                  maximize_fitness=maximize_fitness,\n",
    "                                  statistical_validation=statistical_validation,\n",
    "                                  folder=folder,\n",
    "                                  start_level2=start_level2,\n",
    "                                  frequency_second_level=frequency_second_level)\n",
    "        generational.print(\"Experiment with fitness calculation using mean of thee best val accuracies. \\\n",
    "                           \\nAlso using limited precision to dropout values\")\n",
    "\n",
    "        \n",
    "    ti_all = time()\n",
    "    winner, best_fit, ranking = generational.evolve()\n",
    "    print(\"Total elapsed time: %0.3f\" % (time() - ti_all))\n",
    "    print(\"Previous elapsed time: %s\" % \"Generation (24) in 1380.97 minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChromosomeOp.INITIAL_FILTERS = 64\n",
    "#ChromosomeOp.CELLS_PER_BLOCK = 1\n",
    "#ChromosomeOp.N_BLOCKS = 1\n",
    "winner = generational.best_individual['winner']\n",
    "fitness_cnn.precise_epochs = 75\n",
    "fitness_cnn.verb = True\n",
    "fitness_cnn.smooth = 0.1\n",
    "fitness_cnn.learning_rate_base = 0.02\n",
    "score = generational.fitness_evaluator.calc(winner, test=True, precise_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in generational.best_individual.items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    print()\n",
    "print(winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution with 2 cells per block and 2 blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['cifar10']\n",
    "experiments_folder = '../../exp_op_coding'\n",
    "\n",
    "experiments_folder = experiments_folder\n",
    "os.makedirs(experiments_folder, exist_ok=True)\n",
    "for dataset in datasets:\n",
    "    print(\"\\nEVOLVING IN DATASET %s ...\\n\" % dataset)\n",
    "    exp_folder = os.path.join(experiments_folder, dataset)\n",
    "    folder = os.path.join(exp_folder, 'genetic')\n",
    "    fitness_folder = exp_folder\n",
    "    fitness_file = os.path.join(fitness_folder, 'fitness_example')   \n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        generational = TwoLevelGA.load_genetic_algorithm(folder=folder)\n",
    "    except:\n",
    "        # Load data\n",
    "        dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder) #, max_examples=8000)\n",
    "        data = dm.load_data()\n",
    "        fitness_cnn.set_params(data=data, verbose=verbose, batch_size=batch_size, reduce_plateau=redu_plat,\n",
    "                       epochs=epochs, cosine_decay=cosine_dec, early_stop=early_stop, \n",
    "                       warm_epochs=warm_up_epochs, base_lr=base_lr, smooth_label=smooth, find_lr=lr_find,\n",
    "                       precise_epochs=precise_eps)\n",
    "\n",
    "        fitness_cnn.save(fitness_file)\n",
    "\n",
    "        del dm, data\n",
    "\n",
    "        fitness = FitnessCNNParallel()\n",
    "        fitness.set_params(chrom_files_folder=fitness_folder, fitness_file=fitness_file, max_gpus=gpus,\n",
    "                       fp=32, main_line=command)\n",
    "        generational = TwoLevelGA(chromosome=c,\n",
    "                                  fitness=fitness,\n",
    "                                  generations=generations,\n",
    "                                  population_first_level=population_first_level,\n",
    "                                  population_second_level=population_second_level,\n",
    "                                  training_hours=training_hours,\n",
    "                                  save_progress=save_progress,\n",
    "                                  maximize_fitness=maximize_fitness,\n",
    "                                  statistical_validation=statistical_validation,\n",
    "                                  folder=folder,\n",
    "                                  start_level2=start_level2,\n",
    "                                  frequency_second_level=frequency_second_level)\n",
    "        \n",
    "    print(generational.generation)\n",
    "    print(generational.num_generations)\n",
    "    if generational.generation < generational.num_generations:\n",
    "        winner, best_fit, ranking = generational.evolve()\n",
    "    print(\"Total elapsed time: %0.3f\" % (time() - ti_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generational.best_individual['winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "num_clases = 100 if dataset == 'cifar100' else 10\n",
    "dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder, num_clases=num_clases) #, max_examples=8000)\n",
    "data = dm.load_data()\n",
    "fitness_cnn.set_params(data=data, verbose=verbose, batch_size=batch_size, reduce_plateau=redu_plat,\n",
    "               epochs=epochs, cosine_decay=cosine_dec, early_stop=early_stop, \n",
    "               warm_epochs=warm_up_epochs, base_lr=base_lr, smooth_label=smooth, find_lr=lr_find,\n",
    "               precise_epochs=precise_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChromosomeOp.INITIAL_FILTERS = 45\n",
    "ChromosomeOp.CELLS_PER_BLOCK = 2\n",
    "ChromosomeOp.N_BLOCKS = 2\n",
    "winner = generational.best_individual['winner']\n",
    "fitness_cnn.precise_epochs = 75\n",
    "fitness_cnn.verb = True\n",
    "fitness_cnn.smooth = 0.1\n",
    "fitness_cnn.learning_rate_base = 0.05\n",
    "fitness_cnn.batch_size= 128\n",
    "score = fitness_cnn.calc(winner, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generational.training_hours = 48\n",
    "ti_all = time()\n",
    "winner, best_fit, ranking = generational.evolve()\n",
    "print(\"Total elapsed time: %0.3f\" % (time() - ti_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking1 = generational.evaluate_population(level=1)\n",
    "ranking2 = generational.evaluate_population(level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fitness_cnn.precise_epochs = 75\n",
    "fitness_cnn.verb = True\n",
    "fitness_cnn.smooth = 0.1\n",
    "fitness_cnn.learning_rate_base = 0.05\n",
    "score = fitness_cnn.calc(winner, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = generational.best_individual['winner']\n",
    "ChromosomeOp.INITIAL_FILTERS = 45\n",
    "ChromosomeOp.CELLS_PER_BLOCK = 2\n",
    "ChromosomeOp.N_BLOCKS = 2\n",
    "\n",
    "fitness_cnn.precise_epochs = 75\n",
    "score = fitness_cnn.calc(winner, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = generational.best_individual['winner']\n",
    "ChromosomeOp.INITIAL_FILTERS = 45\n",
    "ChromosomeOp.CELLS_PER_BLOCK = 2\n",
    "ChromosomeOp.N_BLOCKS = 2\n",
    "\n",
    "fitness_cnn.precise_epochs = 108\n",
    "score = fitness_cnn.calc(winner, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution with 1 cell per block and 1 block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_folder = '../../exp_op_coding2'\n",
    "experiments_folder = experiments_folder\n",
    "os.makedirs(experiments_folder, exist_ok=True)\n",
    "for dataset in datasets:\n",
    "    print(\"\\nEVOLVING IN DATASET %s ...\\n\" % dataset)\n",
    "    exp_folder = os.path.join(experiments_folder, dataset)\n",
    "    folder = os.path.join(exp_folder, 'genetic')\n",
    "    fitness_folder = exp_folder\n",
    "    fitness_file = os.path.join(fitness_folder, 'fitness_example')   \n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        generational = TwoLevelGA.load_genetic_algorithm(folder=folder)\n",
    "        break\n",
    "    except:\n",
    "        # Load data\n",
    "        dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder) #, max_examples=8000)\n",
    "        data = dm.load_data()\n",
    "        fitness_cnn.set_params(data=data, verbose=verbose, batch_size=batch_size, reduce_plateau=redu_plat,\n",
    "                       epochs=epochs, cosine_decay=cosine_dec, early_stop=early_stop, \n",
    "                       warm_epochs=warm_up_epochs, base_lr=base_lr, smooth_label=smooth, find_lr=lr_find,\n",
    "                       precise_epochs=precise_eps)\n",
    "\n",
    "        fitness_cnn.save(fitness_file)\n",
    "\n",
    "        del dm, data\n",
    "\n",
    "        fitness = FitnessCNNParallel()\n",
    "        fitness.set_params(chrom_files_folder=fitness_folder, fitness_file=fitness_file, max_gpus=gpus,\n",
    "                       fp=32, main_line=command)\n",
    "        generational = TwoLevelGA(chromosome=c,\n",
    "                                  fitness=fitness,\n",
    "                                  generations=generations,\n",
    "                                  population_first_level=population_first_level,\n",
    "                                  population_second_level=population_second_level,\n",
    "                                  training_hours=training_hours,\n",
    "                                  save_progress=save_progress,\n",
    "                                  maximize_fitness=maximize_fitness,\n",
    "                                  statistical_validation=statistical_validation,\n",
    "                                  folder=folder,\n",
    "                                  start_level2=start_level2,\n",
    "                                  frequency_second_level=frequency_second_level)\n",
    "        \n",
    "    ti_all = time()\n",
    "    winner, best_fit, ranking = generational.evolve()\n",
    "    print(\"Total elapsed time: %0.3f\" % (time() - ti_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generational.ti/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder) #, max_examples=8000)\n",
    "data = dm.load_data()\n",
    "fitness_cnn.set_params(data=data, verbose=verbose, batch_size=batch_size, reduce_plateau=redu_plat,\n",
    "                       epochs=epochs, cosine_decay=cosine_dec, early_stop=early_stop, \n",
    "                       warm_epochs=warm_up_epochs, base_lr=base_lr, smooth_label=smooth, find_lr=lr_find,\n",
    "                       precise_epochs=precise_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_cnn.verb = True\n",
    "fitness_cnn.precise_epochs = 75\n",
    "\n",
    "w = generational.best_individual['winner']\n",
    "w_copy = w.self_copy()\n",
    "for block in w_copy.blocks:\n",
    "    for op in block.ops:\n",
    "        if op.type() == 'CNN':\n",
    "            op.k_size = 3\n",
    "\n",
    "print(w)\n",
    "print(w_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# ChromosomeOp.INITIAL_FILTERS = 45\n",
    "ChromosomeOp.CELLS_PER_BLOCK = 1\n",
    "ChromosomeOp.N_BLOCKS = 1\n",
    "\n",
    "score = fitness_cnn.calc(w_copy, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generational.best_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChromosomeOp.INITIAL_FILTERS = 45\n",
    "ChromosomeOp.CELLS_PER_BLOCK = 1\n",
    "ChromosomeOp.N_BLOCKS = 2\n",
    "\n",
    "score = fitness_cnn.calc(w_copy, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChromosomeOp.INITIAL_FILTERS = 45\n",
    "ChromosomeOp.CELLS_PER_BLOCK = 1\n",
    "ChromosomeOp.N_BLOCKS = 3\n",
    "\n",
    "score = fitness_cnn.calc(w_copy, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChromosomeOp.INITIAL_FILTERS = 45\n",
    "ChromosomeOp.CELLS_PER_BLOCK = 1\n",
    "ChromosomeOp.N_BLOCKS = 4\n",
    "\n",
    "score = fitness_cnn.calc(w_copy, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChromosomeOp.INITIAL_FILTERS = 32\n",
    "ChromosomeOp.CELLS_PER_BLOCK = 1\n",
    "ChromosomeOp.N_BLOCKS = 3\n",
    "\n",
    "score = fitness_cnn.calc(w_copy, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution with 1 cells per block and 3 blocks, but 45 filters\n",
    "##### (and possible kernel sizes: 1, 3 and 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_folder = '../../exp_op_coding3'\n",
    "experiments_folder = experiments_folder\n",
    "os.makedirs(experiments_folder, exist_ok=True)\n",
    "for dataset in datasets:\n",
    "    print(\"\\nEVOLVING IN DATASET %s ...\\n\" % dataset)\n",
    "    exp_folder = os.path.join(experiments_folder, dataset)\n",
    "    folder = os.path.join(exp_folder, 'genetic')\n",
    "    fitness_folder = exp_folder\n",
    "    fitness_file = os.path.join(fitness_folder, 'fitness_example')   \n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        generational = TwoLevelGA.load_genetic_algorithm(folder=folder)\n",
    "        break\n",
    "    except:\n",
    "        # Load data\n",
    "        dm = DataManager(dataset, clases=classes, folder_var_mnist=data_folder) #, max_examples=8000)\n",
    "        data = dm.load_data()\n",
    "        fitness_cnn.set_params(data=data, verbose=verbose, batch_size=batch_size, reduce_plateau=redu_plat,\n",
    "                       epochs=epochs, cosine_decay=cosine_dec, early_stop=early_stop, \n",
    "                       warm_epochs=warm_up_epochs, base_lr=base_lr, smooth_label=smooth, find_lr=lr_find,\n",
    "                       precise_epochs=precise_eps)\n",
    "        fitness_cnn.save(fitness_file)\n",
    "\n",
    "        del dm, data\n",
    "\n",
    "        fitness = FitnessCNNParallel()\n",
    "        fitness.set_params(chrom_files_folder=fitness_folder, fitness_file=fitness_file, max_gpus=gpus,\n",
    "                       fp=32, main_line=command)\n",
    "        generational = TwoLevelGA(chromosome=c,\n",
    "                                  fitness=fitness,\n",
    "                                  generations=generations,\n",
    "                                  population_first_level=population_first_level,\n",
    "                                  population_second_level=population_second_level,\n",
    "                                  training_hours=training_hours,\n",
    "                                  save_progress=save_progress,\n",
    "                                  maximize_fitness=maximize_fitness,\n",
    "                                  statistical_validation=statistical_validation,\n",
    "                                  folder=folder,\n",
    "                                  start_level2=start_level2,\n",
    "                                  frequency_second_level=frequency_second_level)\n",
    "        \n",
    "    ti_all = time()\n",
    "    winner, best_fit, ranking = generational.evolve()\n",
    "    print(\"Total elapsed time: %0.3f\" % (time() - ti_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChromosomeOp.CELLS_PER_BLOCK = 1\n",
    "ChromosomeOp.N_BLOCKS = 3\n",
    "\n",
    "fitness_cnn.precise_epochs = 200\n",
    "fitness_cnn.verb = True\n",
    "score = fitness_cnn.calc(winner, test=True, precise_mode=True, augmnt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generational.paint\n",
    "generational.filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "780/60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-4-027ed6f62034>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-027ed6f62034>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a = 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
