{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import  Model\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, PReLU, LeakyReLU\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from time import time\n",
    "import time as T\n",
    "import traceback\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from GA.geneticAlgorithm import GenerationalGA\n",
    "from GA.parentSelector.parentSelector import RandomParentSelector, LinealOrder, TournamentSelection\n",
    "from GA.parentSelector.parentSelector import WheelSelection, LinealOrderII\n",
    "from utils.datamanager import DataManager\n",
    "#import tensorflow as tf\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, units=128, activation='relu', dropout=0):\n",
    "        self.units = units\n",
    "        self.posible_activations = ['relu', 'sigmoid', 'tanh', 'elu', 'prelu', 'leakyreLu']\n",
    "        assert activation in self.posible_activations\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.units_lim = 1024\n",
    "        self.units_prob = 0.2\n",
    "        self.act_prob = 0.2\n",
    "        self.drop_prob = 0.2\n",
    "\n",
    "    def cross(self, other_layer):\n",
    "        new_units = self.cross_units(other_layer.units)\n",
    "        new_activation = self.cross_activation(other_layer.activation)\n",
    "        new_dropout = self.cross_dropout(other_layer.dropout)\n",
    "        return Layer(new_units, new_activation, new_dropout)\n",
    "\n",
    "    def cross_activation(self, other_activation):\n",
    "        if np.random.rand() > 0.5:\n",
    "            return self.activation\n",
    "        return other_activation\n",
    "\n",
    "    def cross_dropout(self, other_dropout):\n",
    "        b = np.random.rand()\n",
    "        return self.dropout * (1 - b) + b * other_dropout\n",
    "\n",
    "    def cross_units(self, other_units):\n",
    "        b = np.random.rand()\n",
    "        return int(self.units * (1 - b) + other_units * b)\n",
    "\n",
    "    def mutate(self):\n",
    "        aleatory = np.random.rand(4)\n",
    "        if aleatory[0] < self.units_prob:\n",
    "            self.units = np.random.randint(0, self.units_lim)\n",
    "        if aleatory[1] < self.act_prob:\n",
    "            self.activation = random.choice(self.posible_activations)\n",
    "        if aleatory[2] < self.drop_prob:\n",
    "            self.dropout = np.random.rand()\n",
    "\n",
    "    def compare(self, other_layer):\n",
    "        if self.units != other_layer.units:\n",
    "            return False\n",
    "        if self.activation != other_layer.activation:\n",
    "            return False\n",
    "        if self.dropout != other_layer.dropout:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def self_copy(self):\n",
    "        return Layer(self.units, self.activation, self.dropout)\n",
    "\n",
    "    def random_layer(self):\n",
    "        units = np.random.randint(0, self.units_lim)\n",
    "        act = random.choice(self.posible_activations)\n",
    "        drop = np.random.rand()\n",
    "        return Layer(units, act, drop)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"U:%d|A:%s|D:%0.3f\" % (self.units, self.activation, self.dropout)\n",
    "\n",
    "\n",
    "class Cromosome(object):\n",
    "\n",
    "    def __init__(self, layers=[], fit=None):\n",
    "        assert type(layers) == list\n",
    "        self.n_layers = len(layers)\n",
    "        self.layers = layers\n",
    "        self.max_layers = 10\n",
    "        self.layer_prob = 0.1\n",
    "        self.fit = None\n",
    "        self.evaluator = Fitness.get_instance()\n",
    "\n",
    "    def set_fitness(self, fit):\n",
    "        self.evaluator = fit\n",
    "\n",
    "    def random_indiv(self):\n",
    "        n_layers = np.random.randint(0, self.max_layers)\n",
    "        layers = [Layer().random_layer() for i in range(n_layers)]\n",
    "        return Cromosome(layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def simple_indiv():\n",
    "        return Cromosome([Layer()])\n",
    "\n",
    "    def cross(self, other_cromosome):\n",
    "        new_layers = []\n",
    "\n",
    "        if self.n_layers == 0:\n",
    "            return other_cromosome\n",
    "\n",
    "        n_intersection = np.random.randint(0, self.n_layers)\n",
    "        for i in range(self.n_layers):\n",
    "            if i < n_intersection or i >= other_cromosome.n_layers:\n",
    "                new_layers.append(self.layers[i].self_copy())\n",
    "            else:\n",
    "                try:\n",
    "                    new_layers.append(self.layers[i].cross(other_cromosome.layers[i - n_intersection]))\n",
    "                except IndexError:\n",
    "                    print(\"Problem with index %d\" % i)\n",
    "                    print(\"Intersection point at %d\" % n_intersection)\n",
    "                    print(len(self.layers), self.layers)\n",
    "                    print(len(other_cromosome.layers), other_cromosome.layers)\n",
    "                    print(len(new_layers), new_layers)\n",
    "                    raise IndexError\n",
    "        return Cromosome(new_layers)\n",
    "\n",
    "    def mutate(self):\n",
    "        for i in range(self.n_layers):\n",
    "            self.layers[i].mutate()\n",
    "        if np.random.rand() < self.layer_prob and self.n_layers < self.max_layers:\n",
    "            self.layers.append(Layer().random_layer())\n",
    "            self.n_layers = len(self.layers)\n",
    "\n",
    "    def equals(self, other_cromosome):\n",
    "        if self.n_layers != other_cromosome.n_layers:\n",
    "            return False\n",
    "        for i in range(self.n_layers):\n",
    "            if not self.layers[i].compare(other_cromosome.layers[i]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def __repr__(self):\n",
    "        rep = \"\"\n",
    "        for i in range(self.n_layers):\n",
    "            rep += \"%d - %s \\n\" % (i, self.layers[i])\n",
    "        return rep\n",
    "\n",
    "    def fitness(self):\n",
    "        return self.evaluator.calc(self)\n",
    "\n",
    "\n",
    "class Fitness:\n",
    "    __instance = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_instance():\n",
    "        \"\"\" Static access method. \"\"\"\n",
    "        if Fitness.__instance == None:\n",
    "            Fitness()\n",
    "        return Fitness.__instance\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Virtually private constructor. \"\"\"\n",
    "        if Fitness.__instance != None:\n",
    "            raise Exception(\"This class is a singleton!\")\n",
    "        else:\n",
    "            Fitness.__instance = self\n",
    "\n",
    "    def set_params(self, data, batch_size=128, epochs=100, early_stop=True, reduce_plateau=True, verbose=1,\n",
    "                  reset=True, test=False):\n",
    "        self.reset = reset\n",
    "        self.test =test\n",
    "        self.time = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.early_stop = early_stop\n",
    "        self.reduce_plateu = reduce_plateau\n",
    "        self.verb = verbose\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test), (self.x_val, self.y_val) = data\n",
    "        self.num_clases = self.y_train.shape[1]\n",
    "        self.callbacks = []\n",
    "        if self.early_stop and keras.__version__=='2.2.4':\n",
    "            #self.run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "            self.callbacks.append(EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True))\n",
    "        elif self.early_stop:\n",
    "            self.callbacks.append(EarlyStopping(monitor='val_acc', patience=10))\n",
    "        if self.reduce_plateu:\n",
    "            self.callbacks.append(ReduceLROnPlateau(monitor='val_acc', factor=0.2, \n",
    "                                                    patience=5, verbose=self.verb))\n",
    "        return self\n",
    "\n",
    "    def calc(self, chromosome):\n",
    "        try:\n",
    "            ti = time()\n",
    "            if self.reset:\n",
    "                keras.backend.clear_session()\n",
    "            model = self.decode(chromosome)\n",
    "            h = model.fit(self.x_train, self.y_train,\n",
    "                              batch_size=self.batch_size,\n",
    "                              epochs=self.epochs,\n",
    "                              verbose=self.verb,\n",
    "                              validation_data=(self.x_val, self.y_val),\n",
    "                              callbacks=self.callbacks)\n",
    "            score = model.evaluate(self.x_val, self.y_val, verbose=0)\n",
    "            if self.test:\n",
    "                score_t = model.evaluate(self.x_test, self.y_test, verbose=0)\n",
    "        except Exception as e:\n",
    "            score = [0,0]\n",
    "            score_t = [0,0]\n",
    "            print(\"Some Error with gen:\")\n",
    "            print(chromosome)\n",
    "            logging.error(traceback.format_exc())\n",
    "            keras.backend.clear_session()\n",
    "        if self.verb:\n",
    "            print('Val loss: %0.4f, Val acc: %0.4f' % (score[0], score[1]))\n",
    "            if self.test:\n",
    "                print('Test loss: %0.4f, Test acc: %0.4f' % (score_t[1], score_t[1]))\n",
    "            self.show_result(h, 'acc')\n",
    "            self.show_result(h, 'loss')\n",
    "        self.time += time() - ti\n",
    "        return score[1]\n",
    "\n",
    "    def decode(self, chromosome):\n",
    "\n",
    "        inp = Input(shape=(28, 28, 1))\n",
    "        x = Flatten()(inp)\n",
    "        for i in range(chromosome.n_layers):\n",
    "            act = chromosome.layers[i].activation\n",
    "            if act in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
    "                x = Dense(chromosome.layers[i].units, activation=act)(x)\n",
    "            elif act == 'prelu':\n",
    "                x = Dense(chromosome.layers[i].units)(x)\n",
    "                x = PReLU()(x)\n",
    "            else:\n",
    "                x = Dense(chromosome.layers[i].units)(x)\n",
    "                x = LeakyReLU()(x)\n",
    "            x = Dropout(chromosome.layers[i].dropout)(x)\n",
    "        x = Dense(self.num_clases, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        if self.verb:\n",
    "            model.summary()\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "                      #options = self.run_opts)\n",
    "        return model\n",
    "\n",
    "    def show_result(self, history, metric='acc'):\n",
    "        epochs = np.linspace(0, len(history.history['acc']) - 1, len(history.history['acc']))\n",
    "        plt.plot(epochs, history.history['val_%s' % metric], label='validation')\n",
    "        plt.plot(epochs, history.history[metric], label='train')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(metric)\n",
    "        plt.show()\n",
    "\n",
    "    def calc_mean(self, chromosome, iters=5):\n",
    "        f = []\n",
    "        ti = time()\n",
    "        for i in range(iters):\n",
    "            f.append(self.calc(chromosome))\n",
    "        print(\"Acc: %0.3f\" % np.mean(f), np.std(f), np.max(f))\n",
    "        print(\"Time elapsed: %0.3f\" % (time() - ti))\n",
    "        \n",
    "    def fitness_N_models(self, c1, c2):\n",
    "        from keras.layers.core import Activation\n",
    "        def decode_C(chromosome, inp, name=''):\n",
    "            x = Flatten()(inp)\n",
    "            for i in range(chromosome.n_layers):\n",
    "                act = chromosome.layers[i].activation\n",
    "                if act in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
    "                    x = Dense(chromosome.layers[i].units, activation=act)(x)\n",
    "                elif act == 'prelu':\n",
    "                    x = Dense(chromosome.layers[i].units)(x)\n",
    "                    x = PReLU()(x)\n",
    "                else:\n",
    "                    x = Dense(chromosome.layers[i].units)(x)\n",
    "                    x = LeakyReLU()(x)\n",
    "                x = Dropout(chromosome.layers[i].dropout)(x)\n",
    "            x = Dense(self.num_clases, activation='softmax', name=name)(x)\n",
    "            return x\n",
    "        \n",
    "        inputs = Input(shape=(28, 28, 1))\n",
    "        model = Model(inputs=inputs, outputs=[decode_C(c1, inputs,'x1'), decode_C(c2, inputs,'x2')],\n",
    "                        name=\"all_net\")\n",
    "        losses = {'x1':\"categorical_crossentropy\", 'x2':\"categorical_crossentropy\"}\n",
    "        metrics = {'x1': 'accuracy',\n",
    "                   'x2': 'accuracy'}\n",
    "        model.compile(optimizer=Adam(), loss=losses, metrics=metrics)\n",
    "        model.summary()\n",
    "        model.fit(self.x_train, [self.y_train, self.y_train],\n",
    "                  batch_size=self.batch_size,\n",
    "                  epochs=self.epochs,\n",
    "                  verbose=self.verb,\n",
    "                  validation_data=(self.x_val, [self.y_val, self.y_val]))\n",
    "                  #callbacks=self.callbacks)\n",
    "        score = model.evaluate(self.x_val, [self.y_val, self.y_val], verbose=1)\n",
    "        return score\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Layer(516, 'relu', 0.2)\n",
    "l2 = Layer(516, 'relu', 0.2)\n",
    "c = Cromosome([l, l2])\n",
    "\n",
    "ps = {'random':RandomParentSelector(), 'lineal':LinealOrder(), 'wheel':WheelSelection(), \n",
    "      'tournament':TournamentSelection(5)}\n",
    "\n",
    "# dataset params:\n",
    "dataset = 'mnist'\n",
    "classes = []\n",
    "\n",
    "# genetci algorithm params:\n",
    "parents_selector_key = 'wheel'\n",
    "num_parents = 0.3\n",
    "generations = 40\n",
    "population = 15\n",
    "train_time = 11\n",
    "\n",
    "# Fitness params\n",
    "epochs = 50\n",
    "maximize_fit = True\n",
    "reset= True\n",
    "verbose = 0\n",
    "redu_plat = False\n",
    "test = True\n",
    "early_stop = True\n",
    "\n",
    "# Load data\n",
    "dm = DataManager(dataset, clases=classes)\n",
    "data = dm.load_data()\n",
    "fitness = Fitness.get_instance()\n",
    "fitness.set_params(data, verbose=verbose, reduce_plateau=redu_plat, \n",
    "                   epochs=epochs, reset=reset, early_stop=early_stop)\n",
    "p = ps[parents_selector_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_all = time()\n",
    "generational = GenerationalGA(num_parents=num_parents, chromosome=c, parent_selector=p, generations=generations,\n",
    "                              num_population=population, crossover_prob=0.5, mutation_prob=0.7,\n",
    "                              maximize_fitness=maximize_fit, training_hours=train_time)\n",
    "winner, best_fit, ranking = generational.evolve()\n",
    "print(\"Total elapsed time: %0.3f\" % (time() - ti_all))\n",
    "print(\"Total training time: %0.3f\" % fitness.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c.fitness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness.fitness_N_models(c, c)\n",
    "print(\"Training time: %0.3f\" % fitness.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_measure(chrom, iters=50):\n",
    "    \n",
    "    times = []\n",
    "    for i in range(iters):\n",
    "        ti = time()\n",
    "        c.fitness()\n",
    "        times.append(time() - ti)\n",
    "    return times\n",
    "\n",
    "l = Layer(516, 'relu', 0.2)\n",
    "l2 = Layer(516, 'relu', 0.2)\n",
    "c = Cromosome([l, l2])\n",
    "\n",
    "\n",
    "# params:\n",
    "dataset = 'mnist'\n",
    "classes = [4, 9]\n",
    "epochs = 2\n",
    "\n",
    "# Load data\n",
    "dm = DataManager(dataset, clases=classes)\n",
    "data = dm.load_data()\n",
    "fitness = Fitness.get_instance()\n",
    "fitness.set_params(data, verbose=0, reduce_plateau=False, epochs=epochs, reset=True)\n",
    "\n",
    "t_with_reset = time_measure(c)\n",
    "print(\"mean time:\\t%0.3f\\nstd:\\t%0.3f\" % (np.mean(t_with_reset), np.std(t_with_reset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness.set_params(data, verbose=0, reduce_plateau=False, epochs=epochs, reset=False)\n",
    "\n",
    "t_without_reset = time_measure(c)\n",
    "print(\"mean time:\\t%0.3f\\nstd:\\t%0.3f\" % (np.mean(t_without_reset), np.std(t_without_reset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "t_value, p_value = stats.ttest_ind(t_without_reset, t_with_reset)\n",
    "print(\"T-value: %0.3f \" % t_value)\n",
    "print(\"P-value: %0.3f \" % p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = {'random':RandomParentSelector(), 'lineal':LinealOrder(), 'wheel':WheelSelection(), \n",
    "      'tournament':TournamentSelection(5)}\n",
    "\n",
    "# params:\n",
    "dataset = 'fashion_mnist'\n",
    "classes = [0, 1, 2]\n",
    "parents_selector_key = 'wheel'\n",
    "num_parents = 0.3\n",
    "generations = 30\n",
    "population = 10\n",
    "maximize_fit = True\n",
    "\n",
    "# Load data\n",
    "dm = DataManager(dataset, clases=classes)\n",
    "data = dm.load_data()\n",
    "fitness = Fitness.get_instance()\n",
    "fitness.set_params(data, verbose=0, reduce_plateau=False)\n",
    "\n",
    "p = ps[parents_selector_key]\n",
    "\n",
    "ti_all = time()\n",
    "generational = GenerationalGA(num_parents=num_parents, chromosome=c, parent_selector=p, generations=generations,\n",
    "                              num_population=population, crossover_prob=0.5, mutation_prob=0.7,\n",
    "                              maximize_fitness=maximize_fit)\n",
    "winner, best_fit, ranking = generational.evolve()\n",
    "print(\"Total elapsed time: %0.3f\" % (time() - ti_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, N_participants=3):\n",
    "        self.N = N_participants\n",
    "        self.history_fitness = {}\n",
    "        \n",
    "    def set_params(self,maximize, history):\n",
    "        self.maximize = maximize\n",
    "        self.history_fitness = history\n",
    "        \n",
    "    def eval_individual(self, chrom):\n",
    "        gen = chrom.__repr__()\n",
    "        if gen not in self.history_fitness.keys():\n",
    "            self.history_fitness[gen] = chrom.fitness()\n",
    "        elif chrom.fit is None:\n",
    "            chrom.fit = self.history_fitness[gen]\n",
    "        return chrom.fit\n",
    "    \n",
    "    def get_one_offspring(self, population):\n",
    "        idxs = np.linspace(0, len(population) - 1, len(population)).astype(np.int32)\n",
    "        idxs_perm = np.random.permutation(idxs)\n",
    "        participants_1 = [population[idxs_perm[i]] for i in range(self.N)]\n",
    "        participants_2 = [population[idxs_perm[-i]] for i in range(1, self.N + 1)]\n",
    "        win_1 = np.argmax([self.eval_individual(chrom) for chrom in participants_1])\n",
    "        win_2 = np.argmax([self.eval_individual(chrom) for chrom in participants_2])\n",
    "        parent1 = participants_1[win_1]\n",
    "        parent2 = participants_2[win_2]\n",
    "        offspring = parent1.cross(parent2)\n",
    "        offspring.mutate()\n",
    "        self.eval_individual(offspring)\n",
    "        return offspring, (parent1, parent2)\n",
    "        \n",
    "    def next_gen(self, population, num_offspring=1):\n",
    "        next_generation = []\n",
    "        all_parents = []\n",
    "        for n in range(num_offspring):\n",
    "            print(len(population))\n",
    "            offspring, parents = self.get_one_offspring(population)\n",
    "            next_generation.append(offspring)\n",
    "            all_parents.append(parents)\n",
    "        return next_generation, all_parents\n",
    "    \n",
    "class B:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.fit = self.n\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.n)\n",
    "\n",
    "    def fitness(self):\n",
    "        return self.n\n",
    "    \n",
    "    def cross(self, aB):\n",
    "        return B(np.mean([self.n, aB.n]))\n",
    "    \n",
    "    def mutate(self):\n",
    "        self.n += np.random.rand()*0\n",
    "        \n",
    "a = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "b = [B(aux) for aux in a]\n",
    "a_ = LinealOrder()\n",
    "next_generation, all_parents = a_.next_gen(b, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chromosome to minimize the fuction:\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = x \\cdot sin(4x) + 1.1  y \\cdot sin(2y)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class chrom:\n",
    "    def __init__(self, x=0, y=0, mutation_prob=0.2):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mut_prob = mutation_prob\n",
    "        self.fit = None\n",
    "    \n",
    "    def set_fitness(self, fit):\n",
    "        self.evaluator = fit\n",
    "        \n",
    "    def random_indiv(self):\n",
    "        x = 10 * np.random.rand()\n",
    "        y = 10 * np.random.rand()\n",
    "        return chrom(x, y)\n",
    "    \n",
    "    def simple_indiv(self):\n",
    "        return chrom(0, 0)\n",
    "        \n",
    "    def cross(self, other_cromosome):\n",
    "        bx = np.random.rand()\n",
    "        by = np.random.rand()\n",
    "        x = bx * self.x + (1 - bx) * other_cromosome.x\n",
    "        y = by * self.y + (1 - by) * other_cromosome.y\n",
    "        return chrom(x, y)\n",
    "        \n",
    "    \n",
    "    def mutate(self):\n",
    "        if np.random.rand() < self.mut_prob:\n",
    "            self.x = 10 * np.random.rand()\n",
    "        if np.random.rand() < self.mut_prob:\n",
    "            self.y = 10 * np.random.rand()\n",
    "            \n",
    "    def equals(self, other_cromosome):\n",
    "        return (self.x == other_cromosome.x) and (self.y == other_cromosome.y)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"(%0.3f, %0.3f)\" % (self.x, self.y)\n",
    "    \n",
    "    def fitness(self):\n",
    "        self.fit = self.x * np.sin(4 * self.x) + 1.1 * self.y * np.sin(2 * self.y)\n",
    "        return self.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 12\n",
    "mut_prob = 0.2\n",
    "generations = 100\n",
    "num_parents = 0.5\n",
    "\n",
    "c = chrom(mutation_prob=mut_prob)\n",
    "ps = [RandomParentSelector(), LinealOrder(), LinealOrderII(), WheelSelection(), TournamentSelection(5)]\n",
    "p = ps[2]\n",
    "generational = GenerationalGA(num_parents=num_parents, chromosome=c, parent_selector=p, generations=generations,\n",
    "                              num_population=pop_size, crossover_prob=0.5,\n",
    "                              mutation_prob=0.7, maximize_fitness=False, save_pop=True)\n",
    "\n",
    "winner, best_fit, ranking = generational.evolve(show=False)\n",
    "print(best_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "from matplotlib import ticker, cm\n",
    "\n",
    "N = 1000\n",
    "x = np.linspace(0, 10.0, N)\n",
    "y = np.linspace(0, 10.0, N)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "z = X * np.sin(4 * X) + 1.1 * Y * np.sin(2 * Y) \n",
    "print(np.min(z), np.max(z))\n",
    "z += np.abs(np.min(z))\n",
    "min_z = np.min(z)\n",
    "max_z = np.max(z)\n",
    "max_idxs = []\n",
    "min_idxs = []\n",
    "for i in range(N):\n",
    "    for k in range(N):\n",
    "        if z[i, k] == min_z:\n",
    "            min_idxs.append((i, k))\n",
    "        elif z[i, k] == max_z:\n",
    "            max_idxs.append((i, k))\n",
    "\n",
    "# The following is not strictly essential, but it will eliminate\n",
    "# a warning.  Comment it out to see the warning.\n",
    "#z = ma.masked_where(z <= 0, z)\n",
    "\n",
    "\n",
    "# Automatic selection of levels works; setting the\n",
    "# log locator tells contourf to use a log scale:\n",
    "fig, ax = plt.subplots()\n",
    "cs = ax.contourf(X, Y, z, cmap=cm.PuBu_r, alpha = 0.7)\n",
    "for i, k in max_idxs:\n",
    "    continue\n",
    "    plt.scatter(x[k], y[i], c='r', label='max', s=20)\n",
    "for i, k in min_idxs:\n",
    "    plt.scatter(x[k], y[i], c='k', label='min', s=50, marker='x')\n",
    "# Alternatively, you can manually set the levels\n",
    "# and the norm:\n",
    "# lev_exp = np.arange(np.floor(np.log10(z.min())-1),\n",
    "#                    np.ceil(np.log10(z.max())+1))\n",
    "# levs = np.power(10, lev_exp)\n",
    "# cs = ax.contourf(X, Y, z, levs, norm=colors.LogNorm())\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Fitness')\n",
    "ax.set_ylim((np.min(Y), np.max(Y)))\n",
    "cbar = fig.colorbar(cs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = generational.population_history\n",
    "def scatter_pop(h, generation, ax):\n",
    "    for p in h[generation]:\n",
    "        ax.scatter(p.x, p.y, c='g', label='min', s=100)\n",
    "        \n",
    "print(len(h), generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set_xlim((np.min(X), np.max(X)))\n",
    "ax.set_ylim((np.min(Y), np.max(Y)))\n",
    "cs = ax.contourf(X, Y, z, cmap=cm.PuBu_r, alpha = 0.7)\n",
    "for i, k in min_idxs:\n",
    "    plt.scatter(x[k], y[i], c='k', label='min', s=100, marker='x')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "title = ax.set_title('')\n",
    "plt.close(fig)\n",
    "            \n",
    "def animate2(i):\n",
    "    ax.cla()\n",
    "    ax.set_title('generation %s' % str(i).zfill(4))\n",
    "    cs = ax.contourf(X, Y, z, cmap=cm.PuBu_r, alpha = 0.7)\n",
    "    for i_, k_ in min_idxs:\n",
    "        ax.scatter(x[k_], y[i_], c='k', label='min', s=100, marker='x')\n",
    "    ax.set_xlim((np.min(X), np.max(X)))\n",
    "    ax.set_ylim((np.min(Y), np.max(Y)))\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    scatter_pop(h, i, ax)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = animation.FuncAnimation(fig,\n",
    "                               animate2,\n",
    "                               init_func=None,\n",
    "                               frames=generations,\n",
    "                               interval=100000)\n",
    "\n",
    "# Set up formatting for the movie files\n",
    "Writer = animation.writers['imagemagick']\n",
    "writer = Writer(fps=5, metadata=dict(artist='Me'), bitrate=1800)\n",
    "anim.save('/home/daniel/proyectos/Tesis/project/GA/NeuroEvolution/anim2.gif', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())\n",
    "\n",
    "animation.FuncAnimation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 12\n",
    "mut_prob = 0.2\n",
    "generations = 100\n",
    "num_parents = 0.5\n",
    "iters = 1000\n",
    "\n",
    "c = chrom(mutation_prob=mut_prob)\n",
    "\n",
    "ps = {'random':RandomParentSelector(), 'linealI':LinealOrder(), 'linealII':LinealOrderII(), \n",
    "      'wheel':WheelSelection(), 'tournament5': TournamentSelection(5), 'tournament3': TournamentSelection(3)}\n",
    "\n",
    "all_fits = {}\n",
    "for key in ps.keys():\n",
    "    if key == 'wheel':\n",
    "        continue\n",
    "    print(\"Evaluating \" + key + \"parent selector\")\n",
    "    p = ps[key]\n",
    "    all_fits[key] = []\n",
    "    for i in range(iters):\n",
    "        generational = GenerationalGA(num_parents=num_parents, chromosome=c, parent_selector=p, generations=generations,\n",
    "                              num_population=pop_size, crossover_prob=0.5,\n",
    "                              mutation_prob=0.7, maximize_fitness=False, save_pop=True,\n",
    "                              statistical_validation=False)\n",
    "\n",
    "        winner, best_fit, ranking = generational.evolve(show=False)\n",
    "        all_fits[key].append(best_fit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in all_fits.items():\n",
    "    print(key,\"score: %0.4f  +-  %0.4f\" % (np.mean(value), np.std(value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineal Order I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "SelectionProb_i = \\frac{Position_i}{\\sum_{j}{Position_j}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineal Order II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "SelectionProb_i = \\frac{N_{keep} - Position_i + 1}{\\sum_{j}^{N_{keep}}{Position_j}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
