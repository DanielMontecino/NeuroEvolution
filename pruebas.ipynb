{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import  Model\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, PReLU, LeakyReLU\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from time import time\n",
    "import time as T\n",
    "import traceback\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from GA.geneticAlgorithm import GenerationalGA\n",
    "from GA.parentSelector.parentSelector import RandomParentSelector, LinealOrder, TournamentSelection\n",
    "from GA.parentSelector.parentSelector import WheelSelection, LinealOrderII\n",
    "from utils.datamanager import DataManager\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, units=128, activation='relu', dropout=0):\n",
    "        self.units = units\n",
    "        self.posible_activations = ['relu', 'sigmoid', 'tanh', 'elu', 'prelu', 'leakyreLu']\n",
    "        assert activation in self.posible_activations\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.units_lim = 1024\n",
    "        self.units_prob = 0.2\n",
    "        self.act_prob = 0.2\n",
    "        self.drop_prob = 0.2\n",
    "\n",
    "    def cross(self, other_layer):\n",
    "        new_units = self.cross_units(other_layer.units)\n",
    "        new_activation = self.cross_activation(other_layer.activation)\n",
    "        new_dropout = self.cross_dropout(other_layer.dropout)\n",
    "        return Layer(new_units, new_activation, new_dropout)\n",
    "\n",
    "    def cross_activation(self, other_activation):\n",
    "        if np.random.rand() > 0.5:\n",
    "            return self.activation\n",
    "        return other_activation\n",
    "\n",
    "    def cross_dropout(self, other_dropout):\n",
    "        b = np.random.rand()\n",
    "        return self.dropout * (1 - b) + b * other_dropout\n",
    "\n",
    "    def cross_units(self, other_units):\n",
    "        b = np.random.rand()\n",
    "        return int(self.units * (1 - b) + other_units * b)\n",
    "\n",
    "    def mutate(self):\n",
    "        aleatory = np.random.rand(4)\n",
    "        if aleatory[0] < self.units_prob:\n",
    "            self.units = np.random.randint(0, self.units_lim)\n",
    "        if aleatory[1] < self.act_prob:\n",
    "            self.activation = random.choice(self.posible_activations)\n",
    "        if aleatory[2] < self.drop_prob:\n",
    "            self.dropout = np.random.rand()\n",
    "\n",
    "    def compare(self, other_layer):\n",
    "        if self.units != other_layer.units:\n",
    "            return False\n",
    "        if self.activation != other_layer.activation:\n",
    "            return False\n",
    "        if self.dropout != other_layer.dropout:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def self_copy(self):\n",
    "        return Layer(self.units, self.activation, self.dropout)\n",
    "\n",
    "    def random_layer(self):\n",
    "        units = np.random.randint(0, self.units_lim)\n",
    "        act = random.choice(self.posible_activations)\n",
    "        drop = np.random.rand()\n",
    "        return Layer(units, act, drop)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"U:%d|A:%s|D:%0.3f\" % (self.units, self.activation, self.dropout)\n",
    "\n",
    "\n",
    "class Cromosome(object):\n",
    "\n",
    "    def __init__(self, layers=[], fit=None):\n",
    "        assert type(layers) == list\n",
    "        self.n_layers = len(layers)\n",
    "        self.layers = layers\n",
    "        self.max_layers = 10\n",
    "        self.layer_prob = 0.1\n",
    "        self.fit = None\n",
    "        self.evaluator = Fitness.get_instance()\n",
    "\n",
    "    def set_fitness(self, fit):\n",
    "        self.evaluator = fit\n",
    "\n",
    "    def random_indiv(self):\n",
    "        n_layers = np.random.randint(0, self.max_layers)\n",
    "        layers = [Layer().random_layer() for i in range(n_layers)]\n",
    "        return Cromosome(layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def simple_indiv():\n",
    "        return Cromosome([Layer()])\n",
    "\n",
    "    def cross(self, other_cromosome):\n",
    "        new_layers = []\n",
    "\n",
    "        if self.n_layers == 0:\n",
    "            return other_cromosome\n",
    "\n",
    "        n_intersection = np.random.randint(0, self.n_layers)\n",
    "        for i in range(self.n_layers):\n",
    "            if i < n_intersection or i >= other_cromosome.n_layers:\n",
    "                new_layers.append(self.layers[i].self_copy())\n",
    "            else:\n",
    "                try:\n",
    "                    new_layers.append(self.layers[i].cross(other_cromosome.layers[i - n_intersection]))\n",
    "                except IndexError:\n",
    "                    print(\"Problem with index %d\" % i)\n",
    "                    print(\"Intersection point at %d\" % n_intersection)\n",
    "                    print(len(self.layers), self.layers)\n",
    "                    print(len(other_cromosome.layers), other_cromosome.layers)\n",
    "                    print(len(new_layers), new_layers)\n",
    "                    raise IndexError\n",
    "        return Cromosome(new_layers)\n",
    "\n",
    "    def mutate(self):\n",
    "        for i in range(self.n_layers):\n",
    "            self.layers[i].mutate()\n",
    "        if np.random.rand() < self.layer_prob and self.n_layers < self.max_layers:\n",
    "            self.layers.append(Layer().random_layer())\n",
    "            self.n_layers = len(self.layers)\n",
    "\n",
    "    def equals(self, other_cromosome):\n",
    "        if self.n_layers != other_cromosome.n_layers:\n",
    "            return False\n",
    "        for i in range(self.n_layers):\n",
    "            if not self.layers[i].compare(other_cromosome.layers[i]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def __repr__(self):\n",
    "        rep = \"\"\n",
    "        for i in range(self.n_layers):\n",
    "            rep += \"%d - %s \\n\" % (i, self.layers[i])\n",
    "        return rep\n",
    "\n",
    "    def fitness(self):\n",
    "        return self.evaluator.calc(self)\n",
    "\n",
    "\n",
    "class Fitness:\n",
    "    __instance = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_instance():\n",
    "        \"\"\" Static access method. \"\"\"\n",
    "        if Fitness.__instance == None:\n",
    "            Fitness()\n",
    "        return Fitness.__instance\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Virtually private constructor. \"\"\"\n",
    "        if Fitness.__instance != None:\n",
    "            raise Exception(\"This class is a singleton!\")\n",
    "        else:\n",
    "            Fitness.__instance = self\n",
    "\n",
    "    def set_params(self, data, batch_size=128, epochs=100, early_stop=True, reduce_plateau=True, verbose=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.early_stop = early_stop\n",
    "        self.reduce_plateu = reduce_plateau\n",
    "        self.verb = verbose\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test), (self.x_val, self.y_val) = data\n",
    "        self.num_clases = self.y_train.shape[1]\n",
    "        self.run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "        self.callbacks = []\n",
    "        if self.early_stop and keras.__version__=='2.2.4':\n",
    "            self.callbacks.append(EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True))\n",
    "        elif self.early_stop:\n",
    "            self.callbacks.append(EarlyStopping(monitor='val_acc', patience=10))\n",
    "        if self.reduce_plateu:\n",
    "            self.callbacks.append(ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, verbose=self.verb))\n",
    "        return self\n",
    "\n",
    "    def calc(self, chromosome):\n",
    "        try:\n",
    "            model = self.decode(chromosome)\n",
    "            h = model.fit(self.x_train, self.y_train,\n",
    "                              batch_size=self.batch_size,\n",
    "                              epochs=self.epochs,\n",
    "                              verbose=self.verb,\n",
    "                              validation_data=(self.x_val, self.y_val),\n",
    "                              callbacks=self.callbacks)\n",
    "            score = model.evaluate(self.x_val, self.y_val, verbose=0)\n",
    "            score_t = model.evaluate(self.x_test, self.y_test, verbose=0)\n",
    "        except Exception as e:\n",
    "            score = [0,0]\n",
    "            score_t = [0,0]\n",
    "            print(\"Some Error with gen:\")\n",
    "            print(chromosome)\n",
    "            logging.error(traceback.format_exc())\n",
    "            keras.backend.clear_session()\n",
    "            T.sleep(5)\n",
    "        if self.verb:\n",
    "            print('Val loss: %0.4f, Test loss: %0.4f' % (score[0], score_t[0]))\n",
    "            print('Val accuracy: %0.4f, Test accuracy: %0.4f' % (score[1], score_t[1]))\n",
    "            self.show_result(h, 'acc')\n",
    "            self.show_result(h, 'loss')\n",
    "        return score[1]\n",
    "\n",
    "    def decode(self, chromosome):\n",
    "\n",
    "        inp = Input(shape=(28, 28, 1))\n",
    "        x = Flatten()(inp)\n",
    "        for i in range(chromosome.n_layers):\n",
    "            act = chromosome.layers[i].activation\n",
    "            if act in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
    "                x = Dense(chromosome.layers[i].units, activation=act)(x)\n",
    "            elif act == 'prelu':\n",
    "                x = Dense(chromosome.layers[i].units)(x)\n",
    "                x = PReLU()(x)\n",
    "            else:\n",
    "                x = Dense(chromosome.layers[i].units)(x)\n",
    "                x = LeakyReLU()(x)\n",
    "            x = Dropout(chromosome.layers[i].dropout)(x)\n",
    "        x = Dense(self.num_clases, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        if self.verb:\n",
    "            model.summary()\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'],\n",
    "                      options = self.run_opts)\n",
    "        return model\n",
    "\n",
    "    def show_result(self, history, metric='acc'):\n",
    "        epochs = np.linspace(0, len(history.history['acc']) - 1, len(history.history['acc']))\n",
    "        plt.plot(epochs, history.history['val_%s' % metric], label='validation')\n",
    "        plt.plot(epochs, history.history[metric], label='train')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(metric)\n",
    "        plt.show()\n",
    "\n",
    "    def calc_mean(self, chromosome, iters=5):\n",
    "        f = []\n",
    "        ti = time()\n",
    "        for i in range(iters):\n",
    "            f.append(self.calc(chromosome))\n",
    "        print(\"Acc: %0.3f\" % np.mean(f), np.std(f), np.max(f))\n",
    "        print(\"Time elapsed: %0.3f\" % (time() - ti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9432, 28, 28, 1) train samples\n",
      "(2359, 28, 28, 1) validation samples\n",
      "(1991, 28, 28, 1) test samples\n",
      "Generic algorith params:\n",
      "Number of generations: 40\n",
      "Population size: 15\n",
      "num parents: 4\n",
      "offspring size: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"<ipython-input-1-c2a35f9ad07f>\", line 195, in calc\n",
      "    model = self.decode(chromosome)\n",
      "  File \"<ipython-input-1-c2a35f9ad07f>\", line 226, in decode\n",
      "    x = Dense(chromosome.layers[i].units, activation=act)(x)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 474, in __call__\n",
      "    output_shape = self.compute_output_shape(input_shape)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/layers/core.py\", line 888, in compute_output_shape\n",
      "    assert input_shape[-1]\n",
      "AssertionError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some Error with gen:\n",
      "0 - U:744|A:prelu|D:0.736 \n",
      "1 - U:575|A:elu|D:0.622 \n",
      "2 - U:500|A:leakyreLu|D:0.541 \n",
      "3 - U:0|A:leakyreLu|D:0.779 \n",
      "4 - U:981|A:sigmoid|D:0.120 \n",
      "5 - U:226|A:prelu|D:0.855 \n",
      "6 - U:876|A:sigmoid|D:0.125 \n",
      "7 - U:247|A:prelu|D:0.090 \n",
      "\n",
      "1) best fit: 0.989 in batch time: 340.69\n",
      "5) best fit: 0.992 in batch time: 1072.24\n",
      "9) best fit: 0.992 in batch time: 1323.57\n",
      "13) best fit: 0.992 in batch time: 1917.51\n",
      "17) best fit: 0.992 in batch time: 2446.87\n",
      "Some Error with gen:\n",
      "0 - U:968|A:prelu|D:0.088 \n",
      "1 - U:610|A:relu|D:0.279 \n",
      "2 - U:526|A:tanh|D:0.555 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\n",
      "    target_list, status, run_metadata)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[128,526] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[Node: dense_907/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_638/cond/Merge, dense_907/kernel/read)]]\n",
      "\n",
      "Current usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n",
      "  2.89MiB from training_268/Adam/mul_1\n",
      "  2.89MiB from training_268/Adam/mul_3\n",
      "  2.25MiB from training_268/Adam/mul_16\n",
      "  2.25MiB from training_268/Adam/mul_18\n",
      "  1.22MiB from training_268/Adam/mul_26\n",
      "  1.22MiB from training_268/Adam/mul_28\n",
      "  730.5KiB from p_re_lu_146/mul\n",
      "  693.8KiB from dense_905/MatMul\n",
      "  489.0KiB from dropout_638/cond/dropout/random_uniform/RandomUniform\n",
      "  484.0KiB from p_re_lu_146/Neg_1\n",
      "  484.0KiB from training_268/Adam/gradients/zeros_4\n",
      "  484.0KiB from dropout_637/cond/dropout/random_uniform/RandomUniform\n",
      "  305.0KiB from dense_906/MatMul\n",
      "  305.0KiB from dropout_638/cond/mul\n",
      "  305.0KiB from training_268/Adam/gradients/zeros_2\n",
      "  Remaining 18 nodes with 40.5KiB\n",
      "\n",
      "\t [[Node: loss_268/mul/_50519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_911_loss_268/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n",
      "Current usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n",
      "  2.89MiB from training_268/Adam/mul_1\n",
      "  2.89MiB from training_268/Adam/mul_3\n",
      "  2.25MiB from training_268/Adam/mul_16\n",
      "  2.25MiB from training_268/Adam/mul_18\n",
      "  1.22MiB from training_268/Adam/mul_26\n",
      "  1.22MiB from training_268/Adam/mul_28\n",
      "  730.5KiB from p_re_lu_146/mul\n",
      "  693.8KiB from dense_905/MatMul\n",
      "  489.0KiB from dropout_638/cond/dropout/random_uniform/RandomUniform\n",
      "  484.0KiB from p_re_lu_146/Neg_1\n",
      "  484.0KiB from training_268/Adam/gradients/zeros_4\n",
      "  484.0KiB from dropout_637/cond/dropout/random_uniform/RandomUniform\n",
      "  305.0KiB from dense_906/MatMul\n",
      "  305.0KiB from dropout_638/cond/mul\n",
      "  305.0KiB from training_268/Adam/gradients/zeros_2\n",
      "  Remaining 18 nodes with 40.5KiB\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-1-c2a35f9ad07f>\", line 201, in calc\n",
      "    callbacks=self.callbacks)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2721, in __call__\n",
      "    return self._legacy_call(inputs)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2693, in _legacy_call\n",
      "    **self.session_kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 905, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1137, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\n",
      "    options, run_metadata)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1374, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[128,526] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[Node: dense_907/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_638/cond/Merge, dense_907/kernel/read)]]\n",
      "\n",
      "Current usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n",
      "  2.89MiB from training_268/Adam/mul_1\n",
      "  2.89MiB from training_268/Adam/mul_3\n",
      "  2.25MiB from training_268/Adam/mul_16\n",
      "  2.25MiB from training_268/Adam/mul_18\n",
      "  1.22MiB from training_268/Adam/mul_26\n",
      "  1.22MiB from training_268/Adam/mul_28\n",
      "  730.5KiB from p_re_lu_146/mul\n",
      "  693.8KiB from dense_905/MatMul\n",
      "  489.0KiB from dropout_638/cond/dropout/random_uniform/RandomUniform\n",
      "  484.0KiB from p_re_lu_146/Neg_1\n",
      "  484.0KiB from training_268/Adam/gradients/zeros_4\n",
      "  484.0KiB from dropout_637/cond/dropout/random_uniform/RandomUniform\n",
      "  305.0KiB from dense_906/MatMul\n",
      "  305.0KiB from dropout_638/cond/mul\n",
      "  305.0KiB from training_268/Adam/gradients/zeros_2\n",
      "  Remaining 18 nodes with 40.5KiB\n",
      "\n",
      "\t [[Node: loss_268/mul/_50519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_911_loss_268/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n",
      "Current usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n",
      "  2.89MiB from training_268/Adam/mul_1\n",
      "  2.89MiB from training_268/Adam/mul_3\n",
      "  2.25MiB from training_268/Adam/mul_16\n",
      "  2.25MiB from training_268/Adam/mul_18\n",
      "  1.22MiB from training_268/Adam/mul_26\n",
      "  1.22MiB from training_268/Adam/mul_28\n",
      "  730.5KiB from p_re_lu_146/mul\n",
      "  693.8KiB from dense_905/MatMul\n",
      "  489.0KiB from dropout_638/cond/dropout/random_uniform/RandomUniform\n",
      "  484.0KiB from p_re_lu_146/Neg_1\n",
      "  484.0KiB from training_268/Adam/gradients/zeros_4\n",
      "  484.0KiB from dropout_637/cond/dropout/random_uniform/RandomUniform\n",
      "  305.0KiB from dense_906/MatMul\n",
      "  305.0KiB from dropout_638/cond/mul\n",
      "  305.0KiB from training_268/Adam/gradients/zeros_2\n",
      "  Remaining 18 nodes with 40.5KiB\n",
      "\n",
      "\n",
      "Caused by op 'dense_907/MatMul', defined at:\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-22b1735beacc>\", line 30, in <module>\n",
      "    winner, best_fit, ranking = generational.evolve()\n",
      "  File \"/home/daniel/proyectos/Tesis/project/GA/NeuroEvolution/GA/geneticAlgorithm.py\", line 138, in evolve\n",
      "    self.validate_best(ranking, population)\n",
      "  File \"/home/daniel/proyectos/Tesis/project/GA/NeuroEvolution/GA/geneticAlgorithm.py\", line 129, in validate_best\n",
      "    all_fits.append(best.fitness())\n",
      "  File \"<ipython-input-1-c2a35f9ad07f>\", line 155, in fitness\n",
      "    return self.evaluator.calc(self)\n",
      "  File \"<ipython-input-1-c2a35f9ad07f>\", line 195, in calc\n",
      "    model = self.decode(chromosome)\n",
      "  File \"<ipython-input-1-c2a35f9ad07f>\", line 226, in decode\n",
      "    x = Dense(chromosome.layers[i].units, activation=act)(x)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n",
      "    output = self.call(inputs, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/layers/core.py\", line 879, in call\n",
      "    output = K.dot(inputs, self.kernel)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1085, in dot\n",
      "    out = tf.matmul(x, y)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 2064, in matmul\n",
      "    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2507, in _mat_mul\n",
      "    name=name)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n",
      "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
      "\n",
      "ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128,526] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[Node: dense_907/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_638/cond/Merge, dense_907/kernel/read)]]\n",
      "\n",
      "Current usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n",
      "  2.89MiB from training_268/Adam/mul_1\n",
      "  2.89MiB from training_268/Adam/mul_3\n",
      "  2.25MiB from training_268/Adam/mul_16\n",
      "  2.25MiB from training_268/Adam/mul_18\n",
      "  1.22MiB from training_268/Adam/mul_26\n",
      "  1.22MiB from training_268/Adam/mul_28\n",
      "  730.5KiB from p_re_lu_146/mul\n",
      "  693.8KiB from dense_905/MatMul\n",
      "  489.0KiB from dropout_638/cond/dropout/random_uniform/RandomUniform\n",
      "  484.0KiB from p_re_lu_146/Neg_1\n",
      "  484.0KiB from training_268/Adam/gradients/zeros_4\n",
      "  484.0KiB from dropout_637/cond/dropout/random_uniform/RandomUniform\n",
      "  305.0KiB from dense_906/MatMul\n",
      "  305.0KiB from dropout_638/cond/mul\n",
      "  305.0KiB from training_268/Adam/gradients/zeros_2\n",
      "  Remaining 18 nodes with 40.5KiB\n",
      "\n",
      "\t [[Node: loss_268/mul/_50519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_911_loss_268/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n",
      "Current usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n",
      "  2.89MiB from training_268/Adam/mul_1\n",
      "  2.89MiB from training_268/Adam/mul_3\n",
      "  2.25MiB from training_268/Adam/mul_16\n",
      "  2.25MiB from training_268/Adam/mul_18\n",
      "  1.22MiB from training_268/Adam/mul_26\n",
      "  1.22MiB from training_268/Adam/mul_28\n",
      "  730.5KiB from p_re_lu_146/mul\n",
      "  693.8KiB from dense_905/MatMul\n",
      "  489.0KiB from dropout_638/cond/dropout/random_uniform/RandomUniform\n",
      "  484.0KiB from p_re_lu_146/Neg_1\n",
      "  484.0KiB from training_268/Adam/gradients/zeros_4\n",
      "  484.0KiB from dropout_637/cond/dropout/random_uniform/RandomUniform\n",
      "  305.0KiB from dense_906/MatMul\n",
      "  305.0KiB from dropout_638/cond/mul\n",
      "  305.0KiB from training_268/Adam/gradients/zeros_2\n",
      "  Remaining 18 nodes with 40.5KiB\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21) best fit: 0.992 in batch time: 2008.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-22b1735beacc>\", line 30, in <module>\n",
      "    winner, best_fit, ranking = generational.evolve()\n",
      "  File \"/home/daniel/proyectos/Tesis/project/GA/NeuroEvolution/GA/geneticAlgorithm.py\", line 138, in evolve\n",
      "    self.validate_best(ranking, population)\n",
      "  File \"/home/daniel/proyectos/Tesis/project/GA/NeuroEvolution/GA/geneticAlgorithm.py\", line 129, in validate_best\n",
      "    all_fits.append(best.fitness())\n",
      "  File \"<ipython-input-1-c2a35f9ad07f>\", line 155, in fitness\n",
      "    return self.evaluator.calc(self)\n",
      "  File \"<ipython-input-1-c2a35f9ad07f>\", line 201, in calc\n",
      "    callbacks=self.callbacks)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2721, in __call__\n",
      "    return self._legacy_call(inputs)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2693, in _legacy_call\n",
      "    **self.session_kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 905, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1137, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\n",
      "    options, run_metadata)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\n",
      "    target_list, status, run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2016, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/daniel/anaconda3/envs/python3/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "l = Layer(516, 'relu', 0.2)\n",
    "l2 = Layer(516, 'relu', 0.2)\n",
    "c = Cromosome([l, l2])\n",
    "clases = [4, 9]\n",
    "\n",
    "ps = {'random':RandomParentSelector(), 'lineal':LinealOrder(), 'wheel':WheelSelection(), \n",
    "      'tournament':TournamentSelection(5)}\n",
    "\n",
    "# params:\n",
    "dataset = 'mnist'\n",
    "classes = [4, 9]\n",
    "parents_selector_key = 'wheel'\n",
    "num_parents = 0.3\n",
    "generations = 40\n",
    "population = 15\n",
    "maximize_fit = True\n",
    "\n",
    "# Load data\n",
    "dm = DataManager(dataset, clases=classes)\n",
    "data = dm.load_data()\n",
    "fitness = Fitness.get_instance()\n",
    "fitness.set_params(data, verbose=0, reduce_plateau=False)\n",
    "\n",
    "p = ps[parents_selector_key]\n",
    "\n",
    "ti_all = time()\n",
    "generational = GenerationalGA(num_parents=num_parents, chromosome=c, parent_selector=p, generations=generations,\n",
    "                              num_population=population, crossover_prob=0.5, mutation_prob=0.7,\n",
    "                              maximize_fitness=maximize_fit)\n",
    "winner, best_fit, ranking = generational.evolve()\n",
    "print(\"Total elapsed time: %0.3f\" % (time() - ti_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, N_participants=3):\n",
    "        self.N = N_participants\n",
    "        self.history_fitness = {}\n",
    "        \n",
    "    def set_params(self,maximize, history):\n",
    "        self.maximize = maximize\n",
    "        self.history_fitness = history\n",
    "        \n",
    "    def eval_individual(self, chrom):\n",
    "        gen = chrom.__repr__()\n",
    "        if gen not in self.history_fitness.keys():\n",
    "            self.history_fitness[gen] = chrom.fitness()\n",
    "        elif chrom.fit is None:\n",
    "            chrom.fit = self.history_fitness[gen]\n",
    "        return chrom.fit\n",
    "    \n",
    "    def get_one_offspring(self, population):\n",
    "        idxs = np.linspace(0, len(population) - 1, len(population)).astype(np.int32)\n",
    "        idxs_perm = np.random.permutation(idxs)\n",
    "        participants_1 = [population[idxs_perm[i]] for i in range(self.N)]\n",
    "        participants_2 = [population[idxs_perm[-i]] for i in range(1, self.N + 1)]\n",
    "        win_1 = np.argmax([self.eval_individual(chrom) for chrom in participants_1])\n",
    "        win_2 = np.argmax([self.eval_individual(chrom) for chrom in participants_2])\n",
    "        parent1 = participants_1[win_1]\n",
    "        parent2 = participants_2[win_2]\n",
    "        offspring = parent1.cross(parent2)\n",
    "        offspring.mutate()\n",
    "        self.eval_individual(offspring)\n",
    "        return offspring, (parent1, parent2)\n",
    "        \n",
    "    def next_gen(self, population, num_offspring=1):\n",
    "        next_generation = []\n",
    "        all_parents = []\n",
    "        for n in range(num_offspring):\n",
    "            print(len(population))\n",
    "            offspring, parents = self.get_one_offspring(population)\n",
    "            next_generation.append(offspring)\n",
    "            all_parents.append(parents)\n",
    "        return next_generation, all_parents\n",
    "    \n",
    "class B:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.fit = self.n\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.n)\n",
    "\n",
    "    def fitness(self):\n",
    "        return self.n\n",
    "    \n",
    "    def cross(self, aB):\n",
    "        return B(np.mean([self.n, aB.n]))\n",
    "    \n",
    "    def mutate(self):\n",
    "        self.n += np.random.rand()*0\n",
    "        \n",
    "a = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "b = [B(aux) for aux in a]\n",
    "a_ = LinealOrder()\n",
    "next_generation, all_parents = a_.next_gen(b, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Layer(10, 'relu', 0.1)\n",
    "l2 = Layer(20, 'elu', 0.2)\n",
    "l3 = Layer(30, 'prelu', 0.3)\n",
    "\n",
    "c1 = Cromosome([l1])\n",
    "c2 = Cromosome([l2])\n",
    "c3 = Cromosome([l3])\n",
    "c12 = Cromosome([l1, l2])\n",
    "c21 = Cromosome([l2, l1])\n",
    "c13 = Cromosome([l1, l3])\n",
    "c31 = Cromosome([l3, l1])\n",
    "c23 = Cromosome([l2, l3])\n",
    "c32 = Cromosome([l3, l2])\n",
    "c123 = Cromosome([l1, l2, l3])\n",
    "c132 = Cromosome([l1, l3, l2])\n",
    "c213 = Cromosome([l2, l1, l3])\n",
    "c231 = Cromosome([l2, l3, l1])\n",
    "c312 = Cromosome([l3, l1, l2])\n",
    "c321 = Cromosome([l3, l2, l1])\n",
    "\n",
    "F = Fitness_str(c321)\n",
    "\n",
    "population = [c1, c2, c3, c12, c21, c13, c31, c23, c32, c123, c132, c213, c231, c312, c321]\n",
    "for c in population:\n",
    "    c.set_fitness(F)\n",
    "    \n",
    "population = population[:10]\n",
    "_=[print(a.fitness(), end=' ') for a in population]\n",
    "print('\\n', F.crom)\n",
    "print(c321.fitness())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RandomParentSelector(num_offspring=3, history_fitness={}, maximize_fit=True)\n",
    "next_generation, all_parents = r.next_gen(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(next_generation), len(next_generation), type(all_parents), len(all_parents))\n",
    "print(next_generation[0], next_generation[0].fitness())\n",
    "print(all_parents[0][0], all_parents[0][0].fitness())\n",
    "print(all_parents[0][1], all_parents[0][1].fitness())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pop = r.replace(population, next_generation, all_parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a , b in zip(new_pop, population):\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class printer:\n",
    "    def prt(self, objecto):\n",
    "        print(objecto)\n",
    "        return\n",
    "        \n",
    "class A(object):\n",
    "    def __init__(self, name, printer):\n",
    "        self.printer = printer\n",
    "        self.name = name\n",
    "        \n",
    "    def self_print(self):\n",
    "        self.printer.prt(self)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = printer()\n",
    "p.prt('hi')\n",
    "\n",
    "a = A('wolo', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.self_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class chrom:\n",
    "    def __init__(self, x=0, y=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mut_prob = 0.2\n",
    "        self.fit = None\n",
    "    \n",
    "    def set_fitness(self, fit):\n",
    "        self.evaluator = fit\n",
    "        \n",
    "    def random_indiv(self):\n",
    "        x = 10 * np.random.rand()\n",
    "        y = 10 * np.random.rand()\n",
    "        return chrom(x, y)\n",
    "    \n",
    "    def simple_indiv(self):\n",
    "        return chrom(0, 0)\n",
    "        \n",
    "    def cross(self, other_cromosome):\n",
    "        bx = np.random.rand()\n",
    "        by = np.random.rand()\n",
    "        x = bx * self.x + (1 - bx) * other_cromosome.x\n",
    "        y = by * self.y + (1 - by) * other_cromosome.y\n",
    "        return chrom(x, y)\n",
    "        \n",
    "    \n",
    "    def mutate(self):\n",
    "        if np.random.rand() < self.mut_prob:\n",
    "            self.x = 10 * np.random.rand()\n",
    "        if np.random.rand() < self.mut_prob:\n",
    "            self.y = 10 * np.random.rand()\n",
    "            \n",
    "    def equals(self, other_cromosome):\n",
    "        return (self.x == other_cromosome.x) and (self.y == other_cromosome.y)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"(%0.3f, %0.3f)\" % (self.x, self.y)\n",
    "    \n",
    "    def fitness(self):\n",
    "        self.fit = self.x * np.sin(4 * self.x) + 1.1 * self.y * np.sin(2 * self.y)\n",
    "        return self.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 12\n",
    "mut_prob = 0.2\n",
    "generations = 1000\n",
    "num_parents = 0.5\n",
    "\n",
    "c = chrom()\n",
    "ps = [RandomParentSelector(), LinealOrder(), LinealOrderII(), WheelSelection(), TournamentSelection(5)]\n",
    "p = ps[2]\n",
    "generational = GenerationalGA(num_parents=num_parents, chromosome=c, parent_selector=p, generations=generations,\n",
    "                              num_population=pop_size, crossover_prob=0.5,\n",
    "                              mutation_prob=0.7, maximize_fitness=False)\n",
    "\n",
    "winner, best_fit, ranking = generational.evolve()\n",
    "print(best_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "from matplotlib import ticker, cm\n",
    "\n",
    "N = 1000\n",
    "x = np.linspace(0, 10.0, N)\n",
    "y = np.linspace(0, 10.0, N)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "z = X * np.sin(4 * X) + 1.1 * Y * np.sin(2 * Y) \n",
    "print(np.min(z), np.max(z))\n",
    "z += np.abs(np.min(z))\n",
    "min_z = np.min(z)\n",
    "max_z = np.max(z)\n",
    "max_idxs = []\n",
    "min_idxs = []\n",
    "for i in range(N):\n",
    "    for k in range(N):\n",
    "        if z[i, k] == min_z:\n",
    "            min_idxs.append((i, k))\n",
    "        elif z[i, k] == max_z:\n",
    "            max_idxs.append((i, k))\n",
    "\n",
    "# The following is not strictly essential, but it will eliminate\n",
    "# a warning.  Comment it out to see the warning.\n",
    "#z = ma.masked_where(z <= 0, z)\n",
    "\n",
    "\n",
    "# Automatic selection of levels works; setting the\n",
    "# log locator tells contourf to use a log scale:\n",
    "fig, ax = plt.subplots()\n",
    "cs = ax.contourf(X, Y, z, cmap=cm.PuBu_r, alpha = 0.7)\n",
    "for i, k in max_idxs:\n",
    "    plt.scatter(x[k], y[i], c='r', label='max', s=20)\n",
    "for i, k in min_idxs:\n",
    "    plt.scatter(x[k], y[i], c='g', label='min', s=20)\n",
    "# Alternatively, you can manually set the levels\n",
    "# and the norm:\n",
    "# lev_exp = np.arange(np.floor(np.log10(z.min())-1),\n",
    "#                    np.ceil(np.log10(z.max())+1))\n",
    "# levs = np.power(10, lev_exp)\n",
    "# cs = ax.contourf(X, Y, z, levs, norm=colors.LogNorm())\n",
    "\n",
    "cbar = fig.colorbar(cs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_z = np.argmin(z)\n",
    "print(X.shape, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[min_z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params:\n",
    "dataset = 'mnist'\n",
    "classes = [4, 9]\n",
    "\n",
    "\n",
    "# Load data\n",
    "dm = DataManager(dataset, clases=classes)\n",
    "data = dm.load_data()\n",
    "(x_train, y_train), (x_test, y_test), (x_val, y_val) = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = 1\n",
    "iters = 100\n",
    "\n",
    "for k in range(iters):\n",
    "    verb = k%10==0\n",
    "        \n",
    "    inp = Input(shape=(28, 28, 1))\n",
    "    x = Flatten()(inp)\n",
    "    for i in range(5):\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "    x = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    if verb:\n",
    "        model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=Adam(),\n",
    "                          metrics=['accuracy'])\n",
    "    score = model.evaluate(x_val, y_val, verbose=0)\n",
    "    score_t = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(score, score_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
