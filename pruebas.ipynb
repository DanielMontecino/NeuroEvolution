{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from GA.geneticAlgorithm import GenerationalGA\n",
    "from GA.parentSelector.parentSelector import RandomParentSelector, LinealOrder, TournamentSelection\n",
    "from GA.parentSelector.parentSelector import WheelSelection, LinealOrderII\n",
    "from utils.datamanager import DataManager\n",
    "from utils.codificication_mlp import Layer, Cromosome, Fitness        \n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def time_measure(chrom, iters=50):\n",
    "    '''\n",
    "    Function tu mesure the training time of a model\n",
    "    '''\n",
    "    times = []\n",
    "    for i in range(iters):\n",
    "        ti = time()\n",
    "        c.fitness()\n",
    "        times.append(time() - ti)\n",
    "    return times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the capability of a neural network with a single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1) train samples\n",
      "(12000, 28, 28, 1) validation samples\n",
      "(10000, 28, 28, 1) test samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.codificication_mlp.Fitness at 0x7f5219b4d5f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Cromosome([Layer(930, 'prelu', 0.654)])\n",
    "\n",
    "\n",
    "# Fitness params\n",
    "epochs = 75\n",
    "batch_size = 256\n",
    "verbose = 1\n",
    "redu_plat = False\n",
    "early_stop = True\n",
    "\n",
    "# dataset params:\n",
    "dataset = 'mnist'\n",
    "classes = []\n",
    "\n",
    "# Load data\n",
    "dm = DataManager(dataset, clases=classes)\n",
    "data = dm.load_data()\n",
    "fitness = Fitness.get_instance()\n",
    "fitness.set_params(data, verbose=verbose, reduce_plateau=redu_plat, \n",
    "                   epochs=epochs, early_stop=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 930)               730050    \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 930)               930       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 930)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                9310      \n",
      "=================================================================\n",
      "Total params: 740,290\n",
      "Trainable params: 740,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/75\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.3636 - acc: 0.8907 - val_loss: 0.1605 - val_acc: 0.9525\n",
      "Epoch 2/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.1800 - acc: 0.9468 - val_loss: 0.1199 - val_acc: 0.9637\n",
      "Epoch 3/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.1379 - acc: 0.9583 - val_loss: 0.0991 - val_acc: 0.9704\n",
      "Epoch 4/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.1123 - acc: 0.9664 - val_loss: 0.0923 - val_acc: 0.9713\n",
      "Epoch 5/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.1010 - acc: 0.9691 - val_loss: 0.0805 - val_acc: 0.9762\n",
      "Epoch 6/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0889 - acc: 0.9725 - val_loss: 0.0735 - val_acc: 0.9779\n",
      "Epoch 7/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0822 - acc: 0.9742 - val_loss: 0.0709 - val_acc: 0.9779\n",
      "Epoch 8/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0738 - acc: 0.9766 - val_loss: 0.0719 - val_acc: 0.9793\n",
      "Epoch 9/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0681 - acc: 0.9781 - val_loss: 0.0710 - val_acc: 0.9796\n",
      "Epoch 10/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0663 - acc: 0.9782 - val_loss: 0.0734 - val_acc: 0.9785\n",
      "Epoch 11/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0581 - acc: 0.9813 - val_loss: 0.0687 - val_acc: 0.9794\n",
      "Epoch 12/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0601 - acc: 0.9801 - val_loss: 0.0681 - val_acc: 0.9792\n",
      "Epoch 13/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0530 - acc: 0.9825 - val_loss: 0.0665 - val_acc: 0.9804\n",
      "Epoch 14/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0528 - acc: 0.9829 - val_loss: 0.0709 - val_acc: 0.9809\n",
      "Epoch 15/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0490 - acc: 0.9835 - val_loss: 0.0678 - val_acc: 0.9818\n",
      "Epoch 16/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0478 - acc: 0.9840 - val_loss: 0.0684 - val_acc: 0.9819\n",
      "Epoch 17/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0471 - acc: 0.9835 - val_loss: 0.0695 - val_acc: 0.9816\n",
      "Epoch 18/75\n",
      "48000/48000 [==============================] - 2s 31us/step - loss: 0.0426 - acc: 0.9862 - val_loss: 0.0691 - val_acc: 0.9812\n",
      "Epoch 19/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0433 - acc: 0.9855 - val_loss: 0.0680 - val_acc: 0.9820\n",
      "Epoch 20/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0418 - acc: 0.9852 - val_loss: 0.0683 - val_acc: 0.9820\n",
      "Epoch 21/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0404 - acc: 0.9865 - val_loss: 0.0676 - val_acc: 0.9821\n",
      "Epoch 22/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0410 - acc: 0.9866 - val_loss: 0.0673 - val_acc: 0.9832\n",
      "Epoch 23/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0356 - acc: 0.9870 - val_loss: 0.0708 - val_acc: 0.9821\n",
      "Epoch 24/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0375 - acc: 0.9871 - val_loss: 0.0686 - val_acc: 0.9820\n",
      "Epoch 25/75\n",
      "48000/48000 [==============================] - 2s 31us/step - loss: 0.0360 - acc: 0.9874 - val_loss: 0.0687 - val_acc: 0.9824\n",
      "Epoch 26/75\n",
      "48000/48000 [==============================] - 2s 31us/step - loss: 0.0357 - acc: 0.9876 - val_loss: 0.0706 - val_acc: 0.9830\n",
      "Epoch 27/75\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0324 - acc: 0.9893 - val_loss: 0.0686 - val_acc: 0.9827\n",
      "Epoch 28/75\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.0303 - acc: 0.9897 - val_loss: 0.0755 - val_acc: 0.9814\n",
      "Epoch 29/75\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0328 - acc: 0.9892 - val_loss: 0.0727 - val_acc: 0.9820\n",
      "Epoch 30/75\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 0.0340 - acc: 0.9886 - val_loss: 0.0767 - val_acc: 0.9817\n",
      "Epoch 31/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0327 - acc: 0.9895 - val_loss: 0.0695 - val_acc: 0.9837\n",
      "Epoch 32/75\n",
      "48000/48000 [==============================] - 2s 31us/step - loss: 0.0303 - acc: 0.9895 - val_loss: 0.0733 - val_acc: 0.9819\n",
      "Epoch 33/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0314 - acc: 0.9894 - val_loss: 0.0727 - val_acc: 0.9826\n",
      "Epoch 34/75\n",
      "48000/48000 [==============================] - 2s 31us/step - loss: 0.0320 - acc: 0.9894 - val_loss: 0.0750 - val_acc: 0.9824\n",
      "Epoch 35/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0304 - acc: 0.9895 - val_loss: 0.0779 - val_acc: 0.9833\n",
      "Epoch 36/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0309 - acc: 0.9894 - val_loss: 0.0739 - val_acc: 0.9836\n",
      "Epoch 37/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0276 - acc: 0.9905 - val_loss: 0.0822 - val_acc: 0.9821\n",
      "Epoch 38/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0291 - acc: 0.9903 - val_loss: 0.0785 - val_acc: 0.9827\n",
      "Epoch 39/75\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0268 - acc: 0.9910 - val_loss: 0.0783 - val_acc: 0.9836\n",
      "Epoch 40/75\n",
      "48000/48000 [==============================] - 2s 31us/step - loss: 0.0269 - acc: 0.9910 - val_loss: 0.0742 - val_acc: 0.9845\n",
      "Epoch 41/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0260 - acc: 0.9913 - val_loss: 0.0841 - val_acc: 0.9842\n",
      "Epoch 42/75\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 0.0296 - acc: 0.9902 - val_loss: 0.0796 - val_acc: 0.9832\n",
      "Epoch 43/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0295 - acc: 0.9904 - val_loss: 0.0861 - val_acc: 0.9825\n",
      "Epoch 44/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0230 - acc: 0.9921 - val_loss: 0.0769 - val_acc: 0.9828\n",
      "Epoch 45/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0265 - acc: 0.9915 - val_loss: 0.0773 - val_acc: 0.9837\n",
      "Epoch 46/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0226 - acc: 0.9918 - val_loss: 0.0778 - val_acc: 0.9835\n",
      "Epoch 47/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0257 - acc: 0.9916 - val_loss: 0.0813 - val_acc: 0.9830\n",
      "Epoch 48/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0238 - acc: 0.9920 - val_loss: 0.0857 - val_acc: 0.9832\n",
      "Epoch 49/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0286 - acc: 0.9910 - val_loss: 0.0807 - val_acc: 0.9840\n",
      "Epoch 50/75\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0224 - acc: 0.9925 - val_loss: 0.0829 - val_acc: 0.9827\n",
      "Val loss: 0.0742,Val acc: 0.9845\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9845"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.fitness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training time measurement when resetting VRAM memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9432, 28, 28, 1) train samples\n",
      "(2359, 28, 28, 1) validation samples\n",
      "(1991, 28, 28, 1) test samples\n",
      "mean time:\t1.326\n",
      "std:\t1.473\n"
     ]
    }
   ],
   "source": [
    "l = Layer(516, 'relu', 0.2)\n",
    "l2 = Layer(516, 'relu', 0.2)\n",
    "c = Cromosome([l, l2])\n",
    "\n",
    "# params:\n",
    "dataset = 'mnist'\n",
    "classes = [4, 9]\n",
    "epochs = 2\n",
    "\n",
    "# Load data\n",
    "dm = DataManager(dataset, clases=classes)\n",
    "data = dm.load_data()\n",
    "fitness = Fitness.get_instance()\n",
    "fitness.set_params(data, verbose=0, reduce_plateau=False, epochs=epochs)\n",
    "\n",
    "t_with_reset = time_measure(c)\n",
    "print(\"mean time:\\t%0.3f\\nstd:\\t%0.3f\" % (np.mean(t_with_reset), np.std(t_with_reset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean time:\t2.145\n",
      "std:\t0.610\n"
     ]
    }
   ],
   "source": [
    "fitness.set_params(data, verbose=0, reduce_plateau=False, epochs=epochs, reset=False)\n",
    "\n",
    "t_without_reset = time_measure(c)\n",
    "print(\"mean time:\\t%0.3f\\nstd:\\t%0.3f\" % (np.mean(t_without_reset), np.std(t_without_reset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "t_value, p_value = stats.ttest_ind(t_without_reset, t_with_reset)\n",
    "print(\"T-value: %0.3f \" % t_value)\n",
    "print(\"P-value: %0.3f \" % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A little class to test the Parent Selector Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, N_participants=3):\n",
    "        self.N = N_participants\n",
    "        self.history_fitness = {}\n",
    "        \n",
    "    def set_params(self,maximize, history):\n",
    "        self.maximize = maximize\n",
    "        self.history_fitness = history\n",
    "        \n",
    "    def eval_individual(self, chrom):\n",
    "        gen = chrom.__repr__()\n",
    "        if gen not in self.history_fitness.keys():\n",
    "            self.history_fitness[gen] = chrom.fitness()\n",
    "        elif chrom.fit is None:\n",
    "            chrom.fit = self.history_fitness[gen]\n",
    "        return chrom.fit\n",
    "    \n",
    "    def get_one_offspring(self, population):\n",
    "        idxs = np.linspace(0, len(population) - 1, len(population)).astype(np.int32)\n",
    "        idxs_perm = np.random.permutation(idxs)\n",
    "        participants_1 = [population[idxs_perm[i]] for i in range(self.N)]\n",
    "        participants_2 = [population[idxs_perm[-i]] for i in range(1, self.N + 1)]\n",
    "        win_1 = np.argmax([self.eval_individual(chrom) for chrom in participants_1])\n",
    "        win_2 = np.argmax([self.eval_individual(chrom) for chrom in participants_2])\n",
    "        parent1 = participants_1[win_1]\n",
    "        parent2 = participants_2[win_2]\n",
    "        offspring = parent1.cross(parent2)\n",
    "        offspring.mutate()\n",
    "        self.eval_individual(offspring)\n",
    "        return offspring, (parent1, parent2)\n",
    "        \n",
    "    def next_gen(self, population, num_offspring=1):\n",
    "        next_generation = []\n",
    "        all_parents = []\n",
    "        for n in range(num_offspring):\n",
    "            print(len(population))\n",
    "            offspring, parents = self.get_one_offspring(population)\n",
    "            next_generation.append(offspring)\n",
    "            all_parents.append(parents)\n",
    "        return next_generation, all_parents\n",
    "    \n",
    "class B:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.fit = self.n\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.n)\n",
    "\n",
    "    def fitness(self):\n",
    "        return self.n\n",
    "    \n",
    "    def cross(self, aB):\n",
    "        return B(np.mean([self.n, aB.n]))\n",
    "    \n",
    "    def mutate(self):\n",
    "        self.n += np.random.rand()*0\n",
    "        \n",
    "a = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "b = [B(aux) for aux in a]\n",
    "\n",
    "# Test LinealOrder\n",
    "a_ = LinealOrder()\n",
    "next_generation, all_parents = a_.next_gen(b, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize a 2D - function with GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Chromosome to minimize the fuction:\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = x \\cdot sin(4x) + 1.1  y \\cdot sin(2y)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "class chrom:\n",
    "    def __init__(self, x=0, y=0, mutation_prob=0.2):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mut_prob = mutation_prob\n",
    "        self.fit = None\n",
    "    \n",
    "    def set_fitness(self, fit):\n",
    "        self.evaluator = fit\n",
    "        \n",
    "    def random_indiv(self):\n",
    "        x = 10 * np.random.rand()\n",
    "        y = 10 * np.random.rand()\n",
    "        return chrom(x, y)\n",
    "    \n",
    "    def simple_indiv(self):\n",
    "        return chrom(0, 0)\n",
    "        \n",
    "    def cross(self, other_cromosome):\n",
    "        bx = np.random.rand()\n",
    "        by = np.random.rand()\n",
    "        x = bx * self.x + (1 - bx) * other_cromosome.x\n",
    "        y = by * self.y + (1 - by) * other_cromosome.y\n",
    "        return chrom(x, y)\n",
    "        \n",
    "    \n",
    "    def mutate(self):\n",
    "        if np.random.rand() < self.mut_prob:\n",
    "            self.x = 10 * np.random.rand()\n",
    "        if np.random.rand() < self.mut_prob:\n",
    "            self.y = 10 * np.random.rand()\n",
    "            \n",
    "    def equals(self, other_cromosome):\n",
    "        return (self.x == other_cromosome.x) and (self.y == other_cromosome.y)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"(%0.3f, %0.3f)\" % (self.x, self.y)\n",
    "    \n",
    "    def fitness(self):\n",
    "        self.fit = self.x * np.sin(4 * self.x) + 1.1 * self.y * np.sin(2 * self.y)\n",
    "        return self.fit\n",
    "    \n",
    "    def cross_val(self):\n",
    "        return [self.fitness() for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "-18.54115976408368\n",
      "(9.027, 8.681)\n"
     ]
    }
   ],
   "source": [
    "pop_size = 12\n",
    "mut_prob = 0.2\n",
    "generations = 100\n",
    "num_parents = 0.5\n",
    "\n",
    "c = chrom(mutation_prob=mut_prob)\n",
    "ps = [RandomParentSelector(), LinealOrder(), LinealOrderII(), WheelSelection(), TournamentSelection(5)]\n",
    "p = ps[2]\n",
    "generational = GenerationalGA(num_parents=num_parents, chromosome=c, parent_selector=p, generations=generations,\n",
    "                              num_population=pop_size, crossover_prob=0.5,\n",
    "                              mutation_prob=0.7, maximize_fitness=False, save_pop=True,\n",
    "                              statistical_validation=False)\n",
    "\n",
    "winner, best_fit, ranking = generational.evolve(show=False)\n",
    "print(best_fit)\n",
    "print(winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.554716504097726 19.861786404025292\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "from matplotlib import ticker, cm\n",
    "\n",
    "N = 1000\n",
    "x = np.linspace(0, 10.0, N)\n",
    "y = np.linspace(0, 10.0, N)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "z = X * np.sin(4 * X) + 1.1 * Y * np.sin(2 * Y) \n",
    "print(np.min(z), np.max(z))\n",
    "z += np.abs(np.min(z))\n",
    "min_z = np.min(z)\n",
    "max_z = np.max(z)\n",
    "max_idxs = []\n",
    "min_idxs = []\n",
    "for i in range(N):\n",
    "    for k in range(N):\n",
    "        if z[i, k] == min_z:\n",
    "            min_idxs.append((i, k))\n",
    "        elif z[i, k] == max_z:\n",
    "            max_idxs.append((i, k))\n",
    "\n",
    "# The following is not strictly essential, but it will eliminate\n",
    "# a warning.  Comment it out to see the warning.\n",
    "#z = ma.masked_where(z <= 0, z)\n",
    "\n",
    "\n",
    "# Automatic selection of levels works; setting the\n",
    "# log locator tells contourf to use a log scale:\n",
    "fig, ax = plt.subplots()\n",
    "cs = ax.contourf(X, Y, z, cmap=cm.PuBu_r, alpha = 0.7)\n",
    "for i, k in max_idxs:\n",
    "    continue\n",
    "    plt.scatter(x[k], y[i], c='r', label='max', s=20)\n",
    "for i, k in min_idxs:\n",
    "    plt.scatter(x[k], y[i], c='k', label='min', s=50, marker='x')\n",
    "# Alternatively, you can manually set the levels\n",
    "# and the norm:\n",
    "# lev_exp = np.arange(np.floor(np.log10(z.min())-1),\n",
    "#                    np.ceil(np.log10(z.max())+1))\n",
    "# levs = np.power(10, lev_exp)\n",
    "# cs = ax.contourf(X, Y, z, levs, norm=colors.LogNorm())\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Fitness')\n",
    "ax.set_ylim((np.min(Y), np.max(Y)))\n",
    "cbar = fig.colorbar(cs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 100\n"
     ]
    }
   ],
   "source": [
    "h = generational.population_history\n",
    "def scatter_pop(h, generation, ax):\n",
    "    for p in h[generation]:\n",
    "        ax.scatter(p.x, p.y, c='g', label='min', s=100)\n",
    "        \n",
    "print(len(h), generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set_xlim((np.min(X), np.max(X)))\n",
    "ax.set_ylim((np.min(Y), np.max(Y)))\n",
    "cs = ax.contourf(X, Y, z, cmap=cm.PuBu_r, alpha = 0.7)\n",
    "for i, k in min_idxs:\n",
    "    plt.scatter(x[k], y[i], c='k', label='min', s=100, marker='x')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "title = ax.set_title('')\n",
    "plt.close(fig)\n",
    "            \n",
    "def animate2(i):\n",
    "    ax.cla()\n",
    "    ax.set_title('generation %s' % str(i).zfill(4))\n",
    "    cs = ax.contourf(X, Y, z, cmap=cm.PuBu_r, alpha = 0.7)\n",
    "    for i_, k_ in min_idxs:\n",
    "        ax.scatter(x[k_], y[i_], c='k', label='min', s=100, marker='x')\n",
    "    ax.set_xlim((np.min(X), np.max(X)))\n",
    "    ax.set_ylim((np.min(Y), np.max(Y)))\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    scatter_pop(h, i, ax)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "anim = animation.FuncAnimation(fig,\n",
    "                               animate2,\n",
    "                               init_func=None,\n",
    "                               frames=generations,\n",
    "                               interval=100000)\n",
    "\n",
    "# Set up formatting for the movie files\n",
    "Writer = animation.writers['imagemagick']\n",
    "writer = Writer(fps=5, metadata=dict(artist='Me'), bitrate=1800)\n",
    "anim.save('/home/daniel/proyectos/Tesis/project/GA/NeuroEvolution/anim2.gif', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating randomparent selector\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Evaluating linealIparent selector\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Evaluating linealIIparent selector\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Evaluating tournament5parent selector\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Evaluating tournament3parent selector\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n",
      "Genetic algorithm params:\n",
      "Number of generations: 100\n",
      "Population size: 12\n",
      "num parents: 6\n",
      "offspring size: 6\n"
     ]
    }
   ],
   "source": [
    "pop_size = 12\n",
    "mut_prob = 0.2\n",
    "generations = 100\n",
    "num_parents = 0.5\n",
    "iters = 100\n",
    "\n",
    "c = chrom(mutation_prob=mut_prob)\n",
    "\n",
    "ps = {'random':RandomParentSelector(), 'linealI':LinealOrder(), 'linealII':LinealOrderII(), \n",
    "      'wheel':WheelSelection(), 'tournament5': TournamentSelection(5), 'tournament3': TournamentSelection(3)}\n",
    "\n",
    "all_fits = {}\n",
    "for key in ps.keys():\n",
    "    if key == 'wheel':\n",
    "        continue\n",
    "    print(\"Evaluating \" + key + \" parent selector\")\n",
    "    p = ps[key]\n",
    "    all_fits[key] = []\n",
    "    for i in range(iters):\n",
    "        generational = GenerationalGA(num_parents=num_parents, chromosome=c, parent_selector=p, generations=generations,\n",
    "                              num_population=pop_size, crossover_prob=0.5,\n",
    "                              mutation_prob=0.7, maximize_fitness=False, save_pop=True,\n",
    "                              statistical_validation=False)\n",
    "\n",
    "        winner, best_fit, ranking = generational.evolve(show=False)\n",
    "        all_fits[key].append(best_fit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random score: -25.5032  +-  6.1512\n",
      "linealI score: -26.0051  +-  5.4390\n",
      "linealII score: -26.4715  +-  5.4950\n",
      "tournament5 score: -27.9516  +-  5.6047\n",
      "tournament3 score: -27.3675  +-  6.1080\n"
     ]
    }
   ],
   "source": [
    "for key, value in all_fits.items():\n",
    "    print(key,\"score: %0.4f  +-  %0.4f\" % (np.mean(value), np.std(value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Lineal Order I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "\\begin{equation}\n",
    "SelectionProb_i = \\frac{Position_i}{\\sum_{j}{Position_j}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Lineal Order II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "\\begin{equation}\n",
    "SelectionProb_i = \\frac{N_{keep} - Position_i + 1}{\\sum_{j}^{N_{keep}}{Position_j}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Load variations of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_variations(folder, data):\n",
    "    file_list = [f for f in os.listdir(folder) if f[-3:]!='zip']\n",
    "    files = {'MB':'mnist',\n",
    "             'MBI':'mnist_background_images',\n",
    "             'MRB':'mnist_background_random',\n",
    "             'MRD':'mnist_rotation_new',\n",
    "             'MRDBI':'mnist_rotation_back_image_new'}\n",
    "    T_mode = {'MB':False,\n",
    "             'MBI':True,\n",
    "             'MRB':True,\n",
    "             'MRD':True,\n",
    "             'MRDBI':True}\n",
    "    assert data in files.keys()\n",
    "    dataset = files[data]\n",
    "    folder_datasets = os.path.join(folder, dataset)\n",
    "    datasets = os.listdir(folder_datasets)\n",
    "    file_train = os.path.join(folder_datasets, [d for d in datasets if 'train' in d][0])\n",
    "    file_test  = os.path.join(folder_datasets, [d for d in datasets if 'test'  in d][0])\n",
    "\n",
    "        \n",
    "    def get_XY(file):\n",
    "        with open(file, 'r') as f:\n",
    "            X, Y = [], []\n",
    "            for c, line in enumerate(f):\n",
    "                array = line.split(' ')\n",
    "                array = [float(l) for l in array if len(l)>0]\n",
    "                array = np.array(array)\n",
    "                Y.append(int(array[-1]))\n",
    "                if T_mode[data]:\n",
    "                    X.append(array[:-1].reshape(28, 28).T)\n",
    "                else:\n",
    "                    X.append(array[:-1].reshape(28, 28))\n",
    "        return np.array(X), np.array(Y, dtype=np.int32)\n",
    "\n",
    "    x_train, y_train = get_XY(file_train)\n",
    "    x_test , y_test  = get_XY(file_test)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 28, 28) (12000,)\n",
      "(50000, 28, 28) (50000,)\n"
     ]
    }
   ],
   "source": [
    "folder = '../../../../../datasets/MNIST_variations'\n",
    "data = 'MRDBI'\n",
    "(x_train, y_train), (x_test, y_test) = get_mnist_variations(folder, data)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "N = 2\n",
    "n = 5\n",
    "for k in range(N):\n",
    "    figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "    for i in range(n):\n",
    "        plt.subplot(1,n,i+1)\n",
    "        plt.imshow(x_train[N * k + i,...], cmap='gray')\n",
    "        plt.title(y_train[N * k + i])\n",
    "        plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluato models on MNIST's variants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.datamanager import DataManager\n",
    "from utils.codificication_mlp import Layer, Cromosome, Fitness        \n",
    "\n",
    "from time import time\n",
    "\n",
    "# Fitness params\n",
    "epochs = 50000\n",
    "batch_size = 128\n",
    "verbose = 1\n",
    "redu_plat = False\n",
    "early_stop = True\n",
    "\n",
    "# dataset params:\n",
    "dataset = 'MB'\n",
    "folder = '../../../../../datasets/MNIST_variations'\n",
    "classes = []\n",
    "\n",
    "fitness = Fitness.get_instance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  DATASET MB  ----------\n",
      "(9600, 28, 28, 1) train samples\n",
      "(2400, 28, 28, 1) validation samples\n",
      "(50000, 28, 28, 1) test samples\n",
      "\n",
      "\tTraining model:\n",
      "logreg\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/50000\n",
      "9600/9600 [==============================] - 1s 99us/step - loss: 2.2963 - acc: 0.3405 - val_loss: 2.2893 - val_acc: 0.4321\n",
      "Epoch 2/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2832 - acc: 0.4154 - val_loss: 2.2763 - val_acc: 0.4575\n",
      "Epoch 3/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.2705 - acc: 0.4697 - val_loss: 2.2635 - val_acc: 0.4496\n",
      "Epoch 4/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2581 - acc: 0.4635 - val_loss: 2.2509 - val_acc: 0.4663\n",
      "Epoch 5/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2458 - acc: 0.4917 - val_loss: 2.2384 - val_acc: 0.4837\n",
      "Epoch 6/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2335 - acc: 0.4985 - val_loss: 2.2259 - val_acc: 0.5012\n",
      "Epoch 7/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2214 - acc: 0.5186 - val_loss: 2.2135 - val_acc: 0.5183\n",
      "Epoch 8/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.2095 - acc: 0.5419 - val_loss: 2.2012 - val_acc: 0.5321\n",
      "Epoch 9/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1975 - acc: 0.5631 - val_loss: 2.1890 - val_acc: 0.5529\n",
      "Epoch 10/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1857 - acc: 0.5601 - val_loss: 2.1769 - val_acc: 0.5567\n",
      "Epoch 11/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1739 - acc: 0.5800 - val_loss: 2.1648 - val_acc: 0.5746\n",
      "Epoch 12/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1622 - acc: 0.5873 - val_loss: 2.1528 - val_acc: 0.5842\n",
      "Epoch 13/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1506 - acc: 0.6053 - val_loss: 2.1409 - val_acc: 0.5979\n",
      "Epoch 14/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1390 - acc: 0.6108 - val_loss: 2.1291 - val_acc: 0.6008\n",
      "Epoch 15/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1276 - acc: 0.6127 - val_loss: 2.1173 - val_acc: 0.6117\n",
      "Epoch 16/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1162 - acc: 0.6254 - val_loss: 2.1056 - val_acc: 0.6246\n",
      "Epoch 17/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1048 - acc: 0.6279 - val_loss: 2.0940 - val_acc: 0.6321\n",
      "Epoch 18/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0936 - acc: 0.6388 - val_loss: 2.0824 - val_acc: 0.6450\n",
      "Epoch 19/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0824 - acc: 0.6440 - val_loss: 2.0709 - val_acc: 0.6500\n",
      "Epoch 20/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0713 - acc: 0.6540 - val_loss: 2.0595 - val_acc: 0.6558\n",
      "Epoch 21/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0603 - acc: 0.6606 - val_loss: 2.0483 - val_acc: 0.6629\n",
      "Epoch 22/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0493 - acc: 0.6591 - val_loss: 2.0370 - val_acc: 0.6613\n",
      "Epoch 23/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0384 - acc: 0.6646 - val_loss: 2.0258 - val_acc: 0.6663\n",
      "Epoch 24/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0276 - acc: 0.6767 - val_loss: 2.0147 - val_acc: 0.6787\n",
      "Epoch 25/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0168 - acc: 0.6720 - val_loss: 2.0037 - val_acc: 0.6796\n",
      "Epoch 26/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0061 - acc: 0.6781 - val_loss: 1.9927 - val_acc: 0.6850\n",
      "Epoch 27/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9954 - acc: 0.6828 - val_loss: 1.9818 - val_acc: 0.6879\n",
      "Epoch 28/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9849 - acc: 0.6831 - val_loss: 1.9709 - val_acc: 0.6871\n",
      "Epoch 29/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.9744 - acc: 0.6869 - val_loss: 1.9602 - val_acc: 0.6983\n",
      "Epoch 30/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9640 - acc: 0.6918 - val_loss: 1.9495 - val_acc: 0.6996\n",
      "Epoch 31/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9536 - acc: 0.6946 - val_loss: 1.9389 - val_acc: 0.7008\n",
      "Epoch 32/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9433 - acc: 0.6981 - val_loss: 1.9284 - val_acc: 0.7067\n",
      "Epoch 33/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9331 - acc: 0.7029 - val_loss: 1.9179 - val_acc: 0.7050\n",
      "Epoch 34/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9229 - acc: 0.7040 - val_loss: 1.9074 - val_acc: 0.7100\n",
      "Epoch 35/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9128 - acc: 0.7054 - val_loss: 1.8971 - val_acc: 0.7137\n",
      "Epoch 36/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.9027 - acc: 0.7092 - val_loss: 1.8869 - val_acc: 0.7162\n",
      "Epoch 37/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.8928 - acc: 0.7130 - val_loss: 1.8765 - val_acc: 0.7196\n",
      "Epoch 38/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8829 - acc: 0.7127 - val_loss: 1.8664 - val_acc: 0.7204\n",
      "Epoch 39/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8730 - acc: 0.7160 - val_loss: 1.8563 - val_acc: 0.7233\n",
      "Epoch 40/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8632 - acc: 0.7171 - val_loss: 1.8463 - val_acc: 0.7238\n",
      "Epoch 41/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8535 - acc: 0.7205 - val_loss: 1.8363 - val_acc: 0.7271\n",
      "Epoch 42/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8438 - acc: 0.7243 - val_loss: 1.8264 - val_acc: 0.7325\n",
      "Epoch 43/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8342 - acc: 0.7224 - val_loss: 1.8166 - val_acc: 0.7308\n",
      "Epoch 44/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8247 - acc: 0.7273 - val_loss: 1.8069 - val_acc: 0.7304\n",
      "Epoch 45/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.8152 - acc: 0.7289 - val_loss: 1.7971 - val_acc: 0.7329\n",
      "Epoch 46/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.8058 - acc: 0.7293 - val_loss: 1.7875 - val_acc: 0.7350\n",
      "Epoch 47/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7964 - acc: 0.7325 - val_loss: 1.7779 - val_acc: 0.7371\n",
      "Epoch 48/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7871 - acc: 0.7329 - val_loss: 1.7684 - val_acc: 0.7392\n",
      "Epoch 49/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7779 - acc: 0.7346 - val_loss: 1.7589 - val_acc: 0.7417\n",
      "Epoch 50/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7687 - acc: 0.7365 - val_loss: 1.7496 - val_acc: 0.7417\n",
      "Epoch 51/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7595 - acc: 0.7377 - val_loss: 1.7402 - val_acc: 0.7425\n",
      "Epoch 52/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7505 - acc: 0.7398 - val_loss: 1.7309 - val_acc: 0.7446\n",
      "Epoch 53/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7415 - acc: 0.7420 - val_loss: 1.7217 - val_acc: 0.7462\n",
      "Epoch 54/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7325 - acc: 0.7418 - val_loss: 1.7125 - val_acc: 0.7500\n",
      "Epoch 55/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.7236 - acc: 0.7434 - val_loss: 1.7034 - val_acc: 0.7496\n",
      "Epoch 56/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7148 - acc: 0.7445 - val_loss: 1.6944 - val_acc: 0.7496\n",
      "Epoch 57/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7060 - acc: 0.7455 - val_loss: 1.6855 - val_acc: 0.7525\n",
      "Epoch 58/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6973 - acc: 0.7483 - val_loss: 1.6765 - val_acc: 0.7529\n",
      "Epoch 59/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6886 - acc: 0.7515 - val_loss: 1.6677 - val_acc: 0.7563\n",
      "Epoch 60/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6800 - acc: 0.7494 - val_loss: 1.6589 - val_acc: 0.7575\n",
      "Epoch 61/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6715 - acc: 0.7520 - val_loss: 1.6502 - val_acc: 0.7608\n",
      "Epoch 62/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.6630 - acc: 0.7519 - val_loss: 1.6415 - val_acc: 0.7608\n",
      "Epoch 63/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6546 - acc: 0.7528 - val_loss: 1.6329 - val_acc: 0.7629\n",
      "Epoch 64/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6462 - acc: 0.7544 - val_loss: 1.6244 - val_acc: 0.7638\n",
      "Epoch 65/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6379 - acc: 0.7556 - val_loss: 1.6158 - val_acc: 0.7629\n",
      "Epoch 66/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6296 - acc: 0.7565 - val_loss: 1.6074 - val_acc: 0.7658\n",
      "Epoch 67/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6214 - acc: 0.7584 - val_loss: 1.5991 - val_acc: 0.7671\n",
      "Epoch 68/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6133 - acc: 0.7574 - val_loss: 1.5908 - val_acc: 0.7671\n",
      "Epoch 69/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6052 - acc: 0.7593 - val_loss: 1.5826 - val_acc: 0.7679\n",
      "Epoch 70/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5971 - acc: 0.7601 - val_loss: 1.5744 - val_acc: 0.7692\n",
      "Epoch 71/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5891 - acc: 0.7618 - val_loss: 1.5662 - val_acc: 0.7692\n",
      "Epoch 72/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5812 - acc: 0.7615 - val_loss: 1.5581 - val_acc: 0.7704\n",
      "Epoch 73/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5734 - acc: 0.7625 - val_loss: 1.5501 - val_acc: 0.7708\n",
      "Epoch 74/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5656 - acc: 0.7628 - val_loss: 1.5421 - val_acc: 0.7725\n",
      "Epoch 75/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5578 - acc: 0.7655 - val_loss: 1.5342 - val_acc: 0.7767\n",
      "Epoch 76/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5501 - acc: 0.7655 - val_loss: 1.5264 - val_acc: 0.7750\n",
      "Epoch 77/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5425 - acc: 0.7655 - val_loss: 1.5186 - val_acc: 0.7754\n",
      "Epoch 78/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5349 - acc: 0.7666 - val_loss: 1.5109 - val_acc: 0.7783\n",
      "Epoch 79/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5274 - acc: 0.7691 - val_loss: 1.5032 - val_acc: 0.7792\n",
      "Epoch 80/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5199 - acc: 0.7697 - val_loss: 1.4956 - val_acc: 0.7796\n",
      "Epoch 81/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5125 - acc: 0.7705 - val_loss: 1.4881 - val_acc: 0.7804\n",
      "Epoch 82/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5051 - acc: 0.7701 - val_loss: 1.4805 - val_acc: 0.7812\n",
      "Epoch 83/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4978 - acc: 0.7727 - val_loss: 1.4731 - val_acc: 0.7829\n",
      "Epoch 84/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4905 - acc: 0.7728 - val_loss: 1.4657 - val_acc: 0.7825\n",
      "Epoch 85/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4833 - acc: 0.7726 - val_loss: 1.4583 - val_acc: 0.7838\n",
      "Epoch 86/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4761 - acc: 0.7725 - val_loss: 1.4510 - val_acc: 0.7842\n",
      "Epoch 87/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.4690 - acc: 0.7750 - val_loss: 1.4437 - val_acc: 0.7867\n",
      "Epoch 88/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4619 - acc: 0.7744 - val_loss: 1.4366 - val_acc: 0.7858\n",
      "Epoch 89/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4549 - acc: 0.7756 - val_loss: 1.4294 - val_acc: 0.7858\n",
      "Epoch 90/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4479 - acc: 0.7756 - val_loss: 1.4223 - val_acc: 0.7875\n",
      "Epoch 91/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4410 - acc: 0.7777 - val_loss: 1.4153 - val_acc: 0.7871\n",
      "Epoch 92/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4341 - acc: 0.7782 - val_loss: 1.4083 - val_acc: 0.7900\n",
      "Epoch 93/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4273 - acc: 0.7804 - val_loss: 1.4014 - val_acc: 0.7908\n",
      "Epoch 94/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4205 - acc: 0.7794 - val_loss: 1.3945 - val_acc: 0.7904\n",
      "Epoch 95/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4138 - acc: 0.7801 - val_loss: 1.3877 - val_acc: 0.7908\n",
      "Epoch 96/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4071 - acc: 0.7821 - val_loss: 1.3809 - val_acc: 0.7925\n",
      "Epoch 97/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4005 - acc: 0.7823 - val_loss: 1.3741 - val_acc: 0.7917\n",
      "Epoch 98/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3940 - acc: 0.7828 - val_loss: 1.3675 - val_acc: 0.7933\n",
      "Epoch 99/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3874 - acc: 0.7834 - val_loss: 1.3608 - val_acc: 0.7946\n",
      "Epoch 100/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3809 - acc: 0.7848 - val_loss: 1.3542 - val_acc: 0.7950\n",
      "Epoch 101/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3745 - acc: 0.7850 - val_loss: 1.3477 - val_acc: 0.7954\n",
      "Epoch 102/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3681 - acc: 0.7858 - val_loss: 1.3412 - val_acc: 0.7967\n",
      "Epoch 103/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3618 - acc: 0.7852 - val_loss: 1.3348 - val_acc: 0.7971\n",
      "Epoch 104/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3554 - acc: 0.7875 - val_loss: 1.3284 - val_acc: 0.8000\n",
      "Epoch 105/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3492 - acc: 0.7879 - val_loss: 1.3221 - val_acc: 0.8008\n",
      "Epoch 106/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3430 - acc: 0.7883 - val_loss: 1.3158 - val_acc: 0.8017\n",
      "Epoch 107/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3369 - acc: 0.7887 - val_loss: 1.3095 - val_acc: 0.8013\n",
      "Epoch 108/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3307 - acc: 0.7897 - val_loss: 1.3033 - val_acc: 0.8021\n",
      "Epoch 109/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3247 - acc: 0.7913 - val_loss: 1.2972 - val_acc: 0.8033\n",
      "Epoch 110/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3187 - acc: 0.7902 - val_loss: 1.2911 - val_acc: 0.8025\n",
      "Epoch 111/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3127 - acc: 0.7915 - val_loss: 1.2850 - val_acc: 0.8033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3067 - acc: 0.7914 - val_loss: 1.2790 - val_acc: 0.8037\n",
      "Epoch 113/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3008 - acc: 0.7934 - val_loss: 1.2731 - val_acc: 0.8054\n",
      "Epoch 114/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.2950 - acc: 0.7940 - val_loss: 1.2671 - val_acc: 0.8054\n",
      "Epoch 115/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.2892 - acc: 0.7938 - val_loss: 1.2613 - val_acc: 0.8050\n",
      "Epoch 116/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.2834 - acc: 0.7948 - val_loss: 1.2554 - val_acc: 0.8054\n",
      "Epoch 117/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.2777 - acc: 0.7957 - val_loss: 1.2495 - val_acc: 0.8058\n",
      "Epoch 118/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.2720 - acc: 0.7963 - val_loss: 1.2438 - val_acc: 0.8063\n",
      "Epoch 119/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2664 - acc: 0.7966 - val_loss: 1.2382 - val_acc: 0.8079\n",
      "Epoch 120/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2608 - acc: 0.7974 - val_loss: 1.2324 - val_acc: 0.8083\n",
      "Epoch 121/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2552 - acc: 0.7976 - val_loss: 1.2269 - val_acc: 0.8087\n",
      "Epoch 122/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2498 - acc: 0.7982 - val_loss: 1.2213 - val_acc: 0.8096\n",
      "Epoch 123/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2443 - acc: 0.7986 - val_loss: 1.2157 - val_acc: 0.8087\n",
      "Epoch 124/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2388 - acc: 0.8002 - val_loss: 1.2102 - val_acc: 0.8108\n",
      "Epoch 125/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2334 - acc: 0.8006 - val_loss: 1.2048 - val_acc: 0.8121\n",
      "Epoch 126/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2281 - acc: 0.8015 - val_loss: 1.1993 - val_acc: 0.8104\n",
      "Epoch 127/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2228 - acc: 0.8004 - val_loss: 1.1940 - val_acc: 0.8113\n",
      "Epoch 128/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2175 - acc: 0.8019 - val_loss: 1.1887 - val_acc: 0.8117\n",
      "Epoch 129/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2123 - acc: 0.8018 - val_loss: 1.1834 - val_acc: 0.8121\n",
      "Epoch 130/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2070 - acc: 0.8026 - val_loss: 1.1781 - val_acc: 0.8129\n",
      "Epoch 131/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2019 - acc: 0.8031 - val_loss: 1.1729 - val_acc: 0.8121\n",
      "Epoch 132/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1968 - acc: 0.8028 - val_loss: 1.1678 - val_acc: 0.8129\n",
      "Epoch 133/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1917 - acc: 0.8035 - val_loss: 1.1627 - val_acc: 0.8125\n",
      "Epoch 134/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1867 - acc: 0.8040 - val_loss: 1.1576 - val_acc: 0.8121\n",
      "Epoch 135/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1817 - acc: 0.8043 - val_loss: 1.1525 - val_acc: 0.8138\n",
      "Epoch 136/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1767 - acc: 0.8063 - val_loss: 1.1475 - val_acc: 0.8146\n",
      "Epoch 137/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1718 - acc: 0.8059 - val_loss: 1.1425 - val_acc: 0.8167\n",
      "Epoch 138/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1669 - acc: 0.8059 - val_loss: 1.1376 - val_acc: 0.8167\n",
      "Epoch 139/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1620 - acc: 0.8064 - val_loss: 1.1327 - val_acc: 0.8183\n",
      "Epoch 140/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1573 - acc: 0.8075 - val_loss: 1.1278 - val_acc: 0.8183\n",
      "Epoch 141/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1524 - acc: 0.8068 - val_loss: 1.1230 - val_acc: 0.8196\n",
      "Epoch 142/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1477 - acc: 0.8069 - val_loss: 1.1182 - val_acc: 0.8196\n",
      "Epoch 143/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1430 - acc: 0.8082 - val_loss: 1.1135 - val_acc: 0.8213\n",
      "Epoch 144/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1383 - acc: 0.8092 - val_loss: 1.1088 - val_acc: 0.8221\n",
      "Epoch 145/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1337 - acc: 0.8094 - val_loss: 1.1042 - val_acc: 0.8213\n",
      "Epoch 146/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1291 - acc: 0.8094 - val_loss: 1.0995 - val_acc: 0.8217\n",
      "Epoch 147/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1245 - acc: 0.8102 - val_loss: 1.0949 - val_acc: 0.8217\n",
      "Epoch 148/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1200 - acc: 0.8100 - val_loss: 1.0903 - val_acc: 0.8217\n",
      "Epoch 149/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1154 - acc: 0.8108 - val_loss: 1.0858 - val_acc: 0.8225\n",
      "Epoch 150/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1109 - acc: 0.8111 - val_loss: 1.0813 - val_acc: 0.8233\n",
      "Epoch 151/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1065 - acc: 0.8117 - val_loss: 1.0769 - val_acc: 0.8242\n",
      "Epoch 152/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1021 - acc: 0.8126 - val_loss: 1.0724 - val_acc: 0.8242\n",
      "Epoch 153/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0978 - acc: 0.8126 - val_loss: 1.0680 - val_acc: 0.8246\n",
      "Epoch 154/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0934 - acc: 0.8131 - val_loss: 1.0637 - val_acc: 0.8254\n",
      "Epoch 155/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0891 - acc: 0.8130 - val_loss: 1.0594 - val_acc: 0.8263\n",
      "Epoch 156/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0849 - acc: 0.8143 - val_loss: 1.0551 - val_acc: 0.8258\n",
      "Epoch 157/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0806 - acc: 0.8146 - val_loss: 1.0508 - val_acc: 0.8254\n",
      "Epoch 158/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0764 - acc: 0.8146 - val_loss: 1.0466 - val_acc: 0.8263\n",
      "Epoch 159/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0723 - acc: 0.8161 - val_loss: 1.0424 - val_acc: 0.8263\n",
      "Epoch 160/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0681 - acc: 0.8157 - val_loss: 1.0382 - val_acc: 0.8271\n",
      "Epoch 161/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0640 - acc: 0.8168 - val_loss: 1.0341 - val_acc: 0.8258\n",
      "Epoch 162/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0599 - acc: 0.8178 - val_loss: 1.0300 - val_acc: 0.8279\n",
      "Epoch 163/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0558 - acc: 0.8178 - val_loss: 1.0259 - val_acc: 0.8267\n",
      "Epoch 164/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0518 - acc: 0.8182 - val_loss: 1.0219 - val_acc: 0.8279\n",
      "Epoch 165/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0478 - acc: 0.8182 - val_loss: 1.0179 - val_acc: 0.8287\n",
      "Epoch 166/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0439 - acc: 0.8196 - val_loss: 1.0139 - val_acc: 0.8300\n",
      "Epoch 167/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0399 - acc: 0.8200 - val_loss: 1.0100 - val_acc: 0.8296\n",
      "Epoch 168/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0360 - acc: 0.8204 - val_loss: 1.0060 - val_acc: 0.8304\n",
      "Epoch 169/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0321 - acc: 0.8203 - val_loss: 1.0022 - val_acc: 0.8304\n",
      "Epoch 170/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0283 - acc: 0.8214 - val_loss: 0.9983 - val_acc: 0.8308\n",
      "Epoch 171/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0245 - acc: 0.8219 - val_loss: 0.9945 - val_acc: 0.8317\n",
      "Epoch 172/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0207 - acc: 0.8221 - val_loss: 0.9907 - val_acc: 0.8317\n",
      "Epoch 173/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0169 - acc: 0.8229 - val_loss: 0.9869 - val_acc: 0.8317\n",
      "Epoch 174/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0132 - acc: 0.8228 - val_loss: 0.9832 - val_acc: 0.8321\n",
      "Epoch 175/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0095 - acc: 0.8234 - val_loss: 0.9795 - val_acc: 0.8321\n",
      "Epoch 176/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0058 - acc: 0.8232 - val_loss: 0.9758 - val_acc: 0.8321\n",
      "Epoch 177/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0022 - acc: 0.8242 - val_loss: 0.9721 - val_acc: 0.8325\n",
      "Epoch 178/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9985 - acc: 0.8245 - val_loss: 0.9685 - val_acc: 0.8317\n",
      "Epoch 179/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9949 - acc: 0.8250 - val_loss: 0.9649 - val_acc: 0.8317\n",
      "Epoch 180/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9913 - acc: 0.8256 - val_loss: 0.9613 - val_acc: 0.8329\n",
      "Epoch 181/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9878 - acc: 0.8266 - val_loss: 0.9578 - val_acc: 0.8325\n",
      "Epoch 182/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9843 - acc: 0.8267 - val_loss: 0.9542 - val_acc: 0.8325\n",
      "Epoch 183/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9808 - acc: 0.8270 - val_loss: 0.9507 - val_acc: 0.8321\n",
      "Epoch 184/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9773 - acc: 0.8269 - val_loss: 0.9473 - val_acc: 0.8325\n",
      "Epoch 185/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9738 - acc: 0.8274 - val_loss: 0.9438 - val_acc: 0.8321\n",
      "Epoch 186/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9704 - acc: 0.8280 - val_loss: 0.9404 - val_acc: 0.8329\n",
      "Epoch 187/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9670 - acc: 0.8285 - val_loss: 0.9370 - val_acc: 0.8325\n",
      "Epoch 188/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9636 - acc: 0.8289 - val_loss: 0.9336 - val_acc: 0.8333\n",
      "Epoch 189/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9603 - acc: 0.8291 - val_loss: 0.9303 - val_acc: 0.8333\n",
      "Epoch 190/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9570 - acc: 0.8292 - val_loss: 0.9270 - val_acc: 0.8342\n",
      "Epoch 191/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9537 - acc: 0.8295 - val_loss: 0.9237 - val_acc: 0.8337\n",
      "Epoch 192/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9504 - acc: 0.8300 - val_loss: 0.9204 - val_acc: 0.8342\n",
      "Epoch 193/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9471 - acc: 0.8307 - val_loss: 0.9172 - val_acc: 0.8358\n",
      "Epoch 194/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9439 - acc: 0.8303 - val_loss: 0.9139 - val_acc: 0.8346\n",
      "Epoch 195/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9407 - acc: 0.8309 - val_loss: 0.9107 - val_acc: 0.8350\n",
      "Epoch 196/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9375 - acc: 0.8314 - val_loss: 0.9076 - val_acc: 0.8363\n",
      "Epoch 197/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9343 - acc: 0.8326 - val_loss: 0.9044 - val_acc: 0.8358\n",
      "Epoch 198/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9312 - acc: 0.8324 - val_loss: 0.9013 - val_acc: 0.8367\n",
      "Epoch 199/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9281 - acc: 0.8329 - val_loss: 0.8982 - val_acc: 0.8367\n",
      "Epoch 200/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9250 - acc: 0.8336 - val_loss: 0.8951 - val_acc: 0.8371\n",
      "Epoch 201/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9219 - acc: 0.8340 - val_loss: 0.8921 - val_acc: 0.8367\n",
      "Epoch 202/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9189 - acc: 0.8343 - val_loss: 0.8890 - val_acc: 0.8379\n",
      "Epoch 203/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9158 - acc: 0.8349 - val_loss: 0.8860 - val_acc: 0.8387\n",
      "Epoch 204/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9129 - acc: 0.8355 - val_loss: 0.8831 - val_acc: 0.8396\n",
      "Epoch 205/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9099 - acc: 0.8352 - val_loss: 0.8800 - val_acc: 0.8396\n",
      "Epoch 206/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9068 - acc: 0.8359 - val_loss: 0.8771 - val_acc: 0.8404\n",
      "Epoch 207/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9039 - acc: 0.8364 - val_loss: 0.8741 - val_acc: 0.8400\n",
      "Epoch 208/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9010 - acc: 0.8367 - val_loss: 0.8712 - val_acc: 0.8404\n",
      "Epoch 209/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8981 - acc: 0.8369 - val_loss: 0.8684 - val_acc: 0.8404\n",
      "Epoch 210/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8952 - acc: 0.8371 - val_loss: 0.8655 - val_acc: 0.8421\n",
      "Epoch 211/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8923 - acc: 0.8369 - val_loss: 0.8627 - val_acc: 0.8417\n",
      "Epoch 212/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8895 - acc: 0.8373 - val_loss: 0.8598 - val_acc: 0.8417\n",
      "Epoch 213/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8866 - acc: 0.8374 - val_loss: 0.8570 - val_acc: 0.8425\n",
      "Epoch 214/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8839 - acc: 0.8376 - val_loss: 0.8543 - val_acc: 0.8433\n",
      "Epoch 215/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8811 - acc: 0.8377 - val_loss: 0.8515 - val_acc: 0.8433\n",
      "Epoch 216/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8783 - acc: 0.8381 - val_loss: 0.8488 - val_acc: 0.8429\n",
      "Epoch 217/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8755 - acc: 0.8384 - val_loss: 0.8460 - val_acc: 0.8438\n",
      "Epoch 218/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8728 - acc: 0.8387 - val_loss: 0.8433 - val_acc: 0.8438\n",
      "Epoch 219/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8701 - acc: 0.8383 - val_loss: 0.8406 - val_acc: 0.8442\n",
      "Epoch 220/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8674 - acc: 0.8385 - val_loss: 0.8379 - val_acc: 0.8442\n",
      "Epoch 221/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8647 - acc: 0.8386 - val_loss: 0.8353 - val_acc: 0.8442\n",
      "Epoch 222/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8621 - acc: 0.8396 - val_loss: 0.8326 - val_acc: 0.8450\n",
      "Epoch 223/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8595 - acc: 0.8399 - val_loss: 0.8301 - val_acc: 0.8450\n",
      "Epoch 224/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8569 - acc: 0.8391 - val_loss: 0.8274 - val_acc: 0.8454\n",
      "Epoch 225/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8542 - acc: 0.8399 - val_loss: 0.8249 - val_acc: 0.8454\n",
      "Epoch 226/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8516 - acc: 0.8403 - val_loss: 0.8224 - val_acc: 0.8454\n",
      "Epoch 227/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8491 - acc: 0.8403 - val_loss: 0.8198 - val_acc: 0.8458\n",
      "Epoch 228/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8465 - acc: 0.8406 - val_loss: 0.8172 - val_acc: 0.8467\n",
      "Epoch 229/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8440 - acc: 0.8405 - val_loss: 0.8148 - val_acc: 0.8462\n",
      "Epoch 230/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8415 - acc: 0.8408 - val_loss: 0.8123 - val_acc: 0.8475\n",
      "Epoch 231/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8390 - acc: 0.8416 - val_loss: 0.8098 - val_acc: 0.8479\n",
      "Epoch 232/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8365 - acc: 0.8417 - val_loss: 0.8074 - val_acc: 0.8479\n",
      "Epoch 233/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8340 - acc: 0.8417 - val_loss: 0.8049 - val_acc: 0.8483\n",
      "Epoch 234/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8316 - acc: 0.8422 - val_loss: 0.8025 - val_acc: 0.8483\n",
      "Epoch 235/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.8291 - acc: 0.8423 - val_loss: 0.8001 - val_acc: 0.8479\n",
      "Epoch 236/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8267 - acc: 0.8421 - val_loss: 0.7977 - val_acc: 0.8483\n",
      "Epoch 237/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8243 - acc: 0.8423 - val_loss: 0.7953 - val_acc: 0.8483\n",
      "Epoch 238/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8219 - acc: 0.8428 - val_loss: 0.7930 - val_acc: 0.8483\n",
      "Epoch 239/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8196 - acc: 0.8432 - val_loss: 0.7906 - val_acc: 0.8483\n",
      "Epoch 240/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8172 - acc: 0.8432 - val_loss: 0.7883 - val_acc: 0.8492\n",
      "Epoch 241/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8149 - acc: 0.8440 - val_loss: 0.7860 - val_acc: 0.8492\n",
      "Epoch 242/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8126 - acc: 0.8438 - val_loss: 0.7837 - val_acc: 0.8492\n",
      "Epoch 243/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8102 - acc: 0.8439 - val_loss: 0.7814 - val_acc: 0.8496\n",
      "Epoch 244/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8079 - acc: 0.8444 - val_loss: 0.7792 - val_acc: 0.8496\n",
      "Epoch 245/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8057 - acc: 0.8444 - val_loss: 0.7770 - val_acc: 0.8496\n",
      "Epoch 246/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8034 - acc: 0.8449 - val_loss: 0.7747 - val_acc: 0.8496\n",
      "Epoch 247/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8012 - acc: 0.8450 - val_loss: 0.7725 - val_acc: 0.8508\n",
      "Epoch 248/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7989 - acc: 0.8454 - val_loss: 0.7703 - val_acc: 0.8513\n",
      "Epoch 249/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7967 - acc: 0.8460 - val_loss: 0.7681 - val_acc: 0.8512\n",
      "Epoch 250/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7945 - acc: 0.8459 - val_loss: 0.7659 - val_acc: 0.8529\n",
      "Epoch 251/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7923 - acc: 0.8462 - val_loss: 0.7638 - val_acc: 0.8529\n",
      "Epoch 252/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7901 - acc: 0.8473 - val_loss: 0.7616 - val_acc: 0.8525\n",
      "Epoch 253/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7880 - acc: 0.8472 - val_loss: 0.7596 - val_acc: 0.8525\n",
      "Epoch 254/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7859 - acc: 0.8474 - val_loss: 0.7574 - val_acc: 0.8525\n",
      "Epoch 255/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7837 - acc: 0.8477 - val_loss: 0.7553 - val_acc: 0.8525\n",
      "Epoch 256/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.7816 - acc: 0.8476 - val_loss: 0.7533 - val_acc: 0.8525\n",
      "Epoch 257/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.7795 - acc: 0.8481 - val_loss: 0.7512 - val_acc: 0.8525\n",
      "Epoch 258/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.7774 - acc: 0.8486 - val_loss: 0.7491 - val_acc: 0.8525\n",
      "Epoch 259/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.7753 - acc: 0.8494 - val_loss: 0.7471 - val_acc: 0.8525\n",
      "Epoch 260/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.7733 - acc: 0.8500 - val_loss: 0.7451 - val_acc: 0.8525\n",
      "Epoch 261/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.7713 - acc: 0.8495 - val_loss: 0.7430 - val_acc: 0.8525\n",
      "Epoch 262/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.7692 - acc: 0.8497 - val_loss: 0.7411 - val_acc: 0.8525\n",
      "Epoch 263/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.7672 - acc: 0.8500 - val_loss: 0.7391 - val_acc: 0.8525\n",
      "Epoch 264/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.7652 - acc: 0.8503 - val_loss: 0.7371 - val_acc: 0.8525\n",
      "Epoch 265/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 0.7632 - acc: 0.8514 - val_loss: 0.7352 - val_acc: 0.8533\n",
      "Epoch 266/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 0.7612 - acc: 0.8508 - val_loss: 0.7332 - val_acc: 0.8529\n",
      "Epoch 267/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.7592 - acc: 0.8509 - val_loss: 0.7313 - val_acc: 0.8529\n",
      "Epoch 268/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.7573 - acc: 0.8516 - val_loss: 0.7294 - val_acc: 0.8529\n",
      "Epoch 269/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.7554 - acc: 0.8519 - val_loss: 0.7275 - val_acc: 0.8542\n",
      "Epoch 270/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.7534 - acc: 0.8522 - val_loss: 0.7255 - val_acc: 0.8550\n",
      "Epoch 271/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.7515 - acc: 0.8521 - val_loss: 0.7237 - val_acc: 0.8554\n",
      "Epoch 272/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7496 - acc: 0.8525 - val_loss: 0.7218 - val_acc: 0.8554\n",
      "Epoch 273/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7477 - acc: 0.8524 - val_loss: 0.7200 - val_acc: 0.8554\n",
      "Epoch 274/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7458 - acc: 0.8524 - val_loss: 0.7182 - val_acc: 0.8554\n",
      "Epoch 275/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7440 - acc: 0.8528 - val_loss: 0.7164 - val_acc: 0.8558\n",
      "Epoch 276/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7421 - acc: 0.8531 - val_loss: 0.7145 - val_acc: 0.8558\n",
      "Epoch 277/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7403 - acc: 0.8534 - val_loss: 0.7127 - val_acc: 0.8562\n",
      "Epoch 278/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7384 - acc: 0.8536 - val_loss: 0.7109 - val_acc: 0.8575\n",
      "Epoch 279/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7366 - acc: 0.8542 - val_loss: 0.7092 - val_acc: 0.8567\n",
      "Epoch 280/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7348 - acc: 0.8546 - val_loss: 0.7073 - val_acc: 0.8588\n",
      "Epoch 281/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7330 - acc: 0.8548 - val_loss: 0.7056 - val_acc: 0.8567\n",
      "Epoch 282/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.7312 - acc: 0.8547 - val_loss: 0.7039 - val_acc: 0.8583\n",
      "Epoch 283/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.7294 - acc: 0.8552 - val_loss: 0.7021 - val_acc: 0.8583\n",
      "Epoch 284/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7276 - acc: 0.8551 - val_loss: 0.7004 - val_acc: 0.8592\n",
      "Epoch 285/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7259 - acc: 0.8555 - val_loss: 0.6987 - val_acc: 0.8596\n",
      "Epoch 286/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7242 - acc: 0.8560 - val_loss: 0.6970 - val_acc: 0.8596\n",
      "Epoch 287/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7224 - acc: 0.8565 - val_loss: 0.6953 - val_acc: 0.8592\n",
      "Epoch 288/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7207 - acc: 0.8565 - val_loss: 0.6936 - val_acc: 0.8592\n",
      "Epoch 289/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7190 - acc: 0.8567 - val_loss: 0.6919 - val_acc: 0.8592\n",
      "Epoch 290/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7173 - acc: 0.8570 - val_loss: 0.6903 - val_acc: 0.8596\n",
      "Epoch 291/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7156 - acc: 0.8568 - val_loss: 0.6887 - val_acc: 0.8617\n",
      "Epoch 292/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7139 - acc: 0.8570 - val_loss: 0.6870 - val_acc: 0.8604\n",
      "Epoch 293/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.7123 - acc: 0.8575 - val_loss: 0.6854 - val_acc: 0.8617\n",
      "Epoch 294/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7106 - acc: 0.8573 - val_loss: 0.6837 - val_acc: 0.8621\n",
      "Epoch 295/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7089 - acc: 0.8572 - val_loss: 0.6821 - val_acc: 0.8625\n",
      "Epoch 296/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7073 - acc: 0.8579 - val_loss: 0.6805 - val_acc: 0.8625\n",
      "Epoch 297/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 0.7057 - acc: 0.8578 - val_loss: 0.6789 - val_acc: 0.8617\n",
      "Epoch 298/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.7040 - acc: 0.8581 - val_loss: 0.6774 - val_acc: 0.8633\n",
      "Epoch 299/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7024 - acc: 0.8582 - val_loss: 0.6759 - val_acc: 0.8633\n",
      "Epoch 300/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.7008 - acc: 0.8585 - val_loss: 0.6743 - val_acc: 0.8633\n",
      "Epoch 301/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6993 - acc: 0.8594 - val_loss: 0.6727 - val_acc: 0.8637\n",
      "Epoch 302/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6977 - acc: 0.8588 - val_loss: 0.6712 - val_acc: 0.8629\n",
      "Epoch 303/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6961 - acc: 0.8592 - val_loss: 0.6696 - val_acc: 0.8642\n",
      "Epoch 304/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6945 - acc: 0.8595 - val_loss: 0.6681 - val_acc: 0.8642\n",
      "Epoch 305/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6930 - acc: 0.8599 - val_loss: 0.6666 - val_acc: 0.8642\n",
      "Epoch 306/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6914 - acc: 0.8601 - val_loss: 0.6651 - val_acc: 0.8642\n",
      "Epoch 307/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6899 - acc: 0.8604 - val_loss: 0.6636 - val_acc: 0.8642\n",
      "Epoch 308/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.6884 - acc: 0.8602 - val_loss: 0.6622 - val_acc: 0.8642\n",
      "Epoch 309/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6868 - acc: 0.8608 - val_loss: 0.6606 - val_acc: 0.8646\n",
      "Epoch 310/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.6853 - acc: 0.8611 - val_loss: 0.6592 - val_acc: 0.8642\n",
      "Epoch 311/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.6838 - acc: 0.8612 - val_loss: 0.6577 - val_acc: 0.8650\n",
      "Epoch 312/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.6824 - acc: 0.8621 - val_loss: 0.6563 - val_acc: 0.8654\n",
      "Epoch 313/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.6809 - acc: 0.8620 - val_loss: 0.6549 - val_acc: 0.8654\n",
      "Epoch 314/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.6794 - acc: 0.8620 - val_loss: 0.6535 - val_acc: 0.8654\n",
      "Epoch 315/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.6779 - acc: 0.8627 - val_loss: 0.6520 - val_acc: 0.8654\n",
      "Epoch 316/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.6765 - acc: 0.8621 - val_loss: 0.6506 - val_acc: 0.8654\n",
      "Epoch 317/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.6750 - acc: 0.8628 - val_loss: 0.6492 - val_acc: 0.8654\n",
      "Epoch 318/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.6736 - acc: 0.8631 - val_loss: 0.6478 - val_acc: 0.8654\n",
      "Epoch 319/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.6722 - acc: 0.8632 - val_loss: 0.6465 - val_acc: 0.8654\n",
      "Epoch 320/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.6707 - acc: 0.8640 - val_loss: 0.6451 - val_acc: 0.8654\n",
      "Epoch 321/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.6693 - acc: 0.8635 - val_loss: 0.6437 - val_acc: 0.8654\n",
      "Epoch 322/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.6679 - acc: 0.8644 - val_loss: 0.6423 - val_acc: 0.8667\n",
      "Epoch 323/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.6666 - acc: 0.8641 - val_loss: 0.6410 - val_acc: 0.8662\n",
      "Epoch 324/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.6651 - acc: 0.8648 - val_loss: 0.6396 - val_acc: 0.8662\n",
      "Epoch 325/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.6638 - acc: 0.8648 - val_loss: 0.6383 - val_acc: 0.8667\n",
      "Epoch 326/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.6624 - acc: 0.8651 - val_loss: 0.6370 - val_acc: 0.8662\n",
      "Epoch 327/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.6610 - acc: 0.8654 - val_loss: 0.6357 - val_acc: 0.8667\n",
      "Epoch 328/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.6597 - acc: 0.8653 - val_loss: 0.6343 - val_acc: 0.8667\n",
      "Epoch 329/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.6583 - acc: 0.8655 - val_loss: 0.6330 - val_acc: 0.8671\n",
      "Epoch 330/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.6570 - acc: 0.8662 - val_loss: 0.6318 - val_acc: 0.8671\n",
      "Epoch 331/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.6557 - acc: 0.8662 - val_loss: 0.6304 - val_acc: 0.8671\n",
      "Epoch 332/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.6543 - acc: 0.8662 - val_loss: 0.6292 - val_acc: 0.8675\n",
      "Epoch 333/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.6530 - acc: 0.8672 - val_loss: 0.6279 - val_acc: 0.8671\n",
      "Epoch 334/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.6517 - acc: 0.8669 - val_loss: 0.6267 - val_acc: 0.8683\n",
      "Epoch 335/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.6504 - acc: 0.8670 - val_loss: 0.6254 - val_acc: 0.8675\n",
      "Epoch 336/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.6491 - acc: 0.8676 - val_loss: 0.6242 - val_acc: 0.8692\n",
      "Epoch 337/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.6478 - acc: 0.8680 - val_loss: 0.6229 - val_acc: 0.8679\n",
      "Epoch 338/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.6465 - acc: 0.8678 - val_loss: 0.6217 - val_acc: 0.8692\n",
      "Epoch 339/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.6453 - acc: 0.8680 - val_loss: 0.6204 - val_acc: 0.8687\n",
      "Epoch 340/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.6440 - acc: 0.8683 - val_loss: 0.6192 - val_acc: 0.8687\n",
      "Epoch 341/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.6427 - acc: 0.8678 - val_loss: 0.6180 - val_acc: 0.8696\n",
      "Epoch 342/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.6415 - acc: 0.8684 - val_loss: 0.6169 - val_acc: 0.8696\n",
      "Epoch 343/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.6402 - acc: 0.8685 - val_loss: 0.6156 - val_acc: 0.8687\n",
      "Epoch 344/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.6390 - acc: 0.8688 - val_loss: 0.6144 - val_acc: 0.8687\n",
      "Epoch 345/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6378 - acc: 0.8691 - val_loss: 0.6132 - val_acc: 0.8692\n",
      "Epoch 346/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6365 - acc: 0.8691 - val_loss: 0.6120 - val_acc: 0.8692\n",
      "Epoch 347/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6353 - acc: 0.8692 - val_loss: 0.6109 - val_acc: 0.8687\n",
      "Epoch 348/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6341 - acc: 0.8692 - val_loss: 0.6097 - val_acc: 0.8696\n",
      "Epoch 349/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.6329 - acc: 0.8694 - val_loss: 0.6086 - val_acc: 0.8692\n",
      "Epoch 350/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.6317 - acc: 0.8694 - val_loss: 0.6074 - val_acc: 0.8700\n",
      "Epoch 351/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6305 - acc: 0.8696 - val_loss: 0.6062 - val_acc: 0.8704\n",
      "Epoch 352/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6293 - acc: 0.8699 - val_loss: 0.6051 - val_acc: 0.8696\n",
      "Epoch 353/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.6281 - acc: 0.8702 - val_loss: 0.6039 - val_acc: 0.8700\n",
      "Epoch 354/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6270 - acc: 0.8702 - val_loss: 0.6028 - val_acc: 0.8704\n",
      "Epoch 355/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6258 - acc: 0.8705 - val_loss: 0.6017 - val_acc: 0.8704\n",
      "Epoch 356/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6246 - acc: 0.8710 - val_loss: 0.6006 - val_acc: 0.8700\n",
      "Epoch 357/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6235 - acc: 0.8710 - val_loss: 0.5995 - val_acc: 0.8708\n",
      "Epoch 358/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6223 - acc: 0.8711 - val_loss: 0.5984 - val_acc: 0.8704\n",
      "Epoch 359/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6212 - acc: 0.8708 - val_loss: 0.5973 - val_acc: 0.8708\n",
      "Epoch 360/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.6201 - acc: 0.8713 - val_loss: 0.5963 - val_acc: 0.8708\n",
      "Epoch 361/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6189 - acc: 0.8718 - val_loss: 0.5951 - val_acc: 0.8712\n",
      "Epoch 362/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6178 - acc: 0.8717 - val_loss: 0.5941 - val_acc: 0.8717\n",
      "Epoch 363/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6167 - acc: 0.8719 - val_loss: 0.5930 - val_acc: 0.8721\n",
      "Epoch 364/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6156 - acc: 0.8717 - val_loss: 0.5919 - val_acc: 0.8725\n",
      "Epoch 365/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.6145 - acc: 0.8723 - val_loss: 0.5909 - val_acc: 0.8717\n",
      "Epoch 366/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6134 - acc: 0.8714 - val_loss: 0.5898 - val_acc: 0.8721\n",
      "Epoch 367/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.6123 - acc: 0.8722 - val_loss: 0.5888 - val_acc: 0.8721\n",
      "Epoch 368/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6112 - acc: 0.8722 - val_loss: 0.5877 - val_acc: 0.8725\n",
      "Epoch 369/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6101 - acc: 0.8726 - val_loss: 0.5867 - val_acc: 0.8725\n",
      "Epoch 370/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6090 - acc: 0.8725 - val_loss: 0.5857 - val_acc: 0.8725\n",
      "Epoch 371/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6079 - acc: 0.8725 - val_loss: 0.5846 - val_acc: 0.8725\n",
      "Epoch 372/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6069 - acc: 0.8721 - val_loss: 0.5836 - val_acc: 0.8725\n",
      "Epoch 373/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6058 - acc: 0.8726 - val_loss: 0.5826 - val_acc: 0.8725\n",
      "Epoch 374/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6048 - acc: 0.8729 - val_loss: 0.5816 - val_acc: 0.8725\n",
      "Epoch 375/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6037 - acc: 0.8733 - val_loss: 0.5806 - val_acc: 0.8729\n",
      "Epoch 376/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6027 - acc: 0.8735 - val_loss: 0.5795 - val_acc: 0.8729\n",
      "Epoch 377/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6016 - acc: 0.8738 - val_loss: 0.5786 - val_acc: 0.8729\n",
      "Epoch 378/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.6006 - acc: 0.8738 - val_loss: 0.5776 - val_acc: 0.8725\n",
      "Epoch 379/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5996 - acc: 0.8741 - val_loss: 0.5766 - val_acc: 0.8725\n",
      "Epoch 380/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5986 - acc: 0.8740 - val_loss: 0.5757 - val_acc: 0.8725\n",
      "Epoch 381/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5976 - acc: 0.8740 - val_loss: 0.5747 - val_acc: 0.8733\n",
      "Epoch 382/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5965 - acc: 0.8743 - val_loss: 0.5737 - val_acc: 0.8737\n",
      "Epoch 383/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5955 - acc: 0.8741 - val_loss: 0.5728 - val_acc: 0.8733\n",
      "Epoch 384/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5945 - acc: 0.8747 - val_loss: 0.5718 - val_acc: 0.8733\n",
      "Epoch 385/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5935 - acc: 0.8747 - val_loss: 0.5709 - val_acc: 0.8737\n",
      "Epoch 386/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5925 - acc: 0.8749 - val_loss: 0.5699 - val_acc: 0.8737\n",
      "Epoch 387/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5915 - acc: 0.8751 - val_loss: 0.5690 - val_acc: 0.8737\n",
      "Epoch 388/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5905 - acc: 0.8752 - val_loss: 0.5680 - val_acc: 0.8742\n",
      "Epoch 389/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5896 - acc: 0.8748 - val_loss: 0.5670 - val_acc: 0.8742\n",
      "Epoch 390/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5886 - acc: 0.8750 - val_loss: 0.5662 - val_acc: 0.8737\n",
      "Epoch 391/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5876 - acc: 0.8752 - val_loss: 0.5653 - val_acc: 0.8742\n",
      "Epoch 392/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5867 - acc: 0.8753 - val_loss: 0.5643 - val_acc: 0.8746\n",
      "Epoch 393/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5857 - acc: 0.8753 - val_loss: 0.5634 - val_acc: 0.8746\n",
      "Epoch 394/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.5848 - acc: 0.8757 - val_loss: 0.5625 - val_acc: 0.8742\n",
      "Epoch 395/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.5838 - acc: 0.8758 - val_loss: 0.5616 - val_acc: 0.8750\n",
      "Epoch 396/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5829 - acc: 0.8757 - val_loss: 0.5607 - val_acc: 0.8754\n",
      "Epoch 397/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5819 - acc: 0.8758 - val_loss: 0.5598 - val_acc: 0.8750\n",
      "Epoch 398/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5810 - acc: 0.8762 - val_loss: 0.5589 - val_acc: 0.8754\n",
      "Epoch 399/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5801 - acc: 0.8760 - val_loss: 0.5580 - val_acc: 0.8750\n",
      "Epoch 400/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.5791 - acc: 0.8759 - val_loss: 0.5572 - val_acc: 0.8750\n",
      "Epoch 401/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5782 - acc: 0.8760 - val_loss: 0.5563 - val_acc: 0.8750\n",
      "Epoch 402/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.5773 - acc: 0.8762 - val_loss: 0.5555 - val_acc: 0.8750\n",
      "Epoch 403/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5764 - acc: 0.8764 - val_loss: 0.5546 - val_acc: 0.8758\n",
      "Epoch 404/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5755 - acc: 0.8764 - val_loss: 0.5537 - val_acc: 0.8754\n",
      "Epoch 405/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5746 - acc: 0.8760 - val_loss: 0.5529 - val_acc: 0.8750\n",
      "Epoch 406/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5737 - acc: 0.8760 - val_loss: 0.5520 - val_acc: 0.8758\n",
      "Epoch 407/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5728 - acc: 0.8764 - val_loss: 0.5511 - val_acc: 0.8758\n",
      "Epoch 408/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5719 - acc: 0.8762 - val_loss: 0.5503 - val_acc: 0.8758\n",
      "Epoch 409/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5711 - acc: 0.8764 - val_loss: 0.5495 - val_acc: 0.8758\n",
      "Epoch 410/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5702 - acc: 0.8768 - val_loss: 0.5486 - val_acc: 0.8762\n",
      "Epoch 411/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5693 - acc: 0.8765 - val_loss: 0.5478 - val_acc: 0.8762\n",
      "Epoch 412/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5684 - acc: 0.8767 - val_loss: 0.5470 - val_acc: 0.8762\n",
      "Epoch 413/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5675 - acc: 0.8766 - val_loss: 0.5461 - val_acc: 0.8767\n",
      "Epoch 414/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5667 - acc: 0.8770 - val_loss: 0.5453 - val_acc: 0.8767\n",
      "Epoch 415/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5658 - acc: 0.8772 - val_loss: 0.5445 - val_acc: 0.8771\n",
      "Epoch 416/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5650 - acc: 0.8772 - val_loss: 0.5437 - val_acc: 0.8771\n",
      "Epoch 417/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.5641 - acc: 0.8769 - val_loss: 0.5429 - val_acc: 0.8771\n",
      "Epoch 418/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5633 - acc: 0.8777 - val_loss: 0.5421 - val_acc: 0.8767\n",
      "Epoch 419/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5624 - acc: 0.8774 - val_loss: 0.5413 - val_acc: 0.8775\n",
      "Epoch 420/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5616 - acc: 0.8776 - val_loss: 0.5405 - val_acc: 0.8775\n",
      "Epoch 421/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5608 - acc: 0.8778 - val_loss: 0.5398 - val_acc: 0.8771\n",
      "Epoch 422/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5599 - acc: 0.8775 - val_loss: 0.5389 - val_acc: 0.8771\n",
      "Epoch 423/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5591 - acc: 0.8780 - val_loss: 0.5382 - val_acc: 0.8771\n",
      "Epoch 424/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5583 - acc: 0.8780 - val_loss: 0.5374 - val_acc: 0.8775\n",
      "Epoch 425/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5574 - acc: 0.8781 - val_loss: 0.5366 - val_acc: 0.8775\n",
      "Epoch 426/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5566 - acc: 0.8784 - val_loss: 0.5358 - val_acc: 0.8775\n",
      "Epoch 427/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5558 - acc: 0.8784 - val_loss: 0.5351 - val_acc: 0.8775\n",
      "Epoch 428/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5550 - acc: 0.8786 - val_loss: 0.5344 - val_acc: 0.8775\n",
      "Epoch 429/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5542 - acc: 0.8787 - val_loss: 0.5336 - val_acc: 0.8771\n",
      "Epoch 430/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5534 - acc: 0.8789 - val_loss: 0.5328 - val_acc: 0.8775\n",
      "Epoch 431/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5526 - acc: 0.8791 - val_loss: 0.5321 - val_acc: 0.8775\n",
      "Epoch 432/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5518 - acc: 0.8796 - val_loss: 0.5313 - val_acc: 0.8775\n",
      "Epoch 433/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5511 - acc: 0.8792 - val_loss: 0.5306 - val_acc: 0.8775\n",
      "Epoch 434/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5503 - acc: 0.8798 - val_loss: 0.5298 - val_acc: 0.8775\n",
      "Epoch 435/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.5495 - acc: 0.8797 - val_loss: 0.5291 - val_acc: 0.8775\n",
      "Epoch 436/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 0.5487 - acc: 0.8795 - val_loss: 0.5284 - val_acc: 0.8779\n",
      "Epoch 437/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.5480 - acc: 0.8802 - val_loss: 0.5277 - val_acc: 0.8779\n",
      "Epoch 438/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.5472 - acc: 0.8800 - val_loss: 0.5269 - val_acc: 0.8775\n",
      "Epoch 439/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.5464 - acc: 0.8799 - val_loss: 0.5262 - val_acc: 0.8775\n",
      "Epoch 440/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 0.5457 - acc: 0.8801 - val_loss: 0.5255 - val_acc: 0.8775\n",
      "Epoch 441/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.5449 - acc: 0.8802 - val_loss: 0.5248 - val_acc: 0.8779\n",
      "Epoch 442/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.5441 - acc: 0.8804 - val_loss: 0.5241 - val_acc: 0.8779\n",
      "Epoch 443/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 0.5434 - acc: 0.8804 - val_loss: 0.5234 - val_acc: 0.8779\n",
      "Epoch 444/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.5426 - acc: 0.8806 - val_loss: 0.5227 - val_acc: 0.8779\n",
      "Epoch 445/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.5419 - acc: 0.8805 - val_loss: 0.5219 - val_acc: 0.8779\n",
      "Epoch 446/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.5411 - acc: 0.8804 - val_loss: 0.5212 - val_acc: 0.8779\n",
      "Epoch 447/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.5404 - acc: 0.8804 - val_loss: 0.5205 - val_acc: 0.8788\n",
      "Epoch 448/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.5397 - acc: 0.8807 - val_loss: 0.5199 - val_acc: 0.8783\n",
      "Epoch 449/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.5389 - acc: 0.8809 - val_loss: 0.5192 - val_acc: 0.8788\n",
      "Epoch 450/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.5382 - acc: 0.8808 - val_loss: 0.5185 - val_acc: 0.8783\n",
      "Epoch 451/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.5375 - acc: 0.8808 - val_loss: 0.5178 - val_acc: 0.8788\n",
      "Epoch 452/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.5368 - acc: 0.8811 - val_loss: 0.5171 - val_acc: 0.8783\n",
      "Epoch 453/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.5360 - acc: 0.8808 - val_loss: 0.5164 - val_acc: 0.8783\n",
      "Epoch 454/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.5353 - acc: 0.8810 - val_loss: 0.5158 - val_acc: 0.8783\n",
      "Epoch 455/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.5346 - acc: 0.8809 - val_loss: 0.5151 - val_acc: 0.8788\n",
      "Epoch 456/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.5339 - acc: 0.8810 - val_loss: 0.5144 - val_acc: 0.8788\n",
      "Epoch 457/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 0.5332 - acc: 0.8811 - val_loss: 0.5138 - val_acc: 0.8783\n",
      "Epoch 458/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 0.5325 - acc: 0.8812 - val_loss: 0.5131 - val_acc: 0.8787\n",
      "Epoch 459/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.5318 - acc: 0.8816 - val_loss: 0.5124 - val_acc: 0.8792\n",
      "Epoch 460/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.5311 - acc: 0.8812 - val_loss: 0.5118 - val_acc: 0.8787\n",
      "Epoch 461/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5304 - acc: 0.8817 - val_loss: 0.5112 - val_acc: 0.8792\n",
      "Epoch 462/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.5297 - acc: 0.8816 - val_loss: 0.5105 - val_acc: 0.8787\n",
      "Epoch 463/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5290 - acc: 0.8816 - val_loss: 0.5099 - val_acc: 0.8792\n",
      "Epoch 464/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5284 - acc: 0.8818 - val_loss: 0.5092 - val_acc: 0.8796\n",
      "Epoch 465/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5277 - acc: 0.8818 - val_loss: 0.5086 - val_acc: 0.8792\n",
      "Epoch 466/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5270 - acc: 0.8821 - val_loss: 0.5080 - val_acc: 0.8800\n",
      "Epoch 467/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.5263 - acc: 0.8819 - val_loss: 0.5074 - val_acc: 0.8796\n",
      "Epoch 468/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.5256 - acc: 0.8821 - val_loss: 0.5067 - val_acc: 0.8800\n",
      "Epoch 469/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5250 - acc: 0.8823 - val_loss: 0.5060 - val_acc: 0.8804\n",
      "Epoch 470/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.5243 - acc: 0.8824 - val_loss: 0.5054 - val_acc: 0.8796\n",
      "Epoch 471/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.5236 - acc: 0.8825 - val_loss: 0.5048 - val_acc: 0.8796\n",
      "Epoch 472/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.5230 - acc: 0.8825 - val_loss: 0.5042 - val_acc: 0.8800\n",
      "Epoch 473/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5223 - acc: 0.8826 - val_loss: 0.5036 - val_acc: 0.8800\n",
      "Epoch 474/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5217 - acc: 0.8825 - val_loss: 0.5030 - val_acc: 0.8800\n",
      "Epoch 475/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5210 - acc: 0.8828 - val_loss: 0.5024 - val_acc: 0.8800\n",
      "Epoch 476/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5204 - acc: 0.8827 - val_loss: 0.5018 - val_acc: 0.8800\n",
      "Epoch 477/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5197 - acc: 0.8830 - val_loss: 0.5012 - val_acc: 0.8804\n",
      "Epoch 478/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5191 - acc: 0.8831 - val_loss: 0.5006 - val_acc: 0.8804\n",
      "Epoch 479/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5184 - acc: 0.8828 - val_loss: 0.5000 - val_acc: 0.8804\n",
      "Epoch 480/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5178 - acc: 0.8836 - val_loss: 0.4994 - val_acc: 0.8800\n",
      "Epoch 481/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5172 - acc: 0.8836 - val_loss: 0.4988 - val_acc: 0.8812\n",
      "Epoch 482/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.5165 - acc: 0.8833 - val_loss: 0.4982 - val_acc: 0.8812\n",
      "Epoch 483/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.5159 - acc: 0.8840 - val_loss: 0.4976 - val_acc: 0.8804\n",
      "Epoch 484/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.5153 - acc: 0.8839 - val_loss: 0.4970 - val_acc: 0.8808\n",
      "Epoch 485/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5146 - acc: 0.8843 - val_loss: 0.4964 - val_acc: 0.8808\n",
      "Epoch 486/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 0.5140 - acc: 0.8836 - val_loss: 0.4959 - val_acc: 0.8808\n",
      "Epoch 487/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.5134 - acc: 0.8843 - val_loss: 0.4953 - val_acc: 0.8812\n",
      "Epoch 488/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.5128 - acc: 0.8839 - val_loss: 0.4947 - val_acc: 0.8812\n",
      "Epoch 489/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 0.5122 - acc: 0.8842 - val_loss: 0.4941 - val_acc: 0.8817\n",
      "Epoch 490/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.5116 - acc: 0.8844 - val_loss: 0.4936 - val_acc: 0.8812\n",
      "Epoch 491/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.5110 - acc: 0.8841 - val_loss: 0.4931 - val_acc: 0.8812\n",
      "Epoch 492/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5103 - acc: 0.8844 - val_loss: 0.4925 - val_acc: 0.8817\n",
      "Epoch 493/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5097 - acc: 0.8847 - val_loss: 0.4919 - val_acc: 0.8812\n",
      "Epoch 494/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.5091 - acc: 0.8845 - val_loss: 0.4913 - val_acc: 0.8817\n",
      "Epoch 495/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5086 - acc: 0.8846 - val_loss: 0.4908 - val_acc: 0.8812\n",
      "Epoch 496/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5080 - acc: 0.8847 - val_loss: 0.4902 - val_acc: 0.8817\n",
      "Epoch 497/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5073 - acc: 0.8846 - val_loss: 0.4897 - val_acc: 0.8817\n",
      "Epoch 498/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.5068 - acc: 0.8848 - val_loss: 0.4891 - val_acc: 0.8812\n",
      "Epoch 499/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.5062 - acc: 0.8848 - val_loss: 0.4885 - val_acc: 0.8817\n",
      "Epoch 500/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.5056 - acc: 0.8849 - val_loss: 0.4880 - val_acc: 0.8812\n",
      "Epoch 501/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5050 - acc: 0.8851 - val_loss: 0.4875 - val_acc: 0.8817\n",
      "Epoch 502/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.5044 - acc: 0.8851 - val_loss: 0.4869 - val_acc: 0.8817\n",
      "Epoch 503/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.5038 - acc: 0.8855 - val_loss: 0.4864 - val_acc: 0.8812\n",
      "Epoch 504/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 0.5033 - acc: 0.8851 - val_loss: 0.4858 - val_acc: 0.8821\n",
      "Epoch 505/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 0.5027 - acc: 0.8855 - val_loss: 0.4853 - val_acc: 0.8812\n",
      "Epoch 506/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 0.5021 - acc: 0.8858 - val_loss: 0.4848 - val_acc: 0.8817\n",
      "Epoch 507/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 0.5015 - acc: 0.8860 - val_loss: 0.4843 - val_acc: 0.8821\n",
      "Epoch 508/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 0.5010 - acc: 0.8860 - val_loss: 0.4837 - val_acc: 0.8825\n",
      "Epoch 509/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 0.5004 - acc: 0.8857 - val_loss: 0.4832 - val_acc: 0.8821\n",
      "Epoch 510/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.4999 - acc: 0.8861 - val_loss: 0.4827 - val_acc: 0.8821\n",
      "Epoch 511/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.4993 - acc: 0.8860 - val_loss: 0.4822 - val_acc: 0.8817\n",
      "Epoch 512/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.4987 - acc: 0.8861 - val_loss: 0.4817 - val_acc: 0.8821\n",
      "Epoch 513/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.4982 - acc: 0.8861 - val_loss: 0.4811 - val_acc: 0.8821\n",
      "Epoch 514/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.4976 - acc: 0.8865 - val_loss: 0.4806 - val_acc: 0.8821\n",
      "Epoch 515/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.4971 - acc: 0.8865 - val_loss: 0.4801 - val_acc: 0.8821\n",
      "Epoch 516/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.4965 - acc: 0.8861 - val_loss: 0.4796 - val_acc: 0.8821\n",
      "Epoch 517/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.4960 - acc: 0.8867 - val_loss: 0.4791 - val_acc: 0.8821\n",
      "Epoch 518/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.4954 - acc: 0.8863 - val_loss: 0.4786 - val_acc: 0.8821\n",
      "Epoch 519/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.4949 - acc: 0.8871 - val_loss: 0.4782 - val_acc: 0.8821\n",
      "Epoch 520/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 0.4943 - acc: 0.8867 - val_loss: 0.4776 - val_acc: 0.8821\n",
      "Epoch 521/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4938 - acc: 0.8870 - val_loss: 0.4771 - val_acc: 0.8821\n",
      "Epoch 522/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4933 - acc: 0.8865 - val_loss: 0.4766 - val_acc: 0.8821\n",
      "Epoch 523/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4927 - acc: 0.8867 - val_loss: 0.4761 - val_acc: 0.8821\n",
      "Epoch 524/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4922 - acc: 0.8868 - val_loss: 0.4757 - val_acc: 0.8821\n",
      "Epoch 525/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4917 - acc: 0.8869 - val_loss: 0.4752 - val_acc: 0.8821\n",
      "Epoch 526/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4912 - acc: 0.8873 - val_loss: 0.4746 - val_acc: 0.8821\n",
      "Epoch 527/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4906 - acc: 0.8870 - val_loss: 0.4742 - val_acc: 0.8821\n",
      "Epoch 528/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4901 - acc: 0.8874 - val_loss: 0.4737 - val_acc: 0.8825\n",
      "Epoch 529/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4896 - acc: 0.8871 - val_loss: 0.4732 - val_acc: 0.8825\n",
      "Epoch 530/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4891 - acc: 0.8874 - val_loss: 0.4727 - val_acc: 0.8821\n",
      "Epoch 531/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4885 - acc: 0.8871 - val_loss: 0.4723 - val_acc: 0.8825\n",
      "Epoch 532/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4880 - acc: 0.8875 - val_loss: 0.4717 - val_acc: 0.8825\n",
      "Epoch 533/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4875 - acc: 0.8873 - val_loss: 0.4713 - val_acc: 0.8825\n",
      "Epoch 534/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4870 - acc: 0.8873 - val_loss: 0.4708 - val_acc: 0.8829\n",
      "Epoch 535/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4865 - acc: 0.8874 - val_loss: 0.4704 - val_acc: 0.8829\n",
      "Epoch 536/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4860 - acc: 0.8873 - val_loss: 0.4698 - val_acc: 0.8825\n",
      "Epoch 537/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4855 - acc: 0.8872 - val_loss: 0.4694 - val_acc: 0.8825\n",
      "Epoch 538/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4850 - acc: 0.8874 - val_loss: 0.4689 - val_acc: 0.8829\n",
      "Epoch 539/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4845 - acc: 0.8870 - val_loss: 0.4685 - val_acc: 0.8829\n",
      "Epoch 540/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4840 - acc: 0.8875 - val_loss: 0.4681 - val_acc: 0.8829\n",
      "Epoch 541/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4835 - acc: 0.8879 - val_loss: 0.4676 - val_acc: 0.8829\n",
      "Epoch 542/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4830 - acc: 0.8874 - val_loss: 0.4672 - val_acc: 0.8825\n",
      "Epoch 543/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4825 - acc: 0.8875 - val_loss: 0.4667 - val_acc: 0.8829\n",
      "Epoch 544/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4820 - acc: 0.8874 - val_loss: 0.4662 - val_acc: 0.8829\n",
      "Epoch 545/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4815 - acc: 0.8877 - val_loss: 0.4658 - val_acc: 0.8829\n",
      "Epoch 546/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4810 - acc: 0.8879 - val_loss: 0.4653 - val_acc: 0.8829\n",
      "Epoch 547/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4805 - acc: 0.8879 - val_loss: 0.4649 - val_acc: 0.8829\n",
      "Epoch 548/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4801 - acc: 0.8878 - val_loss: 0.4645 - val_acc: 0.8833\n",
      "Epoch 549/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4796 - acc: 0.8878 - val_loss: 0.4640 - val_acc: 0.8842\n",
      "Epoch 550/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4791 - acc: 0.8877 - val_loss: 0.4636 - val_acc: 0.8842\n",
      "Epoch 551/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4786 - acc: 0.8880 - val_loss: 0.4632 - val_acc: 0.8838\n",
      "Epoch 552/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4782 - acc: 0.8878 - val_loss: 0.4627 - val_acc: 0.8833\n",
      "Epoch 553/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4777 - acc: 0.8882 - val_loss: 0.4623 - val_acc: 0.8838\n",
      "Epoch 554/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.4772 - acc: 0.8882 - val_loss: 0.4618 - val_acc: 0.8842\n",
      "Epoch 555/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4767 - acc: 0.8881 - val_loss: 0.4614 - val_acc: 0.8846\n",
      "Epoch 556/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4763 - acc: 0.8882 - val_loss: 0.4610 - val_acc: 0.8846\n",
      "Epoch 557/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4758 - acc: 0.8884 - val_loss: 0.4605 - val_acc: 0.8846\n",
      "Epoch 558/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 0.4754 - acc: 0.8884 - val_loss: 0.4601 - val_acc: 0.8846\n",
      "Epoch 559/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4749 - acc: 0.8884 - val_loss: 0.4597 - val_acc: 0.8846\n",
      "Epoch 560/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4744 - acc: 0.8884 - val_loss: 0.4593 - val_acc: 0.8846\n",
      "Epoch 561/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4739 - acc: 0.8884 - val_loss: 0.4588 - val_acc: 0.8850\n",
      "Epoch 562/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4735 - acc: 0.8890 - val_loss: 0.4584 - val_acc: 0.8850\n",
      "Epoch 563/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4730 - acc: 0.8889 - val_loss: 0.4580 - val_acc: 0.8850\n",
      "Epoch 564/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4726 - acc: 0.8891 - val_loss: 0.4576 - val_acc: 0.8850\n",
      "Epoch 565/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4721 - acc: 0.8889 - val_loss: 0.4571 - val_acc: 0.8850\n",
      "Epoch 566/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4717 - acc: 0.8893 - val_loss: 0.4567 - val_acc: 0.8854\n",
      "Epoch 567/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4712 - acc: 0.8895 - val_loss: 0.4563 - val_acc: 0.8850\n",
      "Epoch 568/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4708 - acc: 0.8890 - val_loss: 0.4558 - val_acc: 0.8854\n",
      "Epoch 569/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4703 - acc: 0.8898 - val_loss: 0.4555 - val_acc: 0.8854\n",
      "Epoch 570/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4699 - acc: 0.8897 - val_loss: 0.4551 - val_acc: 0.8858\n",
      "Epoch 571/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4694 - acc: 0.8897 - val_loss: 0.4547 - val_acc: 0.8858\n",
      "Epoch 572/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4690 - acc: 0.8897 - val_loss: 0.4543 - val_acc: 0.8858\n",
      "Epoch 573/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4685 - acc: 0.8896 - val_loss: 0.4539 - val_acc: 0.8858\n",
      "Epoch 574/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4681 - acc: 0.8897 - val_loss: 0.4535 - val_acc: 0.8858\n",
      "Epoch 575/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.4677 - acc: 0.8900 - val_loss: 0.4531 - val_acc: 0.8858\n",
      "Epoch 576/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.4672 - acc: 0.8902 - val_loss: 0.4527 - val_acc: 0.8858\n",
      "Epoch 577/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.4668 - acc: 0.8899 - val_loss: 0.4523 - val_acc: 0.8863\n",
      "Epoch 578/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4664 - acc: 0.8901 - val_loss: 0.4519 - val_acc: 0.8863\n",
      "Epoch 579/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4659 - acc: 0.8903 - val_loss: 0.4515 - val_acc: 0.8858\n",
      "Epoch 580/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4655 - acc: 0.8903 - val_loss: 0.4511 - val_acc: 0.8863\n",
      "Epoch 581/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4651 - acc: 0.8903 - val_loss: 0.4507 - val_acc: 0.8858\n",
      "Epoch 582/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.4646 - acc: 0.8902 - val_loss: 0.4503 - val_acc: 0.8858\n",
      "Epoch 583/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 0.4642 - acc: 0.8903 - val_loss: 0.4500 - val_acc: 0.8867\n",
      "Epoch 584/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4638 - acc: 0.8904 - val_loss: 0.4496 - val_acc: 0.8863\n",
      "Epoch 585/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4634 - acc: 0.8900 - val_loss: 0.4492 - val_acc: 0.8867\n",
      "Epoch 586/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4630 - acc: 0.8905 - val_loss: 0.4488 - val_acc: 0.8867\n",
      "Epoch 587/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4625 - acc: 0.8909 - val_loss: 0.4484 - val_acc: 0.8867\n",
      "Epoch 588/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4621 - acc: 0.8905 - val_loss: 0.4480 - val_acc: 0.8871\n",
      "Epoch 589/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4617 - acc: 0.8908 - val_loss: 0.4476 - val_acc: 0.8871\n",
      "Epoch 590/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4613 - acc: 0.8909 - val_loss: 0.4472 - val_acc: 0.8875\n",
      "Epoch 591/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4609 - acc: 0.8907 - val_loss: 0.4469 - val_acc: 0.8875\n",
      "Epoch 592/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4605 - acc: 0.8908 - val_loss: 0.4465 - val_acc: 0.8875\n",
      "Epoch 593/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4600 - acc: 0.8909 - val_loss: 0.4461 - val_acc: 0.8875\n",
      "Epoch 594/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4596 - acc: 0.8911 - val_loss: 0.4457 - val_acc: 0.8879\n",
      "Epoch 595/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4592 - acc: 0.8910 - val_loss: 0.4454 - val_acc: 0.8879\n",
      "Epoch 596/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4588 - acc: 0.8912 - val_loss: 0.4450 - val_acc: 0.8879\n",
      "Epoch 597/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4584 - acc: 0.8912 - val_loss: 0.4446 - val_acc: 0.8879\n",
      "Epoch 598/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4580 - acc: 0.8912 - val_loss: 0.4443 - val_acc: 0.8879\n",
      "Epoch 599/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4576 - acc: 0.8917 - val_loss: 0.4439 - val_acc: 0.8875\n",
      "Epoch 600/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.4572 - acc: 0.8918 - val_loss: 0.4436 - val_acc: 0.8879\n",
      "Epoch 601/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4568 - acc: 0.8917 - val_loss: 0.4432 - val_acc: 0.8883\n",
      "Epoch 602/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4564 - acc: 0.8916 - val_loss: 0.4428 - val_acc: 0.8883\n",
      "Epoch 603/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4560 - acc: 0.8918 - val_loss: 0.4425 - val_acc: 0.8883\n",
      "Epoch 604/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4556 - acc: 0.8916 - val_loss: 0.4421 - val_acc: 0.8879\n",
      "Epoch 605/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4552 - acc: 0.8918 - val_loss: 0.4418 - val_acc: 0.8888\n",
      "Epoch 606/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4549 - acc: 0.8919 - val_loss: 0.4414 - val_acc: 0.8883\n",
      "Epoch 607/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4545 - acc: 0.8918 - val_loss: 0.4411 - val_acc: 0.8883\n",
      "Epoch 608/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4541 - acc: 0.8920 - val_loss: 0.4407 - val_acc: 0.8888\n",
      "Epoch 609/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4537 - acc: 0.8917 - val_loss: 0.4404 - val_acc: 0.8883\n",
      "Epoch 610/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4533 - acc: 0.8918 - val_loss: 0.4401 - val_acc: 0.8888\n",
      "Epoch 611/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4529 - acc: 0.8920 - val_loss: 0.4396 - val_acc: 0.8883\n",
      "Epoch 612/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4525 - acc: 0.8919 - val_loss: 0.4393 - val_acc: 0.8888\n",
      "Epoch 613/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4521 - acc: 0.8919 - val_loss: 0.4389 - val_acc: 0.8888\n",
      "Epoch 614/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4518 - acc: 0.8921 - val_loss: 0.4386 - val_acc: 0.8892\n",
      "Epoch 615/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4514 - acc: 0.8921 - val_loss: 0.4382 - val_acc: 0.8896\n",
      "Epoch 616/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4510 - acc: 0.8921 - val_loss: 0.4379 - val_acc: 0.8900\n",
      "Epoch 617/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4506 - acc: 0.8923 - val_loss: 0.4376 - val_acc: 0.8896\n",
      "Epoch 618/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4502 - acc: 0.8922 - val_loss: 0.4372 - val_acc: 0.8900\n",
      "Epoch 619/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4499 - acc: 0.8920 - val_loss: 0.4369 - val_acc: 0.8896\n",
      "Epoch 620/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4495 - acc: 0.8925 - val_loss: 0.4366 - val_acc: 0.8896\n",
      "Epoch 621/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4491 - acc: 0.8923 - val_loss: 0.4362 - val_acc: 0.8900\n",
      "Epoch 622/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.4488 - acc: 0.8925 - val_loss: 0.4358 - val_acc: 0.8900\n",
      "Epoch 623/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.4484 - acc: 0.8926 - val_loss: 0.4355 - val_acc: 0.8896\n",
      "Epoch 624/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 0.4480 - acc: 0.8922 - val_loss: 0.4352 - val_acc: 0.8904\n",
      "Epoch 625/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 0.4476 - acc: 0.8924 - val_loss: 0.4349 - val_acc: 0.8900\n",
      "Epoch 626/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.4473 - acc: 0.8927 - val_loss: 0.4345 - val_acc: 0.8900\n",
      "Epoch 627/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 0.4469 - acc: 0.8926 - val_loss: 0.4342 - val_acc: 0.8900\n",
      "Epoch 628/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.4465 - acc: 0.8927 - val_loss: 0.4339 - val_acc: 0.8904\n",
      "Epoch 629/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4462 - acc: 0.8924 - val_loss: 0.4335 - val_acc: 0.8896\n",
      "Epoch 630/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4458 - acc: 0.8927 - val_loss: 0.4332 - val_acc: 0.8900\n",
      "Epoch 631/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4455 - acc: 0.8927 - val_loss: 0.4329 - val_acc: 0.8900\n",
      "Epoch 632/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4451 - acc: 0.8928 - val_loss: 0.4326 - val_acc: 0.8904\n",
      "Epoch 633/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4448 - acc: 0.8928 - val_loss: 0.4323 - val_acc: 0.8904\n",
      "Epoch 634/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4444 - acc: 0.8928 - val_loss: 0.4319 - val_acc: 0.8904\n",
      "Epoch 635/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4440 - acc: 0.8931 - val_loss: 0.4316 - val_acc: 0.8904\n",
      "Epoch 636/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.4437 - acc: 0.8930 - val_loss: 0.4313 - val_acc: 0.8904\n",
      "Epoch 637/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4433 - acc: 0.8932 - val_loss: 0.4310 - val_acc: 0.8904\n",
      "Epoch 638/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4430 - acc: 0.8934 - val_loss: 0.4307 - val_acc: 0.8904\n",
      "Epoch 639/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4426 - acc: 0.8930 - val_loss: 0.4303 - val_acc: 0.8900\n",
      "Epoch 640/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4423 - acc: 0.8930 - val_loss: 0.4300 - val_acc: 0.8904\n",
      "Epoch 641/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4419 - acc: 0.8930 - val_loss: 0.4297 - val_acc: 0.8904\n",
      "Epoch 642/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4416 - acc: 0.8931 - val_loss: 0.4294 - val_acc: 0.8904\n",
      "Epoch 643/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.4412 - acc: 0.8932 - val_loss: 0.4290 - val_acc: 0.8908\n",
      "Epoch 644/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.4409 - acc: 0.8930 - val_loss: 0.4288 - val_acc: 0.8904\n",
      "Epoch 645/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4405 - acc: 0.8931 - val_loss: 0.4285 - val_acc: 0.8904\n",
      "Epoch 646/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4402 - acc: 0.8935 - val_loss: 0.4281 - val_acc: 0.8908\n",
      "Epoch 647/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4398 - acc: 0.8932 - val_loss: 0.4279 - val_acc: 0.8908\n",
      "Epoch 648/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4395 - acc: 0.8935 - val_loss: 0.4275 - val_acc: 0.8904\n",
      "Epoch 649/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4392 - acc: 0.8934 - val_loss: 0.4272 - val_acc: 0.8904\n",
      "Epoch 650/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4388 - acc: 0.8933 - val_loss: 0.4269 - val_acc: 0.8908\n",
      "Epoch 651/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4385 - acc: 0.8935 - val_loss: 0.4266 - val_acc: 0.8908\n",
      "Epoch 652/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.4382 - acc: 0.8935 - val_loss: 0.4263 - val_acc: 0.8908\n",
      "Epoch 653/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4378 - acc: 0.8936 - val_loss: 0.4260 - val_acc: 0.8908\n",
      "Epoch 654/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4375 - acc: 0.8939 - val_loss: 0.4257 - val_acc: 0.8908\n",
      "Epoch 655/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4371 - acc: 0.8937 - val_loss: 0.4254 - val_acc: 0.8913\n",
      "Epoch 656/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4368 - acc: 0.8939 - val_loss: 0.4251 - val_acc: 0.8908\n",
      "Epoch 657/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4365 - acc: 0.8936 - val_loss: 0.4248 - val_acc: 0.8917\n",
      "Epoch 658/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4362 - acc: 0.8936 - val_loss: 0.4245 - val_acc: 0.8913\n",
      "Epoch 659/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4358 - acc: 0.8939 - val_loss: 0.4242 - val_acc: 0.8913\n",
      "Epoch 660/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4355 - acc: 0.8940 - val_loss: 0.4239 - val_acc: 0.8908\n",
      "Epoch 661/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4352 - acc: 0.8943 - val_loss: 0.4236 - val_acc: 0.8908\n",
      "Epoch 662/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4348 - acc: 0.8939 - val_loss: 0.4233 - val_acc: 0.8917\n",
      "Epoch 663/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4345 - acc: 0.8944 - val_loss: 0.4230 - val_acc: 0.8913\n",
      "Epoch 664/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4342 - acc: 0.8942 - val_loss: 0.4227 - val_acc: 0.8908\n",
      "Epoch 665/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.4339 - acc: 0.8943 - val_loss: 0.4225 - val_acc: 0.8913\n",
      "Epoch 666/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4335 - acc: 0.8941 - val_loss: 0.4222 - val_acc: 0.8917\n",
      "Epoch 667/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4332 - acc: 0.8944 - val_loss: 0.4219 - val_acc: 0.8913\n",
      "Epoch 668/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4329 - acc: 0.8945 - val_loss: 0.4216 - val_acc: 0.8913\n",
      "Epoch 669/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4326 - acc: 0.8944 - val_loss: 0.4213 - val_acc: 0.8904\n",
      "Epoch 670/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4323 - acc: 0.8944 - val_loss: 0.4210 - val_acc: 0.8913\n",
      "Epoch 671/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4320 - acc: 0.8949 - val_loss: 0.4207 - val_acc: 0.8908\n",
      "Epoch 672/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4316 - acc: 0.8949 - val_loss: 0.4205 - val_acc: 0.8908\n",
      "Epoch 673/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4313 - acc: 0.8947 - val_loss: 0.4202 - val_acc: 0.8913\n",
      "Epoch 674/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4310 - acc: 0.8949 - val_loss: 0.4200 - val_acc: 0.8908\n",
      "Epoch 675/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4307 - acc: 0.8947 - val_loss: 0.4196 - val_acc: 0.8913\n",
      "Epoch 676/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4304 - acc: 0.8945 - val_loss: 0.4194 - val_acc: 0.8913\n",
      "Epoch 677/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4301 - acc: 0.8947 - val_loss: 0.4190 - val_acc: 0.8913\n",
      "Epoch 678/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4298 - acc: 0.8950 - val_loss: 0.4188 - val_acc: 0.8908\n",
      "Epoch 679/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4295 - acc: 0.8949 - val_loss: 0.4186 - val_acc: 0.8913\n",
      "Epoch 680/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4291 - acc: 0.8948 - val_loss: 0.4182 - val_acc: 0.8913\n",
      "Epoch 681/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4288 - acc: 0.8950 - val_loss: 0.4180 - val_acc: 0.8913\n",
      "Epoch 682/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4285 - acc: 0.8949 - val_loss: 0.4177 - val_acc: 0.8913\n",
      "Epoch 683/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4282 - acc: 0.8951 - val_loss: 0.4174 - val_acc: 0.8913\n",
      "Epoch 684/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4279 - acc: 0.8952 - val_loss: 0.4171 - val_acc: 0.8913\n",
      "Epoch 685/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4276 - acc: 0.8955 - val_loss: 0.4169 - val_acc: 0.8913\n",
      "Epoch 686/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4273 - acc: 0.8952 - val_loss: 0.4166 - val_acc: 0.8913\n",
      "Epoch 687/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4270 - acc: 0.8954 - val_loss: 0.4163 - val_acc: 0.8913\n",
      "Epoch 688/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4267 - acc: 0.8953 - val_loss: 0.4161 - val_acc: 0.8913\n",
      "Epoch 689/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4264 - acc: 0.8955 - val_loss: 0.4158 - val_acc: 0.8913\n",
      "Epoch 690/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4261 - acc: 0.8957 - val_loss: 0.4155 - val_acc: 0.8913\n",
      "Epoch 691/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4258 - acc: 0.8953 - val_loss: 0.4153 - val_acc: 0.8913\n",
      "Epoch 692/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4255 - acc: 0.8959 - val_loss: 0.4150 - val_acc: 0.8917\n",
      "Epoch 693/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4252 - acc: 0.8953 - val_loss: 0.4147 - val_acc: 0.8917\n",
      "Epoch 694/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4249 - acc: 0.8959 - val_loss: 0.4145 - val_acc: 0.8917\n",
      "Epoch 695/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4246 - acc: 0.8958 - val_loss: 0.4142 - val_acc: 0.8917\n",
      "Epoch 696/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4243 - acc: 0.8965 - val_loss: 0.4140 - val_acc: 0.8917\n",
      "Epoch 697/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4241 - acc: 0.8958 - val_loss: 0.4137 - val_acc: 0.8917\n",
      "Epoch 698/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4237 - acc: 0.8958 - val_loss: 0.4134 - val_acc: 0.8917\n",
      "Epoch 699/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4235 - acc: 0.8961 - val_loss: 0.4132 - val_acc: 0.8917\n",
      "Epoch 700/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4232 - acc: 0.8962 - val_loss: 0.4129 - val_acc: 0.8917\n",
      "Epoch 701/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4229 - acc: 0.8959 - val_loss: 0.4127 - val_acc: 0.8917\n",
      "Epoch 702/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4226 - acc: 0.8961 - val_loss: 0.4124 - val_acc: 0.8921\n",
      "Epoch 703/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4223 - acc: 0.8960 - val_loss: 0.4122 - val_acc: 0.8917\n",
      "Epoch 704/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4220 - acc: 0.8960 - val_loss: 0.4119 - val_acc: 0.8921\n",
      "Epoch 705/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4217 - acc: 0.8961 - val_loss: 0.4116 - val_acc: 0.8917\n",
      "Epoch 706/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4214 - acc: 0.8964 - val_loss: 0.4114 - val_acc: 0.8921\n",
      "Epoch 707/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4212 - acc: 0.8965 - val_loss: 0.4111 - val_acc: 0.8921\n",
      "Epoch 708/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4209 - acc: 0.8966 - val_loss: 0.4109 - val_acc: 0.8921\n",
      "Epoch 709/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4206 - acc: 0.8960 - val_loss: 0.4107 - val_acc: 0.8921\n",
      "Epoch 710/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4203 - acc: 0.8964 - val_loss: 0.4104 - val_acc: 0.8925\n",
      "Epoch 711/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4200 - acc: 0.8964 - val_loss: 0.4101 - val_acc: 0.8925\n",
      "Epoch 712/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4197 - acc: 0.8967 - val_loss: 0.4098 - val_acc: 0.8925\n",
      "Epoch 713/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4195 - acc: 0.8969 - val_loss: 0.4096 - val_acc: 0.8925\n",
      "Epoch 714/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4192 - acc: 0.8969 - val_loss: 0.4094 - val_acc: 0.8925\n",
      "Epoch 715/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4189 - acc: 0.8966 - val_loss: 0.4091 - val_acc: 0.8929\n",
      "Epoch 716/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4186 - acc: 0.8969 - val_loss: 0.4088 - val_acc: 0.8929\n",
      "Epoch 717/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.4184 - acc: 0.8971 - val_loss: 0.4086 - val_acc: 0.8929\n",
      "Epoch 718/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4181 - acc: 0.8971 - val_loss: 0.4084 - val_acc: 0.8929\n",
      "Epoch 719/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4178 - acc: 0.8972 - val_loss: 0.4081 - val_acc: 0.8929\n",
      "Epoch 720/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4175 - acc: 0.8972 - val_loss: 0.4079 - val_acc: 0.8929\n",
      "Epoch 721/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4173 - acc: 0.8975 - val_loss: 0.4077 - val_acc: 0.8929\n",
      "Epoch 722/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4170 - acc: 0.8971 - val_loss: 0.4074 - val_acc: 0.8929\n",
      "Epoch 723/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4167 - acc: 0.8974 - val_loss: 0.4072 - val_acc: 0.8938\n",
      "Epoch 724/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4164 - acc: 0.8973 - val_loss: 0.4069 - val_acc: 0.8933\n",
      "Epoch 725/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4162 - acc: 0.8973 - val_loss: 0.4067 - val_acc: 0.8929\n",
      "Epoch 726/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4159 - acc: 0.8972 - val_loss: 0.4065 - val_acc: 0.8929\n",
      "Epoch 727/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4156 - acc: 0.8975 - val_loss: 0.4062 - val_acc: 0.8942\n",
      "Epoch 728/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4154 - acc: 0.8975 - val_loss: 0.4060 - val_acc: 0.8946\n",
      "Epoch 729/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4151 - acc: 0.8974 - val_loss: 0.4058 - val_acc: 0.8942\n",
      "Epoch 730/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4148 - acc: 0.8975 - val_loss: 0.4055 - val_acc: 0.8942\n",
      "Epoch 731/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4146 - acc: 0.8976 - val_loss: 0.4053 - val_acc: 0.8946\n",
      "Epoch 732/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4143 - acc: 0.8975 - val_loss: 0.4050 - val_acc: 0.8946\n",
      "Epoch 733/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4140 - acc: 0.8976 - val_loss: 0.4048 - val_acc: 0.8942\n",
      "Epoch 734/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.4138 - acc: 0.8975 - val_loss: 0.4046 - val_acc: 0.8946\n",
      "Epoch 735/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4135 - acc: 0.8976 - val_loss: 0.4043 - val_acc: 0.8950\n",
      "Epoch 736/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4133 - acc: 0.8974 - val_loss: 0.4041 - val_acc: 0.8950\n",
      "Epoch 737/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4130 - acc: 0.8976 - val_loss: 0.4039 - val_acc: 0.8950\n",
      "Epoch 738/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.4127 - acc: 0.8976 - val_loss: 0.4036 - val_acc: 0.8946\n",
      "Epoch 739/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4125 - acc: 0.8976 - val_loss: 0.4034 - val_acc: 0.8954\n",
      "Epoch 740/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4122 - acc: 0.8974 - val_loss: 0.4032 - val_acc: 0.8954\n",
      "Epoch 741/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4119 - acc: 0.8977 - val_loss: 0.4030 - val_acc: 0.8950\n",
      "Epoch 742/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4117 - acc: 0.8977 - val_loss: 0.4027 - val_acc: 0.8950\n",
      "Epoch 743/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.4114 - acc: 0.8977 - val_loss: 0.4025 - val_acc: 0.8950\n",
      "Epoch 744/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4112 - acc: 0.8977 - val_loss: 0.4022 - val_acc: 0.8954\n",
      "Epoch 745/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4109 - acc: 0.8977 - val_loss: 0.4020 - val_acc: 0.8950\n",
      "Epoch 746/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4107 - acc: 0.8979 - val_loss: 0.4018 - val_acc: 0.8954\n",
      "Epoch 747/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4104 - acc: 0.8981 - val_loss: 0.4016 - val_acc: 0.8954\n",
      "Epoch 748/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4101 - acc: 0.8979 - val_loss: 0.4014 - val_acc: 0.8954\n",
      "Epoch 749/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4099 - acc: 0.8979 - val_loss: 0.4012 - val_acc: 0.8958\n",
      "Epoch 750/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4096 - acc: 0.8977 - val_loss: 0.4009 - val_acc: 0.8954\n",
      "Epoch 751/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4094 - acc: 0.8980 - val_loss: 0.4007 - val_acc: 0.8958\n",
      "Epoch 752/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4091 - acc: 0.8981 - val_loss: 0.4005 - val_acc: 0.8958\n",
      "Epoch 753/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4089 - acc: 0.8980 - val_loss: 0.4003 - val_acc: 0.8958\n",
      "Epoch 754/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4086 - acc: 0.8980 - val_loss: 0.4000 - val_acc: 0.8958\n",
      "Epoch 755/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4084 - acc: 0.8985 - val_loss: 0.3999 - val_acc: 0.8958\n",
      "Epoch 756/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4082 - acc: 0.8988 - val_loss: 0.3996 - val_acc: 0.8958\n",
      "Epoch 757/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4079 - acc: 0.8985 - val_loss: 0.3994 - val_acc: 0.8958\n",
      "Epoch 758/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4077 - acc: 0.8984 - val_loss: 0.3991 - val_acc: 0.8958\n",
      "Epoch 759/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4074 - acc: 0.8989 - val_loss: 0.3990 - val_acc: 0.8958\n",
      "Epoch 760/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4072 - acc: 0.8990 - val_loss: 0.3987 - val_acc: 0.8958\n",
      "Epoch 761/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4069 - acc: 0.8983 - val_loss: 0.3985 - val_acc: 0.8958\n",
      "Epoch 762/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4067 - acc: 0.8989 - val_loss: 0.3983 - val_acc: 0.8958\n",
      "Epoch 763/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4064 - acc: 0.8988 - val_loss: 0.3981 - val_acc: 0.8963\n",
      "Epoch 764/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4062 - acc: 0.8992 - val_loss: 0.3979 - val_acc: 0.8958\n",
      "Epoch 765/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4059 - acc: 0.8995 - val_loss: 0.3977 - val_acc: 0.8958\n",
      "Epoch 766/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4057 - acc: 0.8995 - val_loss: 0.3975 - val_acc: 0.8963\n",
      "Epoch 767/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4055 - acc: 0.8993 - val_loss: 0.3972 - val_acc: 0.8963\n",
      "Epoch 768/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4052 - acc: 0.8991 - val_loss: 0.3970 - val_acc: 0.8963\n",
      "Epoch 769/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4050 - acc: 0.8994 - val_loss: 0.3968 - val_acc: 0.8963\n",
      "Epoch 770/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4047 - acc: 0.8993 - val_loss: 0.3966 - val_acc: 0.8963\n",
      "Epoch 771/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4045 - acc: 0.8995 - val_loss: 0.3964 - val_acc: 0.8963\n",
      "Epoch 772/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.4043 - acc: 0.8992 - val_loss: 0.3962 - val_acc: 0.8958\n",
      "Epoch 773/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4040 - acc: 0.8994 - val_loss: 0.3960 - val_acc: 0.8963\n",
      "Epoch 774/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4038 - acc: 0.8996 - val_loss: 0.3958 - val_acc: 0.8963\n",
      "Epoch 775/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4035 - acc: 0.8995 - val_loss: 0.3956 - val_acc: 0.8963\n",
      "Epoch 776/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4033 - acc: 0.8994 - val_loss: 0.3954 - val_acc: 0.8963\n",
      "Epoch 777/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4031 - acc: 0.8996 - val_loss: 0.3952 - val_acc: 0.8963\n",
      "Epoch 778/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.4028 - acc: 0.9000 - val_loss: 0.3950 - val_acc: 0.8963\n",
      "Epoch 779/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4026 - acc: 0.8995 - val_loss: 0.3947 - val_acc: 0.8967\n",
      "Epoch 780/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4024 - acc: 0.8994 - val_loss: 0.3945 - val_acc: 0.8962\n",
      "Epoch 781/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4022 - acc: 0.9003 - val_loss: 0.3943 - val_acc: 0.8967\n",
      "Epoch 782/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4019 - acc: 0.8998 - val_loss: 0.3941 - val_acc: 0.8967\n",
      "Epoch 783/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4017 - acc: 0.9001 - val_loss: 0.3939 - val_acc: 0.8971\n",
      "Epoch 784/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4014 - acc: 0.9003 - val_loss: 0.3938 - val_acc: 0.8971\n",
      "Epoch 785/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4012 - acc: 0.8998 - val_loss: 0.3935 - val_acc: 0.8971\n",
      "Epoch 786/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.4010 - acc: 0.8999 - val_loss: 0.3933 - val_acc: 0.8975\n",
      "Epoch 787/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.4007 - acc: 0.9001 - val_loss: 0.3931 - val_acc: 0.8971\n",
      "Epoch 788/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.4005 - acc: 0.9002 - val_loss: 0.3930 - val_acc: 0.8971\n",
      "Epoch 789/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 0.4003 - acc: 0.9001 - val_loss: 0.3927 - val_acc: 0.8971\n",
      "Epoch 790/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 0.4001 - acc: 0.9002 - val_loss: 0.3925 - val_acc: 0.8971\n",
      "Epoch 791/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 0.3998 - acc: 0.9001 - val_loss: 0.3923 - val_acc: 0.8971\n",
      "Epoch 792/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.3996 - acc: 0.9002 - val_loss: 0.3922 - val_acc: 0.8967\n",
      "Epoch 793/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.3994 - acc: 0.9003 - val_loss: 0.3919 - val_acc: 0.8967\n",
      "Epoch 794/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.3991 - acc: 0.9004 - val_loss: 0.3918 - val_acc: 0.8971\n",
      "Epoch 795/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.3989 - acc: 0.9006 - val_loss: 0.3915 - val_acc: 0.8967\n",
      "Epoch 796/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.3987 - acc: 0.9004 - val_loss: 0.3914 - val_acc: 0.8967\n",
      "Epoch 797/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.3985 - acc: 0.9004 - val_loss: 0.3912 - val_acc: 0.8967\n",
      "Epoch 798/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.3983 - acc: 0.9005 - val_loss: 0.3910 - val_acc: 0.8967\n",
      "Epoch 799/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.3981 - acc: 0.9004 - val_loss: 0.3908 - val_acc: 0.8967\n",
      "Epoch 800/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.3978 - acc: 0.9009 - val_loss: 0.3906 - val_acc: 0.8971\n",
      "Epoch 801/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.3976 - acc: 0.9005 - val_loss: 0.3904 - val_acc: 0.8971\n",
      "Epoch 802/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.3974 - acc: 0.9009 - val_loss: 0.3902 - val_acc: 0.8967\n",
      "Epoch 803/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.3972 - acc: 0.9006 - val_loss: 0.3900 - val_acc: 0.8971\n",
      "Epoch 804/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.3970 - acc: 0.9007 - val_loss: 0.3898 - val_acc: 0.8967\n",
      "Epoch 805/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.3967 - acc: 0.9006 - val_loss: 0.3896 - val_acc: 0.8971\n",
      "Epoch 806/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.3965 - acc: 0.9006 - val_loss: 0.3894 - val_acc: 0.8967\n",
      "Epoch 807/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.3963 - acc: 0.9009 - val_loss: 0.3893 - val_acc: 0.8971\n",
      "Epoch 808/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.3961 - acc: 0.9010 - val_loss: 0.3890 - val_acc: 0.8967\n",
      "Epoch 809/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.3959 - acc: 0.9010 - val_loss: 0.3889 - val_acc: 0.8967\n",
      "Epoch 810/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3956 - acc: 0.9013 - val_loss: 0.3887 - val_acc: 0.8971\n",
      "Epoch 811/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.3954 - acc: 0.9010 - val_loss: 0.3885 - val_acc: 0.8967\n",
      "Epoch 812/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.3952 - acc: 0.9010 - val_loss: 0.3883 - val_acc: 0.8967\n",
      "Epoch 813/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.3950 - acc: 0.9013 - val_loss: 0.3882 - val_acc: 0.8967\n",
      "Epoch 814/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.3948 - acc: 0.9013 - val_loss: 0.3880 - val_acc: 0.8967\n",
      "Epoch 815/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.3946 - acc: 0.9011 - val_loss: 0.3877 - val_acc: 0.8967\n",
      "Epoch 816/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3943 - acc: 0.9011 - val_loss: 0.3876 - val_acc: 0.8967\n",
      "Epoch 817/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3941 - acc: 0.9011 - val_loss: 0.3874 - val_acc: 0.8967\n",
      "Epoch 818/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3939 - acc: 0.9014 - val_loss: 0.3872 - val_acc: 0.8971\n",
      "Epoch 819/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3937 - acc: 0.9015 - val_loss: 0.3871 - val_acc: 0.8971\n",
      "Epoch 820/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3935 - acc: 0.9016 - val_loss: 0.3868 - val_acc: 0.8967\n",
      "Epoch 821/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3933 - acc: 0.9014 - val_loss: 0.3867 - val_acc: 0.8967\n",
      "Epoch 822/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3931 - acc: 0.9016 - val_loss: 0.3865 - val_acc: 0.8979\n",
      "Epoch 823/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3929 - acc: 0.9014 - val_loss: 0.3863 - val_acc: 0.8975\n",
      "Epoch 824/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3927 - acc: 0.9015 - val_loss: 0.3861 - val_acc: 0.8975\n",
      "Epoch 825/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3925 - acc: 0.9015 - val_loss: 0.3860 - val_acc: 0.8967\n",
      "Epoch 826/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 0.3923 - acc: 0.9017 - val_loss: 0.3857 - val_acc: 0.8975\n",
      "Epoch 827/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3921 - acc: 0.9019 - val_loss: 0.3856 - val_acc: 0.8967\n",
      "Epoch 828/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3919 - acc: 0.9019 - val_loss: 0.3854 - val_acc: 0.8979\n",
      "Epoch 829/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3917 - acc: 0.9019 - val_loss: 0.3852 - val_acc: 0.8975\n",
      "Epoch 830/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3914 - acc: 0.9017 - val_loss: 0.3850 - val_acc: 0.8971\n",
      "Epoch 831/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3912 - acc: 0.9015 - val_loss: 0.3849 - val_acc: 0.8979\n",
      "Epoch 832/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3910 - acc: 0.9019 - val_loss: 0.3847 - val_acc: 0.8979\n",
      "Epoch 833/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3908 - acc: 0.9017 - val_loss: 0.3845 - val_acc: 0.8975\n",
      "Epoch 834/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3906 - acc: 0.9020 - val_loss: 0.3843 - val_acc: 0.8975\n",
      "Epoch 835/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3904 - acc: 0.9022 - val_loss: 0.3842 - val_acc: 0.8983\n",
      "Epoch 836/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3902 - acc: 0.9020 - val_loss: 0.3839 - val_acc: 0.8979\n",
      "Epoch 837/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3900 - acc: 0.9019 - val_loss: 0.3839 - val_acc: 0.8979\n",
      "Epoch 838/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3898 - acc: 0.9022 - val_loss: 0.3836 - val_acc: 0.8971\n",
      "Epoch 839/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3896 - acc: 0.9019 - val_loss: 0.3835 - val_acc: 0.8979\n",
      "Epoch 840/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3894 - acc: 0.9020 - val_loss: 0.3833 - val_acc: 0.8983\n",
      "Epoch 841/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3892 - acc: 0.9022 - val_loss: 0.3831 - val_acc: 0.8979\n",
      "Epoch 842/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3890 - acc: 0.9019 - val_loss: 0.3830 - val_acc: 0.8983\n",
      "Epoch 843/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3888 - acc: 0.9022 - val_loss: 0.3828 - val_acc: 0.8983\n",
      "Epoch 844/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3886 - acc: 0.9021 - val_loss: 0.3826 - val_acc: 0.8983\n",
      "Epoch 845/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3884 - acc: 0.9021 - val_loss: 0.3824 - val_acc: 0.8983\n",
      "Epoch 846/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3882 - acc: 0.9022 - val_loss: 0.3823 - val_acc: 0.8983\n",
      "Epoch 847/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3880 - acc: 0.9023 - val_loss: 0.3821 - val_acc: 0.8983\n",
      "Epoch 848/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3878 - acc: 0.9023 - val_loss: 0.3819 - val_acc: 0.8983\n",
      "Epoch 849/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3876 - acc: 0.9022 - val_loss: 0.3818 - val_acc: 0.8983\n",
      "Epoch 850/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3874 - acc: 0.9023 - val_loss: 0.3816 - val_acc: 0.8983\n",
      "Epoch 851/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3872 - acc: 0.9024 - val_loss: 0.3814 - val_acc: 0.8983\n",
      "Epoch 852/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3870 - acc: 0.9025 - val_loss: 0.3812 - val_acc: 0.8983\n",
      "Epoch 853/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3868 - acc: 0.9023 - val_loss: 0.3811 - val_acc: 0.8983\n",
      "Epoch 854/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3866 - acc: 0.9024 - val_loss: 0.3809 - val_acc: 0.8983\n",
      "Epoch 855/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3865 - acc: 0.9025 - val_loss: 0.3807 - val_acc: 0.8983\n",
      "Epoch 856/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3863 - acc: 0.9024 - val_loss: 0.3806 - val_acc: 0.8983\n",
      "Epoch 857/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3861 - acc: 0.9027 - val_loss: 0.3804 - val_acc: 0.8983\n",
      "Epoch 858/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3859 - acc: 0.9025 - val_loss: 0.3803 - val_acc: 0.8983\n",
      "Epoch 859/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3857 - acc: 0.9026 - val_loss: 0.3801 - val_acc: 0.8983\n",
      "Epoch 860/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3855 - acc: 0.9025 - val_loss: 0.3799 - val_acc: 0.8983\n",
      "Epoch 861/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3853 - acc: 0.9026 - val_loss: 0.3798 - val_acc: 0.8983\n",
      "Epoch 862/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3851 - acc: 0.9026 - val_loss: 0.3796 - val_acc: 0.8983\n",
      "Epoch 863/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3849 - acc: 0.9026 - val_loss: 0.3794 - val_acc: 0.8983\n",
      "Epoch 864/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3847 - acc: 0.9025 - val_loss: 0.3793 - val_acc: 0.8983\n",
      "Epoch 865/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3845 - acc: 0.9027 - val_loss: 0.3791 - val_acc: 0.8983\n",
      "Epoch 866/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3844 - acc: 0.9027 - val_loss: 0.3789 - val_acc: 0.8983\n",
      "Epoch 867/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3842 - acc: 0.9029 - val_loss: 0.3788 - val_acc: 0.8983\n",
      "Epoch 868/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3840 - acc: 0.9028 - val_loss: 0.3786 - val_acc: 0.8983\n",
      "Epoch 869/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3838 - acc: 0.9027 - val_loss: 0.3785 - val_acc: 0.8983\n",
      "Epoch 870/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3836 - acc: 0.9029 - val_loss: 0.3783 - val_acc: 0.8983\n",
      "Epoch 871/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3834 - acc: 0.9028 - val_loss: 0.3781 - val_acc: 0.8983\n",
      "Epoch 872/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3832 - acc: 0.9028 - val_loss: 0.3780 - val_acc: 0.8983\n",
      "Epoch 873/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3830 - acc: 0.9028 - val_loss: 0.3778 - val_acc: 0.8988\n",
      "Epoch 874/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3829 - acc: 0.9029 - val_loss: 0.3777 - val_acc: 0.8983\n",
      "Epoch 875/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3827 - acc: 0.9029 - val_loss: 0.3775 - val_acc: 0.8983\n",
      "Epoch 876/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3825 - acc: 0.9027 - val_loss: 0.3774 - val_acc: 0.8988\n",
      "Epoch 877/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3823 - acc: 0.9030 - val_loss: 0.3772 - val_acc: 0.8988\n",
      "Epoch 878/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3821 - acc: 0.9030 - val_loss: 0.3771 - val_acc: 0.8988\n",
      "Epoch 879/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3820 - acc: 0.9028 - val_loss: 0.3769 - val_acc: 0.8996\n",
      "Epoch 880/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3818 - acc: 0.9028 - val_loss: 0.3768 - val_acc: 0.8988\n",
      "Epoch 881/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3816 - acc: 0.9029 - val_loss: 0.3766 - val_acc: 0.8992\n",
      "Epoch 882/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3814 - acc: 0.9029 - val_loss: 0.3764 - val_acc: 0.8992\n",
      "Epoch 883/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3812 - acc: 0.9029 - val_loss: 0.3763 - val_acc: 0.8992\n",
      "Epoch 884/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.3810 - acc: 0.9030 - val_loss: 0.3761 - val_acc: 0.8992\n",
      "Epoch 885/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.3808 - acc: 0.9030 - val_loss: 0.3759 - val_acc: 0.8996\n",
      "Epoch 886/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.3807 - acc: 0.9031 - val_loss: 0.3758 - val_acc: 0.8996\n",
      "Epoch 887/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.3805 - acc: 0.9030 - val_loss: 0.3757 - val_acc: 0.8996\n",
      "Epoch 888/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.3803 - acc: 0.9032 - val_loss: 0.3755 - val_acc: 0.8996\n",
      "Epoch 889/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.3801 - acc: 0.9030 - val_loss: 0.3753 - val_acc: 0.9000\n",
      "Epoch 890/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.3799 - acc: 0.9033 - val_loss: 0.3752 - val_acc: 0.8996\n",
      "Epoch 891/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.3798 - acc: 0.9030 - val_loss: 0.3750 - val_acc: 0.9004\n",
      "Epoch 892/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.3796 - acc: 0.9033 - val_loss: 0.3749 - val_acc: 0.9004\n",
      "Epoch 893/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.3794 - acc: 0.9032 - val_loss: 0.3748 - val_acc: 0.9000\n",
      "Epoch 894/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.3792 - acc: 0.9032 - val_loss: 0.3746 - val_acc: 0.9008\n",
      "Epoch 895/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.3791 - acc: 0.9033 - val_loss: 0.3744 - val_acc: 0.9000\n",
      "Epoch 896/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.3789 - acc: 0.9033 - val_loss: 0.3743 - val_acc: 0.9004\n",
      "Epoch 897/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3787 - acc: 0.9033 - val_loss: 0.3741 - val_acc: 0.9008\n",
      "Epoch 898/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3785 - acc: 0.9033 - val_loss: 0.3740 - val_acc: 0.9004\n",
      "Epoch 899/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3784 - acc: 0.9036 - val_loss: 0.3738 - val_acc: 0.9004\n",
      "Epoch 900/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3782 - acc: 0.9033 - val_loss: 0.3737 - val_acc: 0.9004\n",
      "Epoch 901/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3780 - acc: 0.9036 - val_loss: 0.3735 - val_acc: 0.9004\n",
      "Epoch 902/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3778 - acc: 0.9034 - val_loss: 0.3734 - val_acc: 0.9004\n",
      "Epoch 903/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3777 - acc: 0.9033 - val_loss: 0.3732 - val_acc: 0.9008\n",
      "Epoch 904/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3775 - acc: 0.9036 - val_loss: 0.3731 - val_acc: 0.9004\n",
      "Epoch 905/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3773 - acc: 0.9033 - val_loss: 0.3729 - val_acc: 0.9008\n",
      "Epoch 906/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 0.3771 - acc: 0.9036 - val_loss: 0.3728 - val_acc: 0.9008\n",
      "Epoch 907/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3770 - acc: 0.9038 - val_loss: 0.3727 - val_acc: 0.9004\n",
      "Epoch 908/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.3768 - acc: 0.9038 - val_loss: 0.3725 - val_acc: 0.9004\n",
      "Epoch 909/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3766 - acc: 0.9035 - val_loss: 0.3723 - val_acc: 0.9008\n",
      "Epoch 910/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3765 - acc: 0.9039 - val_loss: 0.3722 - val_acc: 0.9004\n",
      "Epoch 911/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3763 - acc: 0.9038 - val_loss: 0.3720 - val_acc: 0.9004\n",
      "Epoch 912/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3761 - acc: 0.9036 - val_loss: 0.3719 - val_acc: 0.9004\n",
      "Epoch 913/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3759 - acc: 0.9038 - val_loss: 0.3717 - val_acc: 0.9004\n",
      "Epoch 914/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3758 - acc: 0.9039 - val_loss: 0.3716 - val_acc: 0.9008\n",
      "Epoch 915/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3756 - acc: 0.9040 - val_loss: 0.3715 - val_acc: 0.9008\n",
      "Epoch 916/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3754 - acc: 0.9039 - val_loss: 0.3713 - val_acc: 0.9004\n",
      "Epoch 917/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.3753 - acc: 0.9040 - val_loss: 0.3712 - val_acc: 0.9008\n",
      "Epoch 918/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 0.3751 - acc: 0.9040 - val_loss: 0.3711 - val_acc: 0.9008\n",
      "Epoch 919/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.3749 - acc: 0.9039 - val_loss: 0.3709 - val_acc: 0.9008\n",
      "Epoch 920/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.3748 - acc: 0.9041 - val_loss: 0.3708 - val_acc: 0.9008\n",
      "Epoch 921/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.3746 - acc: 0.9041 - val_loss: 0.3706 - val_acc: 0.9008\n",
      "Epoch 922/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 0.3744 - acc: 0.9041 - val_loss: 0.3704 - val_acc: 0.9008\n",
      "Epoch 923/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 0.3743 - acc: 0.9041 - val_loss: 0.3703 - val_acc: 0.9008\n",
      "Epoch 924/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.3741 - acc: 0.9040 - val_loss: 0.3702 - val_acc: 0.9008\n",
      "Epoch 925/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.3739 - acc: 0.9042 - val_loss: 0.3701 - val_acc: 0.9008\n",
      "Epoch 926/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.3737 - acc: 0.9041 - val_loss: 0.3699 - val_acc: 0.9008\n",
      "Epoch 927/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3736 - acc: 0.9043 - val_loss: 0.3698 - val_acc: 0.9008\n",
      "Epoch 928/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3734 - acc: 0.9043 - val_loss: 0.3697 - val_acc: 0.9008\n",
      "Epoch 929/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3733 - acc: 0.9042 - val_loss: 0.3695 - val_acc: 0.9008\n",
      "Epoch 930/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3731 - acc: 0.9039 - val_loss: 0.3694 - val_acc: 0.9008\n",
      "Epoch 931/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3729 - acc: 0.9045 - val_loss: 0.3692 - val_acc: 0.9012\n",
      "Epoch 932/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3728 - acc: 0.9045 - val_loss: 0.3691 - val_acc: 0.9008\n",
      "Epoch 933/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3726 - acc: 0.9044 - val_loss: 0.3689 - val_acc: 0.9008\n",
      "Epoch 934/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3724 - acc: 0.9045 - val_loss: 0.3688 - val_acc: 0.9008\n",
      "Epoch 935/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3723 - acc: 0.9043 - val_loss: 0.3687 - val_acc: 0.9008\n",
      "Epoch 936/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3721 - acc: 0.9043 - val_loss: 0.3685 - val_acc: 0.9008\n",
      "Epoch 937/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3720 - acc: 0.9044 - val_loss: 0.3684 - val_acc: 0.9012\n",
      "Epoch 938/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3718 - acc: 0.9046 - val_loss: 0.3682 - val_acc: 0.9012\n",
      "Epoch 939/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3716 - acc: 0.9046 - val_loss: 0.3681 - val_acc: 0.9008\n",
      "Epoch 940/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3715 - acc: 0.9047 - val_loss: 0.3680 - val_acc: 0.9012\n",
      "Epoch 941/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.3713 - acc: 0.9046 - val_loss: 0.3679 - val_acc: 0.9008\n",
      "Epoch 942/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.3712 - acc: 0.9047 - val_loss: 0.3678 - val_acc: 0.9008\n",
      "Epoch 943/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3710 - acc: 0.9048 - val_loss: 0.3676 - val_acc: 0.9008\n",
      "Epoch 944/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3708 - acc: 0.9046 - val_loss: 0.3675 - val_acc: 0.9008\n",
      "Epoch 945/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3707 - acc: 0.9048 - val_loss: 0.3673 - val_acc: 0.9008\n",
      "Epoch 946/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.3705 - acc: 0.9048 - val_loss: 0.3672 - val_acc: 0.9012\n",
      "Epoch 947/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3704 - acc: 0.9048 - val_loss: 0.3670 - val_acc: 0.9012\n",
      "Epoch 948/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3702 - acc: 0.9044 - val_loss: 0.3669 - val_acc: 0.9004\n",
      "Epoch 949/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3700 - acc: 0.9047 - val_loss: 0.3668 - val_acc: 0.9004\n",
      "Epoch 950/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3699 - acc: 0.9045 - val_loss: 0.3667 - val_acc: 0.9008\n",
      "Epoch 951/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3697 - acc: 0.9048 - val_loss: 0.3666 - val_acc: 0.9008\n",
      "Epoch 952/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3696 - acc: 0.9048 - val_loss: 0.3664 - val_acc: 0.9008\n",
      "Epoch 953/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3694 - acc: 0.9045 - val_loss: 0.3663 - val_acc: 0.9008\n",
      "Epoch 954/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3693 - acc: 0.9048 - val_loss: 0.3661 - val_acc: 0.9008\n",
      "Epoch 955/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3691 - acc: 0.9046 - val_loss: 0.3660 - val_acc: 0.9004\n",
      "Epoch 956/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3690 - acc: 0.9050 - val_loss: 0.3659 - val_acc: 0.9008\n",
      "Epoch 957/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3688 - acc: 0.9049 - val_loss: 0.3657 - val_acc: 0.9008\n",
      "Epoch 958/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3686 - acc: 0.9048 - val_loss: 0.3656 - val_acc: 0.9008\n",
      "Epoch 959/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3685 - acc: 0.9045 - val_loss: 0.3655 - val_acc: 0.9008\n",
      "Epoch 960/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3683 - acc: 0.9049 - val_loss: 0.3653 - val_acc: 0.9008\n",
      "Epoch 961/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3682 - acc: 0.9050 - val_loss: 0.3652 - val_acc: 0.9008\n",
      "Epoch 962/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3680 - acc: 0.9048 - val_loss: 0.3651 - val_acc: 0.9008\n",
      "Epoch 963/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3679 - acc: 0.9047 - val_loss: 0.3650 - val_acc: 0.9012\n",
      "Epoch 964/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3677 - acc: 0.9050 - val_loss: 0.3648 - val_acc: 0.9012\n",
      "Epoch 965/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3676 - acc: 0.9050 - val_loss: 0.3647 - val_acc: 0.9008\n",
      "Epoch 966/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3674 - acc: 0.9048 - val_loss: 0.3646 - val_acc: 0.9012\n",
      "Epoch 967/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.3673 - acc: 0.9049 - val_loss: 0.3644 - val_acc: 0.9012\n",
      "Epoch 968/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3671 - acc: 0.9049 - val_loss: 0.3643 - val_acc: 0.9012\n",
      "Epoch 969/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3670 - acc: 0.9050 - val_loss: 0.3642 - val_acc: 0.9012\n",
      "Epoch 970/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3668 - acc: 0.9049 - val_loss: 0.3641 - val_acc: 0.9008\n",
      "Epoch 971/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3666 - acc: 0.9049 - val_loss: 0.3639 - val_acc: 0.9012\n",
      "Epoch 972/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3665 - acc: 0.9050 - val_loss: 0.3638 - val_acc: 0.9012\n",
      "Epoch 973/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3664 - acc: 0.9051 - val_loss: 0.3637 - val_acc: 0.9012\n",
      "Epoch 974/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3662 - acc: 0.9052 - val_loss: 0.3636 - val_acc: 0.9008\n",
      "Epoch 975/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3661 - acc: 0.9049 - val_loss: 0.3634 - val_acc: 0.9004\n",
      "Epoch 976/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3659 - acc: 0.9050 - val_loss: 0.3633 - val_acc: 0.9008\n",
      "Epoch 977/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3658 - acc: 0.9050 - val_loss: 0.3632 - val_acc: 0.9008\n",
      "Epoch 978/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3656 - acc: 0.9050 - val_loss: 0.3631 - val_acc: 0.9008\n",
      "Epoch 979/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3655 - acc: 0.9050 - val_loss: 0.3629 - val_acc: 0.9008\n",
      "Epoch 980/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.3653 - acc: 0.9054 - val_loss: 0.3628 - val_acc: 0.9008\n",
      "Epoch 981/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.3652 - acc: 0.9051 - val_loss: 0.3627 - val_acc: 0.9004\n",
      "Val loss: 0.3692,Val acc: 0.9012\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  DATASET MBI  ----------\n",
      "(9600, 28, 28, 1) train samples\n",
      "(2400, 28, 28, 1) validation samples\n",
      "(50000, 28, 28, 1) test samples\n",
      "\n",
      "\tTraining model:\n",
      "logreg\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 2.3007 - acc: 0.1140 - val_loss: 2.2989 - val_acc: 0.1129\n",
      "Epoch 2/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2969 - acc: 0.1147 - val_loss: 2.2957 - val_acc: 0.1129\n",
      "Epoch 3/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2938 - acc: 0.1147 - val_loss: 2.2929 - val_acc: 0.1129\n",
      "Epoch 4/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2908 - acc: 0.1182 - val_loss: 2.2900 - val_acc: 0.1175\n",
      "Epoch 5/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2879 - acc: 0.1298 - val_loss: 2.2871 - val_acc: 0.1375\n",
      "Epoch 6/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2848 - acc: 0.1430 - val_loss: 2.2843 - val_acc: 0.1333\n",
      "Epoch 7/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2818 - acc: 0.1302 - val_loss: 2.2811 - val_acc: 0.1350\n",
      "Epoch 8/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2790 - acc: 0.1629 - val_loss: 2.2783 - val_acc: 0.1458\n",
      "Epoch 9/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.2760 - acc: 0.1321 - val_loss: 2.2752 - val_acc: 0.1471\n",
      "Epoch 10/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.2732 - acc: 0.1845 - val_loss: 2.2722 - val_acc: 0.1708\n",
      "Epoch 11/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.2702 - acc: 0.1821 - val_loss: 2.2695 - val_acc: 0.1821\n",
      "Epoch 12/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2673 - acc: 0.1814 - val_loss: 2.2666 - val_acc: 0.1908\n",
      "Epoch 13/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2644 - acc: 0.1996 - val_loss: 2.2636 - val_acc: 0.2058\n",
      "Epoch 14/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2616 - acc: 0.2272 - val_loss: 2.2607 - val_acc: 0.2217\n",
      "Epoch 15/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2586 - acc: 0.2172 - val_loss: 2.2579 - val_acc: 0.2242\n",
      "Epoch 16/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2558 - acc: 0.2242 - val_loss: 2.2551 - val_acc: 0.2517\n",
      "Epoch 17/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2530 - acc: 0.2589 - val_loss: 2.2522 - val_acc: 0.2725\n",
      "Epoch 18/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2502 - acc: 0.2520 - val_loss: 2.2496 - val_acc: 0.2612\n",
      "Epoch 19/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2472 - acc: 0.2966 - val_loss: 2.2464 - val_acc: 0.2762\n",
      "Epoch 20/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2443 - acc: 0.3013 - val_loss: 2.2437 - val_acc: 0.2979\n",
      "Epoch 21/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2416 - acc: 0.2985 - val_loss: 2.2408 - val_acc: 0.3229\n",
      "Epoch 22/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2387 - acc: 0.3023 - val_loss: 2.2380 - val_acc: 0.3233\n",
      "Epoch 23/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2358 - acc: 0.3152 - val_loss: 2.2352 - val_acc: 0.3313\n",
      "Epoch 24/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2330 - acc: 0.3263 - val_loss: 2.2323 - val_acc: 0.3504\n",
      "Epoch 25/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2302 - acc: 0.3502 - val_loss: 2.2295 - val_acc: 0.3683\n",
      "Epoch 26/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2274 - acc: 0.3563 - val_loss: 2.2267 - val_acc: 0.3637\n",
      "Epoch 27/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2246 - acc: 0.3828 - val_loss: 2.2238 - val_acc: 0.3688\n",
      "Epoch 28/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2218 - acc: 0.3698 - val_loss: 2.2211 - val_acc: 0.3746\n",
      "Epoch 29/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2190 - acc: 0.3752 - val_loss: 2.2184 - val_acc: 0.4037\n",
      "Epoch 30/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2162 - acc: 0.3903 - val_loss: 2.2153 - val_acc: 0.4000\n",
      "Epoch 31/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2134 - acc: 0.4074 - val_loss: 2.2127 - val_acc: 0.4017\n",
      "Epoch 32/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2106 - acc: 0.3868 - val_loss: 2.2100 - val_acc: 0.4046\n",
      "Epoch 33/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2078 - acc: 0.4141 - val_loss: 2.2072 - val_acc: 0.4100\n",
      "Epoch 34/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2050 - acc: 0.4155 - val_loss: 2.2045 - val_acc: 0.4142\n",
      "Epoch 35/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2023 - acc: 0.4236 - val_loss: 2.2017 - val_acc: 0.4262\n",
      "Epoch 36/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1996 - acc: 0.4143 - val_loss: 2.1988 - val_acc: 0.4400\n",
      "Epoch 37/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1968 - acc: 0.4334 - val_loss: 2.1960 - val_acc: 0.4437\n",
      "Epoch 38/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1941 - acc: 0.4445 - val_loss: 2.1933 - val_acc: 0.4392\n",
      "Epoch 39/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1913 - acc: 0.4456 - val_loss: 2.1906 - val_acc: 0.4537\n",
      "Epoch 40/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1886 - acc: 0.4513 - val_loss: 2.1880 - val_acc: 0.4571\n",
      "Epoch 41/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1859 - acc: 0.4621 - val_loss: 2.1850 - val_acc: 0.4604\n",
      "Epoch 42/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1831 - acc: 0.4534 - val_loss: 2.1824 - val_acc: 0.4550\n",
      "Epoch 43/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1805 - acc: 0.4552 - val_loss: 2.1798 - val_acc: 0.4608\n",
      "Epoch 44/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1778 - acc: 0.4698 - val_loss: 2.1771 - val_acc: 0.4688\n",
      "Epoch 45/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1750 - acc: 0.4653 - val_loss: 2.1740 - val_acc: 0.4712\n",
      "Epoch 46/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1723 - acc: 0.4777 - val_loss: 2.1715 - val_acc: 0.4821\n",
      "Epoch 47/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1696 - acc: 0.4725 - val_loss: 2.1689 - val_acc: 0.4888\n",
      "Epoch 48/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1670 - acc: 0.4858 - val_loss: 2.1663 - val_acc: 0.4796\n",
      "Epoch 49/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1643 - acc: 0.4852 - val_loss: 2.1635 - val_acc: 0.4863\n",
      "Epoch 50/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1616 - acc: 0.4816 - val_loss: 2.1609 - val_acc: 0.4871\n",
      "Epoch 51/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1589 - acc: 0.5015 - val_loss: 2.1582 - val_acc: 0.4925\n",
      "Epoch 52/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1563 - acc: 0.4885 - val_loss: 2.1554 - val_acc: 0.4954\n",
      "Epoch 53/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1536 - acc: 0.4949 - val_loss: 2.1530 - val_acc: 0.4958\n",
      "Epoch 54/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1510 - acc: 0.5023 - val_loss: 2.1501 - val_acc: 0.5021\n",
      "Epoch 55/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1483 - acc: 0.4975 - val_loss: 2.1476 - val_acc: 0.5017\n",
      "Epoch 56/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1457 - acc: 0.5016 - val_loss: 2.1448 - val_acc: 0.5029\n",
      "Epoch 57/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1431 - acc: 0.5061 - val_loss: 2.1422 - val_acc: 0.5042\n",
      "Epoch 58/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 2.1405 - acc: 0.5093 - val_loss: 2.1396 - val_acc: 0.5138\n",
      "Epoch 59/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1378 - acc: 0.5216 - val_loss: 2.1370 - val_acc: 0.5167\n",
      "Epoch 60/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1353 - acc: 0.5074 - val_loss: 2.1345 - val_acc: 0.5129\n",
      "Epoch 61/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1326 - acc: 0.5122 - val_loss: 2.1320 - val_acc: 0.5142\n",
      "Epoch 62/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1301 - acc: 0.5249 - val_loss: 2.1294 - val_acc: 0.5212\n",
      "Epoch 63/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1274 - acc: 0.5222 - val_loss: 2.1267 - val_acc: 0.5200\n",
      "Epoch 64/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1248 - acc: 0.5133 - val_loss: 2.1241 - val_acc: 0.5154\n",
      "Epoch 65/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1223 - acc: 0.5288 - val_loss: 2.1214 - val_acc: 0.5233\n",
      "Epoch 66/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1197 - acc: 0.5273 - val_loss: 2.1190 - val_acc: 0.5275\n",
      "Epoch 67/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1171 - acc: 0.5240 - val_loss: 2.1164 - val_acc: 0.5292\n",
      "Epoch 68/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1146 - acc: 0.5292 - val_loss: 2.1138 - val_acc: 0.5304\n",
      "Epoch 69/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1120 - acc: 0.5318 - val_loss: 2.1112 - val_acc: 0.5304\n",
      "Epoch 70/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1095 - acc: 0.5332 - val_loss: 2.1087 - val_acc: 0.5388\n",
      "Epoch 71/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1069 - acc: 0.5311 - val_loss: 2.1062 - val_acc: 0.5379\n",
      "Epoch 72/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1044 - acc: 0.5370 - val_loss: 2.1037 - val_acc: 0.5417\n",
      "Epoch 73/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1018 - acc: 0.5418 - val_loss: 2.1010 - val_acc: 0.5392\n",
      "Epoch 74/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0993 - acc: 0.5396 - val_loss: 2.0986 - val_acc: 0.5421\n",
      "Epoch 75/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0968 - acc: 0.5393 - val_loss: 2.0960 - val_acc: 0.5413\n",
      "Epoch 76/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0943 - acc: 0.5377 - val_loss: 2.0935 - val_acc: 0.5413\n",
      "Epoch 77/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0917 - acc: 0.5449 - val_loss: 2.0909 - val_acc: 0.5408\n",
      "Epoch 78/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0893 - acc: 0.5429 - val_loss: 2.0885 - val_acc: 0.5454\n",
      "Epoch 79/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0868 - acc: 0.5517 - val_loss: 2.0859 - val_acc: 0.5450\n",
      "Epoch 80/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0843 - acc: 0.5419 - val_loss: 2.0834 - val_acc: 0.5446\n",
      "Epoch 81/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0818 - acc: 0.5472 - val_loss: 2.0809 - val_acc: 0.5508\n",
      "Epoch 82/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0793 - acc: 0.5527 - val_loss: 2.0785 - val_acc: 0.5529\n",
      "Epoch 83/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0768 - acc: 0.5517 - val_loss: 2.0759 - val_acc: 0.5533\n",
      "Epoch 84/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0744 - acc: 0.5541 - val_loss: 2.0735 - val_acc: 0.5538\n",
      "Epoch 85/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0719 - acc: 0.5607 - val_loss: 2.0709 - val_acc: 0.5550\n",
      "Epoch 86/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0695 - acc: 0.5530 - val_loss: 2.0685 - val_acc: 0.5525\n",
      "Epoch 87/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0670 - acc: 0.5564 - val_loss: 2.0662 - val_acc: 0.5575\n",
      "Epoch 88/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0646 - acc: 0.5625 - val_loss: 2.0637 - val_acc: 0.5554\n",
      "Epoch 89/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0621 - acc: 0.5552 - val_loss: 2.0614 - val_acc: 0.5562\n",
      "Epoch 90/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0597 - acc: 0.5606 - val_loss: 2.0589 - val_acc: 0.5592\n",
      "Epoch 91/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0573 - acc: 0.5645 - val_loss: 2.0563 - val_acc: 0.5583\n",
      "Epoch 92/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0548 - acc: 0.5664 - val_loss: 2.0541 - val_acc: 0.5642\n",
      "Epoch 93/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0525 - acc: 0.5640 - val_loss: 2.0517 - val_acc: 0.5592\n",
      "Epoch 94/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.0500 - acc: 0.5650 - val_loss: 2.0492 - val_acc: 0.5633\n",
      "Epoch 95/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0477 - acc: 0.5683 - val_loss: 2.0468 - val_acc: 0.5617\n",
      "Epoch 96/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.0453 - acc: 0.5609 - val_loss: 2.0444 - val_acc: 0.5633\n",
      "Epoch 97/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0429 - acc: 0.5702 - val_loss: 2.0422 - val_acc: 0.5667\n",
      "Epoch 98/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0405 - acc: 0.5699 - val_loss: 2.0395 - val_acc: 0.5642\n",
      "Epoch 99/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0383 - acc: 0.5715 - val_loss: 2.0371 - val_acc: 0.5650\n",
      "Epoch 100/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0358 - acc: 0.5735 - val_loss: 2.0349 - val_acc: 0.5650\n",
      "Epoch 101/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0335 - acc: 0.5670 - val_loss: 2.0325 - val_acc: 0.5638\n",
      "Epoch 102/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0311 - acc: 0.5744 - val_loss: 2.0301 - val_acc: 0.5667\n",
      "Epoch 103/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0288 - acc: 0.5711 - val_loss: 2.0281 - val_acc: 0.5650\n",
      "Epoch 104/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0264 - acc: 0.5779 - val_loss: 2.0255 - val_acc: 0.5687\n",
      "Epoch 105/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0241 - acc: 0.5710 - val_loss: 2.0231 - val_acc: 0.5692\n",
      "Epoch 106/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0218 - acc: 0.5778 - val_loss: 2.0209 - val_acc: 0.5700\n",
      "Epoch 107/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0195 - acc: 0.5769 - val_loss: 2.0185 - val_acc: 0.5696\n",
      "Epoch 108/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0171 - acc: 0.5763 - val_loss: 2.0162 - val_acc: 0.5688\n",
      "Epoch 109/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0149 - acc: 0.5786 - val_loss: 2.0140 - val_acc: 0.5737\n",
      "Epoch 110/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0126 - acc: 0.5780 - val_loss: 2.0117 - val_acc: 0.5783\n",
      "Epoch 111/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0104 - acc: 0.5773 - val_loss: 2.0094 - val_acc: 0.5742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0080 - acc: 0.5808 - val_loss: 2.0071 - val_acc: 0.5763\n",
      "Epoch 113/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0057 - acc: 0.5834 - val_loss: 2.0048 - val_acc: 0.5787\n",
      "Epoch 114/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0034 - acc: 0.5827 - val_loss: 2.0024 - val_acc: 0.5796\n",
      "Epoch 115/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0011 - acc: 0.5820 - val_loss: 2.0003 - val_acc: 0.5829\n",
      "Epoch 116/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9989 - acc: 0.5854 - val_loss: 1.9979 - val_acc: 0.5800\n",
      "Epoch 117/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9966 - acc: 0.5872 - val_loss: 1.9957 - val_acc: 0.5787\n",
      "Epoch 118/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9944 - acc: 0.5841 - val_loss: 1.9934 - val_acc: 0.5796\n",
      "Epoch 119/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9920 - acc: 0.5844 - val_loss: 1.9911 - val_acc: 0.5817\n",
      "Epoch 120/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9898 - acc: 0.5877 - val_loss: 1.9889 - val_acc: 0.5837\n",
      "Epoch 121/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9876 - acc: 0.5902 - val_loss: 1.9865 - val_acc: 0.5833\n",
      "Epoch 122/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9853 - acc: 0.5854 - val_loss: 1.9843 - val_acc: 0.5854\n",
      "Epoch 123/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9832 - acc: 0.5852 - val_loss: 1.9822 - val_acc: 0.5842\n",
      "Epoch 124/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9809 - acc: 0.5848 - val_loss: 1.9800 - val_acc: 0.5833\n",
      "Epoch 125/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9787 - acc: 0.5942 - val_loss: 1.9779 - val_acc: 0.5896\n",
      "Epoch 126/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9765 - acc: 0.5898 - val_loss: 1.9755 - val_acc: 0.5888\n",
      "Epoch 127/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9743 - acc: 0.5933 - val_loss: 1.9733 - val_acc: 0.5883\n",
      "Epoch 128/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9721 - acc: 0.5925 - val_loss: 1.9712 - val_acc: 0.5883\n",
      "Epoch 129/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9699 - acc: 0.5931 - val_loss: 1.9689 - val_acc: 0.5908\n",
      "Epoch 130/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9677 - acc: 0.5930 - val_loss: 1.9668 - val_acc: 0.5904\n",
      "Epoch 131/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9654 - acc: 0.5935 - val_loss: 1.9646 - val_acc: 0.5883\n",
      "Epoch 132/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9633 - acc: 0.5921 - val_loss: 1.9623 - val_acc: 0.5950\n",
      "Epoch 133/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9611 - acc: 0.5985 - val_loss: 1.9600 - val_acc: 0.5946\n",
      "Epoch 134/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9589 - acc: 0.5945 - val_loss: 1.9578 - val_acc: 0.5917\n",
      "Epoch 135/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9568 - acc: 0.5968 - val_loss: 1.9558 - val_acc: 0.5921\n",
      "Epoch 136/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9547 - acc: 0.5946 - val_loss: 1.9538 - val_acc: 0.5946\n",
      "Epoch 137/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9525 - acc: 0.5951 - val_loss: 1.9515 - val_acc: 0.5937\n",
      "Epoch 138/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9503 - acc: 0.5984 - val_loss: 1.9492 - val_acc: 0.5975\n",
      "Epoch 139/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9483 - acc: 0.5994 - val_loss: 1.9472 - val_acc: 0.5942\n",
      "Epoch 140/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9461 - acc: 0.5986 - val_loss: 1.9452 - val_acc: 0.5937\n",
      "Epoch 141/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9440 - acc: 0.5981 - val_loss: 1.9431 - val_acc: 0.5958\n",
      "Epoch 142/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9419 - acc: 0.5952 - val_loss: 1.9408 - val_acc: 0.6012\n",
      "Epoch 143/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9397 - acc: 0.5996 - val_loss: 1.9390 - val_acc: 0.5971\n",
      "Epoch 144/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9376 - acc: 0.6007 - val_loss: 1.9367 - val_acc: 0.5983\n",
      "Epoch 145/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9355 - acc: 0.6008 - val_loss: 1.9343 - val_acc: 0.6008\n",
      "Epoch 146/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9334 - acc: 0.6061 - val_loss: 1.9326 - val_acc: 0.6013\n",
      "Epoch 147/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9313 - acc: 0.6012 - val_loss: 1.9303 - val_acc: 0.6021\n",
      "Epoch 148/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9292 - acc: 0.6036 - val_loss: 1.9283 - val_acc: 0.6008\n",
      "Epoch 149/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9270 - acc: 0.6036 - val_loss: 1.9261 - val_acc: 0.6042\n",
      "Epoch 150/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9250 - acc: 0.6024 - val_loss: 1.9240 - val_acc: 0.6046\n",
      "Epoch 151/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9230 - acc: 0.6008 - val_loss: 1.9218 - val_acc: 0.6037\n",
      "Epoch 152/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9208 - acc: 0.6043 - val_loss: 1.9198 - val_acc: 0.6063\n",
      "Epoch 153/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9188 - acc: 0.6041 - val_loss: 1.9178 - val_acc: 0.6083\n",
      "Epoch 154/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9167 - acc: 0.6047 - val_loss: 1.9159 - val_acc: 0.6025\n",
      "Epoch 155/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9146 - acc: 0.6061 - val_loss: 1.9136 - val_acc: 0.6075\n",
      "Epoch 156/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9126 - acc: 0.6044 - val_loss: 1.9117 - val_acc: 0.6071\n",
      "Epoch 157/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9105 - acc: 0.6081 - val_loss: 1.9096 - val_acc: 0.6075\n",
      "Epoch 158/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9085 - acc: 0.6073 - val_loss: 1.9075 - val_acc: 0.6088\n",
      "Epoch 159/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9065 - acc: 0.6073 - val_loss: 1.9054 - val_acc: 0.6071\n",
      "Epoch 160/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9044 - acc: 0.6098 - val_loss: 1.9036 - val_acc: 0.6079\n",
      "Epoch 161/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9024 - acc: 0.6109 - val_loss: 1.9013 - val_acc: 0.6104\n",
      "Epoch 162/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9003 - acc: 0.6086 - val_loss: 1.8993 - val_acc: 0.6088\n",
      "Epoch 163/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.8984 - acc: 0.6094 - val_loss: 1.8976 - val_acc: 0.6079\n",
      "Epoch 164/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.8964 - acc: 0.6086 - val_loss: 1.8956 - val_acc: 0.6092\n",
      "Epoch 165/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.8943 - acc: 0.6119 - val_loss: 1.8933 - val_acc: 0.6100\n",
      "Epoch 166/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8924 - acc: 0.6118 - val_loss: 1.8912 - val_acc: 0.6104\n",
      "Epoch 167/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.8904 - acc: 0.6124 - val_loss: 1.8894 - val_acc: 0.6121\n",
      "Epoch 168/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.8884 - acc: 0.6138 - val_loss: 1.8875 - val_acc: 0.6092\n",
      "Epoch 169/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.8864 - acc: 0.6109 - val_loss: 1.8856 - val_acc: 0.6104\n",
      "Epoch 170/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8843 - acc: 0.6114 - val_loss: 1.8833 - val_acc: 0.6092\n",
      "Epoch 171/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.8824 - acc: 0.6112 - val_loss: 1.8813 - val_acc: 0.6113\n",
      "Epoch 172/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.8804 - acc: 0.6142 - val_loss: 1.8796 - val_acc: 0.6108\n",
      "Epoch 173/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8785 - acc: 0.6169 - val_loss: 1.8774 - val_acc: 0.6125\n",
      "Epoch 174/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8764 - acc: 0.6142 - val_loss: 1.8756 - val_acc: 0.6104\n",
      "Epoch 175/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.8745 - acc: 0.6130 - val_loss: 1.8738 - val_acc: 0.6121\n",
      "Epoch 176/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.8726 - acc: 0.6136 - val_loss: 1.8717 - val_acc: 0.6138\n",
      "Epoch 177/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8706 - acc: 0.6168 - val_loss: 1.8698 - val_acc: 0.6142\n",
      "Epoch 178/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8687 - acc: 0.6157 - val_loss: 1.8677 - val_acc: 0.6129\n",
      "Epoch 179/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8667 - acc: 0.6159 - val_loss: 1.8658 - val_acc: 0.6137\n",
      "Epoch 180/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8648 - acc: 0.6166 - val_loss: 1.8639 - val_acc: 0.6138\n",
      "Epoch 181/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8628 - acc: 0.6182 - val_loss: 1.8619 - val_acc: 0.6125\n",
      "Epoch 182/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8609 - acc: 0.6192 - val_loss: 1.8601 - val_acc: 0.6167\n",
      "Epoch 183/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8590 - acc: 0.6185 - val_loss: 1.8580 - val_acc: 0.6167\n",
      "Epoch 184/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8571 - acc: 0.6172 - val_loss: 1.8562 - val_acc: 0.6175\n",
      "Epoch 185/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8552 - acc: 0.6185 - val_loss: 1.8544 - val_acc: 0.6183\n",
      "Epoch 186/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8533 - acc: 0.6217 - val_loss: 1.8523 - val_acc: 0.6150\n",
      "Epoch 187/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8514 - acc: 0.6178 - val_loss: 1.8505 - val_acc: 0.6188\n",
      "Epoch 188/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8495 - acc: 0.6201 - val_loss: 1.8486 - val_acc: 0.6200\n",
      "Epoch 189/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8476 - acc: 0.6226 - val_loss: 1.8467 - val_acc: 0.6187\n",
      "Epoch 190/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8458 - acc: 0.6199 - val_loss: 1.8449 - val_acc: 0.6183\n",
      "Epoch 191/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8439 - acc: 0.6194 - val_loss: 1.8431 - val_acc: 0.6183\n",
      "Epoch 192/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.8420 - acc: 0.6225 - val_loss: 1.8411 - val_acc: 0.6200\n",
      "Epoch 193/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.8401 - acc: 0.6224 - val_loss: 1.8392 - val_acc: 0.6188\n",
      "Epoch 194/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8383 - acc: 0.6203 - val_loss: 1.8373 - val_acc: 0.6217\n",
      "Epoch 195/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8364 - acc: 0.6254 - val_loss: 1.8357 - val_acc: 0.6213\n",
      "Epoch 196/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8345 - acc: 0.6249 - val_loss: 1.8336 - val_acc: 0.6229\n",
      "Epoch 197/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8327 - acc: 0.6227 - val_loss: 1.8319 - val_acc: 0.6217\n",
      "Epoch 198/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8308 - acc: 0.6228 - val_loss: 1.8301 - val_acc: 0.6233\n",
      "Epoch 199/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8290 - acc: 0.6256 - val_loss: 1.8283 - val_acc: 0.6225\n",
      "Epoch 200/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8272 - acc: 0.6239 - val_loss: 1.8263 - val_acc: 0.6221\n",
      "Epoch 201/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8253 - acc: 0.6253 - val_loss: 1.8245 - val_acc: 0.6233\n",
      "Epoch 202/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8235 - acc: 0.6253 - val_loss: 1.8225 - val_acc: 0.6237\n",
      "Epoch 203/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8217 - acc: 0.6261 - val_loss: 1.8210 - val_acc: 0.6237\n",
      "Epoch 204/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8198 - acc: 0.6260 - val_loss: 1.8189 - val_acc: 0.6233\n",
      "Epoch 205/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8180 - acc: 0.6274 - val_loss: 1.8172 - val_acc: 0.6225\n",
      "Epoch 206/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8162 - acc: 0.6247 - val_loss: 1.8155 - val_acc: 0.6229\n",
      "Epoch 207/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.8144 - acc: 0.6282 - val_loss: 1.8136 - val_acc: 0.6250\n",
      "Epoch 208/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.8126 - acc: 0.6264 - val_loss: 1.8117 - val_acc: 0.6242\n",
      "Epoch 209/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8108 - acc: 0.6262 - val_loss: 1.8101 - val_acc: 0.6271\n",
      "Epoch 210/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8089 - acc: 0.6285 - val_loss: 1.8080 - val_acc: 0.6258\n",
      "Epoch 211/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.8071 - acc: 0.6293 - val_loss: 1.8064 - val_acc: 0.6267\n",
      "Epoch 212/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.8053 - acc: 0.6292 - val_loss: 1.8045 - val_acc: 0.6254\n",
      "Epoch 213/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.8036 - acc: 0.6306 - val_loss: 1.8027 - val_acc: 0.6288\n",
      "Epoch 214/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8018 - acc: 0.6300 - val_loss: 1.8012 - val_acc: 0.6258\n",
      "Epoch 215/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8000 - acc: 0.6323 - val_loss: 1.7994 - val_acc: 0.6287\n",
      "Epoch 216/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7982 - acc: 0.6296 - val_loss: 1.7974 - val_acc: 0.6279\n",
      "Epoch 217/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7964 - acc: 0.6290 - val_loss: 1.7958 - val_acc: 0.6275\n",
      "Epoch 218/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7947 - acc: 0.6318 - val_loss: 1.7940 - val_acc: 0.6283\n",
      "Epoch 219/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7929 - acc: 0.6320 - val_loss: 1.7922 - val_acc: 0.6288\n",
      "Epoch 220/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7912 - acc: 0.6329 - val_loss: 1.7905 - val_acc: 0.6287\n",
      "Epoch 221/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7894 - acc: 0.6314 - val_loss: 1.7886 - val_acc: 0.6292\n",
      "Epoch 222/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7877 - acc: 0.6310 - val_loss: 1.7868 - val_acc: 0.6304\n",
      "Epoch 223/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7859 - acc: 0.6347 - val_loss: 1.7854 - val_acc: 0.6317\n",
      "Epoch 224/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7842 - acc: 0.6375 - val_loss: 1.7834 - val_acc: 0.6333\n",
      "Epoch 225/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7824 - acc: 0.6316 - val_loss: 1.7816 - val_acc: 0.6313\n",
      "Epoch 226/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7806 - acc: 0.6338 - val_loss: 1.7800 - val_acc: 0.6317\n",
      "Epoch 227/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7789 - acc: 0.6342 - val_loss: 1.7782 - val_acc: 0.6321\n",
      "Epoch 228/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7772 - acc: 0.6331 - val_loss: 1.7764 - val_acc: 0.6304\n",
      "Epoch 229/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7755 - acc: 0.6354 - val_loss: 1.7748 - val_acc: 0.6279\n",
      "Epoch 230/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7738 - acc: 0.6332 - val_loss: 1.7728 - val_acc: 0.6325\n",
      "Epoch 231/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7720 - acc: 0.6350 - val_loss: 1.7713 - val_acc: 0.6321\n",
      "Epoch 232/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7704 - acc: 0.6365 - val_loss: 1.7697 - val_acc: 0.6300\n",
      "Epoch 233/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.7687 - acc: 0.6365 - val_loss: 1.7682 - val_acc: 0.6325\n",
      "Epoch 234/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7670 - acc: 0.6343 - val_loss: 1.7663 - val_acc: 0.6325\n",
      "Epoch 235/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.7653 - acc: 0.6361 - val_loss: 1.7644 - val_acc: 0.6325\n",
      "Epoch 236/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7635 - acc: 0.6358 - val_loss: 1.7628 - val_acc: 0.6354\n",
      "Epoch 237/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.7619 - acc: 0.6390 - val_loss: 1.7613 - val_acc: 0.6367\n",
      "Epoch 238/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7602 - acc: 0.6359 - val_loss: 1.7596 - val_acc: 0.6329\n",
      "Epoch 239/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.7585 - acc: 0.6386 - val_loss: 1.7580 - val_acc: 0.6317\n",
      "Epoch 240/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.7569 - acc: 0.6366 - val_loss: 1.7564 - val_acc: 0.6346\n",
      "Epoch 241/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.7553 - acc: 0.6374 - val_loss: 1.7547 - val_acc: 0.6350\n",
      "Epoch 242/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7535 - acc: 0.6375 - val_loss: 1.7530 - val_acc: 0.6350\n",
      "Epoch 243/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7519 - acc: 0.6356 - val_loss: 1.7514 - val_acc: 0.6358\n",
      "Epoch 244/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7503 - acc: 0.6382 - val_loss: 1.7496 - val_acc: 0.6354\n",
      "Epoch 245/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.7486 - acc: 0.6388 - val_loss: 1.7482 - val_acc: 0.6342\n",
      "Epoch 246/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7470 - acc: 0.6392 - val_loss: 1.7465 - val_acc: 0.6367\n",
      "Epoch 247/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.7453 - acc: 0.6396 - val_loss: 1.7448 - val_acc: 0.6350\n",
      "Epoch 248/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7437 - acc: 0.6402 - val_loss: 1.7432 - val_acc: 0.6371\n",
      "Epoch 249/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.7420 - acc: 0.6390 - val_loss: 1.7415 - val_acc: 0.6375\n",
      "Epoch 250/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7404 - acc: 0.6398 - val_loss: 1.7398 - val_acc: 0.6375\n",
      "Epoch 251/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7388 - acc: 0.6396 - val_loss: 1.7383 - val_acc: 0.6362\n",
      "Epoch 252/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7372 - acc: 0.6404 - val_loss: 1.7366 - val_acc: 0.6371\n",
      "Epoch 253/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7355 - acc: 0.6398 - val_loss: 1.7351 - val_acc: 0.6375\n",
      "Epoch 254/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7340 - acc: 0.6419 - val_loss: 1.7335 - val_acc: 0.6358\n",
      "Epoch 255/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7324 - acc: 0.6428 - val_loss: 1.7320 - val_acc: 0.6367\n",
      "Epoch 256/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.7307 - acc: 0.6404 - val_loss: 1.7303 - val_acc: 0.6375\n",
      "Epoch 257/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7292 - acc: 0.6426 - val_loss: 1.7290 - val_acc: 0.6383\n",
      "Epoch 258/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7275 - acc: 0.6418 - val_loss: 1.7272 - val_acc: 0.6383\n",
      "Epoch 259/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.7259 - acc: 0.6407 - val_loss: 1.7257 - val_acc: 0.6362\n",
      "Epoch 260/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7243 - acc: 0.6450 - val_loss: 1.7239 - val_acc: 0.6379\n",
      "Epoch 261/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.7227 - acc: 0.6439 - val_loss: 1.7224 - val_acc: 0.6392\n",
      "Epoch 262/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7212 - acc: 0.6449 - val_loss: 1.7208 - val_acc: 0.6375\n",
      "Epoch 263/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.7196 - acc: 0.6423 - val_loss: 1.7193 - val_acc: 0.6388\n",
      "Epoch 264/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7180 - acc: 0.6429 - val_loss: 1.7176 - val_acc: 0.6383\n",
      "Epoch 265/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.7165 - acc: 0.6459 - val_loss: 1.7161 - val_acc: 0.6408\n",
      "Epoch 266/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.7149 - acc: 0.6470 - val_loss: 1.7148 - val_acc: 0.6383\n",
      "Epoch 267/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7134 - acc: 0.6428 - val_loss: 1.7130 - val_acc: 0.6383\n",
      "Epoch 268/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.7118 - acc: 0.6450 - val_loss: 1.7113 - val_acc: 0.6404\n",
      "Epoch 269/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.7102 - acc: 0.6442 - val_loss: 1.7099 - val_acc: 0.6404\n",
      "Epoch 270/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.7087 - acc: 0.6431 - val_loss: 1.7083 - val_acc: 0.6404\n",
      "Epoch 271/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7072 - acc: 0.6448 - val_loss: 1.7068 - val_acc: 0.6388\n",
      "Epoch 272/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7057 - acc: 0.6448 - val_loss: 1.7055 - val_acc: 0.6396\n",
      "Epoch 273/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7041 - acc: 0.6461 - val_loss: 1.7041 - val_acc: 0.6396\n",
      "Epoch 274/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7026 - acc: 0.6464 - val_loss: 1.7024 - val_acc: 0.6417\n",
      "Epoch 275/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7011 - acc: 0.6439 - val_loss: 1.7008 - val_acc: 0.6396\n",
      "Epoch 276/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6995 - acc: 0.6464 - val_loss: 1.6994 - val_acc: 0.6412\n",
      "Epoch 277/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6980 - acc: 0.6467 - val_loss: 1.6978 - val_acc: 0.6412\n",
      "Epoch 278/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6965 - acc: 0.6472 - val_loss: 1.6964 - val_acc: 0.6417\n",
      "Epoch 279/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6951 - acc: 0.6474 - val_loss: 1.6950 - val_acc: 0.6450\n",
      "Epoch 280/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6935 - acc: 0.6478 - val_loss: 1.6934 - val_acc: 0.6417\n",
      "Epoch 281/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6920 - acc: 0.6457 - val_loss: 1.6919 - val_acc: 0.6425\n",
      "Epoch 282/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6905 - acc: 0.6472 - val_loss: 1.6903 - val_acc: 0.6425\n",
      "Epoch 283/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6891 - acc: 0.6481 - val_loss: 1.6890 - val_acc: 0.6467\n",
      "Epoch 284/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6875 - acc: 0.6473 - val_loss: 1.6873 - val_acc: 0.6425\n",
      "Epoch 285/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6861 - acc: 0.6482 - val_loss: 1.6858 - val_acc: 0.6442\n",
      "Epoch 286/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6846 - acc: 0.6473 - val_loss: 1.6844 - val_acc: 0.6454\n",
      "Epoch 287/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6831 - acc: 0.6473 - val_loss: 1.6830 - val_acc: 0.6446\n",
      "Epoch 288/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.6816 - acc: 0.6474 - val_loss: 1.6817 - val_acc: 0.6462\n",
      "Epoch 289/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6802 - acc: 0.6489 - val_loss: 1.6802 - val_acc: 0.6458\n",
      "Epoch 290/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6787 - acc: 0.6480 - val_loss: 1.6786 - val_acc: 0.6442\n",
      "Epoch 291/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6773 - acc: 0.6480 - val_loss: 1.6772 - val_acc: 0.6471\n",
      "Epoch 292/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.6758 - acc: 0.6489 - val_loss: 1.6759 - val_acc: 0.6475\n",
      "Epoch 293/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.6743 - acc: 0.6501 - val_loss: 1.6743 - val_acc: 0.6433\n",
      "Epoch 294/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6729 - acc: 0.6484 - val_loss: 1.6729 - val_acc: 0.6458\n",
      "Epoch 295/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6714 - acc: 0.6503 - val_loss: 1.6714 - val_acc: 0.6475\n",
      "Epoch 296/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6701 - acc: 0.6499 - val_loss: 1.6700 - val_acc: 0.6442\n",
      "Epoch 297/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6686 - acc: 0.6494 - val_loss: 1.6687 - val_acc: 0.6475\n",
      "Epoch 298/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6671 - acc: 0.6497 - val_loss: 1.6672 - val_acc: 0.6471\n",
      "Epoch 299/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.6657 - acc: 0.6490 - val_loss: 1.6657 - val_acc: 0.6479\n",
      "Epoch 300/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6642 - acc: 0.6502 - val_loss: 1.6644 - val_acc: 0.6488\n",
      "Epoch 301/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6628 - acc: 0.6514 - val_loss: 1.6628 - val_acc: 0.6504\n",
      "Epoch 302/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6613 - acc: 0.6506 - val_loss: 1.6613 - val_acc: 0.6504\n",
      "Epoch 303/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6600 - acc: 0.6505 - val_loss: 1.6600 - val_acc: 0.6488\n",
      "Epoch 304/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6586 - acc: 0.6510 - val_loss: 1.6586 - val_acc: 0.6496\n",
      "Epoch 305/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6571 - acc: 0.6515 - val_loss: 1.6571 - val_acc: 0.6508\n",
      "Epoch 306/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6557 - acc: 0.6517 - val_loss: 1.6558 - val_acc: 0.6508\n",
      "Epoch 307/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6543 - acc: 0.6517 - val_loss: 1.6545 - val_acc: 0.6517\n",
      "Epoch 308/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6529 - acc: 0.6509 - val_loss: 1.6529 - val_acc: 0.6500\n",
      "Epoch 309/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6515 - acc: 0.6518 - val_loss: 1.6516 - val_acc: 0.6513\n",
      "Epoch 310/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6500 - acc: 0.6530 - val_loss: 1.6502 - val_acc: 0.6529\n",
      "Epoch 311/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6487 - acc: 0.6514 - val_loss: 1.6489 - val_acc: 0.6537\n",
      "Epoch 312/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6473 - acc: 0.6534 - val_loss: 1.6475 - val_acc: 0.6525\n",
      "Epoch 313/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6459 - acc: 0.6534 - val_loss: 1.6463 - val_acc: 0.6517\n",
      "Epoch 314/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6445 - acc: 0.6520 - val_loss: 1.6448 - val_acc: 0.6533\n",
      "Epoch 315/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.6432 - acc: 0.6534 - val_loss: 1.6438 - val_acc: 0.6525\n",
      "Epoch 316/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6417 - acc: 0.6545 - val_loss: 1.6422 - val_acc: 0.6529\n",
      "Epoch 317/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6404 - acc: 0.6531 - val_loss: 1.6407 - val_acc: 0.6533\n",
      "Epoch 318/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6390 - acc: 0.6535 - val_loss: 1.6394 - val_acc: 0.6542\n",
      "Epoch 319/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6376 - acc: 0.6534 - val_loss: 1.6380 - val_acc: 0.6533\n",
      "Epoch 320/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6362 - acc: 0.6543 - val_loss: 1.6366 - val_acc: 0.6537\n",
      "Epoch 321/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6349 - acc: 0.6532 - val_loss: 1.6352 - val_acc: 0.6554\n",
      "Epoch 322/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6334 - acc: 0.6550 - val_loss: 1.6339 - val_acc: 0.6562\n",
      "Epoch 323/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6321 - acc: 0.6532 - val_loss: 1.6326 - val_acc: 0.6575\n",
      "Epoch 324/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6307 - acc: 0.6549 - val_loss: 1.6311 - val_acc: 0.6562\n",
      "Epoch 325/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6294 - acc: 0.6547 - val_loss: 1.6297 - val_acc: 0.6567\n",
      "Epoch 326/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6280 - acc: 0.6541 - val_loss: 1.6285 - val_acc: 0.6562\n",
      "Epoch 327/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6266 - acc: 0.6550 - val_loss: 1.6272 - val_acc: 0.6550\n",
      "Epoch 328/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6253 - acc: 0.6553 - val_loss: 1.6258 - val_acc: 0.6554\n",
      "Epoch 329/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6239 - acc: 0.6546 - val_loss: 1.6244 - val_acc: 0.6571\n",
      "Epoch 330/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6226 - acc: 0.6540 - val_loss: 1.6230 - val_acc: 0.6587\n",
      "Epoch 331/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6213 - acc: 0.6561 - val_loss: 1.6219 - val_acc: 0.6567\n",
      "Epoch 332/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6200 - acc: 0.6575 - val_loss: 1.6206 - val_acc: 0.6567\n",
      "Epoch 333/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6187 - acc: 0.6559 - val_loss: 1.6191 - val_acc: 0.6579\n",
      "Epoch 334/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6173 - acc: 0.6552 - val_loss: 1.6178 - val_acc: 0.6575\n",
      "Epoch 335/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6160 - acc: 0.6570 - val_loss: 1.6165 - val_acc: 0.6571\n",
      "Epoch 336/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6148 - acc: 0.6562 - val_loss: 1.6153 - val_acc: 0.6587\n",
      "Epoch 337/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6133 - acc: 0.6570 - val_loss: 1.6138 - val_acc: 0.6608\n",
      "Epoch 338/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6120 - acc: 0.6560 - val_loss: 1.6126 - val_acc: 0.6587\n",
      "Epoch 339/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6108 - acc: 0.6555 - val_loss: 1.6114 - val_acc: 0.6583\n",
      "Epoch 340/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6094 - acc: 0.6575 - val_loss: 1.6101 - val_acc: 0.6583\n",
      "Epoch 341/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6080 - acc: 0.6572 - val_loss: 1.6087 - val_acc: 0.6575\n",
      "Epoch 342/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6068 - acc: 0.6573 - val_loss: 1.6075 - val_acc: 0.6583\n",
      "Epoch 343/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.6055 - acc: 0.6575 - val_loss: 1.6061 - val_acc: 0.6583\n",
      "Epoch 344/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6042 - acc: 0.6579 - val_loss: 1.6048 - val_acc: 0.6604\n",
      "Epoch 345/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6029 - acc: 0.6582 - val_loss: 1.6037 - val_acc: 0.6604\n",
      "Epoch 346/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6016 - acc: 0.6582 - val_loss: 1.6023 - val_acc: 0.6587\n",
      "Epoch 347/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.6003 - acc: 0.6583 - val_loss: 1.6010 - val_acc: 0.6613\n",
      "Epoch 348/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.5990 - acc: 0.6593 - val_loss: 1.5998 - val_acc: 0.6600\n",
      "Epoch 349/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5977 - acc: 0.6578 - val_loss: 1.5985 - val_acc: 0.6596\n",
      "Epoch 350/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5964 - acc: 0.6586 - val_loss: 1.5973 - val_acc: 0.6592\n",
      "Epoch 351/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5952 - acc: 0.6595 - val_loss: 1.5958 - val_acc: 0.6600\n",
      "Epoch 352/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5940 - acc: 0.6581 - val_loss: 1.5948 - val_acc: 0.6596\n",
      "Epoch 353/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5927 - acc: 0.6582 - val_loss: 1.5932 - val_acc: 0.6621\n",
      "Epoch 354/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5913 - acc: 0.6581 - val_loss: 1.5922 - val_acc: 0.6600\n",
      "Epoch 355/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5901 - acc: 0.6589 - val_loss: 1.5910 - val_acc: 0.6596\n",
      "Epoch 356/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5889 - acc: 0.6591 - val_loss: 1.5899 - val_acc: 0.6604\n",
      "Epoch 357/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5876 - acc: 0.6579 - val_loss: 1.5884 - val_acc: 0.6608\n",
      "Epoch 358/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5863 - acc: 0.6599 - val_loss: 1.5871 - val_acc: 0.6617\n",
      "Epoch 359/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.5851 - acc: 0.6600 - val_loss: 1.5859 - val_acc: 0.6587\n",
      "Epoch 360/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5838 - acc: 0.6594 - val_loss: 1.5848 - val_acc: 0.6604\n",
      "Epoch 361/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5825 - acc: 0.6602 - val_loss: 1.5836 - val_acc: 0.6608\n",
      "Epoch 362/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5814 - acc: 0.6591 - val_loss: 1.5824 - val_acc: 0.6600\n",
      "Epoch 363/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.5801 - acc: 0.6595 - val_loss: 1.5811 - val_acc: 0.6629\n",
      "Epoch 364/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5789 - acc: 0.6601 - val_loss: 1.5799 - val_acc: 0.6617\n",
      "Epoch 365/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5778 - acc: 0.6595 - val_loss: 1.5786 - val_acc: 0.6608\n",
      "Epoch 366/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5764 - acc: 0.6593 - val_loss: 1.5775 - val_acc: 0.6617\n",
      "Epoch 367/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5752 - acc: 0.6614 - val_loss: 1.5761 - val_acc: 0.6617\n",
      "Epoch 368/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.5739 - acc: 0.6605 - val_loss: 1.5751 - val_acc: 0.6625\n",
      "Epoch 369/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5728 - acc: 0.6620 - val_loss: 1.5739 - val_acc: 0.6604\n",
      "Epoch 370/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5716 - acc: 0.6596 - val_loss: 1.5725 - val_acc: 0.6633\n",
      "Epoch 371/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5704 - acc: 0.6614 - val_loss: 1.5715 - val_acc: 0.6625\n",
      "Epoch 372/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5691 - acc: 0.6611 - val_loss: 1.5703 - val_acc: 0.6629\n",
      "Epoch 373/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5679 - acc: 0.6615 - val_loss: 1.5691 - val_acc: 0.6629\n",
      "Epoch 374/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5667 - acc: 0.6611 - val_loss: 1.5680 - val_acc: 0.6617\n",
      "Epoch 375/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5655 - acc: 0.6622 - val_loss: 1.5667 - val_acc: 0.6625\n",
      "Epoch 376/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5643 - acc: 0.6618 - val_loss: 1.5653 - val_acc: 0.6633\n",
      "Epoch 377/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5631 - acc: 0.6615 - val_loss: 1.5644 - val_acc: 0.6613\n",
      "Epoch 378/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5619 - acc: 0.6608 - val_loss: 1.5630 - val_acc: 0.6637\n",
      "Epoch 379/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.5607 - acc: 0.6619 - val_loss: 1.5620 - val_acc: 0.6621\n",
      "Epoch 380/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5596 - acc: 0.6630 - val_loss: 1.5607 - val_acc: 0.6613\n",
      "Epoch 381/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5584 - acc: 0.6614 - val_loss: 1.5596 - val_acc: 0.6621\n",
      "Epoch 382/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.5572 - acc: 0.6628 - val_loss: 1.5584 - val_acc: 0.6629\n",
      "Epoch 383/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.5560 - acc: 0.6623 - val_loss: 1.5573 - val_acc: 0.6633\n",
      "Epoch 384/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5549 - acc: 0.6616 - val_loss: 1.5561 - val_acc: 0.6633\n",
      "Epoch 385/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5536 - acc: 0.6609 - val_loss: 1.5549 - val_acc: 0.6629\n",
      "Epoch 386/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.5524 - acc: 0.6619 - val_loss: 1.5539 - val_acc: 0.6608\n",
      "Epoch 387/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5513 - acc: 0.6627 - val_loss: 1.5528 - val_acc: 0.6625\n",
      "Epoch 388/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5502 - acc: 0.6622 - val_loss: 1.5515 - val_acc: 0.6621\n",
      "Epoch 389/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5490 - acc: 0.6604 - val_loss: 1.5504 - val_acc: 0.6617\n",
      "Epoch 390/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5478 - acc: 0.6631 - val_loss: 1.5492 - val_acc: 0.6633\n",
      "Epoch 391/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5467 - acc: 0.6630 - val_loss: 1.5480 - val_acc: 0.6604\n",
      "Epoch 392/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5455 - acc: 0.6630 - val_loss: 1.5470 - val_acc: 0.6629\n",
      "Epoch 393/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5444 - acc: 0.6637 - val_loss: 1.5459 - val_acc: 0.6625\n",
      "Epoch 394/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5433 - acc: 0.6619 - val_loss: 1.5448 - val_acc: 0.6617\n",
      "Epoch 395/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5421 - acc: 0.6652 - val_loss: 1.5436 - val_acc: 0.6613\n",
      "Epoch 396/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5410 - acc: 0.6634 - val_loss: 1.5424 - val_acc: 0.6637\n",
      "Epoch 397/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5398 - acc: 0.6644 - val_loss: 1.5413 - val_acc: 0.6633\n",
      "Epoch 398/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5387 - acc: 0.6636 - val_loss: 1.5403 - val_acc: 0.6617\n",
      "Epoch 399/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5376 - acc: 0.6642 - val_loss: 1.5392 - val_acc: 0.6617\n",
      "Epoch 400/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5364 - acc: 0.6649 - val_loss: 1.5381 - val_acc: 0.6613\n",
      "Epoch 401/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.5353 - acc: 0.6650 - val_loss: 1.5370 - val_acc: 0.6629\n",
      "Epoch 402/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5342 - acc: 0.6642 - val_loss: 1.5358 - val_acc: 0.6625\n",
      "Epoch 403/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5330 - acc: 0.6651 - val_loss: 1.5348 - val_acc: 0.6612\n",
      "Epoch 404/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5319 - acc: 0.6646 - val_loss: 1.5336 - val_acc: 0.6617\n",
      "Epoch 405/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5308 - acc: 0.6649 - val_loss: 1.5323 - val_acc: 0.6625\n",
      "Epoch 406/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5297 - acc: 0.6650 - val_loss: 1.5315 - val_acc: 0.6629\n",
      "Epoch 407/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5286 - acc: 0.6649 - val_loss: 1.5304 - val_acc: 0.6617\n",
      "Epoch 408/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5275 - acc: 0.6652 - val_loss: 1.5293 - val_acc: 0.6612\n",
      "Epoch 409/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5264 - acc: 0.6654 - val_loss: 1.5282 - val_acc: 0.6625\n",
      "Epoch 410/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5253 - acc: 0.6658 - val_loss: 1.5272 - val_acc: 0.6612\n",
      "Epoch 411/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5242 - acc: 0.6645 - val_loss: 1.5260 - val_acc: 0.6617\n",
      "Epoch 412/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5231 - acc: 0.6652 - val_loss: 1.5250 - val_acc: 0.6617\n",
      "Epoch 413/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5220 - acc: 0.6663 - val_loss: 1.5241 - val_acc: 0.6621\n",
      "Epoch 414/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5209 - acc: 0.6651 - val_loss: 1.5228 - val_acc: 0.6625\n",
      "Epoch 415/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.5199 - acc: 0.6658 - val_loss: 1.5217 - val_acc: 0.6621\n",
      "Epoch 416/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5187 - acc: 0.6664 - val_loss: 1.5207 - val_acc: 0.6621\n",
      "Epoch 417/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5177 - acc: 0.6664 - val_loss: 1.5195 - val_acc: 0.6621\n",
      "Epoch 418/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.5166 - acc: 0.6644 - val_loss: 1.5184 - val_acc: 0.6646\n",
      "Epoch 419/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5155 - acc: 0.6664 - val_loss: 1.5175 - val_acc: 0.6625\n",
      "Epoch 420/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5144 - acc: 0.6664 - val_loss: 1.5163 - val_acc: 0.6617\n",
      "Epoch 421/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5133 - acc: 0.6649 - val_loss: 1.5155 - val_acc: 0.6617\n",
      "Epoch 422/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.5123 - acc: 0.6656 - val_loss: 1.5142 - val_acc: 0.6629\n",
      "Epoch 423/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.5112 - acc: 0.6677 - val_loss: 1.5132 - val_acc: 0.6621\n",
      "Epoch 424/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.5101 - acc: 0.6658 - val_loss: 1.5122 - val_acc: 0.6629\n",
      "Epoch 425/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5091 - acc: 0.6663 - val_loss: 1.5110 - val_acc: 0.6625\n",
      "Epoch 426/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.5080 - acc: 0.6674 - val_loss: 1.5102 - val_acc: 0.6650\n",
      "Epoch 427/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5069 - acc: 0.6650 - val_loss: 1.5090 - val_acc: 0.6637\n",
      "Epoch 428/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.5059 - acc: 0.6669 - val_loss: 1.5080 - val_acc: 0.6625\n",
      "Epoch 429/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5049 - acc: 0.6668 - val_loss: 1.5070 - val_acc: 0.6642\n",
      "Epoch 430/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5038 - acc: 0.6657 - val_loss: 1.5059 - val_acc: 0.6629\n",
      "Epoch 431/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5028 - acc: 0.6665 - val_loss: 1.5050 - val_acc: 0.6612\n",
      "Epoch 432/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5017 - acc: 0.6680 - val_loss: 1.5041 - val_acc: 0.6633\n",
      "Epoch 433/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5007 - acc: 0.6671 - val_loss: 1.5026 - val_acc: 0.6650\n",
      "Epoch 434/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.4997 - acc: 0.6674 - val_loss: 1.5019 - val_acc: 0.6633\n",
      "Epoch 435/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4986 - acc: 0.6672 - val_loss: 1.5008 - val_acc: 0.6637\n",
      "Epoch 436/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4976 - acc: 0.6691 - val_loss: 1.5000 - val_acc: 0.6654\n",
      "Epoch 437/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.4966 - acc: 0.6675 - val_loss: 1.4988 - val_acc: 0.6662\n",
      "Epoch 438/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.4955 - acc: 0.6677 - val_loss: 1.4979 - val_acc: 0.6642\n",
      "Epoch 439/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.4945 - acc: 0.6669 - val_loss: 1.4970 - val_acc: 0.6642\n",
      "Epoch 440/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.4936 - acc: 0.6681 - val_loss: 1.4957 - val_acc: 0.6646\n",
      "Epoch 441/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.4925 - acc: 0.6674 - val_loss: 1.4950 - val_acc: 0.6654\n",
      "Epoch 442/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.4915 - acc: 0.6684 - val_loss: 1.4939 - val_acc: 0.6629\n",
      "Epoch 443/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4905 - acc: 0.6692 - val_loss: 1.4931 - val_acc: 0.6637\n",
      "Epoch 444/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4895 - acc: 0.6694 - val_loss: 1.4919 - val_acc: 0.6662\n",
      "Epoch 445/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.4885 - acc: 0.6676 - val_loss: 1.4909 - val_acc: 0.6642\n",
      "Epoch 446/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4875 - acc: 0.6677 - val_loss: 1.4899 - val_acc: 0.6658\n",
      "Epoch 447/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4864 - acc: 0.6680 - val_loss: 1.4890 - val_acc: 0.6679\n",
      "Epoch 448/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.4855 - acc: 0.6683 - val_loss: 1.4880 - val_acc: 0.6658\n",
      "Epoch 449/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.4845 - acc: 0.6691 - val_loss: 1.4871 - val_acc: 0.6667\n",
      "Epoch 450/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4835 - acc: 0.6696 - val_loss: 1.4861 - val_acc: 0.6662\n",
      "Epoch 451/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4824 - acc: 0.6688 - val_loss: 1.4852 - val_acc: 0.6654\n",
      "Epoch 452/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4815 - acc: 0.6675 - val_loss: 1.4840 - val_acc: 0.6650\n",
      "Epoch 453/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4805 - acc: 0.6707 - val_loss: 1.4833 - val_acc: 0.6650\n",
      "Epoch 454/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4794 - acc: 0.6698 - val_loss: 1.4821 - val_acc: 0.6654\n",
      "Epoch 455/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4785 - acc: 0.6681 - val_loss: 1.4812 - val_acc: 0.6662\n",
      "Epoch 456/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4775 - acc: 0.6695 - val_loss: 1.4802 - val_acc: 0.6650\n",
      "Epoch 457/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4765 - acc: 0.6684 - val_loss: 1.4792 - val_acc: 0.6671\n",
      "Epoch 458/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4755 - acc: 0.6701 - val_loss: 1.4784 - val_acc: 0.6667\n",
      "Epoch 459/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4746 - acc: 0.6703 - val_loss: 1.4774 - val_acc: 0.6662\n",
      "Epoch 460/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4736 - acc: 0.6697 - val_loss: 1.4764 - val_acc: 0.6675\n",
      "Epoch 461/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4726 - acc: 0.6699 - val_loss: 1.4753 - val_acc: 0.6679\n",
      "Epoch 462/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.4717 - acc: 0.6705 - val_loss: 1.4743 - val_acc: 0.6658\n",
      "Epoch 463/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4707 - acc: 0.6701 - val_loss: 1.4734 - val_acc: 0.6683\n",
      "Epoch 464/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4697 - acc: 0.6697 - val_loss: 1.4726 - val_acc: 0.6683\n",
      "Epoch 465/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4687 - acc: 0.6710 - val_loss: 1.4716 - val_acc: 0.6675\n",
      "Epoch 466/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4678 - acc: 0.6708 - val_loss: 1.4707 - val_acc: 0.6671\n",
      "Epoch 467/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.4668 - acc: 0.6701 - val_loss: 1.4696 - val_acc: 0.6675\n",
      "Epoch 468/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.4658 - acc: 0.6724 - val_loss: 1.4688 - val_acc: 0.6687\n",
      "Epoch 469/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4649 - acc: 0.6701 - val_loss: 1.4677 - val_acc: 0.6683\n",
      "Epoch 470/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4639 - acc: 0.6722 - val_loss: 1.4669 - val_acc: 0.6683\n",
      "Epoch 471/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4630 - acc: 0.6715 - val_loss: 1.4660 - val_acc: 0.6683\n",
      "Epoch 472/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4620 - acc: 0.6721 - val_loss: 1.4651 - val_acc: 0.6667\n",
      "Epoch 473/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4611 - acc: 0.6716 - val_loss: 1.4642 - val_acc: 0.6679\n",
      "Epoch 474/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4601 - acc: 0.6701 - val_loss: 1.4632 - val_acc: 0.6687\n",
      "Epoch 475/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4592 - acc: 0.6708 - val_loss: 1.4623 - val_acc: 0.6675\n",
      "Epoch 476/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4583 - acc: 0.6732 - val_loss: 1.4615 - val_acc: 0.6671\n",
      "Epoch 477/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4573 - acc: 0.6722 - val_loss: 1.4604 - val_acc: 0.6671\n",
      "Epoch 478/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4564 - acc: 0.6720 - val_loss: 1.4595 - val_acc: 0.6679\n",
      "Epoch 479/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4555 - acc: 0.6726 - val_loss: 1.4586 - val_acc: 0.6671\n",
      "Epoch 480/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4545 - acc: 0.6718 - val_loss: 1.4576 - val_acc: 0.6679\n",
      "Epoch 481/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4537 - acc: 0.6726 - val_loss: 1.4568 - val_acc: 0.6687\n",
      "Epoch 482/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4527 - acc: 0.6717 - val_loss: 1.4557 - val_acc: 0.6683\n",
      "Epoch 483/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4517 - acc: 0.6724 - val_loss: 1.4550 - val_acc: 0.6696\n",
      "Epoch 484/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4508 - acc: 0.6723 - val_loss: 1.4539 - val_acc: 0.6683\n",
      "Epoch 485/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4499 - acc: 0.6729 - val_loss: 1.4531 - val_acc: 0.6700\n",
      "Epoch 486/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4489 - acc: 0.6719 - val_loss: 1.4521 - val_acc: 0.6708\n",
      "Epoch 487/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4480 - acc: 0.6728 - val_loss: 1.4514 - val_acc: 0.6696\n",
      "Epoch 488/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4471 - acc: 0.6727 - val_loss: 1.4506 - val_acc: 0.6687\n",
      "Epoch 489/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4462 - acc: 0.6726 - val_loss: 1.4495 - val_acc: 0.6700\n",
      "Epoch 490/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.4454 - acc: 0.6749 - val_loss: 1.4486 - val_acc: 0.6683\n",
      "Epoch 491/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.4444 - acc: 0.6730 - val_loss: 1.4477 - val_acc: 0.6679\n",
      "Epoch 492/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4435 - acc: 0.6731 - val_loss: 1.4470 - val_acc: 0.6696\n",
      "Epoch 493/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4425 - acc: 0.6728 - val_loss: 1.4460 - val_acc: 0.6704\n",
      "Epoch 494/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4417 - acc: 0.6742 - val_loss: 1.4451 - val_acc: 0.6700\n",
      "Epoch 495/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4408 - acc: 0.6728 - val_loss: 1.4441 - val_acc: 0.6696\n",
      "Epoch 496/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4399 - acc: 0.6732 - val_loss: 1.4434 - val_acc: 0.6696\n",
      "Epoch 497/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4390 - acc: 0.6739 - val_loss: 1.4425 - val_acc: 0.6692\n",
      "Epoch 498/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.4381 - acc: 0.6746 - val_loss: 1.4416 - val_acc: 0.6687\n",
      "Epoch 499/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.4372 - acc: 0.6743 - val_loss: 1.4409 - val_acc: 0.6675\n",
      "Epoch 500/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4363 - acc: 0.6739 - val_loss: 1.4400 - val_acc: 0.6683\n",
      "Epoch 501/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4354 - acc: 0.6742 - val_loss: 1.4390 - val_acc: 0.6687\n",
      "Epoch 502/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4345 - acc: 0.6745 - val_loss: 1.4381 - val_acc: 0.6696\n",
      "Epoch 503/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.4335 - acc: 0.6745 - val_loss: 1.4373 - val_acc: 0.6700\n",
      "Epoch 504/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4327 - acc: 0.6748 - val_loss: 1.4364 - val_acc: 0.6704\n",
      "Epoch 505/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4318 - acc: 0.6750 - val_loss: 1.4355 - val_acc: 0.6700\n",
      "Epoch 506/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.4310 - acc: 0.6739 - val_loss: 1.4346 - val_acc: 0.6687\n",
      "Epoch 507/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4301 - acc: 0.6742 - val_loss: 1.4338 - val_acc: 0.6696\n",
      "Epoch 508/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4292 - acc: 0.6744 - val_loss: 1.4329 - val_acc: 0.6687\n",
      "Epoch 509/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4283 - acc: 0.6753 - val_loss: 1.4322 - val_acc: 0.6708\n",
      "Epoch 510/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4274 - acc: 0.6748 - val_loss: 1.4312 - val_acc: 0.6696\n",
      "Epoch 511/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.4265 - acc: 0.6753 - val_loss: 1.4304 - val_acc: 0.6700\n",
      "Epoch 512/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4257 - acc: 0.6761 - val_loss: 1.4296 - val_acc: 0.6700\n",
      "Epoch 513/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.4249 - acc: 0.6759 - val_loss: 1.4286 - val_acc: 0.6692\n",
      "Epoch 514/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.4239 - acc: 0.6764 - val_loss: 1.4279 - val_acc: 0.6692\n",
      "Epoch 515/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4231 - acc: 0.6750 - val_loss: 1.4270 - val_acc: 0.6696\n",
      "Epoch 516/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4223 - acc: 0.6760 - val_loss: 1.4261 - val_acc: 0.6704\n",
      "Epoch 517/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4213 - acc: 0.6752 - val_loss: 1.4253 - val_acc: 0.6704\n",
      "Epoch 518/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4206 - acc: 0.6758 - val_loss: 1.4246 - val_acc: 0.6708\n",
      "Epoch 519/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4196 - acc: 0.6771 - val_loss: 1.4238 - val_acc: 0.6704\n",
      "Epoch 520/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4188 - acc: 0.6754 - val_loss: 1.4227 - val_acc: 0.6700\n",
      "Epoch 521/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4179 - acc: 0.6764 - val_loss: 1.4220 - val_acc: 0.6708\n",
      "Epoch 522/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4172 - acc: 0.6752 - val_loss: 1.4212 - val_acc: 0.6708\n",
      "Epoch 523/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4163 - acc: 0.6761 - val_loss: 1.4203 - val_acc: 0.6717\n",
      "Epoch 524/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4154 - acc: 0.6769 - val_loss: 1.4194 - val_acc: 0.6704\n",
      "Epoch 525/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4145 - acc: 0.6766 - val_loss: 1.4189 - val_acc: 0.6696\n",
      "Epoch 526/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4137 - acc: 0.6769 - val_loss: 1.4178 - val_acc: 0.6700\n",
      "Epoch 527/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4129 - acc: 0.6755 - val_loss: 1.4170 - val_acc: 0.6708\n",
      "Epoch 528/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4120 - acc: 0.6763 - val_loss: 1.4162 - val_acc: 0.6713\n",
      "Epoch 529/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4112 - acc: 0.6770 - val_loss: 1.4154 - val_acc: 0.6708\n",
      "Epoch 530/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4104 - acc: 0.6777 - val_loss: 1.4146 - val_acc: 0.6713\n",
      "Epoch 531/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.4095 - acc: 0.6763 - val_loss: 1.4136 - val_acc: 0.6708\n",
      "Epoch 532/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4087 - acc: 0.6768 - val_loss: 1.4129 - val_acc: 0.6721\n",
      "Epoch 533/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4078 - acc: 0.6766 - val_loss: 1.4120 - val_acc: 0.6704\n",
      "Epoch 534/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4070 - acc: 0.6778 - val_loss: 1.4113 - val_acc: 0.6713\n",
      "Epoch 535/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4062 - acc: 0.6769 - val_loss: 1.4105 - val_acc: 0.6721\n",
      "Epoch 536/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4054 - acc: 0.6768 - val_loss: 1.4097 - val_acc: 0.6717\n",
      "Epoch 537/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4045 - acc: 0.6768 - val_loss: 1.4090 - val_acc: 0.6713\n",
      "Epoch 538/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4037 - acc: 0.6782 - val_loss: 1.4081 - val_acc: 0.6725\n",
      "Epoch 539/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4029 - acc: 0.6774 - val_loss: 1.4076 - val_acc: 0.6700\n",
      "Epoch 540/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4021 - acc: 0.6777 - val_loss: 1.4066 - val_acc: 0.6725\n",
      "Epoch 541/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4013 - acc: 0.6794 - val_loss: 1.4058 - val_acc: 0.6729\n",
      "Epoch 542/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4004 - acc: 0.6789 - val_loss: 1.4051 - val_acc: 0.6725\n",
      "Epoch 543/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3996 - acc: 0.6777 - val_loss: 1.4041 - val_acc: 0.6725\n",
      "Epoch 544/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3989 - acc: 0.6785 - val_loss: 1.4033 - val_acc: 0.6713\n",
      "Epoch 545/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3981 - acc: 0.6792 - val_loss: 1.4026 - val_acc: 0.6721\n",
      "Epoch 546/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3973 - acc: 0.6787 - val_loss: 1.4018 - val_acc: 0.6733\n",
      "Epoch 547/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3964 - acc: 0.6776 - val_loss: 1.4011 - val_acc: 0.6721\n",
      "Epoch 548/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3956 - acc: 0.6790 - val_loss: 1.4004 - val_acc: 0.6737\n",
      "Epoch 549/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3949 - acc: 0.6783 - val_loss: 1.3995 - val_acc: 0.6733\n",
      "Epoch 550/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3940 - acc: 0.6796 - val_loss: 1.3988 - val_acc: 0.6721\n",
      "Epoch 551/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3932 - acc: 0.6786 - val_loss: 1.3979 - val_acc: 0.6733\n",
      "Epoch 552/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3924 - acc: 0.6777 - val_loss: 1.3971 - val_acc: 0.6717\n",
      "Epoch 553/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3916 - acc: 0.6784 - val_loss: 1.3963 - val_acc: 0.6725\n",
      "Epoch 554/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3908 - acc: 0.6784 - val_loss: 1.3955 - val_acc: 0.6729\n",
      "Epoch 555/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3901 - acc: 0.6798 - val_loss: 1.3949 - val_acc: 0.6733\n",
      "Epoch 556/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3893 - acc: 0.6786 - val_loss: 1.3939 - val_acc: 0.6729\n",
      "Epoch 557/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3884 - acc: 0.6784 - val_loss: 1.3933 - val_acc: 0.6733\n",
      "Epoch 558/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3878 - acc: 0.6778 - val_loss: 1.3927 - val_acc: 0.6737\n",
      "Epoch 559/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3868 - acc: 0.6799 - val_loss: 1.3917 - val_acc: 0.6737\n",
      "Epoch 560/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3861 - acc: 0.6791 - val_loss: 1.3910 - val_acc: 0.6750\n",
      "Epoch 561/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3853 - acc: 0.6795 - val_loss: 1.3902 - val_acc: 0.6738\n",
      "Epoch 562/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3846 - acc: 0.6795 - val_loss: 1.3893 - val_acc: 0.6742\n",
      "Epoch 563/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3838 - acc: 0.6802 - val_loss: 1.3886 - val_acc: 0.6746\n",
      "Epoch 564/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3830 - acc: 0.6798 - val_loss: 1.3881 - val_acc: 0.6742\n",
      "Epoch 565/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3822 - acc: 0.6794 - val_loss: 1.3870 - val_acc: 0.6737\n",
      "Epoch 566/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3815 - acc: 0.6796 - val_loss: 1.3864 - val_acc: 0.6746\n",
      "Epoch 567/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3807 - acc: 0.6805 - val_loss: 1.3857 - val_acc: 0.6725\n",
      "Epoch 568/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3799 - acc: 0.6800 - val_loss: 1.3850 - val_acc: 0.6746\n",
      "Epoch 569/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3791 - acc: 0.6789 - val_loss: 1.3842 - val_acc: 0.6742\n",
      "Epoch 570/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3784 - acc: 0.6800 - val_loss: 1.3834 - val_acc: 0.6754\n",
      "Epoch 571/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3776 - acc: 0.6803 - val_loss: 1.3828 - val_acc: 0.6746\n",
      "Epoch 572/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3768 - acc: 0.6804 - val_loss: 1.3821 - val_acc: 0.6742\n",
      "Epoch 573/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3761 - acc: 0.6802 - val_loss: 1.3812 - val_acc: 0.6750\n",
      "Epoch 574/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3753 - acc: 0.6802 - val_loss: 1.3805 - val_acc: 0.6758\n",
      "Epoch 575/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3746 - acc: 0.6805 - val_loss: 1.3798 - val_acc: 0.6733\n",
      "Epoch 576/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3739 - acc: 0.6817 - val_loss: 1.3790 - val_acc: 0.6742\n",
      "Epoch 577/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3730 - acc: 0.6804 - val_loss: 1.3784 - val_acc: 0.6758\n",
      "Epoch 578/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3723 - acc: 0.6804 - val_loss: 1.3776 - val_acc: 0.6758\n",
      "Epoch 579/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.3716 - acc: 0.6813 - val_loss: 1.3768 - val_acc: 0.6758\n",
      "Epoch 580/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3708 - acc: 0.6801 - val_loss: 1.3762 - val_acc: 0.6758\n",
      "Epoch 581/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3701 - acc: 0.6813 - val_loss: 1.3754 - val_acc: 0.6750\n",
      "Epoch 582/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3694 - acc: 0.6808 - val_loss: 1.3747 - val_acc: 0.6767\n",
      "Epoch 583/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3686 - acc: 0.6822 - val_loss: 1.3742 - val_acc: 0.6754\n",
      "Epoch 584/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3679 - acc: 0.6814 - val_loss: 1.3732 - val_acc: 0.6767\n",
      "Epoch 585/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3672 - acc: 0.6805 - val_loss: 1.3728 - val_acc: 0.6758\n",
      "Epoch 586/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3664 - acc: 0.6816 - val_loss: 1.3717 - val_acc: 0.6771\n",
      "Epoch 587/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3657 - acc: 0.6818 - val_loss: 1.3711 - val_acc: 0.6763\n",
      "Epoch 588/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.3650 - acc: 0.6811 - val_loss: 1.3704 - val_acc: 0.6775\n",
      "Epoch 589/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.3642 - acc: 0.6816 - val_loss: 1.3698 - val_acc: 0.6771\n",
      "Epoch 590/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3635 - acc: 0.6823 - val_loss: 1.3691 - val_acc: 0.6771\n",
      "Epoch 591/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.3628 - acc: 0.6811 - val_loss: 1.3683 - val_acc: 0.6788\n",
      "Epoch 592/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3620 - acc: 0.6824 - val_loss: 1.3676 - val_acc: 0.6771\n",
      "Epoch 593/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3613 - acc: 0.6820 - val_loss: 1.3669 - val_acc: 0.6763\n",
      "Epoch 594/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3605 - acc: 0.6824 - val_loss: 1.3663 - val_acc: 0.6763\n",
      "Epoch 595/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3598 - acc: 0.6822 - val_loss: 1.3654 - val_acc: 0.6754\n",
      "Epoch 596/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.3591 - acc: 0.6816 - val_loss: 1.3647 - val_acc: 0.6767\n",
      "Epoch 597/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3584 - acc: 0.6824 - val_loss: 1.3642 - val_acc: 0.6779\n",
      "Epoch 598/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3577 - acc: 0.6820 - val_loss: 1.3636 - val_acc: 0.6771\n",
      "Epoch 599/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.3569 - acc: 0.6822 - val_loss: 1.3627 - val_acc: 0.6767\n",
      "Epoch 600/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.3563 - acc: 0.6822 - val_loss: 1.3621 - val_acc: 0.6775\n",
      "Epoch 601/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.3555 - acc: 0.6830 - val_loss: 1.3613 - val_acc: 0.6767\n",
      "Epoch 602/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.3549 - acc: 0.6822 - val_loss: 1.3606 - val_acc: 0.6763\n",
      "Epoch 603/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.3541 - acc: 0.6829 - val_loss: 1.3600 - val_acc: 0.6771\n",
      "Epoch 604/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3534 - acc: 0.6823 - val_loss: 1.3592 - val_acc: 0.6783\n",
      "Epoch 605/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.3527 - acc: 0.6821 - val_loss: 1.3584 - val_acc: 0.6783\n",
      "Epoch 606/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3520 - acc: 0.6836 - val_loss: 1.3579 - val_acc: 0.6775\n",
      "Epoch 607/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.3513 - acc: 0.6834 - val_loss: 1.3572 - val_acc: 0.6779\n",
      "Epoch 608/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3506 - acc: 0.6833 - val_loss: 1.3567 - val_acc: 0.6775\n",
      "Epoch 609/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3499 - acc: 0.6833 - val_loss: 1.3559 - val_acc: 0.6775\n",
      "Epoch 610/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3492 - acc: 0.6833 - val_loss: 1.3551 - val_acc: 0.6775\n",
      "Epoch 611/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3485 - acc: 0.6835 - val_loss: 1.3545 - val_acc: 0.6783\n",
      "Epoch 612/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3478 - acc: 0.6838 - val_loss: 1.3537 - val_acc: 0.6783\n",
      "Epoch 613/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3471 - acc: 0.6835 - val_loss: 1.3531 - val_acc: 0.6792\n",
      "Epoch 614/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3464 - acc: 0.6835 - val_loss: 1.3525 - val_acc: 0.6758\n",
      "Epoch 615/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.3457 - acc: 0.6849 - val_loss: 1.3519 - val_acc: 0.6771\n",
      "Epoch 616/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3450 - acc: 0.6844 - val_loss: 1.3512 - val_acc: 0.6783\n",
      "Epoch 617/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3443 - acc: 0.6843 - val_loss: 1.3507 - val_acc: 0.6758\n",
      "Epoch 618/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3436 - acc: 0.6834 - val_loss: 1.3497 - val_acc: 0.6775\n",
      "Epoch 619/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3429 - acc: 0.6852 - val_loss: 1.3490 - val_acc: 0.6788\n",
      "Epoch 620/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3422 - acc: 0.6844 - val_loss: 1.3485 - val_acc: 0.6792\n",
      "Epoch 621/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3415 - acc: 0.6848 - val_loss: 1.3478 - val_acc: 0.6775\n",
      "Epoch 622/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3408 - acc: 0.6840 - val_loss: 1.3472 - val_acc: 0.6792\n",
      "Epoch 623/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3401 - acc: 0.6844 - val_loss: 1.3465 - val_acc: 0.6788\n",
      "Epoch 624/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3394 - acc: 0.6854 - val_loss: 1.3457 - val_acc: 0.6804\n",
      "Epoch 625/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.3388 - acc: 0.6852 - val_loss: 1.3452 - val_acc: 0.6804\n",
      "Epoch 626/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.3380 - acc: 0.6855 - val_loss: 1.3444 - val_acc: 0.6808\n",
      "Epoch 627/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3373 - acc: 0.6854 - val_loss: 1.3437 - val_acc: 0.6792\n",
      "Epoch 628/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.3367 - acc: 0.6851 - val_loss: 1.3431 - val_acc: 0.6808\n",
      "Epoch 629/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.3361 - acc: 0.6849 - val_loss: 1.3426 - val_acc: 0.6792\n",
      "Epoch 630/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3354 - acc: 0.6861 - val_loss: 1.3417 - val_acc: 0.6808\n",
      "Epoch 631/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3346 - acc: 0.6868 - val_loss: 1.3411 - val_acc: 0.6796\n",
      "Epoch 632/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3340 - acc: 0.6864 - val_loss: 1.3405 - val_acc: 0.6792\n",
      "Epoch 633/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3333 - acc: 0.6856 - val_loss: 1.3398 - val_acc: 0.6792\n",
      "Epoch 634/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3326 - acc: 0.6866 - val_loss: 1.3391 - val_acc: 0.6783\n",
      "Epoch 635/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3320 - acc: 0.6849 - val_loss: 1.3385 - val_acc: 0.6796\n",
      "Epoch 636/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3313 - acc: 0.6875 - val_loss: 1.3379 - val_acc: 0.6788\n",
      "Epoch 637/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3307 - acc: 0.6875 - val_loss: 1.3376 - val_acc: 0.6787\n",
      "Epoch 638/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3300 - acc: 0.6853 - val_loss: 1.3367 - val_acc: 0.6788\n",
      "Epoch 639/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3293 - acc: 0.6865 - val_loss: 1.3359 - val_acc: 0.6779\n",
      "Epoch 640/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3286 - acc: 0.6867 - val_loss: 1.3353 - val_acc: 0.6788\n",
      "Epoch 641/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3281 - acc: 0.6861 - val_loss: 1.3348 - val_acc: 0.6808\n",
      "Epoch 642/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3273 - acc: 0.6866 - val_loss: 1.3340 - val_acc: 0.6788\n",
      "Epoch 643/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3267 - acc: 0.6867 - val_loss: 1.3334 - val_acc: 0.6796\n",
      "Epoch 644/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3261 - acc: 0.6857 - val_loss: 1.3326 - val_acc: 0.6792\n",
      "Epoch 645/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3253 - acc: 0.6869 - val_loss: 1.3322 - val_acc: 0.6788\n",
      "Epoch 646/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3247 - acc: 0.6877 - val_loss: 1.3316 - val_acc: 0.6796\n",
      "Epoch 647/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3241 - acc: 0.6871 - val_loss: 1.3309 - val_acc: 0.6804\n",
      "Epoch 648/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3234 - acc: 0.6871 - val_loss: 1.3303 - val_acc: 0.6813\n",
      "Epoch 649/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3227 - acc: 0.6875 - val_loss: 1.3297 - val_acc: 0.6796\n",
      "Epoch 650/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3221 - acc: 0.6870 - val_loss: 1.3290 - val_acc: 0.6792\n",
      "Epoch 651/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3214 - acc: 0.6880 - val_loss: 1.3286 - val_acc: 0.6804\n",
      "Epoch 652/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3208 - acc: 0.6892 - val_loss: 1.3278 - val_acc: 0.6808\n",
      "Epoch 653/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3202 - acc: 0.6877 - val_loss: 1.3273 - val_acc: 0.6804\n",
      "Epoch 654/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3195 - acc: 0.6881 - val_loss: 1.3266 - val_acc: 0.6813\n",
      "Epoch 655/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3189 - acc: 0.6884 - val_loss: 1.3260 - val_acc: 0.6800\n",
      "Epoch 656/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3182 - acc: 0.6877 - val_loss: 1.3251 - val_acc: 0.6817\n",
      "Epoch 657/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3176 - acc: 0.6882 - val_loss: 1.3247 - val_acc: 0.6804\n",
      "Epoch 658/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3169 - acc: 0.6890 - val_loss: 1.3241 - val_acc: 0.6817\n",
      "Epoch 659/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3163 - acc: 0.6876 - val_loss: 1.3235 - val_acc: 0.6796\n",
      "Epoch 660/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3157 - acc: 0.6896 - val_loss: 1.3228 - val_acc: 0.6796\n",
      "Epoch 661/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3151 - acc: 0.6890 - val_loss: 1.3221 - val_acc: 0.6813\n",
      "Epoch 662/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3144 - acc: 0.6882 - val_loss: 1.3216 - val_acc: 0.6813\n",
      "Epoch 663/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3138 - acc: 0.6891 - val_loss: 1.3209 - val_acc: 0.6804\n",
      "Epoch 664/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3132 - acc: 0.6894 - val_loss: 1.3205 - val_acc: 0.6804\n",
      "Epoch 665/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3126 - acc: 0.6881 - val_loss: 1.3199 - val_acc: 0.6808\n",
      "Epoch 666/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3119 - acc: 0.6886 - val_loss: 1.3193 - val_acc: 0.6800\n",
      "Epoch 667/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3113 - acc: 0.6894 - val_loss: 1.3186 - val_acc: 0.6813\n",
      "Epoch 668/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3107 - acc: 0.6892 - val_loss: 1.3182 - val_acc: 0.6808\n",
      "Epoch 669/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3101 - acc: 0.6890 - val_loss: 1.3174 - val_acc: 0.6813\n",
      "Epoch 670/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3094 - acc: 0.6890 - val_loss: 1.3169 - val_acc: 0.6808\n",
      "Epoch 671/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3087 - acc: 0.6898 - val_loss: 1.3163 - val_acc: 0.6813\n",
      "Epoch 672/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3081 - acc: 0.6902 - val_loss: 1.3156 - val_acc: 0.6825\n",
      "Epoch 673/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3076 - acc: 0.6893 - val_loss: 1.3150 - val_acc: 0.6808\n",
      "Epoch 674/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3070 - acc: 0.6883 - val_loss: 1.3142 - val_acc: 0.6833\n",
      "Epoch 675/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3063 - acc: 0.6900 - val_loss: 1.3139 - val_acc: 0.6808\n",
      "Epoch 676/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3057 - acc: 0.6905 - val_loss: 1.3133 - val_acc: 0.6808\n",
      "Epoch 677/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3051 - acc: 0.6901 - val_loss: 1.3125 - val_acc: 0.6829\n",
      "Epoch 678/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3045 - acc: 0.6894 - val_loss: 1.3119 - val_acc: 0.6817\n",
      "Epoch 679/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3038 - acc: 0.6902 - val_loss: 1.3114 - val_acc: 0.6813\n",
      "Epoch 680/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3033 - acc: 0.6901 - val_loss: 1.3109 - val_acc: 0.6817\n",
      "Epoch 681/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3027 - acc: 0.6894 - val_loss: 1.3102 - val_acc: 0.6812\n",
      "Epoch 682/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3020 - acc: 0.6898 - val_loss: 1.3098 - val_acc: 0.6813\n",
      "Epoch 683/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3014 - acc: 0.6903 - val_loss: 1.3090 - val_acc: 0.6813\n",
      "Epoch 684/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3008 - acc: 0.6908 - val_loss: 1.3086 - val_acc: 0.6808\n",
      "Epoch 685/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3002 - acc: 0.6905 - val_loss: 1.3079 - val_acc: 0.6821\n",
      "Epoch 686/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2996 - acc: 0.6904 - val_loss: 1.3075 - val_acc: 0.6808\n",
      "Epoch 687/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2990 - acc: 0.6914 - val_loss: 1.3070 - val_acc: 0.6800\n",
      "Epoch 688/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2983 - acc: 0.6912 - val_loss: 1.3063 - val_acc: 0.6817\n",
      "Epoch 689/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2977 - acc: 0.6908 - val_loss: 1.3057 - val_acc: 0.6813\n",
      "Epoch 690/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2972 - acc: 0.6914 - val_loss: 1.3051 - val_acc: 0.6804\n",
      "Epoch 691/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2965 - acc: 0.6910 - val_loss: 1.3043 - val_acc: 0.6825\n",
      "Epoch 692/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2960 - acc: 0.6917 - val_loss: 1.3037 - val_acc: 0.6825\n",
      "Epoch 693/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2953 - acc: 0.6915 - val_loss: 1.3032 - val_acc: 0.6821\n",
      "Epoch 694/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2947 - acc: 0.6904 - val_loss: 1.3027 - val_acc: 0.6808\n",
      "Epoch 695/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2941 - acc: 0.6923 - val_loss: 1.3022 - val_acc: 0.6813\n",
      "Epoch 696/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2936 - acc: 0.6920 - val_loss: 1.3016 - val_acc: 0.6829\n",
      "Epoch 697/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2931 - acc: 0.6910 - val_loss: 1.3011 - val_acc: 0.6813\n",
      "Epoch 698/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2924 - acc: 0.6927 - val_loss: 1.3005 - val_acc: 0.6808\n",
      "Epoch 699/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2918 - acc: 0.6927 - val_loss: 1.3000 - val_acc: 0.6804\n",
      "Epoch 700/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2912 - acc: 0.6919 - val_loss: 1.2992 - val_acc: 0.6829\n",
      "Epoch 701/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2906 - acc: 0.6918 - val_loss: 1.2988 - val_acc: 0.6813\n",
      "Epoch 702/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2901 - acc: 0.6920 - val_loss: 1.2982 - val_acc: 0.6817\n",
      "Epoch 703/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2894 - acc: 0.6930 - val_loss: 1.2976 - val_acc: 0.6829\n",
      "Epoch 704/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2889 - acc: 0.6923 - val_loss: 1.2971 - val_acc: 0.6817\n",
      "Epoch 705/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2883 - acc: 0.6931 - val_loss: 1.2965 - val_acc: 0.6838\n",
      "Epoch 706/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2877 - acc: 0.6937 - val_loss: 1.2961 - val_acc: 0.6817\n",
      "Epoch 707/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2871 - acc: 0.6935 - val_loss: 1.2954 - val_acc: 0.6829\n",
      "Epoch 708/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2865 - acc: 0.6918 - val_loss: 1.2948 - val_acc: 0.6813\n",
      "Epoch 709/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2860 - acc: 0.6932 - val_loss: 1.2941 - val_acc: 0.6829\n",
      "Epoch 710/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2854 - acc: 0.6926 - val_loss: 1.2937 - val_acc: 0.6808\n",
      "Epoch 711/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2848 - acc: 0.6934 - val_loss: 1.2933 - val_acc: 0.6821\n",
      "Epoch 712/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2842 - acc: 0.6945 - val_loss: 1.2927 - val_acc: 0.6825\n",
      "Epoch 713/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2836 - acc: 0.6930 - val_loss: 1.2919 - val_acc: 0.6833\n",
      "Epoch 714/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2830 - acc: 0.6924 - val_loss: 1.2916 - val_acc: 0.6821\n",
      "Epoch 715/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2825 - acc: 0.6948 - val_loss: 1.2909 - val_acc: 0.6833\n",
      "Epoch 716/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2819 - acc: 0.6935 - val_loss: 1.2903 - val_acc: 0.6833\n",
      "Epoch 717/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2813 - acc: 0.6944 - val_loss: 1.2899 - val_acc: 0.6813\n",
      "Epoch 718/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2808 - acc: 0.6944 - val_loss: 1.2894 - val_acc: 0.6804\n",
      "Epoch 719/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2802 - acc: 0.6937 - val_loss: 1.2889 - val_acc: 0.6808\n",
      "Epoch 720/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2797 - acc: 0.6928 - val_loss: 1.2883 - val_acc: 0.6825\n",
      "Epoch 721/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2792 - acc: 0.6945 - val_loss: 1.2878 - val_acc: 0.6829\n",
      "Epoch 722/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2786 - acc: 0.6936 - val_loss: 1.2871 - val_acc: 0.6825\n",
      "Epoch 723/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2780 - acc: 0.6942 - val_loss: 1.2867 - val_acc: 0.6821\n",
      "Epoch 724/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2774 - acc: 0.6944 - val_loss: 1.2860 - val_acc: 0.6842\n",
      "Epoch 725/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2768 - acc: 0.6935 - val_loss: 1.2855 - val_acc: 0.6829\n",
      "Epoch 726/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2763 - acc: 0.6945 - val_loss: 1.2850 - val_acc: 0.6829\n",
      "Epoch 727/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2758 - acc: 0.6947 - val_loss: 1.2846 - val_acc: 0.6833\n",
      "Epoch 728/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2752 - acc: 0.6951 - val_loss: 1.2841 - val_acc: 0.6821\n",
      "Epoch 729/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2746 - acc: 0.6954 - val_loss: 1.2835 - val_acc: 0.6813\n",
      "Epoch 730/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2740 - acc: 0.6952 - val_loss: 1.2829 - val_acc: 0.6821\n",
      "Epoch 731/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2736 - acc: 0.6941 - val_loss: 1.2823 - val_acc: 0.6829\n",
      "Epoch 732/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2730 - acc: 0.6945 - val_loss: 1.2819 - val_acc: 0.6833\n",
      "Epoch 733/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2724 - acc: 0.6956 - val_loss: 1.2813 - val_acc: 0.6833\n",
      "Epoch 734/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2719 - acc: 0.6956 - val_loss: 1.2807 - val_acc: 0.6833\n",
      "Epoch 735/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2713 - acc: 0.6945 - val_loss: 1.2802 - val_acc: 0.6829\n",
      "Epoch 736/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2708 - acc: 0.6960 - val_loss: 1.2798 - val_acc: 0.6829\n",
      "Epoch 737/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2702 - acc: 0.6953 - val_loss: 1.2792 - val_acc: 0.6829\n",
      "Epoch 738/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2697 - acc: 0.6951 - val_loss: 1.2787 - val_acc: 0.6821\n",
      "Epoch 739/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2691 - acc: 0.6961 - val_loss: 1.2782 - val_acc: 0.6838\n",
      "Epoch 740/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2686 - acc: 0.6949 - val_loss: 1.2776 - val_acc: 0.6838\n",
      "Epoch 741/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2680 - acc: 0.6971 - val_loss: 1.2772 - val_acc: 0.6829\n",
      "Epoch 742/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2675 - acc: 0.6947 - val_loss: 1.2766 - val_acc: 0.6833\n",
      "Epoch 743/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2669 - acc: 0.6957 - val_loss: 1.2762 - val_acc: 0.6825\n",
      "Epoch 744/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2664 - acc: 0.6970 - val_loss: 1.2755 - val_acc: 0.6833\n",
      "Epoch 745/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2659 - acc: 0.6967 - val_loss: 1.2750 - val_acc: 0.6850\n",
      "Epoch 746/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2654 - acc: 0.6959 - val_loss: 1.2745 - val_acc: 0.6833\n",
      "Epoch 747/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2648 - acc: 0.6954 - val_loss: 1.2739 - val_acc: 0.6846\n",
      "Epoch 748/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2643 - acc: 0.6961 - val_loss: 1.2736 - val_acc: 0.6829\n",
      "Epoch 749/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2637 - acc: 0.6961 - val_loss: 1.2730 - val_acc: 0.6838\n",
      "Epoch 750/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2632 - acc: 0.6961 - val_loss: 1.2724 - val_acc: 0.6838\n",
      "Epoch 751/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2627 - acc: 0.6967 - val_loss: 1.2720 - val_acc: 0.6838\n",
      "Epoch 752/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2622 - acc: 0.6966 - val_loss: 1.2715 - val_acc: 0.6829\n",
      "Epoch 753/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2616 - acc: 0.6970 - val_loss: 1.2709 - val_acc: 0.6850\n",
      "Epoch 754/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.2611 - acc: 0.6970 - val_loss: 1.2706 - val_acc: 0.6833\n",
      "Epoch 755/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.2605 - acc: 0.6974 - val_loss: 1.2700 - val_acc: 0.6825\n",
      "Epoch 756/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2600 - acc: 0.6968 - val_loss: 1.2695 - val_acc: 0.6838\n",
      "Epoch 757/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.2595 - acc: 0.6974 - val_loss: 1.2689 - val_acc: 0.6837\n",
      "Epoch 758/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2590 - acc: 0.6976 - val_loss: 1.2685 - val_acc: 0.6833\n",
      "Epoch 759/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2584 - acc: 0.6973 - val_loss: 1.2680 - val_acc: 0.6854\n",
      "Epoch 760/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2579 - acc: 0.6976 - val_loss: 1.2676 - val_acc: 0.6842\n",
      "Epoch 761/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2574 - acc: 0.6982 - val_loss: 1.2669 - val_acc: 0.6846\n",
      "Epoch 762/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2569 - acc: 0.6970 - val_loss: 1.2665 - val_acc: 0.6846\n",
      "Epoch 763/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.2563 - acc: 0.6974 - val_loss: 1.2661 - val_acc: 0.6854\n",
      "Epoch 764/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2558 - acc: 0.6975 - val_loss: 1.2654 - val_acc: 0.6846\n",
      "Epoch 765/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2554 - acc: 0.6978 - val_loss: 1.2651 - val_acc: 0.6854\n",
      "Epoch 766/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2548 - acc: 0.6985 - val_loss: 1.2643 - val_acc: 0.6854\n",
      "Epoch 767/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2543 - acc: 0.6983 - val_loss: 1.2638 - val_acc: 0.6850\n",
      "Epoch 768/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2538 - acc: 0.6976 - val_loss: 1.2634 - val_acc: 0.6850\n",
      "Epoch 769/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2533 - acc: 0.6993 - val_loss: 1.2630 - val_acc: 0.6854\n",
      "Epoch 770/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2527 - acc: 0.6982 - val_loss: 1.2625 - val_acc: 0.6854\n",
      "Epoch 771/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2522 - acc: 0.6984 - val_loss: 1.2619 - val_acc: 0.6850\n",
      "Epoch 772/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2517 - acc: 0.6979 - val_loss: 1.2615 - val_acc: 0.6846\n",
      "Epoch 773/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2512 - acc: 0.6992 - val_loss: 1.2609 - val_acc: 0.6846\n",
      "Epoch 774/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.2507 - acc: 0.6975 - val_loss: 1.2604 - val_acc: 0.6833\n",
      "Epoch 775/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2501 - acc: 0.6985 - val_loss: 1.2601 - val_acc: 0.6858\n",
      "Epoch 776/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2496 - acc: 0.6986 - val_loss: 1.2597 - val_acc: 0.6846\n",
      "Epoch 777/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2491 - acc: 0.6975 - val_loss: 1.2589 - val_acc: 0.6858\n",
      "Epoch 778/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2487 - acc: 0.6991 - val_loss: 1.2586 - val_acc: 0.6867\n",
      "Epoch 779/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.2481 - acc: 0.6990 - val_loss: 1.2580 - val_acc: 0.6858\n",
      "Epoch 780/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2477 - acc: 0.6980 - val_loss: 1.2577 - val_acc: 0.6846\n",
      "Epoch 781/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2471 - acc: 0.6994 - val_loss: 1.2571 - val_acc: 0.6867\n",
      "Epoch 782/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2466 - acc: 0.6994 - val_loss: 1.2566 - val_acc: 0.6850\n",
      "Epoch 783/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2461 - acc: 0.6984 - val_loss: 1.2561 - val_acc: 0.6867\n",
      "Epoch 784/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2456 - acc: 0.6992 - val_loss: 1.2556 - val_acc: 0.6854\n",
      "Epoch 785/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2451 - acc: 0.7001 - val_loss: 1.2554 - val_acc: 0.6867\n",
      "Epoch 786/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2447 - acc: 0.6999 - val_loss: 1.2547 - val_acc: 0.6858\n",
      "Epoch 787/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2441 - acc: 0.6990 - val_loss: 1.2543 - val_acc: 0.6867\n",
      "Epoch 788/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2436 - acc: 0.6991 - val_loss: 1.2539 - val_acc: 0.6862\n",
      "Epoch 789/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2431 - acc: 0.7000 - val_loss: 1.2533 - val_acc: 0.6858\n",
      "Epoch 790/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2426 - acc: 0.7000 - val_loss: 1.2527 - val_acc: 0.6858\n",
      "Epoch 791/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2421 - acc: 0.6993 - val_loss: 1.2524 - val_acc: 0.6867\n",
      "Epoch 792/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2416 - acc: 0.6997 - val_loss: 1.2519 - val_acc: 0.6867\n",
      "Epoch 793/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2411 - acc: 0.6996 - val_loss: 1.2515 - val_acc: 0.6862\n",
      "Epoch 794/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2406 - acc: 0.6992 - val_loss: 1.2509 - val_acc: 0.6871\n",
      "Epoch 795/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2401 - acc: 0.7003 - val_loss: 1.2505 - val_acc: 0.6867\n",
      "Epoch 796/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2397 - acc: 0.6991 - val_loss: 1.2501 - val_acc: 0.6862\n",
      "Epoch 797/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2392 - acc: 0.7009 - val_loss: 1.2496 - val_acc: 0.6862\n",
      "Epoch 798/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2386 - acc: 0.7001 - val_loss: 1.2491 - val_acc: 0.6875\n",
      "Epoch 799/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2382 - acc: 0.7002 - val_loss: 1.2487 - val_acc: 0.6867\n",
      "Epoch 800/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2377 - acc: 0.7001 - val_loss: 1.2482 - val_acc: 0.6875\n",
      "Epoch 801/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2373 - acc: 0.6994 - val_loss: 1.2478 - val_acc: 0.6875\n",
      "Epoch 802/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2367 - acc: 0.7004 - val_loss: 1.2474 - val_acc: 0.6871\n",
      "Epoch 803/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.2362 - acc: 0.7005 - val_loss: 1.2468 - val_acc: 0.6862\n",
      "Epoch 804/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2357 - acc: 0.7010 - val_loss: 1.2462 - val_acc: 0.6854\n",
      "Epoch 805/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2352 - acc: 0.7008 - val_loss: 1.2458 - val_acc: 0.6863\n",
      "Epoch 806/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2348 - acc: 0.7003 - val_loss: 1.2454 - val_acc: 0.6871\n",
      "Epoch 807/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2343 - acc: 0.7015 - val_loss: 1.2448 - val_acc: 0.6871\n",
      "Epoch 808/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2338 - acc: 0.7005 - val_loss: 1.2445 - val_acc: 0.6871\n",
      "Epoch 809/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2334 - acc: 0.7017 - val_loss: 1.2441 - val_acc: 0.6867\n",
      "Epoch 810/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.2329 - acc: 0.6998 - val_loss: 1.2435 - val_acc: 0.6875\n",
      "Epoch 811/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2324 - acc: 0.7011 - val_loss: 1.2430 - val_acc: 0.6875\n",
      "Epoch 812/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2319 - acc: 0.7007 - val_loss: 1.2426 - val_acc: 0.6858\n",
      "Epoch 813/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2314 - acc: 0.7008 - val_loss: 1.2421 - val_acc: 0.6871\n",
      "Epoch 814/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2310 - acc: 0.7005 - val_loss: 1.2417 - val_acc: 0.6867\n",
      "Epoch 815/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2305 - acc: 0.7014 - val_loss: 1.2413 - val_acc: 0.6867\n",
      "Epoch 816/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2300 - acc: 0.7014 - val_loss: 1.2409 - val_acc: 0.6883\n",
      "Epoch 817/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2296 - acc: 0.7011 - val_loss: 1.2405 - val_acc: 0.6883\n",
      "Epoch 818/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.2291 - acc: 0.7015 - val_loss: 1.2399 - val_acc: 0.6871\n",
      "Epoch 819/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.2286 - acc: 0.7010 - val_loss: 1.2396 - val_acc: 0.6871\n",
      "Epoch 820/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2281 - acc: 0.7006 - val_loss: 1.2390 - val_acc: 0.6867\n",
      "Epoch 821/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2277 - acc: 0.7022 - val_loss: 1.2387 - val_acc: 0.6883\n",
      "Epoch 822/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2272 - acc: 0.7014 - val_loss: 1.2381 - val_acc: 0.6871\n",
      "Epoch 823/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2267 - acc: 0.7013 - val_loss: 1.2377 - val_acc: 0.6875\n",
      "Epoch 824/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.2263 - acc: 0.7020 - val_loss: 1.2373 - val_acc: 0.6875\n",
      "Epoch 825/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2258 - acc: 0.7015 - val_loss: 1.2369 - val_acc: 0.6871\n",
      "Epoch 826/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2253 - acc: 0.7020 - val_loss: 1.2364 - val_acc: 0.6879\n",
      "Epoch 827/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.2249 - acc: 0.7023 - val_loss: 1.2361 - val_acc: 0.6892\n",
      "Epoch 828/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.2244 - acc: 0.7014 - val_loss: 1.2355 - val_acc: 0.6879\n",
      "Epoch 829/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.2240 - acc: 0.7021 - val_loss: 1.2350 - val_acc: 0.6875\n",
      "Epoch 830/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2235 - acc: 0.7022 - val_loss: 1.2346 - val_acc: 0.6867\n",
      "Epoch 831/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2230 - acc: 0.7020 - val_loss: 1.2343 - val_acc: 0.6879\n",
      "Epoch 832/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.2226 - acc: 0.7020 - val_loss: 1.2338 - val_acc: 0.6892\n",
      "Epoch 833/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.2221 - acc: 0.7030 - val_loss: 1.2334 - val_acc: 0.6896\n",
      "Epoch 834/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2217 - acc: 0.7024 - val_loss: 1.2331 - val_acc: 0.6871\n",
      "Epoch 835/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2213 - acc: 0.7023 - val_loss: 1.2324 - val_acc: 0.6879\n",
      "Epoch 836/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2208 - acc: 0.7016 - val_loss: 1.2319 - val_acc: 0.6875\n",
      "Epoch 837/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2204 - acc: 0.7023 - val_loss: 1.2316 - val_acc: 0.6871\n",
      "Epoch 838/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2198 - acc: 0.7023 - val_loss: 1.2312 - val_acc: 0.6887\n",
      "Epoch 839/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2194 - acc: 0.7028 - val_loss: 1.2307 - val_acc: 0.6887\n",
      "Epoch 840/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2189 - acc: 0.7027 - val_loss: 1.2304 - val_acc: 0.6875\n",
      "Epoch 841/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2185 - acc: 0.7023 - val_loss: 1.2299 - val_acc: 0.6892\n",
      "Epoch 842/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.2180 - acc: 0.7021 - val_loss: 1.2295 - val_acc: 0.6892\n",
      "Epoch 843/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2176 - acc: 0.7023 - val_loss: 1.2290 - val_acc: 0.6887\n",
      "Epoch 844/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2171 - acc: 0.7021 - val_loss: 1.2285 - val_acc: 0.6875\n",
      "Epoch 845/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2167 - acc: 0.7030 - val_loss: 1.2282 - val_acc: 0.6883\n",
      "Epoch 846/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2162 - acc: 0.7025 - val_loss: 1.2278 - val_acc: 0.6892\n",
      "Epoch 847/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2158 - acc: 0.7034 - val_loss: 1.2273 - val_acc: 0.6892\n",
      "Epoch 848/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.2153 - acc: 0.7030 - val_loss: 1.2269 - val_acc: 0.6879\n",
      "Epoch 849/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2149 - acc: 0.7029 - val_loss: 1.2264 - val_acc: 0.6896\n",
      "Epoch 850/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2145 - acc: 0.7034 - val_loss: 1.2260 - val_acc: 0.6883\n",
      "Epoch 851/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2140 - acc: 0.7017 - val_loss: 1.2256 - val_acc: 0.6875\n",
      "Epoch 852/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.2136 - acc: 0.7040 - val_loss: 1.2252 - val_acc: 0.6879\n",
      "Epoch 853/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2132 - acc: 0.7034 - val_loss: 1.2247 - val_acc: 0.6887\n",
      "Epoch 854/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2127 - acc: 0.7029 - val_loss: 1.2244 - val_acc: 0.6871\n",
      "Epoch 855/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2122 - acc: 0.7024 - val_loss: 1.2240 - val_acc: 0.6892\n",
      "Epoch 856/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2118 - acc: 0.7027 - val_loss: 1.2235 - val_acc: 0.6892\n",
      "Epoch 857/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2113 - acc: 0.7037 - val_loss: 1.2231 - val_acc: 0.6883\n",
      "Epoch 858/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2109 - acc: 0.7033 - val_loss: 1.2227 - val_acc: 0.6879\n",
      "Epoch 859/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2105 - acc: 0.7040 - val_loss: 1.2224 - val_acc: 0.6887\n",
      "Epoch 860/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2101 - acc: 0.7032 - val_loss: 1.2219 - val_acc: 0.6887\n",
      "Epoch 861/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2096 - acc: 0.7045 - val_loss: 1.2215 - val_acc: 0.6883\n",
      "Epoch 862/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2092 - acc: 0.7030 - val_loss: 1.2211 - val_acc: 0.6879\n",
      "Epoch 863/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2087 - acc: 0.7040 - val_loss: 1.2207 - val_acc: 0.6892\n",
      "Epoch 864/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2083 - acc: 0.7033 - val_loss: 1.2202 - val_acc: 0.6887\n",
      "Epoch 865/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2080 - acc: 0.7035 - val_loss: 1.2197 - val_acc: 0.6887\n",
      "Epoch 866/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2075 - acc: 0.7040 - val_loss: 1.2194 - val_acc: 0.6879\n",
      "Epoch 867/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2071 - acc: 0.7030 - val_loss: 1.2189 - val_acc: 0.6896\n",
      "Epoch 868/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2066 - acc: 0.7043 - val_loss: 1.2187 - val_acc: 0.6875\n",
      "Epoch 869/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2061 - acc: 0.7034 - val_loss: 1.2180 - val_acc: 0.6892\n",
      "Epoch 870/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2057 - acc: 0.7044 - val_loss: 1.2178 - val_acc: 0.6896\n",
      "Epoch 871/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2052 - acc: 0.7039 - val_loss: 1.2174 - val_acc: 0.6892\n",
      "Epoch 872/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2049 - acc: 0.7046 - val_loss: 1.2170 - val_acc: 0.6896\n",
      "Epoch 873/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2044 - acc: 0.7042 - val_loss: 1.2168 - val_acc: 0.6883\n",
      "Epoch 874/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2040 - acc: 0.7044 - val_loss: 1.2161 - val_acc: 0.6887\n",
      "Epoch 875/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2035 - acc: 0.7041 - val_loss: 1.2159 - val_acc: 0.6892\n",
      "Epoch 876/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2031 - acc: 0.7039 - val_loss: 1.2154 - val_acc: 0.6900\n",
      "Epoch 877/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2027 - acc: 0.7036 - val_loss: 1.2150 - val_acc: 0.6892\n",
      "Epoch 878/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2023 - acc: 0.7044 - val_loss: 1.2145 - val_acc: 0.6896\n",
      "Epoch 879/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2019 - acc: 0.7051 - val_loss: 1.2142 - val_acc: 0.6887\n",
      "Epoch 880/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2014 - acc: 0.7044 - val_loss: 1.2137 - val_acc: 0.6904\n",
      "Epoch 881/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2010 - acc: 0.7047 - val_loss: 1.2133 - val_acc: 0.6892\n",
      "Epoch 882/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2006 - acc: 0.7039 - val_loss: 1.2130 - val_acc: 0.6892\n",
      "Epoch 883/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2002 - acc: 0.7042 - val_loss: 1.2125 - val_acc: 0.6896\n",
      "Epoch 884/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1997 - acc: 0.7047 - val_loss: 1.2121 - val_acc: 0.6892\n",
      "Epoch 885/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1993 - acc: 0.7048 - val_loss: 1.2119 - val_acc: 0.6900\n",
      "Epoch 886/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1989 - acc: 0.7042 - val_loss: 1.2113 - val_acc: 0.6896\n",
      "Epoch 887/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1985 - acc: 0.7050 - val_loss: 1.2109 - val_acc: 0.6904\n",
      "Epoch 888/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1981 - acc: 0.7047 - val_loss: 1.2105 - val_acc: 0.6900\n",
      "Epoch 889/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1976 - acc: 0.7042 - val_loss: 1.2102 - val_acc: 0.6904\n",
      "Epoch 890/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1972 - acc: 0.7052 - val_loss: 1.2098 - val_acc: 0.6904\n",
      "Epoch 891/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1968 - acc: 0.7059 - val_loss: 1.2094 - val_acc: 0.6908\n",
      "Epoch 892/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1964 - acc: 0.7047 - val_loss: 1.2090 - val_acc: 0.6904\n",
      "Epoch 893/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1959 - acc: 0.7044 - val_loss: 1.2086 - val_acc: 0.6904\n",
      "Epoch 894/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1956 - acc: 0.7051 - val_loss: 1.2081 - val_acc: 0.6904\n",
      "Epoch 895/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1952 - acc: 0.7050 - val_loss: 1.2079 - val_acc: 0.6904\n",
      "Epoch 896/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.1947 - acc: 0.7051 - val_loss: 1.2075 - val_acc: 0.6913\n",
      "Epoch 897/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1944 - acc: 0.7051 - val_loss: 1.2070 - val_acc: 0.6917\n",
      "Epoch 898/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1939 - acc: 0.7055 - val_loss: 1.2066 - val_acc: 0.6913\n",
      "Epoch 899/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1936 - acc: 0.7056 - val_loss: 1.2062 - val_acc: 0.6913\n",
      "Epoch 900/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1931 - acc: 0.7061 - val_loss: 1.2058 - val_acc: 0.6917\n",
      "Epoch 901/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1927 - acc: 0.7055 - val_loss: 1.2055 - val_acc: 0.6904\n",
      "Epoch 902/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1923 - acc: 0.7057 - val_loss: 1.2051 - val_acc: 0.6921\n",
      "Epoch 903/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1920 - acc: 0.7049 - val_loss: 1.2049 - val_acc: 0.6908\n",
      "Epoch 904/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1915 - acc: 0.7058 - val_loss: 1.2044 - val_acc: 0.6900\n",
      "Epoch 905/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1911 - acc: 0.7058 - val_loss: 1.2042 - val_acc: 0.6921\n",
      "Epoch 906/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1907 - acc: 0.7058 - val_loss: 1.2035 - val_acc: 0.6908\n",
      "Epoch 907/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1902 - acc: 0.7065 - val_loss: 1.2031 - val_acc: 0.6900\n",
      "Epoch 908/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1899 - acc: 0.7058 - val_loss: 1.2029 - val_acc: 0.6921\n",
      "Epoch 909/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1895 - acc: 0.7059 - val_loss: 1.2024 - val_acc: 0.6925\n",
      "Epoch 910/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1891 - acc: 0.7051 - val_loss: 1.2020 - val_acc: 0.6925\n",
      "Epoch 911/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1886 - acc: 0.7054 - val_loss: 1.2016 - val_acc: 0.6917\n",
      "Epoch 912/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1883 - acc: 0.7061 - val_loss: 1.2011 - val_acc: 0.6925\n",
      "Epoch 913/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1879 - acc: 0.7057 - val_loss: 1.2010 - val_acc: 0.6904\n",
      "Epoch 914/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1875 - acc: 0.7068 - val_loss: 1.2004 - val_acc: 0.6921\n",
      "Epoch 915/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1871 - acc: 0.7064 - val_loss: 1.2002 - val_acc: 0.6929\n",
      "Epoch 916/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1866 - acc: 0.7056 - val_loss: 1.1998 - val_acc: 0.6904\n",
      "Epoch 917/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1863 - acc: 0.7067 - val_loss: 1.1996 - val_acc: 0.6929\n",
      "Epoch 918/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1859 - acc: 0.7060 - val_loss: 1.1992 - val_acc: 0.6913\n",
      "Epoch 919/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1855 - acc: 0.7071 - val_loss: 1.1987 - val_acc: 0.6925\n",
      "Epoch 920/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1851 - acc: 0.7072 - val_loss: 1.1983 - val_acc: 0.6917\n",
      "Epoch 921/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.1847 - acc: 0.7061 - val_loss: 1.1980 - val_acc: 0.6925\n",
      "Epoch 922/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1843 - acc: 0.7060 - val_loss: 1.1976 - val_acc: 0.6917\n",
      "Epoch 923/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1839 - acc: 0.7075 - val_loss: 1.1973 - val_acc: 0.6908\n",
      "Epoch 924/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1835 - acc: 0.7071 - val_loss: 1.1968 - val_acc: 0.6925\n",
      "Epoch 925/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1832 - acc: 0.7066 - val_loss: 1.1966 - val_acc: 0.6921\n",
      "Epoch 926/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1827 - acc: 0.7068 - val_loss: 1.1962 - val_acc: 0.6921\n",
      "Epoch 927/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.1824 - acc: 0.7064 - val_loss: 1.1958 - val_acc: 0.6933\n",
      "Epoch 928/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1820 - acc: 0.7060 - val_loss: 1.1953 - val_acc: 0.6925\n",
      "Epoch 929/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1815 - acc: 0.7071 - val_loss: 1.1950 - val_acc: 0.6929\n",
      "Epoch 930/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1812 - acc: 0.7071 - val_loss: 1.1946 - val_acc: 0.6917\n",
      "Epoch 931/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1808 - acc: 0.7060 - val_loss: 1.1944 - val_acc: 0.6917\n",
      "Epoch 932/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1804 - acc: 0.7068 - val_loss: 1.1938 - val_acc: 0.6933\n",
      "Epoch 933/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1800 - acc: 0.7065 - val_loss: 1.1936 - val_acc: 0.6937\n",
      "Epoch 934/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1796 - acc: 0.7070 - val_loss: 1.1931 - val_acc: 0.6925\n",
      "Epoch 935/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1792 - acc: 0.7073 - val_loss: 1.1927 - val_acc: 0.6929\n",
      "Epoch 936/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1788 - acc: 0.7070 - val_loss: 1.1926 - val_acc: 0.6925\n",
      "Epoch 937/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1785 - acc: 0.7065 - val_loss: 1.1920 - val_acc: 0.6933\n",
      "Epoch 938/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1781 - acc: 0.7068 - val_loss: 1.1917 - val_acc: 0.6937\n",
      "Epoch 939/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1776 - acc: 0.7072 - val_loss: 1.1915 - val_acc: 0.6929\n",
      "Epoch 940/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1773 - acc: 0.7072 - val_loss: 1.1910 - val_acc: 0.6929\n",
      "Epoch 941/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1769 - acc: 0.7069 - val_loss: 1.1908 - val_acc: 0.6933\n",
      "Epoch 942/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1765 - acc: 0.7074 - val_loss: 1.1904 - val_acc: 0.6946\n",
      "Epoch 943/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1762 - acc: 0.7073 - val_loss: 1.1899 - val_acc: 0.6950\n",
      "Epoch 944/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.1758 - acc: 0.7075 - val_loss: 1.1896 - val_acc: 0.6937\n",
      "Epoch 945/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1754 - acc: 0.7079 - val_loss: 1.1892 - val_acc: 0.6929\n",
      "Epoch 946/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1750 - acc: 0.7079 - val_loss: 1.1889 - val_acc: 0.6929\n",
      "Epoch 947/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1746 - acc: 0.7081 - val_loss: 1.1886 - val_acc: 0.6950\n",
      "Epoch 948/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1743 - acc: 0.7078 - val_loss: 1.1882 - val_acc: 0.6942\n",
      "Epoch 949/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1738 - acc: 0.7072 - val_loss: 1.1878 - val_acc: 0.6921\n",
      "Epoch 950/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1735 - acc: 0.7075 - val_loss: 1.1874 - val_acc: 0.6946\n",
      "Epoch 951/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1732 - acc: 0.7087 - val_loss: 1.1871 - val_acc: 0.6946\n",
      "Epoch 952/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1727 - acc: 0.7082 - val_loss: 1.1868 - val_acc: 0.6942\n",
      "Epoch 953/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1723 - acc: 0.7083 - val_loss: 1.1864 - val_acc: 0.6929\n",
      "Epoch 954/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1720 - acc: 0.7078 - val_loss: 1.1859 - val_acc: 0.6942\n",
      "Epoch 955/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1717 - acc: 0.7080 - val_loss: 1.1857 - val_acc: 0.6937\n",
      "Epoch 956/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1713 - acc: 0.7093 - val_loss: 1.1854 - val_acc: 0.6954\n",
      "Epoch 957/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1709 - acc: 0.7079 - val_loss: 1.1850 - val_acc: 0.6946\n",
      "Epoch 958/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.1705 - acc: 0.7086 - val_loss: 1.1846 - val_acc: 0.6946\n",
      "Epoch 959/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1702 - acc: 0.7080 - val_loss: 1.1842 - val_acc: 0.6937\n",
      "Epoch 960/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1698 - acc: 0.7081 - val_loss: 1.1838 - val_acc: 0.6946\n",
      "Epoch 961/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1695 - acc: 0.7085 - val_loss: 1.1836 - val_acc: 0.6933\n",
      "Epoch 962/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1690 - acc: 0.7076 - val_loss: 1.1832 - val_acc: 0.6933\n",
      "Epoch 963/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1687 - acc: 0.7084 - val_loss: 1.1829 - val_acc: 0.6937\n",
      "Epoch 964/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1683 - acc: 0.7091 - val_loss: 1.1824 - val_acc: 0.6950\n",
      "Epoch 965/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1679 - acc: 0.7085 - val_loss: 1.1822 - val_acc: 0.6942\n",
      "Epoch 966/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1676 - acc: 0.7081 - val_loss: 1.1818 - val_acc: 0.6950\n",
      "Epoch 967/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1672 - acc: 0.7083 - val_loss: 1.1817 - val_acc: 0.6937\n",
      "Epoch 968/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1668 - acc: 0.7086 - val_loss: 1.1812 - val_acc: 0.6950\n",
      "Epoch 969/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1664 - acc: 0.7089 - val_loss: 1.1807 - val_acc: 0.6950\n",
      "Epoch 970/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1661 - acc: 0.7087 - val_loss: 1.1806 - val_acc: 0.6946\n",
      "Epoch 971/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1658 - acc: 0.7087 - val_loss: 1.1802 - val_acc: 0.6954\n",
      "Epoch 972/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1653 - acc: 0.7094 - val_loss: 1.1798 - val_acc: 0.6950\n",
      "Epoch 973/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1650 - acc: 0.7095 - val_loss: 1.1794 - val_acc: 0.6950\n",
      "Epoch 974/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1647 - acc: 0.7089 - val_loss: 1.1790 - val_acc: 0.6954\n",
      "Epoch 975/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1643 - acc: 0.7094 - val_loss: 1.1788 - val_acc: 0.6954\n",
      "Epoch 976/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1640 - acc: 0.7100 - val_loss: 1.1785 - val_acc: 0.6954\n",
      "Epoch 977/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1636 - acc: 0.7092 - val_loss: 1.1780 - val_acc: 0.6954\n",
      "Epoch 978/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1632 - acc: 0.7091 - val_loss: 1.1779 - val_acc: 0.6942\n",
      "Epoch 979/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1629 - acc: 0.7098 - val_loss: 1.1775 - val_acc: 0.6954\n",
      "Epoch 980/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1626 - acc: 0.7086 - val_loss: 1.1771 - val_acc: 0.6954\n",
      "Epoch 981/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1621 - acc: 0.7110 - val_loss: 1.1768 - val_acc: 0.6942\n",
      "Epoch 982/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1618 - acc: 0.7096 - val_loss: 1.1765 - val_acc: 0.6946\n",
      "Epoch 983/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1614 - acc: 0.7089 - val_loss: 1.1761 - val_acc: 0.6942\n",
      "Epoch 984/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1611 - acc: 0.7098 - val_loss: 1.1757 - val_acc: 0.6946\n",
      "Epoch 985/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.1607 - acc: 0.7094 - val_loss: 1.1753 - val_acc: 0.6954\n",
      "Epoch 986/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.1603 - acc: 0.7096 - val_loss: 1.1750 - val_acc: 0.6950\n",
      "Epoch 987/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.1599 - acc: 0.7096 - val_loss: 1.1748 - val_acc: 0.6954\n",
      "Epoch 988/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.1596 - acc: 0.7098 - val_loss: 1.1745 - val_acc: 0.6946\n",
      "Epoch 989/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.1593 - acc: 0.7102 - val_loss: 1.1741 - val_acc: 0.6946\n",
      "Epoch 990/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.1589 - acc: 0.7101 - val_loss: 1.1738 - val_acc: 0.6942\n",
      "Epoch 991/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.1585 - acc: 0.7094 - val_loss: 1.1734 - val_acc: 0.6954\n",
      "Epoch 992/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.1582 - acc: 0.7104 - val_loss: 1.1732 - val_acc: 0.6954\n",
      "Epoch 993/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.1579 - acc: 0.7097 - val_loss: 1.1727 - val_acc: 0.6954\n",
      "Epoch 994/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.1575 - acc: 0.7119 - val_loss: 1.1725 - val_acc: 0.6950\n",
      "Epoch 995/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.1571 - acc: 0.7100 - val_loss: 1.1722 - val_acc: 0.6958\n",
      "Epoch 996/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.1568 - acc: 0.7103 - val_loss: 1.1718 - val_acc: 0.6963\n",
      "Epoch 997/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1564 - acc: 0.7105 - val_loss: 1.1715 - val_acc: 0.6967\n",
      "Epoch 998/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1560 - acc: 0.7106 - val_loss: 1.1710 - val_acc: 0.6958\n",
      "Epoch 999/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1557 - acc: 0.7105 - val_loss: 1.1707 - val_acc: 0.6950\n",
      "Epoch 1000/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1554 - acc: 0.7108 - val_loss: 1.1704 - val_acc: 0.6958\n",
      "Epoch 1001/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1550 - acc: 0.7106 - val_loss: 1.1701 - val_acc: 0.6963\n",
      "Epoch 1002/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.1547 - acc: 0.7108 - val_loss: 1.1699 - val_acc: 0.6958\n",
      "Epoch 1003/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1544 - acc: 0.7106 - val_loss: 1.1695 - val_acc: 0.6971\n",
      "Epoch 1004/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1540 - acc: 0.7111 - val_loss: 1.1692 - val_acc: 0.6971\n",
      "Epoch 1005/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1537 - acc: 0.7106 - val_loss: 1.1687 - val_acc: 0.6954\n",
      "Epoch 1006/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1533 - acc: 0.7111 - val_loss: 1.1687 - val_acc: 0.6958\n",
      "Epoch 1007/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1530 - acc: 0.7115 - val_loss: 1.1681 - val_acc: 0.6958\n",
      "Epoch 1008/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1526 - acc: 0.7104 - val_loss: 1.1678 - val_acc: 0.6954\n",
      "Epoch 1009/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1522 - acc: 0.7125 - val_loss: 1.1675 - val_acc: 0.6954\n",
      "Epoch 1010/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1519 - acc: 0.7109 - val_loss: 1.1672 - val_acc: 0.6971\n",
      "Epoch 1011/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1516 - acc: 0.7111 - val_loss: 1.1668 - val_acc: 0.6967\n",
      "Epoch 1012/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1512 - acc: 0.7120 - val_loss: 1.1667 - val_acc: 0.6950\n",
      "Epoch 1013/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1508 - acc: 0.7116 - val_loss: 1.1661 - val_acc: 0.6967\n",
      "Epoch 1014/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1505 - acc: 0.7115 - val_loss: 1.1660 - val_acc: 0.6971\n",
      "Epoch 1015/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1502 - acc: 0.7116 - val_loss: 1.1654 - val_acc: 0.6975\n",
      "Epoch 1016/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1499 - acc: 0.7107 - val_loss: 1.1652 - val_acc: 0.6954\n",
      "Epoch 1017/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1495 - acc: 0.7115 - val_loss: 1.1650 - val_acc: 0.6954\n",
      "Epoch 1018/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1492 - acc: 0.7106 - val_loss: 1.1647 - val_acc: 0.6963\n",
      "Epoch 1019/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1489 - acc: 0.7107 - val_loss: 1.1644 - val_acc: 0.6958\n",
      "Epoch 1020/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1485 - acc: 0.7115 - val_loss: 1.1641 - val_acc: 0.6967\n",
      "Epoch 1021/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1482 - acc: 0.7117 - val_loss: 1.1637 - val_acc: 0.6971\n",
      "Epoch 1022/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1479 - acc: 0.7118 - val_loss: 1.1632 - val_acc: 0.6971\n",
      "Epoch 1023/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1475 - acc: 0.7116 - val_loss: 1.1629 - val_acc: 0.6958\n",
      "Epoch 1024/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1472 - acc: 0.7118 - val_loss: 1.1628 - val_acc: 0.6958\n",
      "Epoch 1025/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1468 - acc: 0.7116 - val_loss: 1.1624 - val_acc: 0.6962\n",
      "Epoch 1026/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1464 - acc: 0.7118 - val_loss: 1.1620 - val_acc: 0.6958\n",
      "Epoch 1027/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1462 - acc: 0.7113 - val_loss: 1.1619 - val_acc: 0.6962\n",
      "Epoch 1028/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1458 - acc: 0.7121 - val_loss: 1.1615 - val_acc: 0.6962\n",
      "Epoch 1029/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1454 - acc: 0.7124 - val_loss: 1.1611 - val_acc: 0.6958\n",
      "Epoch 1030/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1451 - acc: 0.7111 - val_loss: 1.1608 - val_acc: 0.6963\n",
      "Epoch 1031/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1448 - acc: 0.7123 - val_loss: 1.1605 - val_acc: 0.6958\n",
      "Epoch 1032/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.1444 - acc: 0.7124 - val_loss: 1.1602 - val_acc: 0.6958\n",
      "Epoch 1033/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1441 - acc: 0.7116 - val_loss: 1.1601 - val_acc: 0.6967\n",
      "Epoch 1034/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1438 - acc: 0.7120 - val_loss: 1.1596 - val_acc: 0.6971\n",
      "Epoch 1035/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1435 - acc: 0.7129 - val_loss: 1.1594 - val_acc: 0.6975\n",
      "Epoch 1036/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1431 - acc: 0.7120 - val_loss: 1.1588 - val_acc: 0.6958\n",
      "Epoch 1037/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1428 - acc: 0.7124 - val_loss: 1.1585 - val_acc: 0.6963\n",
      "Epoch 1038/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1424 - acc: 0.7127 - val_loss: 1.1586 - val_acc: 0.6967\n",
      "Epoch 1039/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1422 - acc: 0.7128 - val_loss: 1.1581 - val_acc: 0.6975\n",
      "Epoch 1040/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1418 - acc: 0.7126 - val_loss: 1.1577 - val_acc: 0.6983\n",
      "Epoch 1041/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1415 - acc: 0.7127 - val_loss: 1.1576 - val_acc: 0.6971\n",
      "Epoch 1042/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1412 - acc: 0.7125 - val_loss: 1.1571 - val_acc: 0.6983\n",
      "Epoch 1043/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1408 - acc: 0.7128 - val_loss: 1.1568 - val_acc: 0.6979\n",
      "Epoch 1044/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1404 - acc: 0.7129 - val_loss: 1.1566 - val_acc: 0.6975\n",
      "Epoch 1045/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1402 - acc: 0.7131 - val_loss: 1.1563 - val_acc: 0.6975\n",
      "Epoch 1046/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1399 - acc: 0.7130 - val_loss: 1.1560 - val_acc: 0.6983\n",
      "Epoch 1047/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1395 - acc: 0.7130 - val_loss: 1.1556 - val_acc: 0.6967\n",
      "Epoch 1048/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1391 - acc: 0.7124 - val_loss: 1.1554 - val_acc: 0.6975\n",
      "Epoch 1049/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1389 - acc: 0.7137 - val_loss: 1.1551 - val_acc: 0.6979\n",
      "Epoch 1050/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1385 - acc: 0.7130 - val_loss: 1.1546 - val_acc: 0.6996\n",
      "Epoch 1051/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1383 - acc: 0.7139 - val_loss: 1.1544 - val_acc: 0.6983\n",
      "Epoch 1052/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1379 - acc: 0.7128 - val_loss: 1.1541 - val_acc: 0.6987\n",
      "Epoch 1053/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1375 - acc: 0.7130 - val_loss: 1.1537 - val_acc: 0.6988\n",
      "Epoch 1054/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1372 - acc: 0.7125 - val_loss: 1.1535 - val_acc: 0.6988\n",
      "Epoch 1055/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1369 - acc: 0.7134 - val_loss: 1.1531 - val_acc: 0.6975\n",
      "Epoch 1056/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1366 - acc: 0.7134 - val_loss: 1.1529 - val_acc: 0.6983\n",
      "Epoch 1057/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1363 - acc: 0.7133 - val_loss: 1.1524 - val_acc: 0.6983\n",
      "Epoch 1058/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1359 - acc: 0.7132 - val_loss: 1.1522 - val_acc: 0.6971\n",
      "Epoch 1059/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1356 - acc: 0.7130 - val_loss: 1.1520 - val_acc: 0.6967\n",
      "Epoch 1060/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1353 - acc: 0.7131 - val_loss: 1.1517 - val_acc: 0.6987\n",
      "Epoch 1061/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1350 - acc: 0.7135 - val_loss: 1.1516 - val_acc: 0.6975\n",
      "Epoch 1062/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1347 - acc: 0.7131 - val_loss: 1.1512 - val_acc: 0.6983\n",
      "Epoch 1063/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1343 - acc: 0.7144 - val_loss: 1.1510 - val_acc: 0.6979\n",
      "Epoch 1064/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1340 - acc: 0.7137 - val_loss: 1.1506 - val_acc: 0.6979\n",
      "Epoch 1065/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1338 - acc: 0.7140 - val_loss: 1.1504 - val_acc: 0.6983\n",
      "Epoch 1066/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1334 - acc: 0.7140 - val_loss: 1.1499 - val_acc: 0.6975\n",
      "Epoch 1067/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1331 - acc: 0.7136 - val_loss: 1.1495 - val_acc: 0.6992\n",
      "Epoch 1068/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1328 - acc: 0.7139 - val_loss: 1.1494 - val_acc: 0.6983\n",
      "Epoch 1069/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1324 - acc: 0.7139 - val_loss: 1.1490 - val_acc: 0.6992\n",
      "Epoch 1070/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1321 - acc: 0.7146 - val_loss: 1.1488 - val_acc: 0.6983\n",
      "Epoch 1071/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1319 - acc: 0.7135 - val_loss: 1.1486 - val_acc: 0.6983\n",
      "Epoch 1072/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1315 - acc: 0.7137 - val_loss: 1.1481 - val_acc: 0.6971\n",
      "Epoch 1073/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1311 - acc: 0.7137 - val_loss: 1.1479 - val_acc: 0.6983\n",
      "Epoch 1074/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1309 - acc: 0.7141 - val_loss: 1.1477 - val_acc: 0.6971\n",
      "Epoch 1075/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1305 - acc: 0.7140 - val_loss: 1.1472 - val_acc: 0.6987\n",
      "Epoch 1076/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1303 - acc: 0.7148 - val_loss: 1.1470 - val_acc: 0.6987\n",
      "Epoch 1077/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1299 - acc: 0.7147 - val_loss: 1.1468 - val_acc: 0.6987\n",
      "Epoch 1078/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1296 - acc: 0.7152 - val_loss: 1.1465 - val_acc: 0.6983\n",
      "Epoch 1079/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1293 - acc: 0.7147 - val_loss: 1.1462 - val_acc: 0.6987\n",
      "Epoch 1080/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1290 - acc: 0.7149 - val_loss: 1.1458 - val_acc: 0.6979\n",
      "Epoch 1081/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1287 - acc: 0.7142 - val_loss: 1.1456 - val_acc: 0.6987\n",
      "Epoch 1082/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1283 - acc: 0.7142 - val_loss: 1.1452 - val_acc: 0.6992\n",
      "Epoch 1083/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1281 - acc: 0.7149 - val_loss: 1.1451 - val_acc: 0.6987\n",
      "Epoch 1084/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1278 - acc: 0.7144 - val_loss: 1.1449 - val_acc: 0.6992\n",
      "Epoch 1085/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1274 - acc: 0.7144 - val_loss: 1.1444 - val_acc: 0.6987\n",
      "Epoch 1086/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1271 - acc: 0.7147 - val_loss: 1.1441 - val_acc: 0.6996\n",
      "Epoch 1087/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1268 - acc: 0.7144 - val_loss: 1.1437 - val_acc: 0.7000\n",
      "Epoch 1088/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1265 - acc: 0.7153 - val_loss: 1.1434 - val_acc: 0.6992\n",
      "Epoch 1089/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1263 - acc: 0.7151 - val_loss: 1.1433 - val_acc: 0.6992\n",
      "Epoch 1090/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1259 - acc: 0.7152 - val_loss: 1.1430 - val_acc: 0.6992\n",
      "Epoch 1091/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1256 - acc: 0.7149 - val_loss: 1.1426 - val_acc: 0.6992\n",
      "Epoch 1092/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1253 - acc: 0.7153 - val_loss: 1.1424 - val_acc: 0.6992\n",
      "Epoch 1093/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1250 - acc: 0.7151 - val_loss: 1.1422 - val_acc: 0.6996\n",
      "Epoch 1094/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1247 - acc: 0.7148 - val_loss: 1.1419 - val_acc: 0.6992\n",
      "Epoch 1095/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1244 - acc: 0.7146 - val_loss: 1.1415 - val_acc: 0.6992\n",
      "Epoch 1096/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1241 - acc: 0.7157 - val_loss: 1.1413 - val_acc: 0.6996\n",
      "Epoch 1097/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1238 - acc: 0.7157 - val_loss: 1.1412 - val_acc: 0.6987\n",
      "Epoch 1098/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1235 - acc: 0.7152 - val_loss: 1.1407 - val_acc: 0.7000\n",
      "Epoch 1099/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1232 - acc: 0.7155 - val_loss: 1.1405 - val_acc: 0.7004\n",
      "Epoch 1100/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1229 - acc: 0.7159 - val_loss: 1.1400 - val_acc: 0.6987\n",
      "Epoch 1101/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1226 - acc: 0.7150 - val_loss: 1.1399 - val_acc: 0.6996\n",
      "Epoch 1102/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1223 - acc: 0.7151 - val_loss: 1.1396 - val_acc: 0.7004\n",
      "Epoch 1103/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1220 - acc: 0.7155 - val_loss: 1.1393 - val_acc: 0.6987\n",
      "Epoch 1104/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1217 - acc: 0.7154 - val_loss: 1.1391 - val_acc: 0.7004\n",
      "Epoch 1105/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1214 - acc: 0.7158 - val_loss: 1.1389 - val_acc: 0.6996\n",
      "Epoch 1106/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1212 - acc: 0.7157 - val_loss: 1.1384 - val_acc: 0.6987\n",
      "Epoch 1107/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1209 - acc: 0.7145 - val_loss: 1.1384 - val_acc: 0.6996\n",
      "Epoch 1108/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.1206 - acc: 0.7157 - val_loss: 1.1379 - val_acc: 0.7004\n",
      "Epoch 1109/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1203 - acc: 0.7156 - val_loss: 1.1378 - val_acc: 0.7000\n",
      "Epoch 1110/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1199 - acc: 0.7158 - val_loss: 1.1376 - val_acc: 0.7004\n",
      "Epoch 1111/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1196 - acc: 0.7161 - val_loss: 1.1373 - val_acc: 0.7013\n",
      "Epoch 1112/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1193 - acc: 0.7156 - val_loss: 1.1369 - val_acc: 0.7004\n",
      "Epoch 1113/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1190 - acc: 0.7159 - val_loss: 1.1367 - val_acc: 0.6992\n",
      "Epoch 1114/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1187 - acc: 0.7159 - val_loss: 1.1364 - val_acc: 0.7000\n",
      "Epoch 1115/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1185 - acc: 0.7166 - val_loss: 1.1362 - val_acc: 0.6996\n",
      "Epoch 1116/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1181 - acc: 0.7159 - val_loss: 1.1359 - val_acc: 0.7004\n",
      "Epoch 1117/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.1179 - acc: 0.7173 - val_loss: 1.1357 - val_acc: 0.7004\n",
      "Epoch 1118/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.1176 - acc: 0.7161 - val_loss: 1.1351 - val_acc: 0.7000\n",
      "Epoch 1119/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.1172 - acc: 0.7166 - val_loss: 1.1350 - val_acc: 0.7000\n",
      "Epoch 1120/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.1170 - acc: 0.7160 - val_loss: 1.1348 - val_acc: 0.6996\n",
      "Epoch 1121/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.1167 - acc: 0.7166 - val_loss: 1.1345 - val_acc: 0.7000\n",
      "Epoch 1122/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.1165 - acc: 0.7155 - val_loss: 1.1342 - val_acc: 0.7013\n",
      "Epoch 1123/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.1161 - acc: 0.7161 - val_loss: 1.1338 - val_acc: 0.6996\n",
      "Epoch 1124/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.1159 - acc: 0.7163 - val_loss: 1.1337 - val_acc: 0.7000\n",
      "Epoch 1125/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.1156 - acc: 0.7165 - val_loss: 1.1334 - val_acc: 0.7004\n",
      "Epoch 1126/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.1152 - acc: 0.7163 - val_loss: 1.1330 - val_acc: 0.7013\n",
      "Epoch 1127/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.1150 - acc: 0.7168 - val_loss: 1.1328 - val_acc: 0.7013\n",
      "Epoch 1128/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.1146 - acc: 0.7156 - val_loss: 1.1326 - val_acc: 0.7008\n",
      "Epoch 1129/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.1144 - acc: 0.7164 - val_loss: 1.1324 - val_acc: 0.7008\n",
      "Epoch 1130/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.1141 - acc: 0.7164 - val_loss: 1.1322 - val_acc: 0.7017\n",
      "Epoch 1131/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.1138 - acc: 0.7167 - val_loss: 1.1319 - val_acc: 0.7008\n",
      "Epoch 1132/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.1135 - acc: 0.7167 - val_loss: 1.1314 - val_acc: 0.7000\n",
      "Epoch 1133/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.1132 - acc: 0.7173 - val_loss: 1.1313 - val_acc: 0.7017\n",
      "Epoch 1134/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1130 - acc: 0.7166 - val_loss: 1.1311 - val_acc: 0.7017\n",
      "Epoch 1135/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1127 - acc: 0.7159 - val_loss: 1.1306 - val_acc: 0.7008\n",
      "Epoch 1136/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1124 - acc: 0.7169 - val_loss: 1.1304 - val_acc: 0.7013\n",
      "Epoch 1137/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1121 - acc: 0.7174 - val_loss: 1.1303 - val_acc: 0.7021\n",
      "Epoch 1138/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1118 - acc: 0.7168 - val_loss: 1.1299 - val_acc: 0.7021\n",
      "Epoch 1139/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1115 - acc: 0.7169 - val_loss: 1.1298 - val_acc: 0.7037\n",
      "Epoch 1140/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1112 - acc: 0.7168 - val_loss: 1.1295 - val_acc: 0.7025\n",
      "Epoch 1141/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1110 - acc: 0.7167 - val_loss: 1.1291 - val_acc: 0.7021\n",
      "Epoch 1142/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1107 - acc: 0.7165 - val_loss: 1.1288 - val_acc: 0.7025\n",
      "Epoch 1143/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1104 - acc: 0.7169 - val_loss: 1.1285 - val_acc: 0.7013\n",
      "Epoch 1144/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1101 - acc: 0.7169 - val_loss: 1.1283 - val_acc: 0.7029\n",
      "Epoch 1145/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1098 - acc: 0.7168 - val_loss: 1.1283 - val_acc: 0.7033\n",
      "Epoch 1146/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1095 - acc: 0.7168 - val_loss: 1.1278 - val_acc: 0.7013\n",
      "Epoch 1147/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1092 - acc: 0.7167 - val_loss: 1.1275 - val_acc: 0.7017\n",
      "Epoch 1148/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1090 - acc: 0.7174 - val_loss: 1.1273 - val_acc: 0.7021\n",
      "Epoch 1149/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1087 - acc: 0.7178 - val_loss: 1.1271 - val_acc: 0.7029\n",
      "Epoch 1150/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1084 - acc: 0.7172 - val_loss: 1.1267 - val_acc: 0.7025\n",
      "Epoch 1151/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1082 - acc: 0.7172 - val_loss: 1.1266 - val_acc: 0.7033\n",
      "Epoch 1152/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1079 - acc: 0.7178 - val_loss: 1.1263 - val_acc: 0.7021\n",
      "Epoch 1153/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1075 - acc: 0.7171 - val_loss: 1.1259 - val_acc: 0.7037\n",
      "Epoch 1154/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1073 - acc: 0.7171 - val_loss: 1.1257 - val_acc: 0.7029\n",
      "Epoch 1155/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1071 - acc: 0.7175 - val_loss: 1.1255 - val_acc: 0.7025\n",
      "Epoch 1156/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1068 - acc: 0.7178 - val_loss: 1.1253 - val_acc: 0.7042\n",
      "Epoch 1157/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1065 - acc: 0.7181 - val_loss: 1.1250 - val_acc: 0.7021\n",
      "Epoch 1158/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1062 - acc: 0.7169 - val_loss: 1.1248 - val_acc: 0.7042\n",
      "Epoch 1159/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1059 - acc: 0.7171 - val_loss: 1.1245 - val_acc: 0.7037\n",
      "Epoch 1160/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1057 - acc: 0.7173 - val_loss: 1.1242 - val_acc: 0.7021\n",
      "Epoch 1161/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1054 - acc: 0.7176 - val_loss: 1.1241 - val_acc: 0.7029\n",
      "Epoch 1162/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1051 - acc: 0.7174 - val_loss: 1.1238 - val_acc: 0.7033\n",
      "Epoch 1163/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1048 - acc: 0.7176 - val_loss: 1.1235 - val_acc: 0.7042\n",
      "Epoch 1164/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1045 - acc: 0.7177 - val_loss: 1.1233 - val_acc: 0.7025\n",
      "Epoch 1165/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1044 - acc: 0.7168 - val_loss: 1.1229 - val_acc: 0.7042\n",
      "Epoch 1166/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1040 - acc: 0.7182 - val_loss: 1.1228 - val_acc: 0.7033\n",
      "Epoch 1167/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1037 - acc: 0.7170 - val_loss: 1.1224 - val_acc: 0.7025\n",
      "Epoch 1168/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1035 - acc: 0.7172 - val_loss: 1.1222 - val_acc: 0.7025\n",
      "Epoch 1169/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1033 - acc: 0.7181 - val_loss: 1.1221 - val_acc: 0.7029\n",
      "Epoch 1170/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1029 - acc: 0.7178 - val_loss: 1.1217 - val_acc: 0.7042\n",
      "Epoch 1171/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1026 - acc: 0.7174 - val_loss: 1.1215 - val_acc: 0.7033\n",
      "Epoch 1172/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1024 - acc: 0.7176 - val_loss: 1.1211 - val_acc: 0.7029\n",
      "Epoch 1173/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1021 - acc: 0.7174 - val_loss: 1.1210 - val_acc: 0.7033\n",
      "Epoch 1174/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.1018 - acc: 0.7175 - val_loss: 1.1206 - val_acc: 0.7029\n",
      "Epoch 1175/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1016 - acc: 0.7180 - val_loss: 1.1205 - val_acc: 0.7037\n",
      "Epoch 1176/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1013 - acc: 0.7178 - val_loss: 1.1203 - val_acc: 0.7042\n",
      "Epoch 1177/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1010 - acc: 0.7174 - val_loss: 1.1200 - val_acc: 0.7033\n",
      "Epoch 1178/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1007 - acc: 0.7180 - val_loss: 1.1197 - val_acc: 0.7033\n",
      "Epoch 1179/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.1005 - acc: 0.7182 - val_loss: 1.1195 - val_acc: 0.7029\n",
      "Epoch 1180/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1003 - acc: 0.7172 - val_loss: 1.1193 - val_acc: 0.7042\n",
      "Epoch 1181/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1000 - acc: 0.7176 - val_loss: 1.1189 - val_acc: 0.7033\n",
      "Epoch 1182/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0997 - acc: 0.7184 - val_loss: 1.1189 - val_acc: 0.7025\n",
      "Epoch 1183/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0994 - acc: 0.7181 - val_loss: 1.1186 - val_acc: 0.7029\n",
      "Epoch 1184/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0991 - acc: 0.7179 - val_loss: 1.1182 - val_acc: 0.7037\n",
      "Epoch 1185/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0989 - acc: 0.7176 - val_loss: 1.1180 - val_acc: 0.7037\n",
      "Epoch 1186/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0987 - acc: 0.7176 - val_loss: 1.1177 - val_acc: 0.7042\n",
      "Epoch 1187/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0983 - acc: 0.7186 - val_loss: 1.1175 - val_acc: 0.7042\n",
      "Epoch 1188/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0981 - acc: 0.7181 - val_loss: 1.1174 - val_acc: 0.7042\n",
      "Epoch 1189/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0978 - acc: 0.7177 - val_loss: 1.1170 - val_acc: 0.7033\n",
      "Epoch 1190/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0976 - acc: 0.7188 - val_loss: 1.1169 - val_acc: 0.7033\n",
      "Epoch 1191/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0973 - acc: 0.7186 - val_loss: 1.1165 - val_acc: 0.7029\n",
      "Epoch 1192/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0970 - acc: 0.7185 - val_loss: 1.1163 - val_acc: 0.7042\n",
      "Epoch 1193/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0968 - acc: 0.7178 - val_loss: 1.1161 - val_acc: 0.7033\n",
      "Epoch 1194/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0965 - acc: 0.7177 - val_loss: 1.1158 - val_acc: 0.7050\n",
      "Epoch 1195/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0963 - acc: 0.7181 - val_loss: 1.1157 - val_acc: 0.7042\n",
      "Epoch 1196/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0960 - acc: 0.7179 - val_loss: 1.1154 - val_acc: 0.7037\n",
      "Epoch 1197/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0957 - acc: 0.7183 - val_loss: 1.1150 - val_acc: 0.7050\n",
      "Epoch 1198/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0955 - acc: 0.7183 - val_loss: 1.1148 - val_acc: 0.7042\n",
      "Epoch 1199/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0952 - acc: 0.7177 - val_loss: 1.1145 - val_acc: 0.7046\n",
      "Epoch 1200/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0949 - acc: 0.7183 - val_loss: 1.1144 - val_acc: 0.7033\n",
      "Epoch 1201/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0947 - acc: 0.7181 - val_loss: 1.1140 - val_acc: 0.7042\n",
      "Epoch 1202/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0944 - acc: 0.7188 - val_loss: 1.1139 - val_acc: 0.7042\n",
      "Epoch 1203/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0942 - acc: 0.7188 - val_loss: 1.1137 - val_acc: 0.7042\n",
      "Epoch 1204/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0939 - acc: 0.7191 - val_loss: 1.1134 - val_acc: 0.7046\n",
      "Epoch 1205/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0936 - acc: 0.7184 - val_loss: 1.1132 - val_acc: 0.7050\n",
      "Epoch 1206/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0934 - acc: 0.7180 - val_loss: 1.1129 - val_acc: 0.7037\n",
      "Epoch 1207/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0931 - acc: 0.7185 - val_loss: 1.1128 - val_acc: 0.7042\n",
      "Epoch 1208/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0928 - acc: 0.7183 - val_loss: 1.1125 - val_acc: 0.7054\n",
      "Epoch 1209/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0926 - acc: 0.7177 - val_loss: 1.1123 - val_acc: 0.7029\n",
      "Epoch 1210/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0923 - acc: 0.7191 - val_loss: 1.1119 - val_acc: 0.7042\n",
      "Epoch 1211/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0921 - acc: 0.7185 - val_loss: 1.1119 - val_acc: 0.7058\n",
      "Epoch 1212/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0918 - acc: 0.7181 - val_loss: 1.1115 - val_acc: 0.7054\n",
      "Epoch 1213/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0915 - acc: 0.7183 - val_loss: 1.1113 - val_acc: 0.7063\n",
      "Epoch 1214/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0913 - acc: 0.7191 - val_loss: 1.1110 - val_acc: 0.7042\n",
      "Epoch 1215/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0911 - acc: 0.7188 - val_loss: 1.1109 - val_acc: 0.7054\n",
      "Epoch 1216/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0908 - acc: 0.7191 - val_loss: 1.1106 - val_acc: 0.7046\n",
      "Epoch 1217/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0906 - acc: 0.7182 - val_loss: 1.1104 - val_acc: 0.7054\n",
      "Epoch 1218/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0903 - acc: 0.7185 - val_loss: 1.1102 - val_acc: 0.7054\n",
      "Epoch 1219/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0900 - acc: 0.7186 - val_loss: 1.1100 - val_acc: 0.7050\n",
      "Epoch 1220/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0898 - acc: 0.7190 - val_loss: 1.1096 - val_acc: 0.7042\n",
      "Epoch 1221/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0895 - acc: 0.7194 - val_loss: 1.1093 - val_acc: 0.7042\n",
      "Epoch 1222/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0894 - acc: 0.7191 - val_loss: 1.1093 - val_acc: 0.7058\n",
      "Epoch 1223/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0890 - acc: 0.7189 - val_loss: 1.1088 - val_acc: 0.7042\n",
      "Epoch 1224/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0887 - acc: 0.7186 - val_loss: 1.1087 - val_acc: 0.7054\n",
      "Epoch 1225/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0885 - acc: 0.7185 - val_loss: 1.1086 - val_acc: 0.7046\n",
      "Epoch 1226/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0882 - acc: 0.7191 - val_loss: 1.1083 - val_acc: 0.7054\n",
      "Epoch 1227/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0880 - acc: 0.7188 - val_loss: 1.1081 - val_acc: 0.7063\n",
      "Epoch 1228/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0877 - acc: 0.7191 - val_loss: 1.1079 - val_acc: 0.7058\n",
      "Epoch 1229/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0875 - acc: 0.7189 - val_loss: 1.1076 - val_acc: 0.7046\n",
      "Epoch 1230/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0872 - acc: 0.7192 - val_loss: 1.1074 - val_acc: 0.7042\n",
      "Epoch 1231/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0870 - acc: 0.7190 - val_loss: 1.1071 - val_acc: 0.7054\n",
      "Epoch 1232/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0867 - acc: 0.7189 - val_loss: 1.1067 - val_acc: 0.7046\n",
      "Epoch 1233/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0865 - acc: 0.7192 - val_loss: 1.1067 - val_acc: 0.7046\n",
      "Epoch 1234/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0863 - acc: 0.7191 - val_loss: 1.1064 - val_acc: 0.7058\n",
      "Epoch 1235/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0860 - acc: 0.7197 - val_loss: 1.1063 - val_acc: 0.7050\n",
      "Epoch 1236/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0857 - acc: 0.7191 - val_loss: 1.1060 - val_acc: 0.7054\n",
      "Epoch 1237/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0855 - acc: 0.7196 - val_loss: 1.1057 - val_acc: 0.7054\n",
      "Epoch 1238/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0852 - acc: 0.7191 - val_loss: 1.1056 - val_acc: 0.7063\n",
      "Epoch 1239/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0850 - acc: 0.7189 - val_loss: 1.1052 - val_acc: 0.7042\n",
      "Epoch 1240/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0847 - acc: 0.7200 - val_loss: 1.1050 - val_acc: 0.7054\n",
      "Epoch 1241/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0844 - acc: 0.7189 - val_loss: 1.1048 - val_acc: 0.7054\n",
      "Epoch 1242/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0842 - acc: 0.7196 - val_loss: 1.1045 - val_acc: 0.7054\n",
      "Epoch 1243/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0840 - acc: 0.7199 - val_loss: 1.1044 - val_acc: 0.7058\n",
      "Epoch 1244/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0838 - acc: 0.7192 - val_loss: 1.1043 - val_acc: 0.7067\n",
      "Epoch 1245/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.0835 - acc: 0.7195 - val_loss: 1.1038 - val_acc: 0.7054\n",
      "Epoch 1246/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0833 - acc: 0.7194 - val_loss: 1.1036 - val_acc: 0.7063\n",
      "Epoch 1247/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0830 - acc: 0.7196 - val_loss: 1.1035 - val_acc: 0.7058\n",
      "Epoch 1248/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0828 - acc: 0.7190 - val_loss: 1.1033 - val_acc: 0.7058\n",
      "Epoch 1249/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0825 - acc: 0.7200 - val_loss: 1.1031 - val_acc: 0.7058\n",
      "Epoch 1250/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0822 - acc: 0.7200 - val_loss: 1.1028 - val_acc: 0.7067\n",
      "Epoch 1251/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0820 - acc: 0.7196 - val_loss: 1.1025 - val_acc: 0.7071\n",
      "Epoch 1252/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0818 - acc: 0.7199 - val_loss: 1.1024 - val_acc: 0.7058\n",
      "Epoch 1253/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0815 - acc: 0.7203 - val_loss: 1.1021 - val_acc: 0.7067\n",
      "Epoch 1254/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0813 - acc: 0.7192 - val_loss: 1.1019 - val_acc: 0.7079\n",
      "Epoch 1255/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0811 - acc: 0.7200 - val_loss: 1.1016 - val_acc: 0.7058\n",
      "Epoch 1256/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0809 - acc: 0.7193 - val_loss: 1.1012 - val_acc: 0.7058\n",
      "Epoch 1257/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0805 - acc: 0.7199 - val_loss: 1.1011 - val_acc: 0.7067\n",
      "Epoch 1258/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0803 - acc: 0.7196 - val_loss: 1.1009 - val_acc: 0.7067\n",
      "Epoch 1259/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0801 - acc: 0.7201 - val_loss: 1.1008 - val_acc: 0.7063\n",
      "Epoch 1260/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0799 - acc: 0.7190 - val_loss: 1.1006 - val_acc: 0.7054\n",
      "Epoch 1261/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0796 - acc: 0.7202 - val_loss: 1.1006 - val_acc: 0.7058\n",
      "Epoch 1262/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0793 - acc: 0.7203 - val_loss: 1.1002 - val_acc: 0.7058\n",
      "Epoch 1263/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0791 - acc: 0.7205 - val_loss: 1.0999 - val_acc: 0.7071\n",
      "Epoch 1264/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0789 - acc: 0.7198 - val_loss: 1.0997 - val_acc: 0.7071\n",
      "Epoch 1265/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0786 - acc: 0.7204 - val_loss: 1.0996 - val_acc: 0.7067\n",
      "Epoch 1266/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0783 - acc: 0.7196 - val_loss: 1.0993 - val_acc: 0.7063\n",
      "Epoch 1267/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0781 - acc: 0.7200 - val_loss: 1.0991 - val_acc: 0.7058\n",
      "Epoch 1268/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0779 - acc: 0.7204 - val_loss: 1.0988 - val_acc: 0.7058\n",
      "Epoch 1269/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.0777 - acc: 0.7201 - val_loss: 1.0984 - val_acc: 0.7063\n",
      "Epoch 1270/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.0774 - acc: 0.7198 - val_loss: 1.0984 - val_acc: 0.7071\n",
      "Epoch 1271/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.0772 - acc: 0.7197 - val_loss: 1.0981 - val_acc: 0.7071\n",
      "Epoch 1272/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.0769 - acc: 0.7203 - val_loss: 1.0978 - val_acc: 0.7058\n",
      "Epoch 1273/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.0766 - acc: 0.7199 - val_loss: 1.0976 - val_acc: 0.7058\n",
      "Epoch 1274/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.0764 - acc: 0.7204 - val_loss: 1.0974 - val_acc: 0.7067\n",
      "Epoch 1275/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.0762 - acc: 0.7216 - val_loss: 1.0973 - val_acc: 0.7063\n",
      "Epoch 1276/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.0760 - acc: 0.7206 - val_loss: 1.0970 - val_acc: 0.7063\n",
      "Epoch 1277/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.0757 - acc: 0.7203 - val_loss: 1.0968 - val_acc: 0.7063\n",
      "Epoch 1278/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0755 - acc: 0.7207 - val_loss: 1.0965 - val_acc: 0.7063\n",
      "Epoch 1279/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0753 - acc: 0.7199 - val_loss: 1.0965 - val_acc: 0.7071\n",
      "Epoch 1280/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0750 - acc: 0.7201 - val_loss: 1.0960 - val_acc: 0.7058\n",
      "Epoch 1281/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0748 - acc: 0.7200 - val_loss: 1.0960 - val_acc: 0.7071\n",
      "Epoch 1282/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.0746 - acc: 0.7199 - val_loss: 1.0958 - val_acc: 0.7067\n",
      "Epoch 1283/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.0743 - acc: 0.7203 - val_loss: 1.0955 - val_acc: 0.7058\n",
      "Epoch 1284/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0741 - acc: 0.7210 - val_loss: 1.0954 - val_acc: 0.7071\n",
      "Epoch 1285/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0738 - acc: 0.7209 - val_loss: 1.0950 - val_acc: 0.7067\n",
      "Epoch 1286/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0736 - acc: 0.7210 - val_loss: 1.0950 - val_acc: 0.7067\n",
      "Epoch 1287/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.0734 - acc: 0.7202 - val_loss: 1.0946 - val_acc: 0.7071\n",
      "Epoch 1288/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.0732 - acc: 0.7209 - val_loss: 1.0944 - val_acc: 0.7075\n",
      "Epoch 1289/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.0729 - acc: 0.7208 - val_loss: 1.0942 - val_acc: 0.7067\n",
      "Epoch 1290/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0727 - acc: 0.7201 - val_loss: 1.0941 - val_acc: 0.7067\n",
      "Epoch 1291/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.0724 - acc: 0.7204 - val_loss: 1.0939 - val_acc: 0.7067\n",
      "Epoch 1292/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.0722 - acc: 0.7205 - val_loss: 1.0936 - val_acc: 0.7075\n",
      "Epoch 1293/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0720 - acc: 0.7203 - val_loss: 1.0934 - val_acc: 0.7071\n",
      "Epoch 1294/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0717 - acc: 0.7210 - val_loss: 1.0932 - val_acc: 0.7063\n",
      "Epoch 1295/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0715 - acc: 0.7210 - val_loss: 1.0930 - val_acc: 0.7075\n",
      "Epoch 1296/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0713 - acc: 0.7209 - val_loss: 1.0927 - val_acc: 0.7054\n",
      "Epoch 1297/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0711 - acc: 0.7209 - val_loss: 1.0926 - val_acc: 0.7075\n",
      "Epoch 1298/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0708 - acc: 0.7202 - val_loss: 1.0923 - val_acc: 0.7067\n",
      "Epoch 1299/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0706 - acc: 0.7207 - val_loss: 1.0921 - val_acc: 0.7075\n",
      "Epoch 1300/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0703 - acc: 0.7216 - val_loss: 1.0920 - val_acc: 0.7063\n",
      "Epoch 1301/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0701 - acc: 0.7210 - val_loss: 1.0918 - val_acc: 0.7071\n",
      "Epoch 1302/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0699 - acc: 0.7214 - val_loss: 1.0916 - val_acc: 0.7067\n",
      "Epoch 1303/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0697 - acc: 0.7209 - val_loss: 1.0913 - val_acc: 0.7071\n",
      "Epoch 1304/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.0695 - acc: 0.7218 - val_loss: 1.0911 - val_acc: 0.7075\n",
      "Val loss: 1.1019,Val acc: 0.7079\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  DATASET MRB  ----------\n",
      "(9600, 28, 28, 1) train samples\n",
      "(2400, 28, 28, 1) validation samples\n",
      "(50000, 28, 28, 1) test samples\n",
      "\n",
      "\tTraining model:\n",
      "logreg\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 2.3010 - acc: 0.1178 - val_loss: 2.2994 - val_acc: 0.1021\n",
      "Epoch 2/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2975 - acc: 0.1130 - val_loss: 2.2964 - val_acc: 0.1021\n",
      "Epoch 3/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2946 - acc: 0.1130 - val_loss: 2.2938 - val_acc: 0.1021\n",
      "Epoch 4/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2916 - acc: 0.1133 - val_loss: 2.2909 - val_acc: 0.1021\n",
      "Epoch 5/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2888 - acc: 0.1130 - val_loss: 2.2882 - val_acc: 0.1021\n",
      "Epoch 6/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.2858 - acc: 0.1194 - val_loss: 2.2855 - val_acc: 0.1025\n",
      "Epoch 7/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2830 - acc: 0.1133 - val_loss: 2.2827 - val_acc: 0.1025\n",
      "Epoch 8/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2802 - acc: 0.1206 - val_loss: 2.2800 - val_acc: 0.1071\n",
      "Epoch 9/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2773 - acc: 0.1364 - val_loss: 2.2772 - val_acc: 0.1250\n",
      "Epoch 10/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.2745 - acc: 0.1300 - val_loss: 2.2745 - val_acc: 0.1212\n",
      "Epoch 11/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2716 - acc: 0.1730 - val_loss: 2.2717 - val_acc: 0.1454\n",
      "Epoch 12/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2687 - acc: 0.1592 - val_loss: 2.2691 - val_acc: 0.1575\n",
      "Epoch 13/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.2658 - acc: 0.1821 - val_loss: 2.2664 - val_acc: 0.1617\n",
      "Epoch 14/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.2630 - acc: 0.2015 - val_loss: 2.2635 - val_acc: 0.1804\n",
      "Epoch 15/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2601 - acc: 0.1876 - val_loss: 2.2608 - val_acc: 0.1983\n",
      "Epoch 16/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2572 - acc: 0.2488 - val_loss: 2.2580 - val_acc: 0.2429\n",
      "Epoch 17/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2545 - acc: 0.2804 - val_loss: 2.2553 - val_acc: 0.2721\n",
      "Epoch 18/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.2516 - acc: 0.2639 - val_loss: 2.2527 - val_acc: 0.2421\n",
      "Epoch 19/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 2.2488 - acc: 0.3066 - val_loss: 2.2499 - val_acc: 0.3025\n",
      "Epoch 20/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2460 - acc: 0.3088 - val_loss: 2.2472 - val_acc: 0.2996\n",
      "Epoch 21/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2431 - acc: 0.3189 - val_loss: 2.2444 - val_acc: 0.3233\n",
      "Epoch 22/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2403 - acc: 0.2964 - val_loss: 2.2417 - val_acc: 0.3221\n",
      "Epoch 23/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2374 - acc: 0.3644 - val_loss: 2.2389 - val_acc: 0.3708\n",
      "Epoch 24/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2346 - acc: 0.3933 - val_loss: 2.2362 - val_acc: 0.3879\n",
      "Epoch 25/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2318 - acc: 0.3651 - val_loss: 2.2335 - val_acc: 0.3896\n",
      "Epoch 26/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2290 - acc: 0.3845 - val_loss: 2.2310 - val_acc: 0.3787\n",
      "Epoch 27/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2262 - acc: 0.4260 - val_loss: 2.2282 - val_acc: 0.4138\n",
      "Epoch 28/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2234 - acc: 0.4028 - val_loss: 2.2255 - val_acc: 0.4104\n",
      "Epoch 29/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.2207 - acc: 0.4484 - val_loss: 2.2227 - val_acc: 0.4329\n",
      "Epoch 30/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.2178 - acc: 0.4469 - val_loss: 2.2201 - val_acc: 0.4229\n",
      "Epoch 31/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2151 - acc: 0.4492 - val_loss: 2.2175 - val_acc: 0.4333\n",
      "Epoch 32/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2123 - acc: 0.4475 - val_loss: 2.2148 - val_acc: 0.4721\n",
      "Epoch 33/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2095 - acc: 0.4561 - val_loss: 2.2121 - val_acc: 0.4650\n",
      "Epoch 34/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2067 - acc: 0.4830 - val_loss: 2.2094 - val_acc: 0.4758\n",
      "Epoch 35/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2039 - acc: 0.5033 - val_loss: 2.2068 - val_acc: 0.4875\n",
      "Epoch 36/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2012 - acc: 0.4914 - val_loss: 2.2041 - val_acc: 0.4967\n",
      "Epoch 37/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 2.1984 - acc: 0.5019 - val_loss: 2.2016 - val_acc: 0.5029\n",
      "Epoch 38/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.1957 - acc: 0.5045 - val_loss: 2.1988 - val_acc: 0.5112\n",
      "Epoch 39/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 2.1930 - acc: 0.5346 - val_loss: 2.1962 - val_acc: 0.5113\n",
      "Epoch 40/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 2.1902 - acc: 0.5154 - val_loss: 2.1937 - val_acc: 0.5112\n",
      "Epoch 41/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1874 - acc: 0.5465 - val_loss: 2.1910 - val_acc: 0.5221\n",
      "Epoch 42/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.1847 - acc: 0.5281 - val_loss: 2.1884 - val_acc: 0.5238\n",
      "Epoch 43/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1820 - acc: 0.5452 - val_loss: 2.1856 - val_acc: 0.5358\n",
      "Epoch 44/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1792 - acc: 0.5487 - val_loss: 2.1831 - val_acc: 0.5271\n",
      "Epoch 45/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1765 - acc: 0.5476 - val_loss: 2.1805 - val_acc: 0.5383\n",
      "Epoch 46/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1738 - acc: 0.5812 - val_loss: 2.1779 - val_acc: 0.5433\n",
      "Epoch 47/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1712 - acc: 0.5606 - val_loss: 2.1753 - val_acc: 0.5392\n",
      "Epoch 48/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1683 - acc: 0.5647 - val_loss: 2.1726 - val_acc: 0.5487\n",
      "Epoch 49/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1656 - acc: 0.5726 - val_loss: 2.1700 - val_acc: 0.5625\n",
      "Epoch 50/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1629 - acc: 0.5600 - val_loss: 2.1675 - val_acc: 0.5621\n",
      "Epoch 51/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1602 - acc: 0.5760 - val_loss: 2.1648 - val_acc: 0.5625\n",
      "Epoch 52/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1575 - acc: 0.5908 - val_loss: 2.1622 - val_acc: 0.5717\n",
      "Epoch 53/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 22us/step - loss: 2.1549 - acc: 0.5685 - val_loss: 2.1598 - val_acc: 0.5779\n",
      "Epoch 54/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1520 - acc: 0.6025 - val_loss: 2.1570 - val_acc: 0.5763\n",
      "Epoch 55/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1493 - acc: 0.6014 - val_loss: 2.1544 - val_acc: 0.5742\n",
      "Epoch 56/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1467 - acc: 0.5930 - val_loss: 2.1518 - val_acc: 0.5767\n",
      "Epoch 57/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1440 - acc: 0.5974 - val_loss: 2.1494 - val_acc: 0.5754\n",
      "Epoch 58/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1414 - acc: 0.5911 - val_loss: 2.1467 - val_acc: 0.5937\n",
      "Epoch 59/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1387 - acc: 0.6089 - val_loss: 2.1442 - val_acc: 0.5863\n",
      "Epoch 60/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1359 - acc: 0.6155 - val_loss: 2.1415 - val_acc: 0.5917\n",
      "Epoch 61/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1333 - acc: 0.6284 - val_loss: 2.1391 - val_acc: 0.5975\n",
      "Epoch 62/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1306 - acc: 0.6144 - val_loss: 2.1367 - val_acc: 0.5863\n",
      "Epoch 63/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1280 - acc: 0.6076 - val_loss: 2.1341 - val_acc: 0.5871\n",
      "Epoch 64/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1253 - acc: 0.6251 - val_loss: 2.1314 - val_acc: 0.5996\n",
      "Epoch 65/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1227 - acc: 0.6258 - val_loss: 2.1288 - val_acc: 0.5933\n",
      "Epoch 66/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1200 - acc: 0.6224 - val_loss: 2.1264 - val_acc: 0.6025\n",
      "Epoch 67/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1175 - acc: 0.6230 - val_loss: 2.1238 - val_acc: 0.6000\n",
      "Epoch 68/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1148 - acc: 0.6323 - val_loss: 2.1213 - val_acc: 0.6033\n",
      "Epoch 69/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1121 - acc: 0.6279 - val_loss: 2.1188 - val_acc: 0.6021\n",
      "Epoch 70/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1095 - acc: 0.6253 - val_loss: 2.1164 - val_acc: 0.5988\n",
      "Epoch 71/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1069 - acc: 0.6377 - val_loss: 2.1137 - val_acc: 0.6054\n",
      "Epoch 72/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1042 - acc: 0.6377 - val_loss: 2.1111 - val_acc: 0.6096\n",
      "Epoch 73/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1017 - acc: 0.6332 - val_loss: 2.1086 - val_acc: 0.6263\n",
      "Epoch 74/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0990 - acc: 0.6536 - val_loss: 2.1062 - val_acc: 0.6250\n",
      "Epoch 75/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0964 - acc: 0.6371 - val_loss: 2.1038 - val_acc: 0.6054\n",
      "Epoch 76/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0938 - acc: 0.6389 - val_loss: 2.1013 - val_acc: 0.6158\n",
      "Epoch 77/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0911 - acc: 0.6486 - val_loss: 2.0987 - val_acc: 0.6212\n",
      "Epoch 78/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0886 - acc: 0.6488 - val_loss: 2.0962 - val_acc: 0.6229\n",
      "Epoch 79/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0860 - acc: 0.6471 - val_loss: 2.0937 - val_acc: 0.6238\n",
      "Epoch 80/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0834 - acc: 0.6485 - val_loss: 2.0912 - val_acc: 0.6229\n",
      "Epoch 81/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0809 - acc: 0.6511 - val_loss: 2.0888 - val_acc: 0.6258\n",
      "Epoch 82/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0782 - acc: 0.6411 - val_loss: 2.0863 - val_acc: 0.6300\n",
      "Epoch 83/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0756 - acc: 0.6617 - val_loss: 2.0838 - val_acc: 0.6300\n",
      "Epoch 84/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0731 - acc: 0.6466 - val_loss: 2.0815 - val_acc: 0.6254\n",
      "Epoch 85/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0705 - acc: 0.6538 - val_loss: 2.0788 - val_acc: 0.6350\n",
      "Epoch 86/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0679 - acc: 0.6667 - val_loss: 2.0763 - val_acc: 0.6312\n",
      "Epoch 87/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0654 - acc: 0.6597 - val_loss: 2.0741 - val_acc: 0.6329\n",
      "Epoch 88/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0628 - acc: 0.6581 - val_loss: 2.0716 - val_acc: 0.6308\n",
      "Epoch 89/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0602 - acc: 0.6695 - val_loss: 2.0689 - val_acc: 0.6429\n",
      "Epoch 90/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0576 - acc: 0.6548 - val_loss: 2.0668 - val_acc: 0.6296\n",
      "Epoch 91/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0552 - acc: 0.6558 - val_loss: 2.0642 - val_acc: 0.6408\n",
      "Epoch 92/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0526 - acc: 0.6632 - val_loss: 2.0617 - val_acc: 0.6446\n",
      "Epoch 93/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0501 - acc: 0.6696 - val_loss: 2.0592 - val_acc: 0.6408\n",
      "Epoch 94/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0475 - acc: 0.6665 - val_loss: 2.0569 - val_acc: 0.6421\n",
      "Epoch 95/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0450 - acc: 0.6714 - val_loss: 2.0544 - val_acc: 0.6412\n",
      "Epoch 96/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0424 - acc: 0.6719 - val_loss: 2.0520 - val_acc: 0.6500\n",
      "Epoch 97/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0400 - acc: 0.6668 - val_loss: 2.0497 - val_acc: 0.6479\n",
      "Epoch 98/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0375 - acc: 0.6737 - val_loss: 2.0472 - val_acc: 0.6475\n",
      "Epoch 99/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 2.0350 - acc: 0.6666 - val_loss: 2.0447 - val_acc: 0.6458\n",
      "Epoch 100/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0324 - acc: 0.6778 - val_loss: 2.0424 - val_acc: 0.6508\n",
      "Epoch 101/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0299 - acc: 0.6785 - val_loss: 2.0402 - val_acc: 0.6454\n",
      "Epoch 102/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0273 - acc: 0.6816 - val_loss: 2.0376 - val_acc: 0.6554\n",
      "Epoch 103/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 2.0249 - acc: 0.6724 - val_loss: 2.0351 - val_acc: 0.6496\n",
      "Epoch 104/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0224 - acc: 0.6793 - val_loss: 2.0327 - val_acc: 0.6542\n",
      "Epoch 105/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0200 - acc: 0.6703 - val_loss: 2.0304 - val_acc: 0.6513\n",
      "Epoch 106/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0174 - acc: 0.6802 - val_loss: 2.0279 - val_acc: 0.6558\n",
      "Epoch 107/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0149 - acc: 0.6836 - val_loss: 2.0256 - val_acc: 0.6554\n",
      "Epoch 108/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0125 - acc: 0.6835 - val_loss: 2.0232 - val_acc: 0.6592\n",
      "Epoch 109/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0100 - acc: 0.6782 - val_loss: 2.0209 - val_acc: 0.6546\n",
      "Epoch 110/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0075 - acc: 0.6834 - val_loss: 2.0185 - val_acc: 0.6554\n",
      "Epoch 111/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0051 - acc: 0.6885 - val_loss: 2.0163 - val_acc: 0.6554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0026 - acc: 0.6866 - val_loss: 2.0139 - val_acc: 0.6567\n",
      "Epoch 113/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0001 - acc: 0.6828 - val_loss: 2.0116 - val_acc: 0.6529\n",
      "Epoch 114/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9977 - acc: 0.6920 - val_loss: 2.0091 - val_acc: 0.6617\n",
      "Epoch 115/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9952 - acc: 0.6840 - val_loss: 2.0068 - val_acc: 0.6575\n",
      "Epoch 116/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9928 - acc: 0.6894 - val_loss: 2.0045 - val_acc: 0.6558\n",
      "Epoch 117/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9904 - acc: 0.6903 - val_loss: 2.0022 - val_acc: 0.6613\n",
      "Epoch 118/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9879 - acc: 0.6896 - val_loss: 1.9998 - val_acc: 0.6571\n",
      "Epoch 119/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.9854 - acc: 0.6890 - val_loss: 1.9974 - val_acc: 0.6625\n",
      "Epoch 120/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.9831 - acc: 0.6900 - val_loss: 1.9951 - val_acc: 0.6621\n",
      "Epoch 121/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9806 - acc: 0.6911 - val_loss: 1.9928 - val_acc: 0.6613\n",
      "Epoch 122/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9782 - acc: 0.6891 - val_loss: 1.9904 - val_acc: 0.6646\n",
      "Epoch 123/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9758 - acc: 0.6916 - val_loss: 1.9881 - val_acc: 0.6671\n",
      "Epoch 124/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9733 - acc: 0.6903 - val_loss: 1.9857 - val_acc: 0.6637\n",
      "Epoch 125/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9709 - acc: 0.6925 - val_loss: 1.9835 - val_acc: 0.6633\n",
      "Epoch 126/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9685 - acc: 0.6993 - val_loss: 1.9811 - val_acc: 0.6662\n",
      "Epoch 127/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9661 - acc: 0.6969 - val_loss: 1.9787 - val_acc: 0.6675\n",
      "Epoch 128/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9638 - acc: 0.6894 - val_loss: 1.9766 - val_acc: 0.6671\n",
      "Epoch 129/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9613 - acc: 0.7000 - val_loss: 1.9742 - val_acc: 0.6654\n",
      "Epoch 130/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9590 - acc: 0.6945 - val_loss: 1.9721 - val_acc: 0.6692\n",
      "Epoch 131/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9566 - acc: 0.6970 - val_loss: 1.9697 - val_acc: 0.6721\n",
      "Epoch 132/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9542 - acc: 0.6939 - val_loss: 1.9674 - val_acc: 0.6683\n",
      "Epoch 133/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9517 - acc: 0.6961 - val_loss: 1.9651 - val_acc: 0.6683\n",
      "Epoch 134/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9493 - acc: 0.7044 - val_loss: 1.9628 - val_acc: 0.6688\n",
      "Epoch 135/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9470 - acc: 0.7002 - val_loss: 1.9608 - val_acc: 0.6717\n",
      "Epoch 136/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9447 - acc: 0.6950 - val_loss: 1.9583 - val_acc: 0.6696\n",
      "Epoch 137/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9423 - acc: 0.6990 - val_loss: 1.9560 - val_acc: 0.6679\n",
      "Epoch 138/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9399 - acc: 0.6985 - val_loss: 1.9537 - val_acc: 0.6754\n",
      "Epoch 139/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9376 - acc: 0.7076 - val_loss: 1.9515 - val_acc: 0.6733\n",
      "Epoch 140/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9352 - acc: 0.6991 - val_loss: 1.9492 - val_acc: 0.6671\n",
      "Epoch 141/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9328 - acc: 0.7010 - val_loss: 1.9472 - val_acc: 0.6708\n",
      "Epoch 142/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9305 - acc: 0.7047 - val_loss: 1.9447 - val_acc: 0.6717\n",
      "Epoch 143/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9281 - acc: 0.7036 - val_loss: 1.9425 - val_acc: 0.6725\n",
      "Epoch 144/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9258 - acc: 0.7054 - val_loss: 1.9403 - val_acc: 0.6746\n",
      "Epoch 145/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9234 - acc: 0.7108 - val_loss: 1.9380 - val_acc: 0.6729\n",
      "Epoch 146/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9212 - acc: 0.7007 - val_loss: 1.9358 - val_acc: 0.6712\n",
      "Epoch 147/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9188 - acc: 0.7048 - val_loss: 1.9335 - val_acc: 0.6737\n",
      "Epoch 148/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9165 - acc: 0.7022 - val_loss: 1.9314 - val_acc: 0.6754\n",
      "Epoch 149/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9142 - acc: 0.7104 - val_loss: 1.9291 - val_acc: 0.6742\n",
      "Epoch 150/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9119 - acc: 0.7077 - val_loss: 1.9269 - val_acc: 0.6767\n",
      "Epoch 151/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9096 - acc: 0.7080 - val_loss: 1.9248 - val_acc: 0.6758\n",
      "Epoch 152/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9072 - acc: 0.7085 - val_loss: 1.9226 - val_acc: 0.6746\n",
      "Epoch 153/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9049 - acc: 0.7084 - val_loss: 1.9202 - val_acc: 0.6771\n",
      "Epoch 154/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9027 - acc: 0.7078 - val_loss: 1.9181 - val_acc: 0.6725\n",
      "Epoch 155/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.9004 - acc: 0.7083 - val_loss: 1.9159 - val_acc: 0.6754\n",
      "Epoch 156/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8980 - acc: 0.7090 - val_loss: 1.9136 - val_acc: 0.6775\n",
      "Epoch 157/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8958 - acc: 0.7122 - val_loss: 1.9115 - val_acc: 0.6763\n",
      "Epoch 158/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.8934 - acc: 0.7113 - val_loss: 1.9092 - val_acc: 0.6771\n",
      "Epoch 159/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8911 - acc: 0.7103 - val_loss: 1.9070 - val_acc: 0.6767\n",
      "Epoch 160/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8889 - acc: 0.7130 - val_loss: 1.9049 - val_acc: 0.6804\n",
      "Epoch 161/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8865 - acc: 0.7166 - val_loss: 1.9026 - val_acc: 0.6779\n",
      "Epoch 162/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.8843 - acc: 0.7145 - val_loss: 1.9003 - val_acc: 0.6779\n",
      "Epoch 163/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8821 - acc: 0.7072 - val_loss: 1.8985 - val_acc: 0.6796\n",
      "Epoch 164/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8798 - acc: 0.7137 - val_loss: 1.8962 - val_acc: 0.6792\n",
      "Epoch 165/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8776 - acc: 0.7104 - val_loss: 1.8940 - val_acc: 0.6796\n",
      "Epoch 166/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8753 - acc: 0.7169 - val_loss: 1.8918 - val_acc: 0.6829\n",
      "Epoch 167/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8731 - acc: 0.7191 - val_loss: 1.8898 - val_acc: 0.6792\n",
      "Epoch 168/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8708 - acc: 0.7166 - val_loss: 1.8877 - val_acc: 0.6812\n",
      "Epoch 169/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8685 - acc: 0.7168 - val_loss: 1.8855 - val_acc: 0.6779\n",
      "Epoch 170/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8664 - acc: 0.7170 - val_loss: 1.8834 - val_acc: 0.6804\n",
      "Epoch 171/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8641 - acc: 0.7167 - val_loss: 1.8812 - val_acc: 0.6787\n",
      "Epoch 172/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8619 - acc: 0.7129 - val_loss: 1.8790 - val_acc: 0.6825\n",
      "Epoch 173/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8597 - acc: 0.7181 - val_loss: 1.8768 - val_acc: 0.6825\n",
      "Epoch 174/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8574 - acc: 0.7164 - val_loss: 1.8748 - val_acc: 0.6858\n",
      "Epoch 175/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.8551 - acc: 0.7198 - val_loss: 1.8726 - val_acc: 0.6837\n",
      "Epoch 176/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8530 - acc: 0.7204 - val_loss: 1.8705 - val_acc: 0.6837\n",
      "Epoch 177/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8508 - acc: 0.7215 - val_loss: 1.8683 - val_acc: 0.6846\n",
      "Epoch 178/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8485 - acc: 0.7168 - val_loss: 1.8662 - val_acc: 0.6829\n",
      "Epoch 179/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8464 - acc: 0.7212 - val_loss: 1.8643 - val_acc: 0.6858\n",
      "Epoch 180/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8441 - acc: 0.7233 - val_loss: 1.8619 - val_acc: 0.6837\n",
      "Epoch 181/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8419 - acc: 0.7215 - val_loss: 1.8601 - val_acc: 0.6846\n",
      "Epoch 182/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8398 - acc: 0.7210 - val_loss: 1.8580 - val_acc: 0.6854\n",
      "Epoch 183/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8376 - acc: 0.7210 - val_loss: 1.8558 - val_acc: 0.6858\n",
      "Epoch 184/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8354 - acc: 0.7222 - val_loss: 1.8538 - val_acc: 0.6833\n",
      "Epoch 185/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8333 - acc: 0.7204 - val_loss: 1.8517 - val_acc: 0.6854\n",
      "Epoch 186/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.8312 - acc: 0.7259 - val_loss: 1.8497 - val_acc: 0.6854\n",
      "Epoch 187/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8290 - acc: 0.7225 - val_loss: 1.8476 - val_acc: 0.6883\n",
      "Epoch 188/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8268 - acc: 0.7232 - val_loss: 1.8455 - val_acc: 0.6896\n",
      "Epoch 189/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8247 - acc: 0.7216 - val_loss: 1.8434 - val_acc: 0.6908\n",
      "Epoch 190/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8225 - acc: 0.7243 - val_loss: 1.8413 - val_acc: 0.6896\n",
      "Epoch 191/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8204 - acc: 0.7249 - val_loss: 1.8394 - val_acc: 0.6883\n",
      "Epoch 192/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8183 - acc: 0.7253 - val_loss: 1.8373 - val_acc: 0.6904\n",
      "Epoch 193/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.8161 - acc: 0.7243 - val_loss: 1.8351 - val_acc: 0.6875\n",
      "Epoch 194/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8139 - acc: 0.7266 - val_loss: 1.8332 - val_acc: 0.6900\n",
      "Epoch 195/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8119 - acc: 0.7251 - val_loss: 1.8312 - val_acc: 0.6879\n",
      "Epoch 196/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8098 - acc: 0.7255 - val_loss: 1.8292 - val_acc: 0.6892\n",
      "Epoch 197/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8076 - acc: 0.7241 - val_loss: 1.8271 - val_acc: 0.6892\n",
      "Epoch 198/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.8055 - acc: 0.7277 - val_loss: 1.8251 - val_acc: 0.6933\n",
      "Epoch 199/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.8034 - acc: 0.7239 - val_loss: 1.8231 - val_acc: 0.6933\n",
      "Epoch 200/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.8013 - acc: 0.7314 - val_loss: 1.8210 - val_acc: 0.6921\n",
      "Epoch 201/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7991 - acc: 0.7271 - val_loss: 1.8191 - val_acc: 0.6900\n",
      "Epoch 202/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7971 - acc: 0.7273 - val_loss: 1.8171 - val_acc: 0.6900\n",
      "Epoch 203/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7950 - acc: 0.7302 - val_loss: 1.8151 - val_acc: 0.6946\n",
      "Epoch 204/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7928 - acc: 0.7305 - val_loss: 1.8131 - val_acc: 0.6921\n",
      "Epoch 205/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7908 - acc: 0.7277 - val_loss: 1.8110 - val_acc: 0.6921\n",
      "Epoch 206/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7887 - acc: 0.7299 - val_loss: 1.8092 - val_acc: 0.6921\n",
      "Epoch 207/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7866 - acc: 0.7274 - val_loss: 1.8070 - val_acc: 0.6942\n",
      "Epoch 208/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7845 - acc: 0.7306 - val_loss: 1.8049 - val_acc: 0.6958\n",
      "Epoch 209/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7824 - acc: 0.7280 - val_loss: 1.8030 - val_acc: 0.6933\n",
      "Epoch 210/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7803 - acc: 0.7304 - val_loss: 1.8011 - val_acc: 0.6954\n",
      "Epoch 211/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7782 - acc: 0.7289 - val_loss: 1.7991 - val_acc: 0.6929\n",
      "Epoch 212/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7762 - acc: 0.7285 - val_loss: 1.7972 - val_acc: 0.6929\n",
      "Epoch 213/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7741 - acc: 0.7331 - val_loss: 1.7950 - val_acc: 0.6979\n",
      "Epoch 214/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7720 - acc: 0.7336 - val_loss: 1.7931 - val_acc: 0.6942\n",
      "Epoch 215/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7699 - acc: 0.7292 - val_loss: 1.7910 - val_acc: 0.6946\n",
      "Epoch 216/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7679 - acc: 0.7316 - val_loss: 1.7891 - val_acc: 0.7000\n",
      "Epoch 217/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7659 - acc: 0.7352 - val_loss: 1.7872 - val_acc: 0.6979\n",
      "Epoch 218/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7638 - acc: 0.7302 - val_loss: 1.7852 - val_acc: 0.6958\n",
      "Epoch 219/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7617 - acc: 0.7317 - val_loss: 1.7832 - val_acc: 0.6979\n",
      "Epoch 220/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7597 - acc: 0.7323 - val_loss: 1.7813 - val_acc: 0.6987\n",
      "Epoch 221/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7576 - acc: 0.7382 - val_loss: 1.7793 - val_acc: 0.6983\n",
      "Epoch 222/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7556 - acc: 0.7298 - val_loss: 1.7774 - val_acc: 0.6992\n",
      "Epoch 223/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7536 - acc: 0.7352 - val_loss: 1.7755 - val_acc: 0.7017\n",
      "Epoch 224/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7515 - acc: 0.7364 - val_loss: 1.7735 - val_acc: 0.6975\n",
      "Epoch 225/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7495 - acc: 0.7320 - val_loss: 1.7716 - val_acc: 0.6996\n",
      "Epoch 226/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7475 - acc: 0.7379 - val_loss: 1.7696 - val_acc: 0.7004\n",
      "Epoch 227/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7454 - acc: 0.7316 - val_loss: 1.7678 - val_acc: 0.7021\n",
      "Epoch 228/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7434 - acc: 0.7389 - val_loss: 1.7658 - val_acc: 0.7008\n",
      "Epoch 229/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7414 - acc: 0.7353 - val_loss: 1.7638 - val_acc: 0.7008\n",
      "Epoch 230/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7393 - acc: 0.7343 - val_loss: 1.7619 - val_acc: 0.6992\n",
      "Epoch 231/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7374 - acc: 0.7368 - val_loss: 1.7599 - val_acc: 0.7042\n",
      "Epoch 232/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7353 - acc: 0.7359 - val_loss: 1.7580 - val_acc: 0.7000\n",
      "Epoch 233/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7333 - acc: 0.7392 - val_loss: 1.7560 - val_acc: 0.7012\n",
      "Epoch 234/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.7313 - acc: 0.7351 - val_loss: 1.7543 - val_acc: 0.6987\n",
      "Epoch 235/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.7293 - acc: 0.7383 - val_loss: 1.7523 - val_acc: 0.7004\n",
      "Epoch 236/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7273 - acc: 0.7396 - val_loss: 1.7505 - val_acc: 0.7021\n",
      "Epoch 237/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7253 - acc: 0.7347 - val_loss: 1.7484 - val_acc: 0.7033\n",
      "Epoch 238/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7233 - acc: 0.7373 - val_loss: 1.7467 - val_acc: 0.7021\n",
      "Epoch 239/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7214 - acc: 0.7392 - val_loss: 1.7447 - val_acc: 0.7013\n",
      "Epoch 240/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7194 - acc: 0.7360 - val_loss: 1.7429 - val_acc: 0.7008\n",
      "Epoch 241/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7174 - acc: 0.7411 - val_loss: 1.7409 - val_acc: 0.7029\n",
      "Epoch 242/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7155 - acc: 0.7414 - val_loss: 1.7391 - val_acc: 0.7058\n",
      "Epoch 243/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7135 - acc: 0.7362 - val_loss: 1.7372 - val_acc: 0.7013\n",
      "Epoch 244/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7115 - acc: 0.7388 - val_loss: 1.7353 - val_acc: 0.7046\n",
      "Epoch 245/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7096 - acc: 0.7404 - val_loss: 1.7335 - val_acc: 0.7033\n",
      "Epoch 246/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.7076 - acc: 0.7395 - val_loss: 1.7315 - val_acc: 0.7054\n",
      "Epoch 247/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7057 - acc: 0.7377 - val_loss: 1.7296 - val_acc: 0.7067\n",
      "Epoch 248/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7037 - acc: 0.7402 - val_loss: 1.7278 - val_acc: 0.7012\n",
      "Epoch 249/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7018 - acc: 0.7403 - val_loss: 1.7259 - val_acc: 0.7067\n",
      "Epoch 250/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6998 - acc: 0.7431 - val_loss: 1.7241 - val_acc: 0.7063\n",
      "Epoch 251/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6979 - acc: 0.7396 - val_loss: 1.7223 - val_acc: 0.7067\n",
      "Epoch 252/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6960 - acc: 0.7395 - val_loss: 1.7205 - val_acc: 0.7058\n",
      "Epoch 253/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6940 - acc: 0.7412 - val_loss: 1.7186 - val_acc: 0.7058\n",
      "Epoch 254/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6921 - acc: 0.7406 - val_loss: 1.7168 - val_acc: 0.7042\n",
      "Epoch 255/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6902 - acc: 0.7412 - val_loss: 1.7149 - val_acc: 0.7071\n",
      "Epoch 256/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6883 - acc: 0.7458 - val_loss: 1.7130 - val_acc: 0.7075\n",
      "Epoch 257/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6864 - acc: 0.7407 - val_loss: 1.7114 - val_acc: 0.7058\n",
      "Epoch 258/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6845 - acc: 0.7426 - val_loss: 1.7095 - val_acc: 0.7075\n",
      "Epoch 259/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6826 - acc: 0.7420 - val_loss: 1.7075 - val_acc: 0.7079\n",
      "Epoch 260/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6806 - acc: 0.7429 - val_loss: 1.7058 - val_acc: 0.7079\n",
      "Epoch 261/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6787 - acc: 0.7446 - val_loss: 1.7039 - val_acc: 0.7075\n",
      "Epoch 262/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6768 - acc: 0.7435 - val_loss: 1.7022 - val_acc: 0.7075\n",
      "Epoch 263/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6750 - acc: 0.7424 - val_loss: 1.7005 - val_acc: 0.7067\n",
      "Epoch 264/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6731 - acc: 0.7444 - val_loss: 1.6986 - val_acc: 0.7092\n",
      "Epoch 265/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6713 - acc: 0.7444 - val_loss: 1.6967 - val_acc: 0.7067\n",
      "Epoch 266/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.6693 - acc: 0.7431 - val_loss: 1.6950 - val_acc: 0.7104\n",
      "Epoch 267/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6675 - acc: 0.7439 - val_loss: 1.6932 - val_acc: 0.7087\n",
      "Epoch 268/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6656 - acc: 0.7470 - val_loss: 1.6914 - val_acc: 0.7092\n",
      "Epoch 269/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6637 - acc: 0.7432 - val_loss: 1.6896 - val_acc: 0.7075\n",
      "Epoch 270/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6619 - acc: 0.7434 - val_loss: 1.6879 - val_acc: 0.7083\n",
      "Epoch 271/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6600 - acc: 0.7460 - val_loss: 1.6860 - val_acc: 0.7100\n",
      "Epoch 272/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6582 - acc: 0.7469 - val_loss: 1.6843 - val_acc: 0.7079\n",
      "Epoch 273/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6563 - acc: 0.7457 - val_loss: 1.6825 - val_acc: 0.7079\n",
      "Epoch 274/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6545 - acc: 0.7460 - val_loss: 1.6807 - val_acc: 0.7096\n",
      "Epoch 275/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6526 - acc: 0.7464 - val_loss: 1.6791 - val_acc: 0.7079\n",
      "Epoch 276/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6508 - acc: 0.7455 - val_loss: 1.6773 - val_acc: 0.7092\n",
      "Epoch 277/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.6490 - acc: 0.7444 - val_loss: 1.6755 - val_acc: 0.7092\n",
      "Epoch 278/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6471 - acc: 0.7479 - val_loss: 1.6738 - val_acc: 0.7096\n",
      "Epoch 279/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6454 - acc: 0.7478 - val_loss: 1.6720 - val_acc: 0.7113\n",
      "Epoch 280/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6435 - acc: 0.7479 - val_loss: 1.6702 - val_acc: 0.7096\n",
      "Epoch 281/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6416 - acc: 0.7497 - val_loss: 1.6686 - val_acc: 0.7092\n",
      "Epoch 282/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6399 - acc: 0.7446 - val_loss: 1.6668 - val_acc: 0.7121\n",
      "Epoch 283/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6380 - acc: 0.7458 - val_loss: 1.6652 - val_acc: 0.7117\n",
      "Epoch 284/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6362 - acc: 0.7466 - val_loss: 1.6635 - val_acc: 0.7125\n",
      "Epoch 285/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6344 - acc: 0.7488 - val_loss: 1.6615 - val_acc: 0.7125\n",
      "Epoch 286/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6326 - acc: 0.7461 - val_loss: 1.6599 - val_acc: 0.7117\n",
      "Epoch 287/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6308 - acc: 0.7478 - val_loss: 1.6582 - val_acc: 0.7117\n",
      "Epoch 288/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6290 - acc: 0.7510 - val_loss: 1.6564 - val_acc: 0.7138\n",
      "Epoch 289/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6272 - acc: 0.7482 - val_loss: 1.6548 - val_acc: 0.7117\n",
      "Epoch 290/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6254 - acc: 0.7500 - val_loss: 1.6531 - val_acc: 0.7133\n",
      "Epoch 291/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6236 - acc: 0.7483 - val_loss: 1.6514 - val_acc: 0.7121\n",
      "Epoch 292/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6219 - acc: 0.7522 - val_loss: 1.6496 - val_acc: 0.7138\n",
      "Epoch 293/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6200 - acc: 0.7486 - val_loss: 1.6480 - val_acc: 0.7117\n",
      "Epoch 294/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6183 - acc: 0.7499 - val_loss: 1.6462 - val_acc: 0.7125\n",
      "Epoch 295/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6165 - acc: 0.7484 - val_loss: 1.6447 - val_acc: 0.7096\n",
      "Epoch 296/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6147 - acc: 0.7511 - val_loss: 1.6430 - val_acc: 0.7138\n",
      "Epoch 297/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6129 - acc: 0.7488 - val_loss: 1.6412 - val_acc: 0.7125\n",
      "Epoch 298/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6111 - acc: 0.7494 - val_loss: 1.6394 - val_acc: 0.7142\n",
      "Epoch 299/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6094 - acc: 0.7502 - val_loss: 1.6377 - val_acc: 0.7171\n",
      "Epoch 300/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6076 - acc: 0.7515 - val_loss: 1.6361 - val_acc: 0.7142\n",
      "Epoch 301/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6059 - acc: 0.7502 - val_loss: 1.6344 - val_acc: 0.7129\n",
      "Epoch 302/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6041 - acc: 0.7494 - val_loss: 1.6327 - val_acc: 0.7146\n",
      "Epoch 303/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6024 - acc: 0.7495 - val_loss: 1.6312 - val_acc: 0.7146\n",
      "Epoch 304/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6006 - acc: 0.7503 - val_loss: 1.6295 - val_acc: 0.7154\n",
      "Epoch 305/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5988 - acc: 0.7514 - val_loss: 1.6277 - val_acc: 0.7179\n",
      "Epoch 306/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5971 - acc: 0.7527 - val_loss: 1.6262 - val_acc: 0.7167\n",
      "Epoch 307/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5954 - acc: 0.7514 - val_loss: 1.6244 - val_acc: 0.7171\n",
      "Epoch 308/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5937 - acc: 0.7530 - val_loss: 1.6228 - val_acc: 0.7175\n",
      "Epoch 309/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5920 - acc: 0.7493 - val_loss: 1.6212 - val_acc: 0.7150\n",
      "Epoch 310/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5902 - acc: 0.7528 - val_loss: 1.6194 - val_acc: 0.7179\n",
      "Epoch 311/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5885 - acc: 0.7534 - val_loss: 1.6178 - val_acc: 0.7163\n",
      "Epoch 312/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5868 - acc: 0.7524 - val_loss: 1.6161 - val_acc: 0.7192\n",
      "Epoch 313/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5851 - acc: 0.7529 - val_loss: 1.6147 - val_acc: 0.7171\n",
      "Epoch 314/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.5834 - acc: 0.7520 - val_loss: 1.6131 - val_acc: 0.7163\n",
      "Epoch 315/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.5817 - acc: 0.7547 - val_loss: 1.6112 - val_acc: 0.7183\n",
      "Epoch 316/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5799 - acc: 0.7505 - val_loss: 1.6097 - val_acc: 0.7192\n",
      "Epoch 317/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5783 - acc: 0.7523 - val_loss: 1.6082 - val_acc: 0.7212\n",
      "Epoch 318/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5765 - acc: 0.7557 - val_loss: 1.6065 - val_acc: 0.7200\n",
      "Epoch 319/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5748 - acc: 0.7531 - val_loss: 1.6049 - val_acc: 0.7204\n",
      "Epoch 320/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5731 - acc: 0.7557 - val_loss: 1.6033 - val_acc: 0.7179\n",
      "Epoch 321/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5714 - acc: 0.7519 - val_loss: 1.6017 - val_acc: 0.7192\n",
      "Epoch 322/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5698 - acc: 0.7532 - val_loss: 1.6001 - val_acc: 0.7196\n",
      "Epoch 323/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5681 - acc: 0.7549 - val_loss: 1.5984 - val_acc: 0.7196\n",
      "Epoch 324/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5664 - acc: 0.7525 - val_loss: 1.5968 - val_acc: 0.7196\n",
      "Epoch 325/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5647 - acc: 0.7546 - val_loss: 1.5951 - val_acc: 0.7200\n",
      "Epoch 326/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5631 - acc: 0.7552 - val_loss: 1.5935 - val_acc: 0.7212\n",
      "Epoch 327/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5614 - acc: 0.7556 - val_loss: 1.5919 - val_acc: 0.7208\n",
      "Epoch 328/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5597 - acc: 0.7548 - val_loss: 1.5903 - val_acc: 0.7204\n",
      "Epoch 329/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5581 - acc: 0.7535 - val_loss: 1.5887 - val_acc: 0.7204\n",
      "Epoch 330/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5564 - acc: 0.7546 - val_loss: 1.5872 - val_acc: 0.7196\n",
      "Epoch 331/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5547 - acc: 0.7550 - val_loss: 1.5857 - val_acc: 0.7217\n",
      "Epoch 332/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5531 - acc: 0.7547 - val_loss: 1.5840 - val_acc: 0.7217\n",
      "Epoch 333/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5514 - acc: 0.7572 - val_loss: 1.5825 - val_acc: 0.7229\n",
      "Epoch 334/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5497 - acc: 0.7557 - val_loss: 1.5809 - val_acc: 0.7204\n",
      "Epoch 335/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5482 - acc: 0.7529 - val_loss: 1.5793 - val_acc: 0.7237\n",
      "Epoch 336/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5465 - acc: 0.7572 - val_loss: 1.5778 - val_acc: 0.7233\n",
      "Epoch 337/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.5448 - acc: 0.7551 - val_loss: 1.5763 - val_acc: 0.7229\n",
      "Epoch 338/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.5433 - acc: 0.7554 - val_loss: 1.5747 - val_acc: 0.7238\n",
      "Epoch 339/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5416 - acc: 0.7569 - val_loss: 1.5733 - val_acc: 0.7229\n",
      "Epoch 340/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5400 - acc: 0.7562 - val_loss: 1.5716 - val_acc: 0.7217\n",
      "Epoch 341/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5383 - acc: 0.7556 - val_loss: 1.5701 - val_acc: 0.7242\n",
      "Epoch 342/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5367 - acc: 0.7585 - val_loss: 1.5686 - val_acc: 0.7225\n",
      "Epoch 343/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5350 - acc: 0.7560 - val_loss: 1.5670 - val_acc: 0.7217\n",
      "Epoch 344/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5336 - acc: 0.7575 - val_loss: 1.5654 - val_acc: 0.7217\n",
      "Epoch 345/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5319 - acc: 0.7554 - val_loss: 1.5640 - val_acc: 0.7221\n",
      "Epoch 346/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5303 - acc: 0.7581 - val_loss: 1.5624 - val_acc: 0.7246\n",
      "Epoch 347/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5286 - acc: 0.7579 - val_loss: 1.5609 - val_acc: 0.7246\n",
      "Epoch 348/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5270 - acc: 0.7566 - val_loss: 1.5593 - val_acc: 0.7237\n",
      "Epoch 349/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5255 - acc: 0.7566 - val_loss: 1.5578 - val_acc: 0.7246\n",
      "Epoch 350/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5238 - acc: 0.7583 - val_loss: 1.5563 - val_acc: 0.7250\n",
      "Epoch 351/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5223 - acc: 0.7571 - val_loss: 1.5548 - val_acc: 0.7242\n",
      "Epoch 352/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.5207 - acc: 0.7593 - val_loss: 1.5533 - val_acc: 0.7238\n",
      "Epoch 353/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5191 - acc: 0.7575 - val_loss: 1.5518 - val_acc: 0.7262\n",
      "Epoch 354/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5175 - acc: 0.7590 - val_loss: 1.5502 - val_acc: 0.7271\n",
      "Epoch 355/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5159 - acc: 0.7589 - val_loss: 1.5488 - val_acc: 0.7242\n",
      "Epoch 356/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5143 - acc: 0.7588 - val_loss: 1.5473 - val_acc: 0.7267\n",
      "Epoch 357/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5128 - acc: 0.7588 - val_loss: 1.5457 - val_acc: 0.7254\n",
      "Epoch 358/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5113 - acc: 0.7614 - val_loss: 1.5443 - val_acc: 0.7262\n",
      "Epoch 359/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5097 - acc: 0.7586 - val_loss: 1.5428 - val_acc: 0.7250\n",
      "Epoch 360/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5081 - acc: 0.7595 - val_loss: 1.5413 - val_acc: 0.7250\n",
      "Epoch 361/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5065 - acc: 0.7590 - val_loss: 1.5397 - val_acc: 0.7262\n",
      "Epoch 362/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5050 - acc: 0.7593 - val_loss: 1.5382 - val_acc: 0.7267\n",
      "Epoch 363/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5035 - acc: 0.7610 - val_loss: 1.5369 - val_acc: 0.7271\n",
      "Epoch 364/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5019 - acc: 0.7616 - val_loss: 1.5354 - val_acc: 0.7267\n",
      "Epoch 365/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5003 - acc: 0.7579 - val_loss: 1.5339 - val_acc: 0.7279\n",
      "Epoch 366/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4988 - acc: 0.7604 - val_loss: 1.5324 - val_acc: 0.7279\n",
      "Epoch 367/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4972 - acc: 0.7617 - val_loss: 1.5310 - val_acc: 0.7279\n",
      "Epoch 368/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4958 - acc: 0.7593 - val_loss: 1.5294 - val_acc: 0.7258\n",
      "Epoch 369/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4942 - acc: 0.7641 - val_loss: 1.5280 - val_acc: 0.7288\n",
      "Epoch 370/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.4926 - acc: 0.7600 - val_loss: 1.5266 - val_acc: 0.7271\n",
      "Epoch 371/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.4911 - acc: 0.7600 - val_loss: 1.5252 - val_acc: 0.7275\n",
      "Epoch 372/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.4896 - acc: 0.7629 - val_loss: 1.5236 - val_acc: 0.7279\n",
      "Epoch 373/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4881 - acc: 0.7610 - val_loss: 1.5222 - val_acc: 0.7275\n",
      "Epoch 374/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4866 - acc: 0.7618 - val_loss: 1.5208 - val_acc: 0.7271\n",
      "Epoch 375/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.4850 - acc: 0.7606 - val_loss: 1.5193 - val_acc: 0.7292\n",
      "Epoch 376/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4835 - acc: 0.7623 - val_loss: 1.5179 - val_acc: 0.7279\n",
      "Epoch 377/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.4820 - acc: 0.7652 - val_loss: 1.5165 - val_acc: 0.7304\n",
      "Epoch 378/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.4805 - acc: 0.7602 - val_loss: 1.5151 - val_acc: 0.7288\n",
      "Epoch 379/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.4790 - acc: 0.7626 - val_loss: 1.5136 - val_acc: 0.7292\n",
      "Epoch 380/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.4775 - acc: 0.7627 - val_loss: 1.5121 - val_acc: 0.7288\n",
      "Epoch 381/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.4759 - acc: 0.7645 - val_loss: 1.5107 - val_acc: 0.7292\n",
      "Epoch 382/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.4745 - acc: 0.7638 - val_loss: 1.5093 - val_acc: 0.7288\n",
      "Epoch 383/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.4730 - acc: 0.7619 - val_loss: 1.5079 - val_acc: 0.7288\n",
      "Epoch 384/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.4715 - acc: 0.7646 - val_loss: 1.5064 - val_acc: 0.7288\n",
      "Epoch 385/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.4700 - acc: 0.7639 - val_loss: 1.5051 - val_acc: 0.7296\n",
      "Epoch 386/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.4684 - acc: 0.7633 - val_loss: 1.5035 - val_acc: 0.7292\n",
      "Epoch 387/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.4671 - acc: 0.7653 - val_loss: 1.5020 - val_acc: 0.7296\n",
      "Epoch 388/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.4655 - acc: 0.7640 - val_loss: 1.5008 - val_acc: 0.7304\n",
      "Epoch 389/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.4640 - acc: 0.7621 - val_loss: 1.4995 - val_acc: 0.7312\n",
      "Epoch 390/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4625 - acc: 0.7619 - val_loss: 1.4979 - val_acc: 0.7296\n",
      "Epoch 391/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4611 - acc: 0.7671 - val_loss: 1.4965 - val_acc: 0.7300\n",
      "Epoch 392/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4595 - acc: 0.7643 - val_loss: 1.4952 - val_acc: 0.7308\n",
      "Epoch 393/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4581 - acc: 0.7649 - val_loss: 1.4938 - val_acc: 0.7308\n",
      "Epoch 394/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4566 - acc: 0.7642 - val_loss: 1.4923 - val_acc: 0.7300\n",
      "Epoch 395/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4552 - acc: 0.7660 - val_loss: 1.4909 - val_acc: 0.7304\n",
      "Epoch 396/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4537 - acc: 0.7649 - val_loss: 1.4896 - val_acc: 0.7296\n",
      "Epoch 397/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4523 - acc: 0.7639 - val_loss: 1.4881 - val_acc: 0.7304\n",
      "Epoch 398/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4508 - acc: 0.7646 - val_loss: 1.4867 - val_acc: 0.7296\n",
      "Epoch 399/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4493 - acc: 0.7640 - val_loss: 1.4854 - val_acc: 0.7317\n",
      "Epoch 400/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.4478 - acc: 0.7662 - val_loss: 1.4840 - val_acc: 0.7292\n",
      "Epoch 401/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.4465 - acc: 0.7664 - val_loss: 1.4826 - val_acc: 0.7296\n",
      "Epoch 402/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.4450 - acc: 0.7648 - val_loss: 1.4813 - val_acc: 0.7329\n",
      "Epoch 403/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4436 - acc: 0.7665 - val_loss: 1.4799 - val_acc: 0.7325\n",
      "Epoch 404/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4421 - acc: 0.7648 - val_loss: 1.4784 - val_acc: 0.7329\n",
      "Epoch 405/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4407 - acc: 0.7662 - val_loss: 1.4771 - val_acc: 0.7333\n",
      "Epoch 406/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4392 - acc: 0.7676 - val_loss: 1.4758 - val_acc: 0.7329\n",
      "Epoch 407/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.4378 - acc: 0.7659 - val_loss: 1.4743 - val_acc: 0.7325\n",
      "Epoch 408/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4364 - acc: 0.7674 - val_loss: 1.4730 - val_acc: 0.7338\n",
      "Epoch 409/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4349 - acc: 0.7665 - val_loss: 1.4717 - val_acc: 0.7308\n",
      "Epoch 410/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4335 - acc: 0.7682 - val_loss: 1.4702 - val_acc: 0.7350\n",
      "Epoch 411/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4321 - acc: 0.7669 - val_loss: 1.4691 - val_acc: 0.7317\n",
      "Epoch 412/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4307 - acc: 0.7677 - val_loss: 1.4677 - val_acc: 0.7329\n",
      "Epoch 413/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4293 - acc: 0.7680 - val_loss: 1.4664 - val_acc: 0.7338\n",
      "Epoch 414/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4279 - acc: 0.7687 - val_loss: 1.4651 - val_acc: 0.7333\n",
      "Epoch 415/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4265 - acc: 0.7686 - val_loss: 1.4637 - val_acc: 0.7325\n",
      "Epoch 416/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4251 - acc: 0.7664 - val_loss: 1.4623 - val_acc: 0.7354\n",
      "Epoch 417/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4237 - acc: 0.7676 - val_loss: 1.4609 - val_acc: 0.7338\n",
      "Epoch 418/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4223 - acc: 0.7676 - val_loss: 1.4598 - val_acc: 0.7346\n",
      "Epoch 419/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4209 - acc: 0.7693 - val_loss: 1.4584 - val_acc: 0.7358\n",
      "Epoch 420/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.4195 - acc: 0.7673 - val_loss: 1.4570 - val_acc: 0.7354\n",
      "Epoch 421/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4181 - acc: 0.7692 - val_loss: 1.4558 - val_acc: 0.7333\n",
      "Epoch 422/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4167 - acc: 0.7677 - val_loss: 1.4544 - val_acc: 0.7354\n",
      "Epoch 423/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4153 - acc: 0.7672 - val_loss: 1.4532 - val_acc: 0.7346\n",
      "Epoch 424/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4140 - acc: 0.7691 - val_loss: 1.4518 - val_acc: 0.7354\n",
      "Epoch 425/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4126 - acc: 0.7678 - val_loss: 1.4504 - val_acc: 0.7358\n",
      "Epoch 426/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4112 - acc: 0.7696 - val_loss: 1.4492 - val_acc: 0.7371\n",
      "Epoch 427/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4099 - acc: 0.7678 - val_loss: 1.4478 - val_acc: 0.7367\n",
      "Epoch 428/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4085 - acc: 0.7700 - val_loss: 1.4465 - val_acc: 0.7367\n",
      "Epoch 429/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4071 - acc: 0.7702 - val_loss: 1.4453 - val_acc: 0.7354\n",
      "Epoch 430/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4057 - acc: 0.7704 - val_loss: 1.4439 - val_acc: 0.7375\n",
      "Epoch 431/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4043 - acc: 0.7715 - val_loss: 1.4427 - val_acc: 0.7354\n",
      "Epoch 432/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4030 - acc: 0.7704 - val_loss: 1.4412 - val_acc: 0.7363\n",
      "Epoch 433/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4017 - acc: 0.7704 - val_loss: 1.4400 - val_acc: 0.7363\n",
      "Epoch 434/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4003 - acc: 0.7694 - val_loss: 1.4390 - val_acc: 0.7358\n",
      "Epoch 435/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3989 - acc: 0.7695 - val_loss: 1.4376 - val_acc: 0.7342\n",
      "Epoch 436/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3976 - acc: 0.7711 - val_loss: 1.4363 - val_acc: 0.7354\n",
      "Epoch 437/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3962 - acc: 0.7693 - val_loss: 1.4349 - val_acc: 0.7367\n",
      "Epoch 438/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3949 - acc: 0.7703 - val_loss: 1.4336 - val_acc: 0.7375\n",
      "Epoch 439/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3936 - acc: 0.7717 - val_loss: 1.4324 - val_acc: 0.7367\n",
      "Epoch 440/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3921 - acc: 0.7697 - val_loss: 1.4312 - val_acc: 0.7362\n",
      "Epoch 441/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3909 - acc: 0.7718 - val_loss: 1.4299 - val_acc: 0.7371\n",
      "Epoch 442/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3896 - acc: 0.7712 - val_loss: 1.4286 - val_acc: 0.7363\n",
      "Epoch 443/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3882 - acc: 0.7698 - val_loss: 1.4272 - val_acc: 0.7367\n",
      "Epoch 444/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3869 - acc: 0.7709 - val_loss: 1.4260 - val_acc: 0.7375\n",
      "Epoch 445/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3855 - acc: 0.7725 - val_loss: 1.4248 - val_acc: 0.7379\n",
      "Epoch 446/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3842 - acc: 0.7729 - val_loss: 1.4235 - val_acc: 0.7379\n",
      "Epoch 447/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3829 - acc: 0.7707 - val_loss: 1.4223 - val_acc: 0.7362\n",
      "Epoch 448/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3816 - acc: 0.7730 - val_loss: 1.4210 - val_acc: 0.7383\n",
      "Epoch 449/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3803 - acc: 0.7741 - val_loss: 1.4198 - val_acc: 0.7388\n",
      "Epoch 450/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3790 - acc: 0.7727 - val_loss: 1.4186 - val_acc: 0.7367\n",
      "Epoch 451/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3778 - acc: 0.7706 - val_loss: 1.4173 - val_acc: 0.7383\n",
      "Epoch 452/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3764 - acc: 0.7739 - val_loss: 1.4162 - val_acc: 0.7379\n",
      "Epoch 453/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3751 - acc: 0.7735 - val_loss: 1.4149 - val_acc: 0.7383\n",
      "Epoch 454/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3737 - acc: 0.7723 - val_loss: 1.4137 - val_acc: 0.7375\n",
      "Epoch 455/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3725 - acc: 0.7741 - val_loss: 1.4124 - val_acc: 0.7388\n",
      "Epoch 456/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.3711 - acc: 0.7732 - val_loss: 1.4112 - val_acc: 0.7375\n",
      "Epoch 457/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3699 - acc: 0.7719 - val_loss: 1.4099 - val_acc: 0.7392\n",
      "Epoch 458/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3686 - acc: 0.7725 - val_loss: 1.4087 - val_acc: 0.7379\n",
      "Epoch 459/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3673 - acc: 0.7741 - val_loss: 1.4075 - val_acc: 0.7392\n",
      "Epoch 460/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3661 - acc: 0.7749 - val_loss: 1.4063 - val_acc: 0.7383\n",
      "Epoch 461/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3648 - acc: 0.7757 - val_loss: 1.4051 - val_acc: 0.7392\n",
      "Epoch 462/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3635 - acc: 0.7731 - val_loss: 1.4040 - val_acc: 0.7379\n",
      "Epoch 463/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3623 - acc: 0.7772 - val_loss: 1.4028 - val_acc: 0.7400\n",
      "Epoch 464/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3610 - acc: 0.7721 - val_loss: 1.4016 - val_acc: 0.7375\n",
      "Epoch 465/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3597 - acc: 0.7746 - val_loss: 1.4003 - val_acc: 0.7383\n",
      "Epoch 466/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3585 - acc: 0.7765 - val_loss: 1.3990 - val_acc: 0.7396\n",
      "Epoch 467/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3572 - acc: 0.7754 - val_loss: 1.3979 - val_acc: 0.7396\n",
      "Epoch 468/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3559 - acc: 0.7752 - val_loss: 1.3966 - val_acc: 0.7392\n",
      "Epoch 469/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3546 - acc: 0.7739 - val_loss: 1.3954 - val_acc: 0.7396\n",
      "Epoch 470/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3533 - acc: 0.7744 - val_loss: 1.3943 - val_acc: 0.7404\n",
      "Epoch 471/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3521 - acc: 0.7749 - val_loss: 1.3931 - val_acc: 0.7387\n",
      "Epoch 472/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3508 - acc: 0.7744 - val_loss: 1.3918 - val_acc: 0.7408\n",
      "Epoch 473/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3496 - acc: 0.7770 - val_loss: 1.3907 - val_acc: 0.7392\n",
      "Epoch 474/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3484 - acc: 0.7742 - val_loss: 1.3895 - val_acc: 0.7408\n",
      "Epoch 475/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3471 - acc: 0.7767 - val_loss: 1.3884 - val_acc: 0.7400\n",
      "Epoch 476/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3459 - acc: 0.7739 - val_loss: 1.3872 - val_acc: 0.7404\n",
      "Epoch 477/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3447 - acc: 0.7756 - val_loss: 1.3860 - val_acc: 0.7408\n",
      "Epoch 478/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3434 - acc: 0.7778 - val_loss: 1.3849 - val_acc: 0.7425\n",
      "Epoch 479/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3422 - acc: 0.7760 - val_loss: 1.3836 - val_acc: 0.7412\n",
      "Epoch 480/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3409 - acc: 0.7767 - val_loss: 1.3825 - val_acc: 0.7400\n",
      "Epoch 481/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3397 - acc: 0.7770 - val_loss: 1.3813 - val_acc: 0.7400\n",
      "Epoch 482/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3384 - acc: 0.7762 - val_loss: 1.3802 - val_acc: 0.7408\n",
      "Epoch 483/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3372 - acc: 0.7786 - val_loss: 1.3791 - val_acc: 0.7404\n",
      "Epoch 484/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.3360 - acc: 0.7766 - val_loss: 1.3778 - val_acc: 0.7429\n",
      "Epoch 485/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3348 - acc: 0.7785 - val_loss: 1.3767 - val_acc: 0.7412\n",
      "Epoch 486/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3336 - acc: 0.7767 - val_loss: 1.3756 - val_acc: 0.7396\n",
      "Epoch 487/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3324 - acc: 0.7761 - val_loss: 1.3743 - val_acc: 0.7408\n",
      "Epoch 488/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3312 - acc: 0.7779 - val_loss: 1.3733 - val_acc: 0.7417\n",
      "Epoch 489/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3299 - acc: 0.7781 - val_loss: 1.3721 - val_acc: 0.7412\n",
      "Epoch 490/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3287 - acc: 0.7766 - val_loss: 1.3709 - val_acc: 0.7421\n",
      "Epoch 491/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3275 - acc: 0.7762 - val_loss: 1.3698 - val_acc: 0.7408\n",
      "Epoch 492/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3263 - acc: 0.7798 - val_loss: 1.3688 - val_acc: 0.7412\n",
      "Epoch 493/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3251 - acc: 0.7768 - val_loss: 1.3676 - val_acc: 0.7400\n",
      "Epoch 494/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3240 - acc: 0.7785 - val_loss: 1.3665 - val_acc: 0.7433\n",
      "Epoch 495/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3227 - acc: 0.7785 - val_loss: 1.3652 - val_acc: 0.7417\n",
      "Epoch 496/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3215 - acc: 0.7793 - val_loss: 1.3642 - val_acc: 0.7425\n",
      "Epoch 497/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3204 - acc: 0.7792 - val_loss: 1.3631 - val_acc: 0.7433\n",
      "Epoch 498/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3191 - acc: 0.7791 - val_loss: 1.3619 - val_acc: 0.7408\n",
      "Epoch 499/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3180 - acc: 0.7786 - val_loss: 1.3609 - val_acc: 0.7438\n",
      "Epoch 500/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3168 - acc: 0.7794 - val_loss: 1.3597 - val_acc: 0.7408\n",
      "Epoch 501/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3156 - acc: 0.7783 - val_loss: 1.3585 - val_acc: 0.7433\n",
      "Epoch 502/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3144 - acc: 0.7791 - val_loss: 1.3575 - val_acc: 0.7454\n",
      "Epoch 503/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3133 - acc: 0.7794 - val_loss: 1.3563 - val_acc: 0.7412\n",
      "Epoch 504/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3121 - acc: 0.7798 - val_loss: 1.3552 - val_acc: 0.7417\n",
      "Epoch 505/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3109 - acc: 0.7791 - val_loss: 1.3541 - val_acc: 0.7408\n",
      "Epoch 506/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3097 - acc: 0.7800 - val_loss: 1.3530 - val_acc: 0.7425\n",
      "Epoch 507/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3086 - acc: 0.7789 - val_loss: 1.3518 - val_acc: 0.7429\n",
      "Epoch 508/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3073 - acc: 0.7797 - val_loss: 1.3508 - val_acc: 0.7462\n",
      "Epoch 509/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3062 - acc: 0.7805 - val_loss: 1.3496 - val_acc: 0.7433\n",
      "Epoch 510/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3051 - acc: 0.7805 - val_loss: 1.3485 - val_acc: 0.7429\n",
      "Epoch 511/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3038 - acc: 0.7803 - val_loss: 1.3475 - val_acc: 0.7429\n",
      "Epoch 512/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3028 - acc: 0.7785 - val_loss: 1.3463 - val_acc: 0.7421\n",
      "Epoch 513/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3015 - acc: 0.7803 - val_loss: 1.3453 - val_acc: 0.7429\n",
      "Epoch 514/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3004 - acc: 0.7803 - val_loss: 1.3442 - val_acc: 0.7442\n",
      "Epoch 515/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2992 - acc: 0.7806 - val_loss: 1.3432 - val_acc: 0.7429\n",
      "Epoch 516/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2981 - acc: 0.7788 - val_loss: 1.3420 - val_acc: 0.7429\n",
      "Epoch 517/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2969 - acc: 0.7799 - val_loss: 1.3410 - val_acc: 0.7454\n",
      "Epoch 518/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2958 - acc: 0.7815 - val_loss: 1.3399 - val_acc: 0.7450\n",
      "Epoch 519/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2947 - acc: 0.7829 - val_loss: 1.3387 - val_acc: 0.7433\n",
      "Epoch 520/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2935 - acc: 0.7808 - val_loss: 1.3377 - val_acc: 0.7429\n",
      "Epoch 521/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2924 - acc: 0.7790 - val_loss: 1.3366 - val_acc: 0.7425\n",
      "Epoch 522/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2912 - acc: 0.7807 - val_loss: 1.3355 - val_acc: 0.7446\n",
      "Epoch 523/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2901 - acc: 0.7812 - val_loss: 1.3343 - val_acc: 0.7429\n",
      "Epoch 524/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2890 - acc: 0.7812 - val_loss: 1.3334 - val_acc: 0.7446\n",
      "Epoch 525/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.2879 - acc: 0.7811 - val_loss: 1.3324 - val_acc: 0.7462\n",
      "Epoch 526/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.2868 - acc: 0.7814 - val_loss: 1.3313 - val_acc: 0.7446\n",
      "Epoch 527/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2856 - acc: 0.7822 - val_loss: 1.3303 - val_acc: 0.7450\n",
      "Epoch 528/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2845 - acc: 0.7816 - val_loss: 1.3291 - val_acc: 0.7450\n",
      "Epoch 529/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2833 - acc: 0.7826 - val_loss: 1.3280 - val_acc: 0.7458\n",
      "Epoch 530/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2823 - acc: 0.7820 - val_loss: 1.3270 - val_acc: 0.7446\n",
      "Epoch 531/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2811 - acc: 0.7822 - val_loss: 1.3259 - val_acc: 0.7429\n",
      "Epoch 532/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2800 - acc: 0.7825 - val_loss: 1.3249 - val_acc: 0.7446\n",
      "Epoch 533/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2789 - acc: 0.7827 - val_loss: 1.3240 - val_acc: 0.7458\n",
      "Epoch 534/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2779 - acc: 0.7812 - val_loss: 1.3229 - val_acc: 0.7467\n",
      "Epoch 535/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2767 - acc: 0.7821 - val_loss: 1.3219 - val_acc: 0.7458\n",
      "Epoch 536/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2756 - acc: 0.7830 - val_loss: 1.3207 - val_acc: 0.7450\n",
      "Epoch 537/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2746 - acc: 0.7833 - val_loss: 1.3197 - val_acc: 0.7479\n",
      "Epoch 538/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2734 - acc: 0.7828 - val_loss: 1.3186 - val_acc: 0.7450\n",
      "Epoch 539/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2723 - acc: 0.7818 - val_loss: 1.3177 - val_acc: 0.7467\n",
      "Epoch 540/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2712 - acc: 0.7835 - val_loss: 1.3166 - val_acc: 0.7462\n",
      "Epoch 541/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2701 - acc: 0.7823 - val_loss: 1.3156 - val_acc: 0.7450\n",
      "Epoch 542/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2691 - acc: 0.7823 - val_loss: 1.3146 - val_acc: 0.7471\n",
      "Epoch 543/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2680 - acc: 0.7828 - val_loss: 1.3135 - val_acc: 0.7479\n",
      "Epoch 544/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2670 - acc: 0.7830 - val_loss: 1.3125 - val_acc: 0.7488\n",
      "Epoch 545/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2658 - acc: 0.7828 - val_loss: 1.3116 - val_acc: 0.7467\n",
      "Epoch 546/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2648 - acc: 0.7833 - val_loss: 1.3105 - val_acc: 0.7475\n",
      "Epoch 547/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2637 - acc: 0.7831 - val_loss: 1.3094 - val_acc: 0.7462\n",
      "Epoch 548/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2626 - acc: 0.7841 - val_loss: 1.3085 - val_acc: 0.7475\n",
      "Epoch 549/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2615 - acc: 0.7826 - val_loss: 1.3074 - val_acc: 0.7488\n",
      "Epoch 550/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2604 - acc: 0.7836 - val_loss: 1.3065 - val_acc: 0.7475\n",
      "Epoch 551/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2593 - acc: 0.7841 - val_loss: 1.3054 - val_acc: 0.7471\n",
      "Epoch 552/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2583 - acc: 0.7836 - val_loss: 1.3043 - val_acc: 0.7471\n",
      "Epoch 553/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2573 - acc: 0.7843 - val_loss: 1.3034 - val_acc: 0.7450\n",
      "Epoch 554/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2561 - acc: 0.7854 - val_loss: 1.3023 - val_acc: 0.7483\n",
      "Epoch 555/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2551 - acc: 0.7849 - val_loss: 1.3014 - val_acc: 0.7492\n",
      "Epoch 556/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2540 - acc: 0.7846 - val_loss: 1.3004 - val_acc: 0.7479\n",
      "Epoch 557/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2530 - acc: 0.7839 - val_loss: 1.2994 - val_acc: 0.7475\n",
      "Epoch 558/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2519 - acc: 0.7853 - val_loss: 1.2984 - val_acc: 0.7496\n",
      "Epoch 559/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2508 - acc: 0.7853 - val_loss: 1.2974 - val_acc: 0.7488\n",
      "Epoch 560/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2498 - acc: 0.7841 - val_loss: 1.2964 - val_acc: 0.7479\n",
      "Epoch 561/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2487 - acc: 0.7851 - val_loss: 1.2954 - val_acc: 0.7479\n",
      "Epoch 562/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2477 - acc: 0.7839 - val_loss: 1.2944 - val_acc: 0.7488\n",
      "Epoch 563/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2466 - acc: 0.7852 - val_loss: 1.2935 - val_acc: 0.7496\n",
      "Epoch 564/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2456 - acc: 0.7860 - val_loss: 1.2925 - val_acc: 0.7504\n",
      "Epoch 565/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2446 - acc: 0.7837 - val_loss: 1.2915 - val_acc: 0.7492\n",
      "Epoch 566/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2435 - acc: 0.7865 - val_loss: 1.2904 - val_acc: 0.7479\n",
      "Epoch 567/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2425 - acc: 0.7847 - val_loss: 1.2896 - val_acc: 0.7492\n",
      "Epoch 568/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2414 - acc: 0.7850 - val_loss: 1.2885 - val_acc: 0.7488\n",
      "Epoch 569/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2404 - acc: 0.7861 - val_loss: 1.2876 - val_acc: 0.7492\n",
      "Epoch 570/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2394 - acc: 0.7843 - val_loss: 1.2866 - val_acc: 0.7483\n",
      "Epoch 571/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2384 - acc: 0.7867 - val_loss: 1.2857 - val_acc: 0.7479\n",
      "Epoch 572/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2374 - acc: 0.7851 - val_loss: 1.2847 - val_acc: 0.7483\n",
      "Epoch 573/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2363 - acc: 0.7859 - val_loss: 1.2836 - val_acc: 0.7471\n",
      "Epoch 574/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2353 - acc: 0.7867 - val_loss: 1.2827 - val_acc: 0.7479\n",
      "Epoch 575/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2343 - acc: 0.7851 - val_loss: 1.2817 - val_acc: 0.7500\n",
      "Epoch 576/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2332 - acc: 0.7853 - val_loss: 1.2808 - val_acc: 0.7488\n",
      "Epoch 577/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2323 - acc: 0.7867 - val_loss: 1.2798 - val_acc: 0.7488\n",
      "Epoch 578/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2312 - acc: 0.7864 - val_loss: 1.2790 - val_acc: 0.7500\n",
      "Epoch 579/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2302 - acc: 0.7865 - val_loss: 1.2780 - val_acc: 0.7492\n",
      "Epoch 580/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.2292 - acc: 0.7858 - val_loss: 1.2771 - val_acc: 0.7492\n",
      "Epoch 581/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2282 - acc: 0.7868 - val_loss: 1.2759 - val_acc: 0.7492\n",
      "Epoch 582/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2272 - acc: 0.7867 - val_loss: 1.2751 - val_acc: 0.7508\n",
      "Epoch 583/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2261 - acc: 0.7866 - val_loss: 1.2742 - val_acc: 0.7496\n",
      "Epoch 584/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2251 - acc: 0.7866 - val_loss: 1.2733 - val_acc: 0.7496\n",
      "Epoch 585/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2242 - acc: 0.7867 - val_loss: 1.2722 - val_acc: 0.7500\n",
      "Epoch 586/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2232 - acc: 0.7866 - val_loss: 1.2713 - val_acc: 0.7508\n",
      "Epoch 587/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2221 - acc: 0.7872 - val_loss: 1.2704 - val_acc: 0.7492\n",
      "Epoch 588/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.2211 - acc: 0.7863 - val_loss: 1.2694 - val_acc: 0.7500\n",
      "Epoch 589/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.2202 - acc: 0.7868 - val_loss: 1.2683 - val_acc: 0.7517\n",
      "Epoch 590/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2192 - acc: 0.7879 - val_loss: 1.2674 - val_acc: 0.7500\n",
      "Epoch 591/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2182 - acc: 0.7877 - val_loss: 1.2666 - val_acc: 0.7500\n",
      "Epoch 592/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2172 - acc: 0.7876 - val_loss: 1.2657 - val_acc: 0.7513\n",
      "Epoch 593/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2162 - acc: 0.7881 - val_loss: 1.2648 - val_acc: 0.7508\n",
      "Epoch 594/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2152 - acc: 0.7873 - val_loss: 1.2638 - val_acc: 0.7508\n",
      "Epoch 595/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2142 - acc: 0.7875 - val_loss: 1.2629 - val_acc: 0.7517\n",
      "Epoch 596/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.2133 - acc: 0.7877 - val_loss: 1.2619 - val_acc: 0.7483\n",
      "Epoch 597/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.2123 - acc: 0.7872 - val_loss: 1.2610 - val_acc: 0.7504\n",
      "Epoch 598/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.2112 - acc: 0.7872 - val_loss: 1.2601 - val_acc: 0.7504\n",
      "Epoch 599/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2103 - acc: 0.7879 - val_loss: 1.2591 - val_acc: 0.7500\n",
      "Epoch 600/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.2092 - acc: 0.7878 - val_loss: 1.2583 - val_acc: 0.7508\n",
      "Epoch 601/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2083 - acc: 0.7869 - val_loss: 1.2573 - val_acc: 0.7517\n",
      "Epoch 602/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2073 - acc: 0.7886 - val_loss: 1.2565 - val_acc: 0.7525\n",
      "Epoch 603/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2063 - acc: 0.7882 - val_loss: 1.2556 - val_acc: 0.7508\n",
      "Epoch 604/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2054 - acc: 0.7889 - val_loss: 1.2545 - val_acc: 0.7517\n",
      "Epoch 605/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2044 - acc: 0.7880 - val_loss: 1.2537 - val_acc: 0.7500\n",
      "Epoch 606/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2035 - acc: 0.7866 - val_loss: 1.2528 - val_acc: 0.7513\n",
      "Epoch 607/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.2026 - acc: 0.7893 - val_loss: 1.2519 - val_acc: 0.7529\n",
      "Epoch 608/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2015 - acc: 0.7886 - val_loss: 1.2509 - val_acc: 0.7529\n",
      "Epoch 609/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.2006 - acc: 0.7883 - val_loss: 1.2500 - val_acc: 0.7521\n",
      "Epoch 610/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1997 - acc: 0.7883 - val_loss: 1.2492 - val_acc: 0.7525\n",
      "Epoch 611/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1986 - acc: 0.7892 - val_loss: 1.2484 - val_acc: 0.7533\n",
      "Epoch 612/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1977 - acc: 0.7883 - val_loss: 1.2474 - val_acc: 0.7521\n",
      "Epoch 613/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1967 - acc: 0.7892 - val_loss: 1.2465 - val_acc: 0.7512\n",
      "Epoch 614/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1959 - acc: 0.7896 - val_loss: 1.2457 - val_acc: 0.7529\n",
      "Epoch 615/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1949 - acc: 0.7893 - val_loss: 1.2446 - val_acc: 0.7525\n",
      "Epoch 616/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1939 - acc: 0.7894 - val_loss: 1.2439 - val_acc: 0.7525\n",
      "Epoch 617/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1930 - acc: 0.7889 - val_loss: 1.2429 - val_acc: 0.7537\n",
      "Epoch 618/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1921 - acc: 0.7890 - val_loss: 1.2421 - val_acc: 0.7525\n",
      "Epoch 619/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1911 - acc: 0.7902 - val_loss: 1.2412 - val_acc: 0.7529\n",
      "Epoch 620/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1902 - acc: 0.7895 - val_loss: 1.2404 - val_acc: 0.7521\n",
      "Epoch 621/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1893 - acc: 0.7903 - val_loss: 1.2395 - val_acc: 0.7517\n",
      "Epoch 622/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1883 - acc: 0.7896 - val_loss: 1.2385 - val_acc: 0.7563\n",
      "Epoch 623/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1874 - acc: 0.7890 - val_loss: 1.2377 - val_acc: 0.7517\n",
      "Epoch 624/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1865 - acc: 0.7894 - val_loss: 1.2369 - val_acc: 0.7542\n",
      "Epoch 625/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1855 - acc: 0.7908 - val_loss: 1.2360 - val_acc: 0.7546\n",
      "Epoch 626/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1846 - acc: 0.7907 - val_loss: 1.2351 - val_acc: 0.7521\n",
      "Epoch 627/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1837 - acc: 0.7902 - val_loss: 1.2342 - val_acc: 0.7529\n",
      "Epoch 628/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1828 - acc: 0.7905 - val_loss: 1.2334 - val_acc: 0.7533\n",
      "Epoch 629/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1819 - acc: 0.7905 - val_loss: 1.2324 - val_acc: 0.7537\n",
      "Epoch 630/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1810 - acc: 0.7893 - val_loss: 1.2316 - val_acc: 0.7554\n",
      "Epoch 631/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1800 - acc: 0.7924 - val_loss: 1.2307 - val_acc: 0.7567\n",
      "Epoch 632/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1791 - acc: 0.7901 - val_loss: 1.2300 - val_acc: 0.7563\n",
      "Epoch 633/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1782 - acc: 0.7915 - val_loss: 1.2289 - val_acc: 0.7550\n",
      "Epoch 634/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1773 - acc: 0.7894 - val_loss: 1.2282 - val_acc: 0.7542\n",
      "Epoch 635/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1764 - acc: 0.7897 - val_loss: 1.2273 - val_acc: 0.7550\n",
      "Epoch 636/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1755 - acc: 0.7909 - val_loss: 1.2264 - val_acc: 0.7529\n",
      "Epoch 637/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1746 - acc: 0.7913 - val_loss: 1.2256 - val_acc: 0.7550\n",
      "Epoch 638/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1736 - acc: 0.7931 - val_loss: 1.2247 - val_acc: 0.7533\n",
      "Epoch 639/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1728 - acc: 0.7902 - val_loss: 1.2238 - val_acc: 0.7546\n",
      "Epoch 640/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1719 - acc: 0.7915 - val_loss: 1.2231 - val_acc: 0.7542\n",
      "Epoch 641/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1709 - acc: 0.7922 - val_loss: 1.2222 - val_acc: 0.7542\n",
      "Epoch 642/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1701 - acc: 0.7918 - val_loss: 1.2214 - val_acc: 0.7579\n",
      "Epoch 643/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1691 - acc: 0.7911 - val_loss: 1.2205 - val_acc: 0.7542\n",
      "Epoch 644/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1683 - acc: 0.7905 - val_loss: 1.2197 - val_acc: 0.7550\n",
      "Epoch 645/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1673 - acc: 0.7930 - val_loss: 1.2188 - val_acc: 0.7542\n",
      "Epoch 646/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1665 - acc: 0.7927 - val_loss: 1.2180 - val_acc: 0.7562\n",
      "Epoch 647/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1656 - acc: 0.7922 - val_loss: 1.2173 - val_acc: 0.7550\n",
      "Epoch 648/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1647 - acc: 0.7916 - val_loss: 1.2162 - val_acc: 0.7567\n",
      "Epoch 649/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1638 - acc: 0.7940 - val_loss: 1.2155 - val_acc: 0.7571\n",
      "Epoch 650/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1629 - acc: 0.7922 - val_loss: 1.2147 - val_acc: 0.7583\n",
      "Epoch 651/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1620 - acc: 0.7926 - val_loss: 1.2139 - val_acc: 0.7579\n",
      "Epoch 652/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1611 - acc: 0.7916 - val_loss: 1.2130 - val_acc: 0.7592\n",
      "Epoch 653/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1602 - acc: 0.7924 - val_loss: 1.2122 - val_acc: 0.7567\n",
      "Epoch 654/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1593 - acc: 0.7933 - val_loss: 1.2113 - val_acc: 0.7571\n",
      "Epoch 655/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1585 - acc: 0.7925 - val_loss: 1.2106 - val_acc: 0.7558\n",
      "Epoch 656/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1576 - acc: 0.7919 - val_loss: 1.2097 - val_acc: 0.7571\n",
      "Epoch 657/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1567 - acc: 0.7934 - val_loss: 1.2088 - val_acc: 0.7571\n",
      "Epoch 658/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1559 - acc: 0.7939 - val_loss: 1.2081 - val_acc: 0.7575\n",
      "Epoch 659/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1550 - acc: 0.7927 - val_loss: 1.2073 - val_acc: 0.7587\n",
      "Epoch 660/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1541 - acc: 0.7949 - val_loss: 1.2064 - val_acc: 0.7579\n",
      "Epoch 661/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1532 - acc: 0.7946 - val_loss: 1.2056 - val_acc: 0.7575\n",
      "Epoch 662/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1524 - acc: 0.7934 - val_loss: 1.2048 - val_acc: 0.7575\n",
      "Epoch 663/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1515 - acc: 0.7932 - val_loss: 1.2040 - val_acc: 0.7583\n",
      "Epoch 664/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1506 - acc: 0.7935 - val_loss: 1.2032 - val_acc: 0.7587\n",
      "Epoch 665/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1498 - acc: 0.7945 - val_loss: 1.2024 - val_acc: 0.7583\n",
      "Epoch 666/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.1489 - acc: 0.7945 - val_loss: 1.2016 - val_acc: 0.7587\n",
      "Epoch 667/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.1481 - acc: 0.7936 - val_loss: 1.2008 - val_acc: 0.7575\n",
      "Epoch 668/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.1473 - acc: 0.7940 - val_loss: 1.2001 - val_acc: 0.7575\n",
      "Epoch 669/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.1464 - acc: 0.7938 - val_loss: 1.1992 - val_acc: 0.7579\n",
      "Epoch 670/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.1455 - acc: 0.7946 - val_loss: 1.1984 - val_acc: 0.7583\n",
      "Epoch 671/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1448 - acc: 0.7938 - val_loss: 1.1976 - val_acc: 0.7579\n",
      "Epoch 672/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1438 - acc: 0.7944 - val_loss: 1.1968 - val_acc: 0.7587\n",
      "Epoch 673/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1430 - acc: 0.7950 - val_loss: 1.1961 - val_acc: 0.7592\n",
      "Epoch 674/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1422 - acc: 0.7935 - val_loss: 1.1952 - val_acc: 0.7571\n",
      "Epoch 675/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1414 - acc: 0.7939 - val_loss: 1.1945 - val_acc: 0.7579\n",
      "Epoch 676/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.1405 - acc: 0.7961 - val_loss: 1.1937 - val_acc: 0.7583\n",
      "Epoch 677/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1396 - acc: 0.7944 - val_loss: 1.1929 - val_acc: 0.7583\n",
      "Epoch 678/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1388 - acc: 0.7958 - val_loss: 1.1921 - val_acc: 0.7583\n",
      "Epoch 679/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1380 - acc: 0.7955 - val_loss: 1.1914 - val_acc: 0.7592\n",
      "Epoch 680/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1371 - acc: 0.7941 - val_loss: 1.1905 - val_acc: 0.7583\n",
      "Epoch 681/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1364 - acc: 0.7946 - val_loss: 1.1897 - val_acc: 0.7592\n",
      "Epoch 682/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1355 - acc: 0.7954 - val_loss: 1.1890 - val_acc: 0.7583\n",
      "Epoch 683/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.1346 - acc: 0.7949 - val_loss: 1.1882 - val_acc: 0.7583\n",
      "Epoch 684/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.1338 - acc: 0.7961 - val_loss: 1.1874 - val_acc: 0.7587\n",
      "Epoch 685/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.1329 - acc: 0.7944 - val_loss: 1.1866 - val_acc: 0.7587\n",
      "Epoch 686/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1321 - acc: 0.7956 - val_loss: 1.1859 - val_acc: 0.7592\n",
      "Epoch 687/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1313 - acc: 0.7952 - val_loss: 1.1850 - val_acc: 0.7592\n",
      "Epoch 688/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1305 - acc: 0.7960 - val_loss: 1.1844 - val_acc: 0.7596\n",
      "Epoch 689/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1297 - acc: 0.7939 - val_loss: 1.1836 - val_acc: 0.7583\n",
      "Epoch 690/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1289 - acc: 0.7952 - val_loss: 1.1828 - val_acc: 0.7592\n",
      "Epoch 691/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1280 - acc: 0.7953 - val_loss: 1.1820 - val_acc: 0.7587\n",
      "Epoch 692/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1273 - acc: 0.7963 - val_loss: 1.1812 - val_acc: 0.7596\n",
      "Epoch 693/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1265 - acc: 0.7955 - val_loss: 1.1805 - val_acc: 0.7587\n",
      "Epoch 694/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1256 - acc: 0.7974 - val_loss: 1.1798 - val_acc: 0.7600\n",
      "Epoch 695/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1248 - acc: 0.7966 - val_loss: 1.1790 - val_acc: 0.7596\n",
      "Epoch 696/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1239 - acc: 0.7964 - val_loss: 1.1782 - val_acc: 0.7579\n",
      "Epoch 697/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1232 - acc: 0.7964 - val_loss: 1.1775 - val_acc: 0.7587\n",
      "Epoch 698/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1224 - acc: 0.7958 - val_loss: 1.1768 - val_acc: 0.7587\n",
      "Epoch 699/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1216 - acc: 0.7967 - val_loss: 1.1760 - val_acc: 0.7587\n",
      "Epoch 700/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1208 - acc: 0.7959 - val_loss: 1.1754 - val_acc: 0.7600\n",
      "Epoch 701/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1200 - acc: 0.7952 - val_loss: 1.1745 - val_acc: 0.7587\n",
      "Epoch 702/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1191 - acc: 0.7961 - val_loss: 1.1738 - val_acc: 0.7600\n",
      "Epoch 703/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1184 - acc: 0.7961 - val_loss: 1.1730 - val_acc: 0.7592\n",
      "Epoch 704/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1175 - acc: 0.7973 - val_loss: 1.1722 - val_acc: 0.7592\n",
      "Epoch 705/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1168 - acc: 0.7967 - val_loss: 1.1716 - val_acc: 0.7592\n",
      "Epoch 706/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1159 - acc: 0.7964 - val_loss: 1.1707 - val_acc: 0.7587\n",
      "Epoch 707/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1152 - acc: 0.7966 - val_loss: 1.1700 - val_acc: 0.7579\n",
      "Epoch 708/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1144 - acc: 0.7967 - val_loss: 1.1693 - val_acc: 0.7583\n",
      "Epoch 709/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1136 - acc: 0.7968 - val_loss: 1.1686 - val_acc: 0.7600\n",
      "Epoch 710/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1128 - acc: 0.7986 - val_loss: 1.1677 - val_acc: 0.7596\n",
      "Epoch 711/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.1120 - acc: 0.7967 - val_loss: 1.1671 - val_acc: 0.7587\n",
      "Epoch 712/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1112 - acc: 0.7972 - val_loss: 1.1664 - val_acc: 0.7592\n",
      "Epoch 713/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.1104 - acc: 0.7966 - val_loss: 1.1656 - val_acc: 0.7587\n",
      "Epoch 714/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1096 - acc: 0.7982 - val_loss: 1.1647 - val_acc: 0.7587\n",
      "Epoch 715/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1089 - acc: 0.7973 - val_loss: 1.1641 - val_acc: 0.7592\n",
      "Epoch 716/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1081 - acc: 0.7963 - val_loss: 1.1633 - val_acc: 0.7592\n",
      "Epoch 717/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.1072 - acc: 0.7979 - val_loss: 1.1626 - val_acc: 0.7600\n",
      "Epoch 718/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.1065 - acc: 0.7982 - val_loss: 1.1619 - val_acc: 0.7587\n",
      "Epoch 719/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1058 - acc: 0.7970 - val_loss: 1.1611 - val_acc: 0.7592\n",
      "Epoch 720/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1049 - acc: 0.7989 - val_loss: 1.1604 - val_acc: 0.7596\n",
      "Epoch 721/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1042 - acc: 0.7979 - val_loss: 1.1597 - val_acc: 0.7587\n",
      "Epoch 722/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.1033 - acc: 0.7981 - val_loss: 1.1590 - val_acc: 0.7596\n",
      "Epoch 723/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1026 - acc: 0.7971 - val_loss: 1.1583 - val_acc: 0.7592\n",
      "Epoch 724/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.1018 - acc: 0.7976 - val_loss: 1.1576 - val_acc: 0.7596\n",
      "Epoch 725/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.1010 - acc: 0.7977 - val_loss: 1.1568 - val_acc: 0.7617\n",
      "Epoch 726/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.1003 - acc: 0.7987 - val_loss: 1.1561 - val_acc: 0.7613\n",
      "Epoch 727/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.0995 - acc: 0.7986 - val_loss: 1.1553 - val_acc: 0.7604\n",
      "Epoch 728/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.0987 - acc: 0.7983 - val_loss: 1.1547 - val_acc: 0.7612\n",
      "Epoch 729/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.0980 - acc: 0.7982 - val_loss: 1.1540 - val_acc: 0.7600\n",
      "Epoch 730/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.0972 - acc: 0.7979 - val_loss: 1.1532 - val_acc: 0.7600\n",
      "Epoch 731/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.0964 - acc: 0.7983 - val_loss: 1.1525 - val_acc: 0.7587\n",
      "Epoch 732/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.0957 - acc: 0.7984 - val_loss: 1.1518 - val_acc: 0.7596\n",
      "Epoch 733/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.0949 - acc: 0.7986 - val_loss: 1.1510 - val_acc: 0.7621\n",
      "Epoch 734/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0941 - acc: 0.7982 - val_loss: 1.1503 - val_acc: 0.7596\n",
      "Epoch 735/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0934 - acc: 0.7990 - val_loss: 1.1496 - val_acc: 0.7604\n",
      "Epoch 736/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0927 - acc: 0.7992 - val_loss: 1.1490 - val_acc: 0.7612\n",
      "Epoch 737/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.0920 - acc: 0.7990 - val_loss: 1.1483 - val_acc: 0.7612\n",
      "Epoch 738/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0912 - acc: 0.7985 - val_loss: 1.1475 - val_acc: 0.7633\n",
      "Epoch 739/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0904 - acc: 0.7967 - val_loss: 1.1468 - val_acc: 0.7604\n",
      "Epoch 740/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0896 - acc: 0.7985 - val_loss: 1.1461 - val_acc: 0.7633\n",
      "Epoch 741/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0889 - acc: 0.7999 - val_loss: 1.1454 - val_acc: 0.7629\n",
      "Epoch 742/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0881 - acc: 0.7998 - val_loss: 1.1447 - val_acc: 0.7600\n",
      "Epoch 743/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0874 - acc: 0.7987 - val_loss: 1.1441 - val_acc: 0.7604\n",
      "Epoch 744/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0866 - acc: 0.8000 - val_loss: 1.1434 - val_acc: 0.7629\n",
      "Epoch 745/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0859 - acc: 0.7986 - val_loss: 1.1427 - val_acc: 0.7617\n",
      "Epoch 746/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0852 - acc: 0.7991 - val_loss: 1.1420 - val_acc: 0.7625\n",
      "Epoch 747/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0844 - acc: 0.7994 - val_loss: 1.1413 - val_acc: 0.7608\n",
      "Epoch 748/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0837 - acc: 0.7996 - val_loss: 1.1406 - val_acc: 0.7625\n",
      "Epoch 749/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0830 - acc: 0.7994 - val_loss: 1.1399 - val_acc: 0.7633\n",
      "Epoch 750/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0822 - acc: 0.7998 - val_loss: 1.1393 - val_acc: 0.7617\n",
      "Epoch 751/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0815 - acc: 0.8004 - val_loss: 1.1386 - val_acc: 0.7621\n",
      "Epoch 752/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0807 - acc: 0.8007 - val_loss: 1.1378 - val_acc: 0.7633\n",
      "Epoch 753/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0800 - acc: 0.8004 - val_loss: 1.1372 - val_acc: 0.7613\n",
      "Epoch 754/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0793 - acc: 0.7994 - val_loss: 1.1366 - val_acc: 0.7638\n",
      "Epoch 755/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0785 - acc: 0.8000 - val_loss: 1.1358 - val_acc: 0.7638\n",
      "Epoch 756/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0779 - acc: 0.8003 - val_loss: 1.1352 - val_acc: 0.7642\n",
      "Epoch 757/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0771 - acc: 0.7990 - val_loss: 1.1345 - val_acc: 0.7629\n",
      "Epoch 758/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0764 - acc: 0.8007 - val_loss: 1.1338 - val_acc: 0.7625\n",
      "Epoch 759/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0757 - acc: 0.8001 - val_loss: 1.1331 - val_acc: 0.7642\n",
      "Epoch 760/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0750 - acc: 0.7997 - val_loss: 1.1325 - val_acc: 0.7629\n",
      "Epoch 761/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0743 - acc: 0.8005 - val_loss: 1.1319 - val_acc: 0.7633\n",
      "Epoch 762/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0735 - acc: 0.8008 - val_loss: 1.1312 - val_acc: 0.7638\n",
      "Epoch 763/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0728 - acc: 0.8005 - val_loss: 1.1306 - val_acc: 0.7629\n",
      "Epoch 764/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0721 - acc: 0.8011 - val_loss: 1.1298 - val_acc: 0.7642\n",
      "Epoch 765/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0714 - acc: 0.7994 - val_loss: 1.1292 - val_acc: 0.7629\n",
      "Epoch 766/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0707 - acc: 0.8009 - val_loss: 1.1285 - val_acc: 0.7633\n",
      "Epoch 767/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0700 - acc: 0.8015 - val_loss: 1.1278 - val_acc: 0.7638\n",
      "Epoch 768/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0692 - acc: 0.8003 - val_loss: 1.1272 - val_acc: 0.7650\n",
      "Epoch 769/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0686 - acc: 0.8011 - val_loss: 1.1266 - val_acc: 0.7638\n",
      "Epoch 770/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0678 - acc: 0.8010 - val_loss: 1.1259 - val_acc: 0.7646\n",
      "Epoch 771/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0672 - acc: 0.8000 - val_loss: 1.1252 - val_acc: 0.7646\n",
      "Epoch 772/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0665 - acc: 0.8011 - val_loss: 1.1246 - val_acc: 0.7646\n",
      "Epoch 773/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0657 - acc: 0.8004 - val_loss: 1.1239 - val_acc: 0.7629\n",
      "Epoch 774/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0650 - acc: 0.8007 - val_loss: 1.1232 - val_acc: 0.7658\n",
      "Epoch 775/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0643 - acc: 0.8017 - val_loss: 1.1228 - val_acc: 0.7638\n",
      "Epoch 776/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0636 - acc: 0.8014 - val_loss: 1.1220 - val_acc: 0.7642\n",
      "Epoch 777/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0630 - acc: 0.8028 - val_loss: 1.1214 - val_acc: 0.7646\n",
      "Epoch 778/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0623 - acc: 0.8021 - val_loss: 1.1207 - val_acc: 0.7642\n",
      "Epoch 779/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0616 - acc: 0.8010 - val_loss: 1.1200 - val_acc: 0.7642\n",
      "Epoch 780/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0609 - acc: 0.8015 - val_loss: 1.1193 - val_acc: 0.7633\n",
      "Epoch 781/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0602 - acc: 0.8029 - val_loss: 1.1187 - val_acc: 0.7654\n",
      "Epoch 782/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0595 - acc: 0.8015 - val_loss: 1.1182 - val_acc: 0.7638\n",
      "Epoch 783/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0589 - acc: 0.8008 - val_loss: 1.1176 - val_acc: 0.7633\n",
      "Epoch 784/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0581 - acc: 0.8021 - val_loss: 1.1169 - val_acc: 0.7646\n",
      "Epoch 785/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0574 - acc: 0.8013 - val_loss: 1.1162 - val_acc: 0.7650\n",
      "Epoch 786/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0568 - acc: 0.8023 - val_loss: 1.1156 - val_acc: 0.7642\n",
      "Epoch 787/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0561 - acc: 0.8027 - val_loss: 1.1149 - val_acc: 0.7646\n",
      "Epoch 788/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0554 - acc: 0.8018 - val_loss: 1.1144 - val_acc: 0.7654\n",
      "Epoch 789/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.0547 - acc: 0.8024 - val_loss: 1.1136 - val_acc: 0.7646\n",
      "Epoch 790/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0540 - acc: 0.8017 - val_loss: 1.1131 - val_acc: 0.7658\n",
      "Epoch 791/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0534 - acc: 0.8017 - val_loss: 1.1124 - val_acc: 0.7658\n",
      "Epoch 792/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0527 - acc: 0.8027 - val_loss: 1.1118 - val_acc: 0.7658\n",
      "Epoch 793/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0519 - acc: 0.8032 - val_loss: 1.1111 - val_acc: 0.7654\n",
      "Epoch 794/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0513 - acc: 0.8020 - val_loss: 1.1106 - val_acc: 0.7654\n",
      "Epoch 795/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0506 - acc: 0.8021 - val_loss: 1.1098 - val_acc: 0.7650\n",
      "Epoch 796/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0500 - acc: 0.8022 - val_loss: 1.1092 - val_acc: 0.7650\n",
      "Epoch 797/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0493 - acc: 0.8024 - val_loss: 1.1088 - val_acc: 0.7658\n",
      "Epoch 798/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0486 - acc: 0.8018 - val_loss: 1.1080 - val_acc: 0.7654\n",
      "Epoch 799/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0479 - acc: 0.8028 - val_loss: 1.1074 - val_acc: 0.7662\n",
      "Epoch 800/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0473 - acc: 0.8019 - val_loss: 1.1068 - val_acc: 0.7654\n",
      "Epoch 801/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0466 - acc: 0.8033 - val_loss: 1.1061 - val_acc: 0.7654\n",
      "Epoch 802/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0459 - acc: 0.8034 - val_loss: 1.1056 - val_acc: 0.7658\n",
      "Epoch 803/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0452 - acc: 0.8033 - val_loss: 1.1049 - val_acc: 0.7650\n",
      "Epoch 804/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0446 - acc: 0.8032 - val_loss: 1.1042 - val_acc: 0.7646\n",
      "Epoch 805/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0439 - acc: 0.8025 - val_loss: 1.1036 - val_acc: 0.7654\n",
      "Epoch 806/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0432 - acc: 0.8035 - val_loss: 1.1030 - val_acc: 0.7650\n",
      "Epoch 807/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0426 - acc: 0.8035 - val_loss: 1.1025 - val_acc: 0.7654\n",
      "Epoch 808/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0419 - acc: 0.8032 - val_loss: 1.1018 - val_acc: 0.7658\n",
      "Epoch 809/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0413 - acc: 0.8026 - val_loss: 1.1012 - val_acc: 0.7667\n",
      "Epoch 810/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0406 - acc: 0.8027 - val_loss: 1.1006 - val_acc: 0.7654\n",
      "Epoch 811/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0399 - acc: 0.8030 - val_loss: 1.1000 - val_acc: 0.7658\n",
      "Epoch 812/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0393 - acc: 0.8031 - val_loss: 1.0994 - val_acc: 0.7650\n",
      "Epoch 813/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0386 - acc: 0.8027 - val_loss: 1.0988 - val_acc: 0.7667\n",
      "Epoch 814/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0380 - acc: 0.8035 - val_loss: 1.0981 - val_acc: 0.7658\n",
      "Epoch 815/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0373 - acc: 0.8032 - val_loss: 1.0975 - val_acc: 0.7646\n",
      "Epoch 816/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0367 - acc: 0.8031 - val_loss: 1.0970 - val_acc: 0.7658\n",
      "Epoch 817/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0360 - acc: 0.8034 - val_loss: 1.0963 - val_acc: 0.7658\n",
      "Epoch 818/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0354 - acc: 0.8039 - val_loss: 1.0958 - val_acc: 0.7658\n",
      "Epoch 819/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0348 - acc: 0.8031 - val_loss: 1.0951 - val_acc: 0.7654\n",
      "Epoch 820/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0341 - acc: 0.8042 - val_loss: 1.0946 - val_acc: 0.7654\n",
      "Epoch 821/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0334 - acc: 0.8040 - val_loss: 1.0939 - val_acc: 0.7662\n",
      "Epoch 822/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0328 - acc: 0.8031 - val_loss: 1.0934 - val_acc: 0.7650\n",
      "Epoch 823/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.0321 - acc: 0.8033 - val_loss: 1.0927 - val_acc: 0.7646\n",
      "Epoch 824/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0315 - acc: 0.8030 - val_loss: 1.0921 - val_acc: 0.7662\n",
      "Epoch 825/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0308 - acc: 0.8041 - val_loss: 1.0916 - val_acc: 0.7654\n",
      "Epoch 826/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0302 - acc: 0.8036 - val_loss: 1.0909 - val_acc: 0.7658\n",
      "Epoch 827/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0296 - acc: 0.8043 - val_loss: 1.0903 - val_acc: 0.7658\n",
      "Epoch 828/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0289 - acc: 0.8030 - val_loss: 1.0897 - val_acc: 0.7662\n",
      "Epoch 829/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0282 - acc: 0.8042 - val_loss: 1.0891 - val_acc: 0.7654\n",
      "Epoch 830/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0276 - acc: 0.8040 - val_loss: 1.0885 - val_acc: 0.7654\n",
      "Epoch 831/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0270 - acc: 0.8037 - val_loss: 1.0880 - val_acc: 0.7658\n",
      "Epoch 832/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0264 - acc: 0.8041 - val_loss: 1.0874 - val_acc: 0.7667\n",
      "Epoch 833/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0258 - acc: 0.8046 - val_loss: 1.0868 - val_acc: 0.7658\n",
      "Epoch 834/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0252 - acc: 0.8048 - val_loss: 1.0862 - val_acc: 0.7662\n",
      "Epoch 835/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0244 - acc: 0.8039 - val_loss: 1.0856 - val_acc: 0.7654\n",
      "Epoch 836/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0238 - acc: 0.8042 - val_loss: 1.0850 - val_acc: 0.7662\n",
      "Epoch 837/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.0233 - acc: 0.8039 - val_loss: 1.0844 - val_acc: 0.7658\n",
      "Epoch 838/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.0226 - acc: 0.8047 - val_loss: 1.0839 - val_acc: 0.7662\n",
      "Epoch 839/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.0220 - acc: 0.8039 - val_loss: 1.0833 - val_acc: 0.7658\n",
      "Epoch 840/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.0214 - acc: 0.8037 - val_loss: 1.0828 - val_acc: 0.7654\n",
      "Epoch 841/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.0207 - acc: 0.8050 - val_loss: 1.0822 - val_acc: 0.7667\n",
      "Epoch 842/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.0201 - acc: 0.8044 - val_loss: 1.0816 - val_acc: 0.7650\n",
      "Epoch 843/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.0195 - acc: 0.8046 - val_loss: 1.0811 - val_acc: 0.7662\n",
      "Epoch 844/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.0189 - acc: 0.8045 - val_loss: 1.0805 - val_acc: 0.7658\n",
      "Epoch 845/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.0183 - acc: 0.8049 - val_loss: 1.0800 - val_acc: 0.7667\n",
      "Epoch 846/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.0177 - acc: 0.8047 - val_loss: 1.0793 - val_acc: 0.7654\n",
      "Epoch 847/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.0170 - acc: 0.8041 - val_loss: 1.0787 - val_acc: 0.7662\n",
      "Epoch 848/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.0165 - acc: 0.8048 - val_loss: 1.0781 - val_acc: 0.7667\n",
      "Epoch 849/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.0158 - acc: 0.8053 - val_loss: 1.0776 - val_acc: 0.7671\n",
      "Epoch 850/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.0152 - acc: 0.8057 - val_loss: 1.0770 - val_acc: 0.7675\n",
      "Epoch 851/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.0146 - acc: 0.8057 - val_loss: 1.0764 - val_acc: 0.7658\n",
      "Epoch 852/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.0139 - acc: 0.8047 - val_loss: 1.0759 - val_acc: 0.7667\n",
      "Epoch 853/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.0133 - acc: 0.8052 - val_loss: 1.0753 - val_acc: 0.7662\n",
      "Epoch 854/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.0127 - acc: 0.8044 - val_loss: 1.0748 - val_acc: 0.7667\n",
      "Epoch 855/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.0121 - acc: 0.8052 - val_loss: 1.0743 - val_acc: 0.7654\n",
      "Epoch 856/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.0116 - acc: 0.8046 - val_loss: 1.0736 - val_acc: 0.7667\n",
      "Epoch 857/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.0109 - acc: 0.8051 - val_loss: 1.0731 - val_acc: 0.7671\n",
      "Epoch 858/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0103 - acc: 0.8057 - val_loss: 1.0726 - val_acc: 0.7658\n",
      "Epoch 859/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0098 - acc: 0.8048 - val_loss: 1.0720 - val_acc: 0.7667\n",
      "Epoch 860/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0092 - acc: 0.8048 - val_loss: 1.0715 - val_acc: 0.7658\n",
      "Epoch 861/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0086 - acc: 0.8056 - val_loss: 1.0710 - val_acc: 0.7667\n",
      "Epoch 862/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0080 - acc: 0.8059 - val_loss: 1.0705 - val_acc: 0.7671\n",
      "Epoch 863/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0073 - acc: 0.8053 - val_loss: 1.0698 - val_acc: 0.7658\n",
      "Epoch 864/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0068 - acc: 0.8060 - val_loss: 1.0693 - val_acc: 0.7654\n",
      "Epoch 865/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0061 - acc: 0.8054 - val_loss: 1.0687 - val_acc: 0.7667\n",
      "Epoch 866/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.0056 - acc: 0.8058 - val_loss: 1.0682 - val_acc: 0.7658\n",
      "Epoch 867/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.0050 - acc: 0.8055 - val_loss: 1.0677 - val_acc: 0.7662\n",
      "Epoch 868/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.0043 - acc: 0.8055 - val_loss: 1.0671 - val_acc: 0.7658\n",
      "Epoch 869/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.0038 - acc: 0.8066 - val_loss: 1.0665 - val_acc: 0.7662\n",
      "Epoch 870/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0032 - acc: 0.8064 - val_loss: 1.0660 - val_acc: 0.7658\n",
      "Epoch 871/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0026 - acc: 0.8055 - val_loss: 1.0655 - val_acc: 0.7662\n",
      "Epoch 872/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0020 - acc: 0.8064 - val_loss: 1.0649 - val_acc: 0.7662\n",
      "Epoch 873/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.0014 - acc: 0.8066 - val_loss: 1.0645 - val_acc: 0.7658\n",
      "Epoch 874/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.0009 - acc: 0.8049 - val_loss: 1.0637 - val_acc: 0.7675\n",
      "Epoch 875/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.0003 - acc: 0.8070 - val_loss: 1.0633 - val_acc: 0.7658\n",
      "Epoch 876/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.9997 - acc: 0.8054 - val_loss: 1.0628 - val_acc: 0.7683\n",
      "Epoch 877/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9990 - acc: 0.8063 - val_loss: 1.0622 - val_acc: 0.7662\n",
      "Epoch 878/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9985 - acc: 0.8064 - val_loss: 1.0617 - val_acc: 0.7671\n",
      "Epoch 879/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9980 - acc: 0.8051 - val_loss: 1.0611 - val_acc: 0.7671\n",
      "Epoch 880/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9974 - acc: 0.8071 - val_loss: 1.0605 - val_acc: 0.7679\n",
      "Epoch 881/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9967 - acc: 0.8057 - val_loss: 1.0600 - val_acc: 0.7667\n",
      "Epoch 882/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9961 - acc: 0.8064 - val_loss: 1.0595 - val_acc: 0.7671\n",
      "Epoch 883/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9956 - acc: 0.8065 - val_loss: 1.0589 - val_acc: 0.7667\n",
      "Epoch 884/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9950 - acc: 0.8051 - val_loss: 1.0584 - val_acc: 0.7675\n",
      "Epoch 885/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9944 - acc: 0.8060 - val_loss: 1.0579 - val_acc: 0.7679\n",
      "Epoch 886/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9938 - acc: 0.8077 - val_loss: 1.0573 - val_acc: 0.7675\n",
      "Epoch 887/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9932 - acc: 0.8068 - val_loss: 1.0568 - val_acc: 0.7683\n",
      "Epoch 888/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9927 - acc: 0.8063 - val_loss: 1.0564 - val_acc: 0.7667\n",
      "Epoch 889/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9921 - acc: 0.8068 - val_loss: 1.0558 - val_acc: 0.7675\n",
      "Epoch 890/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9915 - acc: 0.8076 - val_loss: 1.0552 - val_acc: 0.7662\n",
      "Epoch 891/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9910 - acc: 0.8061 - val_loss: 1.0547 - val_acc: 0.7675\n",
      "Epoch 892/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 0.9904 - acc: 0.8072 - val_loss: 1.0542 - val_acc: 0.7688\n",
      "Epoch 893/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9898 - acc: 0.8076 - val_loss: 1.0537 - val_acc: 0.7662\n",
      "Epoch 894/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9892 - acc: 0.8075 - val_loss: 1.0531 - val_acc: 0.7667\n",
      "Epoch 895/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9887 - acc: 0.8065 - val_loss: 1.0526 - val_acc: 0.7675\n",
      "Epoch 896/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9881 - acc: 0.8074 - val_loss: 1.0521 - val_acc: 0.7683\n",
      "Epoch 897/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9876 - acc: 0.8076 - val_loss: 1.0516 - val_acc: 0.7662\n",
      "Epoch 898/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9870 - acc: 0.8071 - val_loss: 1.0511 - val_acc: 0.7671\n",
      "Epoch 899/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9864 - acc: 0.8066 - val_loss: 1.0506 - val_acc: 0.7671\n",
      "Epoch 900/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9859 - acc: 0.8084 - val_loss: 1.0501 - val_acc: 0.7662\n",
      "Epoch 901/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9853 - acc: 0.8072 - val_loss: 1.0495 - val_acc: 0.7671\n",
      "Epoch 902/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9847 - acc: 0.8078 - val_loss: 1.0490 - val_acc: 0.7671\n",
      "Epoch 903/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9842 - acc: 0.8082 - val_loss: 1.0485 - val_acc: 0.7679\n",
      "Epoch 904/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9836 - acc: 0.8076 - val_loss: 1.0480 - val_acc: 0.7671\n",
      "Epoch 905/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9831 - acc: 0.8073 - val_loss: 1.0475 - val_acc: 0.7679\n",
      "Epoch 906/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9825 - acc: 0.8074 - val_loss: 1.0469 - val_acc: 0.7688\n",
      "Epoch 907/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9819 - acc: 0.8074 - val_loss: 1.0465 - val_acc: 0.7679\n",
      "Epoch 908/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9814 - acc: 0.8080 - val_loss: 1.0459 - val_acc: 0.7679\n",
      "Epoch 909/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9808 - acc: 0.8082 - val_loss: 1.0454 - val_acc: 0.7679\n",
      "Epoch 910/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9803 - acc: 0.8082 - val_loss: 1.0449 - val_acc: 0.7688\n",
      "Epoch 911/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9797 - acc: 0.8078 - val_loss: 1.0444 - val_acc: 0.7679\n",
      "Epoch 912/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9792 - acc: 0.8079 - val_loss: 1.0438 - val_acc: 0.7679\n",
      "Epoch 913/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9786 - acc: 0.8083 - val_loss: 1.0434 - val_acc: 0.7675\n",
      "Epoch 914/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9781 - acc: 0.8082 - val_loss: 1.0428 - val_acc: 0.7692\n",
      "Epoch 915/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9775 - acc: 0.8083 - val_loss: 1.0423 - val_acc: 0.7675\n",
      "Epoch 916/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9770 - acc: 0.8083 - val_loss: 1.0419 - val_acc: 0.7671\n",
      "Epoch 917/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.9765 - acc: 0.8091 - val_loss: 1.0414 - val_acc: 0.7675\n",
      "Epoch 918/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9759 - acc: 0.8090 - val_loss: 1.0409 - val_acc: 0.7675\n",
      "Epoch 919/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9754 - acc: 0.8077 - val_loss: 1.0404 - val_acc: 0.7692\n",
      "Epoch 920/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9748 - acc: 0.8086 - val_loss: 1.0399 - val_acc: 0.7683\n",
      "Epoch 921/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9743 - acc: 0.8080 - val_loss: 1.0394 - val_acc: 0.7679\n",
      "Epoch 922/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9737 - acc: 0.8084 - val_loss: 1.0388 - val_acc: 0.7683\n",
      "Epoch 923/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9732 - acc: 0.8094 - val_loss: 1.0383 - val_acc: 0.7679\n",
      "Epoch 924/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9726 - acc: 0.8085 - val_loss: 1.0379 - val_acc: 0.7687\n",
      "Epoch 925/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9720 - acc: 0.8084 - val_loss: 1.0374 - val_acc: 0.7688\n",
      "Epoch 926/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9715 - acc: 0.8088 - val_loss: 1.0368 - val_acc: 0.7683\n",
      "Epoch 927/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9710 - acc: 0.8093 - val_loss: 1.0364 - val_acc: 0.7675\n",
      "Epoch 928/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9705 - acc: 0.8096 - val_loss: 1.0359 - val_acc: 0.7675\n",
      "Epoch 929/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9699 - acc: 0.8092 - val_loss: 1.0354 - val_acc: 0.7683\n",
      "Epoch 930/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9694 - acc: 0.8091 - val_loss: 1.0348 - val_acc: 0.7683\n",
      "Epoch 931/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9689 - acc: 0.8091 - val_loss: 1.0344 - val_acc: 0.7692\n",
      "Epoch 932/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9683 - acc: 0.8090 - val_loss: 1.0339 - val_acc: 0.7688\n",
      "Epoch 933/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9678 - acc: 0.8100 - val_loss: 1.0335 - val_acc: 0.7683\n",
      "Epoch 934/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9672 - acc: 0.8093 - val_loss: 1.0330 - val_acc: 0.7683\n",
      "Epoch 935/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9667 - acc: 0.8091 - val_loss: 1.0325 - val_acc: 0.7683\n",
      "Epoch 936/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9662 - acc: 0.8093 - val_loss: 1.0320 - val_acc: 0.7692\n",
      "Epoch 937/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9656 - acc: 0.8094 - val_loss: 1.0315 - val_acc: 0.7696\n",
      "Epoch 938/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9651 - acc: 0.8098 - val_loss: 1.0310 - val_acc: 0.7679\n",
      "Epoch 939/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9646 - acc: 0.8100 - val_loss: 1.0305 - val_acc: 0.7692\n",
      "Epoch 940/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9641 - acc: 0.8096 - val_loss: 1.0300 - val_acc: 0.7696\n",
      "Epoch 941/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9635 - acc: 0.8097 - val_loss: 1.0295 - val_acc: 0.7683\n",
      "Epoch 942/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.9630 - acc: 0.8102 - val_loss: 1.0291 - val_acc: 0.7692\n",
      "Epoch 943/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9625 - acc: 0.8098 - val_loss: 1.0284 - val_acc: 0.7696\n",
      "Epoch 944/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9619 - acc: 0.8099 - val_loss: 1.0280 - val_acc: 0.7700\n",
      "Epoch 945/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9614 - acc: 0.8101 - val_loss: 1.0276 - val_acc: 0.7700\n",
      "Epoch 946/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9609 - acc: 0.8098 - val_loss: 1.0272 - val_acc: 0.7687\n",
      "Epoch 947/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.9604 - acc: 0.8109 - val_loss: 1.0265 - val_acc: 0.7687\n",
      "Epoch 948/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9599 - acc: 0.8102 - val_loss: 1.0262 - val_acc: 0.7687\n",
      "Epoch 949/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9593 - acc: 0.8102 - val_loss: 1.0257 - val_acc: 0.7687\n",
      "Epoch 950/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9588 - acc: 0.8103 - val_loss: 1.0252 - val_acc: 0.7700\n",
      "Epoch 951/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9583 - acc: 0.8103 - val_loss: 1.0247 - val_acc: 0.7696\n",
      "Epoch 952/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9578 - acc: 0.8103 - val_loss: 1.0243 - val_acc: 0.7696\n",
      "Epoch 953/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9573 - acc: 0.8111 - val_loss: 1.0237 - val_acc: 0.7692\n",
      "Epoch 954/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9568 - acc: 0.8102 - val_loss: 1.0233 - val_acc: 0.7696\n",
      "Epoch 955/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9562 - acc: 0.8101 - val_loss: 1.0229 - val_acc: 0.7687\n",
      "Epoch 956/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9557 - acc: 0.8105 - val_loss: 1.0224 - val_acc: 0.7692\n",
      "Epoch 957/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9552 - acc: 0.8107 - val_loss: 1.0219 - val_acc: 0.7692\n",
      "Epoch 958/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9547 - acc: 0.8109 - val_loss: 1.0214 - val_acc: 0.7700\n",
      "Epoch 959/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9542 - acc: 0.8103 - val_loss: 1.0210 - val_acc: 0.7687\n",
      "Epoch 960/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9537 - acc: 0.8113 - val_loss: 1.0205 - val_acc: 0.7696\n",
      "Epoch 961/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9532 - acc: 0.8100 - val_loss: 1.0201 - val_acc: 0.7692\n",
      "Epoch 962/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9526 - acc: 0.8109 - val_loss: 1.0195 - val_acc: 0.7704\n",
      "Epoch 963/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9522 - acc: 0.8109 - val_loss: 1.0190 - val_acc: 0.7696\n",
      "Epoch 964/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9517 - acc: 0.8110 - val_loss: 1.0186 - val_acc: 0.7700\n",
      "Epoch 965/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9511 - acc: 0.8105 - val_loss: 1.0181 - val_acc: 0.7687\n",
      "Epoch 966/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9506 - acc: 0.8109 - val_loss: 1.0178 - val_acc: 0.7700\n",
      "Epoch 967/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9501 - acc: 0.8111 - val_loss: 1.0172 - val_acc: 0.7704\n",
      "Epoch 968/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9496 - acc: 0.8113 - val_loss: 1.0168 - val_acc: 0.7696\n",
      "Epoch 969/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9491 - acc: 0.8119 - val_loss: 1.0164 - val_acc: 0.7700\n",
      "Epoch 970/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9486 - acc: 0.8113 - val_loss: 1.0159 - val_acc: 0.7692\n",
      "Epoch 971/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9481 - acc: 0.8110 - val_loss: 1.0153 - val_acc: 0.7696\n",
      "Epoch 972/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9476 - acc: 0.8116 - val_loss: 1.0149 - val_acc: 0.7696\n",
      "Epoch 973/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9471 - acc: 0.8114 - val_loss: 1.0145 - val_acc: 0.7704\n",
      "Epoch 974/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9466 - acc: 0.8114 - val_loss: 1.0141 - val_acc: 0.7692\n",
      "Epoch 975/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9461 - acc: 0.8113 - val_loss: 1.0135 - val_acc: 0.7700\n",
      "Epoch 976/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9456 - acc: 0.8117 - val_loss: 1.0132 - val_acc: 0.7692\n",
      "Epoch 977/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9451 - acc: 0.8115 - val_loss: 1.0126 - val_acc: 0.7696\n",
      "Epoch 978/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9446 - acc: 0.8117 - val_loss: 1.0122 - val_acc: 0.7700\n",
      "Epoch 979/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9441 - acc: 0.8123 - val_loss: 1.0118 - val_acc: 0.7700\n",
      "Epoch 980/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9436 - acc: 0.8117 - val_loss: 1.0114 - val_acc: 0.7692\n",
      "Epoch 981/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9432 - acc: 0.8119 - val_loss: 1.0108 - val_acc: 0.7700\n",
      "Epoch 982/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9427 - acc: 0.8119 - val_loss: 1.0105 - val_acc: 0.7696\n",
      "Epoch 983/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9422 - acc: 0.8123 - val_loss: 1.0100 - val_acc: 0.7704\n",
      "Epoch 984/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9417 - acc: 0.8120 - val_loss: 1.0094 - val_acc: 0.7704\n",
      "Epoch 985/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9412 - acc: 0.8121 - val_loss: 1.0091 - val_acc: 0.7700\n",
      "Epoch 986/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9407 - acc: 0.8125 - val_loss: 1.0086 - val_acc: 0.7704\n",
      "Epoch 987/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9402 - acc: 0.8122 - val_loss: 1.0081 - val_acc: 0.7704\n",
      "Epoch 988/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9397 - acc: 0.8121 - val_loss: 1.0078 - val_acc: 0.7704\n",
      "Epoch 989/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9392 - acc: 0.8121 - val_loss: 1.0073 - val_acc: 0.7696\n",
      "Epoch 990/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9387 - acc: 0.8122 - val_loss: 1.0068 - val_acc: 0.7704\n",
      "Epoch 991/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.9382 - acc: 0.8121 - val_loss: 1.0063 - val_acc: 0.7700\n",
      "Epoch 992/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9377 - acc: 0.8116 - val_loss: 1.0059 - val_acc: 0.7712\n",
      "Epoch 993/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9372 - acc: 0.8124 - val_loss: 1.0055 - val_acc: 0.7708\n",
      "Epoch 994/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9367 - acc: 0.8124 - val_loss: 1.0051 - val_acc: 0.7696\n",
      "Epoch 995/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9363 - acc: 0.8126 - val_loss: 1.0046 - val_acc: 0.7704\n",
      "Epoch 996/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9357 - acc: 0.8122 - val_loss: 1.0040 - val_acc: 0.7708\n",
      "Epoch 997/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9352 - acc: 0.8122 - val_loss: 1.0037 - val_acc: 0.7700\n",
      "Epoch 998/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9348 - acc: 0.8124 - val_loss: 1.0032 - val_acc: 0.7700\n",
      "Epoch 999/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9343 - acc: 0.8125 - val_loss: 1.0027 - val_acc: 0.7704\n",
      "Epoch 1000/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9338 - acc: 0.8122 - val_loss: 1.0024 - val_acc: 0.7717\n",
      "Epoch 1001/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9333 - acc: 0.8130 - val_loss: 1.0019 - val_acc: 0.7712\n",
      "Epoch 1002/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9328 - acc: 0.8123 - val_loss: 1.0015 - val_acc: 0.7708\n",
      "Epoch 1003/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9324 - acc: 0.8129 - val_loss: 1.0010 - val_acc: 0.7712\n",
      "Epoch 1004/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9319 - acc: 0.8129 - val_loss: 1.0005 - val_acc: 0.7712\n",
      "Epoch 1005/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9314 - acc: 0.8126 - val_loss: 1.0002 - val_acc: 0.7717\n",
      "Epoch 1006/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9309 - acc: 0.8125 - val_loss: 0.9997 - val_acc: 0.7696\n",
      "Epoch 1007/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9304 - acc: 0.8123 - val_loss: 0.9992 - val_acc: 0.7712\n",
      "Epoch 1008/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9299 - acc: 0.8130 - val_loss: 0.9988 - val_acc: 0.7712\n",
      "Epoch 1009/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9295 - acc: 0.8133 - val_loss: 0.9983 - val_acc: 0.7717\n",
      "Epoch 1010/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9291 - acc: 0.8129 - val_loss: 0.9979 - val_acc: 0.7687\n",
      "Epoch 1011/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9285 - acc: 0.8123 - val_loss: 0.9974 - val_acc: 0.7708\n",
      "Epoch 1012/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9281 - acc: 0.8129 - val_loss: 0.9971 - val_acc: 0.7708\n",
      "Epoch 1013/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9276 - acc: 0.8122 - val_loss: 0.9966 - val_acc: 0.7704\n",
      "Epoch 1014/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9271 - acc: 0.8132 - val_loss: 0.9963 - val_acc: 0.7700\n",
      "Epoch 1015/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9266 - acc: 0.8128 - val_loss: 0.9959 - val_acc: 0.7721\n",
      "Epoch 1016/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9262 - acc: 0.8131 - val_loss: 0.9954 - val_acc: 0.7725\n",
      "Epoch 1017/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9257 - acc: 0.8124 - val_loss: 0.9950 - val_acc: 0.7700\n",
      "Epoch 1018/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.9252 - acc: 0.8134 - val_loss: 0.9945 - val_acc: 0.7704\n",
      "Epoch 1019/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9247 - acc: 0.8132 - val_loss: 0.9941 - val_acc: 0.7708\n",
      "Epoch 1020/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9243 - acc: 0.8132 - val_loss: 0.9936 - val_acc: 0.7721\n",
      "Epoch 1021/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9238 - acc: 0.8140 - val_loss: 0.9933 - val_acc: 0.7721\n",
      "Epoch 1022/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9234 - acc: 0.8125 - val_loss: 0.9929 - val_acc: 0.7725\n",
      "Epoch 1023/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9229 - acc: 0.8130 - val_loss: 0.9925 - val_acc: 0.7717\n",
      "Epoch 1024/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9224 - acc: 0.8136 - val_loss: 0.9920 - val_acc: 0.7717\n",
      "Epoch 1025/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9220 - acc: 0.8139 - val_loss: 0.9917 - val_acc: 0.7717\n",
      "Epoch 1026/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9215 - acc: 0.8134 - val_loss: 0.9911 - val_acc: 0.7708\n",
      "Epoch 1027/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9210 - acc: 0.8131 - val_loss: 0.9908 - val_acc: 0.7725\n",
      "Epoch 1028/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9206 - acc: 0.8146 - val_loss: 0.9903 - val_acc: 0.7725\n",
      "Epoch 1029/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9201 - acc: 0.8137 - val_loss: 0.9899 - val_acc: 0.7725\n",
      "Epoch 1030/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9197 - acc: 0.8131 - val_loss: 0.9895 - val_acc: 0.7742\n",
      "Epoch 1031/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.9192 - acc: 0.8136 - val_loss: 0.9891 - val_acc: 0.7733\n",
      "Epoch 1032/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9187 - acc: 0.8137 - val_loss: 0.9887 - val_acc: 0.7738\n",
      "Epoch 1033/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9183 - acc: 0.8131 - val_loss: 0.9882 - val_acc: 0.7729\n",
      "Epoch 1034/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9178 - acc: 0.8140 - val_loss: 0.9878 - val_acc: 0.7725\n",
      "Epoch 1035/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9174 - acc: 0.8132 - val_loss: 0.9875 - val_acc: 0.7729\n",
      "Epoch 1036/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9169 - acc: 0.8134 - val_loss: 0.9869 - val_acc: 0.7717\n",
      "Epoch 1037/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9164 - acc: 0.8141 - val_loss: 0.9866 - val_acc: 0.7721\n",
      "Epoch 1038/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9160 - acc: 0.8137 - val_loss: 0.9861 - val_acc: 0.7729\n",
      "Epoch 1039/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9156 - acc: 0.8141 - val_loss: 0.9858 - val_acc: 0.7733\n",
      "Epoch 1040/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9151 - acc: 0.8139 - val_loss: 0.9853 - val_acc: 0.7721\n",
      "Epoch 1041/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9146 - acc: 0.8143 - val_loss: 0.9849 - val_acc: 0.7733\n",
      "Epoch 1042/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9142 - acc: 0.8141 - val_loss: 0.9844 - val_acc: 0.7733\n",
      "Epoch 1043/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9137 - acc: 0.8139 - val_loss: 0.9841 - val_acc: 0.7750\n",
      "Epoch 1044/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9133 - acc: 0.8139 - val_loss: 0.9837 - val_acc: 0.7737\n",
      "Epoch 1045/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9129 - acc: 0.8139 - val_loss: 0.9833 - val_acc: 0.7738\n",
      "Epoch 1046/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9124 - acc: 0.8144 - val_loss: 0.9829 - val_acc: 0.7721\n",
      "Epoch 1047/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9119 - acc: 0.8141 - val_loss: 0.9824 - val_acc: 0.7725\n",
      "Epoch 1048/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9115 - acc: 0.8137 - val_loss: 0.9821 - val_acc: 0.7725\n",
      "Epoch 1049/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9110 - acc: 0.8132 - val_loss: 0.9816 - val_acc: 0.7742\n",
      "Epoch 1050/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9106 - acc: 0.8144 - val_loss: 0.9813 - val_acc: 0.7725\n",
      "Epoch 1051/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9102 - acc: 0.8144 - val_loss: 0.9809 - val_acc: 0.7746\n",
      "Epoch 1052/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9098 - acc: 0.8139 - val_loss: 0.9805 - val_acc: 0.7742\n",
      "Epoch 1053/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9093 - acc: 0.8148 - val_loss: 0.9800 - val_acc: 0.7754\n",
      "Epoch 1054/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9088 - acc: 0.8148 - val_loss: 0.9796 - val_acc: 0.7750\n",
      "Epoch 1055/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9084 - acc: 0.8146 - val_loss: 0.9793 - val_acc: 0.7746\n",
      "Epoch 1056/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9079 - acc: 0.8141 - val_loss: 0.9788 - val_acc: 0.7758\n",
      "Epoch 1057/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.9076 - acc: 0.8142 - val_loss: 0.9785 - val_acc: 0.7750\n",
      "Epoch 1058/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9071 - acc: 0.8151 - val_loss: 0.9780 - val_acc: 0.7767\n",
      "Epoch 1059/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9067 - acc: 0.8149 - val_loss: 0.9777 - val_acc: 0.7742\n",
      "Epoch 1060/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9062 - acc: 0.8148 - val_loss: 0.9773 - val_acc: 0.7754\n",
      "Epoch 1061/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9058 - acc: 0.8149 - val_loss: 0.9769 - val_acc: 0.7733\n",
      "Epoch 1062/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9053 - acc: 0.8146 - val_loss: 0.9765 - val_acc: 0.7750\n",
      "Epoch 1063/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9049 - acc: 0.8148 - val_loss: 0.9761 - val_acc: 0.7746\n",
      "Epoch 1064/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9045 - acc: 0.8146 - val_loss: 0.9756 - val_acc: 0.7754\n",
      "Epoch 1065/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9040 - acc: 0.8154 - val_loss: 0.9753 - val_acc: 0.7746\n",
      "Epoch 1066/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.9036 - acc: 0.8146 - val_loss: 0.9749 - val_acc: 0.7754\n",
      "Epoch 1067/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9032 - acc: 0.8149 - val_loss: 0.9745 - val_acc: 0.7754\n",
      "Epoch 1068/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.9027 - acc: 0.8150 - val_loss: 0.9742 - val_acc: 0.7767\n",
      "Epoch 1069/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.9023 - acc: 0.8156 - val_loss: 0.9738 - val_acc: 0.7754\n",
      "Epoch 1070/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9019 - acc: 0.8155 - val_loss: 0.9735 - val_acc: 0.7733\n",
      "Epoch 1071/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9015 - acc: 0.8147 - val_loss: 0.9730 - val_acc: 0.7750\n",
      "Epoch 1072/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9010 - acc: 0.8151 - val_loss: 0.9726 - val_acc: 0.7746\n",
      "Epoch 1073/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9006 - acc: 0.8151 - val_loss: 0.9721 - val_acc: 0.7750\n",
      "Epoch 1074/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.9002 - acc: 0.8153 - val_loss: 0.9717 - val_acc: 0.7733\n",
      "Epoch 1075/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8997 - acc: 0.8151 - val_loss: 0.9714 - val_acc: 0.7738\n",
      "Epoch 1076/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.8993 - acc: 0.8146 - val_loss: 0.9710 - val_acc: 0.7754\n",
      "Epoch 1077/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8989 - acc: 0.8155 - val_loss: 0.9706 - val_acc: 0.7742\n",
      "Epoch 1078/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8984 - acc: 0.8152 - val_loss: 0.9702 - val_acc: 0.7738\n",
      "Epoch 1079/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8980 - acc: 0.8156 - val_loss: 0.9699 - val_acc: 0.7750\n",
      "Epoch 1080/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8976 - acc: 0.8155 - val_loss: 0.9695 - val_acc: 0.7754\n",
      "Epoch 1081/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8971 - acc: 0.8161 - val_loss: 0.9690 - val_acc: 0.7754\n",
      "Epoch 1082/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8967 - acc: 0.8156 - val_loss: 0.9687 - val_acc: 0.7775\n",
      "Epoch 1083/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8962 - acc: 0.8157 - val_loss: 0.9684 - val_acc: 0.7762\n",
      "Epoch 1084/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8958 - acc: 0.8154 - val_loss: 0.9679 - val_acc: 0.7767\n",
      "Epoch 1085/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8954 - acc: 0.8156 - val_loss: 0.9675 - val_acc: 0.7758\n",
      "Epoch 1086/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8950 - acc: 0.8153 - val_loss: 0.9672 - val_acc: 0.7779\n",
      "Epoch 1087/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8946 - acc: 0.8159 - val_loss: 0.9668 - val_acc: 0.7758\n",
      "Epoch 1088/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8942 - acc: 0.8160 - val_loss: 0.9664 - val_acc: 0.7771\n",
      "Epoch 1089/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8938 - acc: 0.8150 - val_loss: 0.9660 - val_acc: 0.7750\n",
      "Epoch 1090/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8933 - acc: 0.8153 - val_loss: 0.9657 - val_acc: 0.7762\n",
      "Epoch 1091/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8929 - acc: 0.8161 - val_loss: 0.9653 - val_acc: 0.7767\n",
      "Epoch 1092/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8925 - acc: 0.8158 - val_loss: 0.9649 - val_acc: 0.7767\n",
      "Epoch 1093/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8921 - acc: 0.8153 - val_loss: 0.9645 - val_acc: 0.7771\n",
      "Epoch 1094/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8916 - acc: 0.8157 - val_loss: 0.9641 - val_acc: 0.7767\n",
      "Epoch 1095/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8912 - acc: 0.8167 - val_loss: 0.9637 - val_acc: 0.7767\n",
      "Epoch 1096/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8908 - acc: 0.8162 - val_loss: 0.9634 - val_acc: 0.7754\n",
      "Epoch 1097/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8904 - acc: 0.8155 - val_loss: 0.9630 - val_acc: 0.7762\n",
      "Epoch 1098/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8900 - acc: 0.8153 - val_loss: 0.9626 - val_acc: 0.7762\n",
      "Epoch 1099/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8895 - acc: 0.8160 - val_loss: 0.9623 - val_acc: 0.7762\n",
      "Epoch 1100/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.8891 - acc: 0.8166 - val_loss: 0.9619 - val_acc: 0.7746\n",
      "Epoch 1101/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8888 - acc: 0.8161 - val_loss: 0.9615 - val_acc: 0.7775\n",
      "Epoch 1102/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8883 - acc: 0.8156 - val_loss: 0.9612 - val_acc: 0.7775\n",
      "Epoch 1103/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8879 - acc: 0.8156 - val_loss: 0.9607 - val_acc: 0.7775\n",
      "Epoch 1104/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8876 - acc: 0.8165 - val_loss: 0.9603 - val_acc: 0.7771\n",
      "Epoch 1105/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8871 - acc: 0.8171 - val_loss: 0.9600 - val_acc: 0.7775\n",
      "Epoch 1106/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8867 - acc: 0.8160 - val_loss: 0.9597 - val_acc: 0.7767\n",
      "Epoch 1107/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8863 - acc: 0.8162 - val_loss: 0.9593 - val_acc: 0.7758\n",
      "Epoch 1108/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8859 - acc: 0.8164 - val_loss: 0.9589 - val_acc: 0.7775\n",
      "Epoch 1109/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.8855 - acc: 0.8159 - val_loss: 0.9585 - val_acc: 0.7775\n",
      "Epoch 1110/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8851 - acc: 0.8171 - val_loss: 0.9582 - val_acc: 0.7762\n",
      "Epoch 1111/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8846 - acc: 0.8168 - val_loss: 0.9579 - val_acc: 0.7792\n",
      "Epoch 1112/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8843 - acc: 0.8166 - val_loss: 0.9574 - val_acc: 0.7762\n",
      "Epoch 1113/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8838 - acc: 0.8160 - val_loss: 0.9571 - val_acc: 0.7779\n",
      "Epoch 1114/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8834 - acc: 0.8171 - val_loss: 0.9567 - val_acc: 0.7771\n",
      "Epoch 1115/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8830 - acc: 0.8169 - val_loss: 0.9564 - val_acc: 0.7788\n",
      "Epoch 1116/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8827 - acc: 0.8159 - val_loss: 0.9560 - val_acc: 0.7767\n",
      "Epoch 1117/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8823 - acc: 0.8170 - val_loss: 0.9556 - val_acc: 0.7779\n",
      "Epoch 1118/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8818 - acc: 0.8167 - val_loss: 0.9552 - val_acc: 0.7779\n",
      "Epoch 1119/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8815 - acc: 0.8171 - val_loss: 0.9550 - val_acc: 0.7779\n",
      "Epoch 1120/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8810 - acc: 0.8160 - val_loss: 0.9546 - val_acc: 0.7775\n",
      "Epoch 1121/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8806 - acc: 0.8167 - val_loss: 0.9542 - val_acc: 0.7788\n",
      "Epoch 1122/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8802 - acc: 0.8167 - val_loss: 0.9538 - val_acc: 0.7771\n",
      "Epoch 1123/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8798 - acc: 0.8169 - val_loss: 0.9535 - val_acc: 0.7792\n",
      "Epoch 1124/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8794 - acc: 0.8174 - val_loss: 0.9531 - val_acc: 0.7788\n",
      "Epoch 1125/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8790 - acc: 0.8170 - val_loss: 0.9527 - val_acc: 0.7767\n",
      "Epoch 1126/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8786 - acc: 0.8176 - val_loss: 0.9525 - val_acc: 0.7788\n",
      "Epoch 1127/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8782 - acc: 0.8168 - val_loss: 0.9521 - val_acc: 0.7779\n",
      "Epoch 1128/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8779 - acc: 0.8166 - val_loss: 0.9517 - val_acc: 0.7779\n",
      "Epoch 1129/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8774 - acc: 0.8165 - val_loss: 0.9513 - val_acc: 0.7779\n",
      "Epoch 1130/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8770 - acc: 0.8167 - val_loss: 0.9511 - val_acc: 0.7800\n",
      "Epoch 1131/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8766 - acc: 0.8171 - val_loss: 0.9505 - val_acc: 0.7779\n",
      "Epoch 1132/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8762 - acc: 0.8175 - val_loss: 0.9502 - val_acc: 0.7792\n",
      "Epoch 1133/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.8758 - acc: 0.8174 - val_loss: 0.9499 - val_acc: 0.7783\n",
      "Epoch 1134/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 0.8754 - acc: 0.8170 - val_loss: 0.9495 - val_acc: 0.7779\n",
      "Epoch 1135/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8750 - acc: 0.8176 - val_loss: 0.9491 - val_acc: 0.7792\n",
      "Epoch 1136/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8746 - acc: 0.8168 - val_loss: 0.9488 - val_acc: 0.7783\n",
      "Epoch 1137/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.8742 - acc: 0.8180 - val_loss: 0.9484 - val_acc: 0.7796\n",
      "Epoch 1138/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8739 - acc: 0.8168 - val_loss: 0.9481 - val_acc: 0.7796\n",
      "Epoch 1139/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8735 - acc: 0.8172 - val_loss: 0.9477 - val_acc: 0.7796\n",
      "Epoch 1140/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 0.8731 - acc: 0.8171 - val_loss: 0.9474 - val_acc: 0.7800\n",
      "Epoch 1141/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8727 - acc: 0.8178 - val_loss: 0.9470 - val_acc: 0.7800\n",
      "Epoch 1142/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8723 - acc: 0.8180 - val_loss: 0.9467 - val_acc: 0.7779\n",
      "Epoch 1143/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8719 - acc: 0.8175 - val_loss: 0.9463 - val_acc: 0.7783\n",
      "Epoch 1144/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8715 - acc: 0.8177 - val_loss: 0.9461 - val_acc: 0.7804\n",
      "Epoch 1145/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8711 - acc: 0.8173 - val_loss: 0.9456 - val_acc: 0.7796\n",
      "Epoch 1146/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8707 - acc: 0.8185 - val_loss: 0.9453 - val_acc: 0.7783\n",
      "Epoch 1147/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8704 - acc: 0.8178 - val_loss: 0.9450 - val_acc: 0.7792\n",
      "Epoch 1148/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8699 - acc: 0.8186 - val_loss: 0.9446 - val_acc: 0.7800\n",
      "Epoch 1149/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8696 - acc: 0.8173 - val_loss: 0.9443 - val_acc: 0.7800\n",
      "Epoch 1150/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8692 - acc: 0.8179 - val_loss: 0.9439 - val_acc: 0.7800\n",
      "Epoch 1151/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8688 - acc: 0.8174 - val_loss: 0.9436 - val_acc: 0.7792\n",
      "Epoch 1152/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8684 - acc: 0.8180 - val_loss: 0.9432 - val_acc: 0.7796\n",
      "Epoch 1153/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8680 - acc: 0.8179 - val_loss: 0.9429 - val_acc: 0.7796\n",
      "Epoch 1154/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 0.8677 - acc: 0.8182 - val_loss: 0.9425 - val_acc: 0.7792\n",
      "Epoch 1155/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8673 - acc: 0.8180 - val_loss: 0.9422 - val_acc: 0.7796\n",
      "Epoch 1156/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8669 - acc: 0.8186 - val_loss: 0.9418 - val_acc: 0.7783\n",
      "Epoch 1157/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8665 - acc: 0.8180 - val_loss: 0.9415 - val_acc: 0.7788\n",
      "Epoch 1158/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8661 - acc: 0.8181 - val_loss: 0.9412 - val_acc: 0.7796\n",
      "Epoch 1159/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 0.8658 - acc: 0.8183 - val_loss: 0.9409 - val_acc: 0.7808\n",
      "Epoch 1160/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8654 - acc: 0.8179 - val_loss: 0.9405 - val_acc: 0.7796\n",
      "Epoch 1161/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.8650 - acc: 0.8180 - val_loss: 0.9402 - val_acc: 0.7792\n",
      "Epoch 1162/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 0.8646 - acc: 0.8190 - val_loss: 0.9398 - val_acc: 0.7808\n",
      "Epoch 1163/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8643 - acc: 0.8195 - val_loss: 0.9395 - val_acc: 0.7804\n",
      "Epoch 1164/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8639 - acc: 0.8180 - val_loss: 0.9390 - val_acc: 0.7792\n",
      "Epoch 1165/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8635 - acc: 0.8181 - val_loss: 0.9388 - val_acc: 0.7804\n",
      "Epoch 1166/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8631 - acc: 0.8181 - val_loss: 0.9385 - val_acc: 0.7792\n",
      "Epoch 1167/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8627 - acc: 0.8180 - val_loss: 0.9382 - val_acc: 0.7800\n",
      "Epoch 1168/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8624 - acc: 0.8189 - val_loss: 0.9378 - val_acc: 0.7792\n",
      "Epoch 1169/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8620 - acc: 0.8192 - val_loss: 0.9375 - val_acc: 0.7804\n",
      "Epoch 1170/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8616 - acc: 0.8182 - val_loss: 0.9371 - val_acc: 0.7804\n",
      "Epoch 1171/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8612 - acc: 0.8192 - val_loss: 0.9368 - val_acc: 0.7788\n",
      "Epoch 1172/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8609 - acc: 0.8193 - val_loss: 0.9364 - val_acc: 0.7804\n",
      "Epoch 1173/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8605 - acc: 0.8195 - val_loss: 0.9361 - val_acc: 0.7808\n",
      "Epoch 1174/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8601 - acc: 0.8185 - val_loss: 0.9358 - val_acc: 0.7829\n",
      "Epoch 1175/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8598 - acc: 0.8192 - val_loss: 0.9354 - val_acc: 0.7821\n",
      "Epoch 1176/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8594 - acc: 0.8194 - val_loss: 0.9351 - val_acc: 0.7800\n",
      "Epoch 1177/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8591 - acc: 0.8185 - val_loss: 0.9347 - val_acc: 0.7796\n",
      "Epoch 1178/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8586 - acc: 0.8193 - val_loss: 0.9345 - val_acc: 0.7812\n",
      "Epoch 1179/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8582 - acc: 0.8182 - val_loss: 0.9341 - val_acc: 0.7817\n",
      "Epoch 1180/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8579 - acc: 0.8194 - val_loss: 0.9338 - val_acc: 0.7812\n",
      "Epoch 1181/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8575 - acc: 0.8190 - val_loss: 0.9334 - val_acc: 0.7808\n",
      "Epoch 1182/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8572 - acc: 0.8201 - val_loss: 0.9332 - val_acc: 0.7821\n",
      "Epoch 1183/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8568 - acc: 0.8193 - val_loss: 0.9328 - val_acc: 0.7817\n",
      "Epoch 1184/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8564 - acc: 0.8191 - val_loss: 0.9324 - val_acc: 0.7804\n",
      "Epoch 1185/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8560 - acc: 0.8197 - val_loss: 0.9322 - val_acc: 0.7812\n",
      "Epoch 1186/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8557 - acc: 0.8197 - val_loss: 0.9318 - val_acc: 0.7808\n",
      "Epoch 1187/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8553 - acc: 0.8194 - val_loss: 0.9316 - val_acc: 0.7817\n",
      "Epoch 1188/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8549 - acc: 0.8184 - val_loss: 0.9312 - val_acc: 0.7812\n",
      "Epoch 1189/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8546 - acc: 0.8200 - val_loss: 0.9309 - val_acc: 0.7808\n",
      "Epoch 1190/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8543 - acc: 0.8189 - val_loss: 0.9305 - val_acc: 0.7812\n",
      "Epoch 1191/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8539 - acc: 0.8199 - val_loss: 0.9302 - val_acc: 0.7833\n",
      "Epoch 1192/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8535 - acc: 0.8198 - val_loss: 0.9298 - val_acc: 0.7821\n",
      "Epoch 1193/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 0.8531 - acc: 0.8187 - val_loss: 0.9296 - val_acc: 0.7825\n",
      "Epoch 1194/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 0.8528 - acc: 0.8194 - val_loss: 0.9292 - val_acc: 0.7825\n",
      "Epoch 1195/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8524 - acc: 0.8193 - val_loss: 0.9289 - val_acc: 0.7821\n",
      "Epoch 1196/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8520 - acc: 0.8198 - val_loss: 0.9286 - val_acc: 0.7817\n",
      "Epoch 1197/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8517 - acc: 0.8190 - val_loss: 0.9282 - val_acc: 0.7804\n",
      "Epoch 1198/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8513 - acc: 0.8193 - val_loss: 0.9279 - val_acc: 0.7812\n",
      "Epoch 1199/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8509 - acc: 0.8198 - val_loss: 0.9276 - val_acc: 0.7817\n",
      "Epoch 1200/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8506 - acc: 0.8199 - val_loss: 0.9273 - val_acc: 0.7812\n",
      "Epoch 1201/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8502 - acc: 0.8196 - val_loss: 0.9270 - val_acc: 0.7808\n",
      "Epoch 1202/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8499 - acc: 0.8195 - val_loss: 0.9267 - val_acc: 0.7804\n",
      "Epoch 1203/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8495 - acc: 0.8199 - val_loss: 0.9263 - val_acc: 0.7833\n",
      "Epoch 1204/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8491 - acc: 0.8199 - val_loss: 0.9260 - val_acc: 0.7833\n",
      "Epoch 1205/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8488 - acc: 0.8200 - val_loss: 0.9257 - val_acc: 0.7808\n",
      "Epoch 1206/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8484 - acc: 0.8195 - val_loss: 0.9254 - val_acc: 0.7833\n",
      "Epoch 1207/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8481 - acc: 0.8200 - val_loss: 0.9250 - val_acc: 0.7829\n",
      "Epoch 1208/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8478 - acc: 0.8204 - val_loss: 0.9247 - val_acc: 0.7833\n",
      "Epoch 1209/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8474 - acc: 0.8200 - val_loss: 0.9245 - val_acc: 0.7825\n",
      "Epoch 1210/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8471 - acc: 0.8200 - val_loss: 0.9241 - val_acc: 0.7817\n",
      "Epoch 1211/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8466 - acc: 0.8196 - val_loss: 0.9239 - val_acc: 0.7837\n",
      "Epoch 1212/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8463 - acc: 0.8201 - val_loss: 0.9235 - val_acc: 0.7825\n",
      "Epoch 1213/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8459 - acc: 0.8203 - val_loss: 0.9232 - val_acc: 0.7837\n",
      "Epoch 1214/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8456 - acc: 0.8199 - val_loss: 0.9229 - val_acc: 0.7825\n",
      "Epoch 1215/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8452 - acc: 0.8194 - val_loss: 0.9225 - val_acc: 0.7825\n",
      "Epoch 1216/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8449 - acc: 0.8198 - val_loss: 0.9222 - val_acc: 0.7821\n",
      "Epoch 1217/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8446 - acc: 0.8201 - val_loss: 0.9219 - val_acc: 0.7817\n",
      "Epoch 1218/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8442 - acc: 0.8199 - val_loss: 0.9216 - val_acc: 0.7825\n",
      "Epoch 1219/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8439 - acc: 0.8198 - val_loss: 0.9213 - val_acc: 0.7825\n",
      "Epoch 1220/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8436 - acc: 0.8200 - val_loss: 0.9210 - val_acc: 0.7804\n",
      "Epoch 1221/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8432 - acc: 0.8202 - val_loss: 0.9207 - val_acc: 0.7837\n",
      "Epoch 1222/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8428 - acc: 0.8202 - val_loss: 0.9203 - val_acc: 0.7825\n",
      "Epoch 1223/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8424 - acc: 0.8198 - val_loss: 0.9201 - val_acc: 0.7821\n",
      "Epoch 1224/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8421 - acc: 0.8198 - val_loss: 0.9197 - val_acc: 0.7821\n",
      "Epoch 1225/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8418 - acc: 0.8204 - val_loss: 0.9195 - val_acc: 0.7837\n",
      "Epoch 1226/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8414 - acc: 0.8205 - val_loss: 0.9191 - val_acc: 0.7829\n",
      "Epoch 1227/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8411 - acc: 0.8197 - val_loss: 0.9189 - val_acc: 0.7833\n",
      "Epoch 1228/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.8407 - acc: 0.8201 - val_loss: 0.9185 - val_acc: 0.7825\n",
      "Epoch 1229/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8404 - acc: 0.8211 - val_loss: 0.9182 - val_acc: 0.7837\n",
      "Epoch 1230/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8400 - acc: 0.8203 - val_loss: 0.9179 - val_acc: 0.7846\n",
      "Epoch 1231/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8397 - acc: 0.8204 - val_loss: 0.9175 - val_acc: 0.7837\n",
      "Epoch 1232/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8393 - acc: 0.8210 - val_loss: 0.9173 - val_acc: 0.7842\n",
      "Epoch 1233/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8390 - acc: 0.8208 - val_loss: 0.9170 - val_acc: 0.7833\n",
      "Epoch 1234/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8387 - acc: 0.8210 - val_loss: 0.9166 - val_acc: 0.7833\n",
      "Epoch 1235/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8383 - acc: 0.8205 - val_loss: 0.9164 - val_acc: 0.7825\n",
      "Epoch 1236/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8379 - acc: 0.8204 - val_loss: 0.9160 - val_acc: 0.7817\n",
      "Epoch 1237/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8376 - acc: 0.8210 - val_loss: 0.9157 - val_acc: 0.7825\n",
      "Epoch 1238/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8373 - acc: 0.8203 - val_loss: 0.9155 - val_acc: 0.7825\n",
      "Epoch 1239/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.8369 - acc: 0.8205 - val_loss: 0.9151 - val_acc: 0.7821\n",
      "Epoch 1240/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8366 - acc: 0.8210 - val_loss: 0.9149 - val_acc: 0.7833\n",
      "Epoch 1241/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8362 - acc: 0.8205 - val_loss: 0.9146 - val_acc: 0.7846\n",
      "Epoch 1242/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8360 - acc: 0.8208 - val_loss: 0.9142 - val_acc: 0.7837\n",
      "Epoch 1243/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8356 - acc: 0.8206 - val_loss: 0.9139 - val_acc: 0.7829\n",
      "Epoch 1244/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8352 - acc: 0.8207 - val_loss: 0.9136 - val_acc: 0.7842\n",
      "Epoch 1245/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8349 - acc: 0.8209 - val_loss: 0.9134 - val_acc: 0.7850\n",
      "Epoch 1246/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8346 - acc: 0.8210 - val_loss: 0.9130 - val_acc: 0.7833\n",
      "Epoch 1247/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8342 - acc: 0.8213 - val_loss: 0.9128 - val_acc: 0.7825\n",
      "Epoch 1248/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8339 - acc: 0.8213 - val_loss: 0.9124 - val_acc: 0.7833\n",
      "Epoch 1249/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8335 - acc: 0.8205 - val_loss: 0.9121 - val_acc: 0.7833\n",
      "Epoch 1250/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8332 - acc: 0.8213 - val_loss: 0.9119 - val_acc: 0.7842\n",
      "Epoch 1251/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8328 - acc: 0.8211 - val_loss: 0.9116 - val_acc: 0.7850\n",
      "Epoch 1252/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8325 - acc: 0.8209 - val_loss: 0.9113 - val_acc: 0.7842\n",
      "Epoch 1253/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8322 - acc: 0.8207 - val_loss: 0.9110 - val_acc: 0.7837\n",
      "Epoch 1254/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8319 - acc: 0.8215 - val_loss: 0.9107 - val_acc: 0.7842\n",
      "Epoch 1255/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8315 - acc: 0.8218 - val_loss: 0.9103 - val_acc: 0.7842\n",
      "Epoch 1256/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8312 - acc: 0.8210 - val_loss: 0.9101 - val_acc: 0.7825\n",
      "Epoch 1257/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8309 - acc: 0.8214 - val_loss: 0.9097 - val_acc: 0.7825\n",
      "Epoch 1258/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8306 - acc: 0.8214 - val_loss: 0.9095 - val_acc: 0.7842\n",
      "Epoch 1259/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8302 - acc: 0.8215 - val_loss: 0.9092 - val_acc: 0.7846\n",
      "Epoch 1260/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8299 - acc: 0.8211 - val_loss: 0.9089 - val_acc: 0.7850\n",
      "Epoch 1261/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8295 - acc: 0.8207 - val_loss: 0.9086 - val_acc: 0.7846\n",
      "Epoch 1262/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8292 - acc: 0.8220 - val_loss: 0.9083 - val_acc: 0.7833\n",
      "Epoch 1263/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8288 - acc: 0.8211 - val_loss: 0.9080 - val_acc: 0.7842\n",
      "Epoch 1264/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8285 - acc: 0.8214 - val_loss: 0.9077 - val_acc: 0.7833\n",
      "Epoch 1265/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8282 - acc: 0.8219 - val_loss: 0.9074 - val_acc: 0.7837\n",
      "Epoch 1266/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8279 - acc: 0.8215 - val_loss: 0.9071 - val_acc: 0.7846\n",
      "Epoch 1267/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8275 - acc: 0.8216 - val_loss: 0.9068 - val_acc: 0.7846\n",
      "Epoch 1268/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8272 - acc: 0.8218 - val_loss: 0.9064 - val_acc: 0.7837\n",
      "Epoch 1269/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8269 - acc: 0.8209 - val_loss: 0.9062 - val_acc: 0.7833\n",
      "Epoch 1270/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8266 - acc: 0.8222 - val_loss: 0.9059 - val_acc: 0.7837\n",
      "Epoch 1271/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8262 - acc: 0.8224 - val_loss: 0.9056 - val_acc: 0.7829\n",
      "Epoch 1272/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8259 - acc: 0.8220 - val_loss: 0.9054 - val_acc: 0.7837\n",
      "Epoch 1273/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8256 - acc: 0.8221 - val_loss: 0.9051 - val_acc: 0.7850\n",
      "Epoch 1274/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8252 - acc: 0.8218 - val_loss: 0.9049 - val_acc: 0.7850\n",
      "Epoch 1275/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8249 - acc: 0.8220 - val_loss: 0.9045 - val_acc: 0.7850\n",
      "Epoch 1276/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8245 - acc: 0.8224 - val_loss: 0.9042 - val_acc: 0.7837\n",
      "Epoch 1277/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8243 - acc: 0.8223 - val_loss: 0.9039 - val_acc: 0.7850\n",
      "Epoch 1278/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8239 - acc: 0.8222 - val_loss: 0.9036 - val_acc: 0.7833\n",
      "Epoch 1279/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8236 - acc: 0.8221 - val_loss: 0.9034 - val_acc: 0.7846\n",
      "Epoch 1280/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8233 - acc: 0.8220 - val_loss: 0.9031 - val_acc: 0.7825\n",
      "Epoch 1281/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8230 - acc: 0.8216 - val_loss: 0.9029 - val_acc: 0.7846\n",
      "Epoch 1282/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8226 - acc: 0.8223 - val_loss: 0.9024 - val_acc: 0.7825\n",
      "Epoch 1283/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 0.8223 - acc: 0.8220 - val_loss: 0.9022 - val_acc: 0.7842\n",
      "Epoch 1284/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8220 - acc: 0.8221 - val_loss: 0.9019 - val_acc: 0.7854\n",
      "Epoch 1285/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 0.8217 - acc: 0.8226 - val_loss: 0.9016 - val_acc: 0.7837\n",
      "Epoch 1286/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8214 - acc: 0.8228 - val_loss: 0.9014 - val_acc: 0.7837\n",
      "Epoch 1287/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8211 - acc: 0.8220 - val_loss: 0.9011 - val_acc: 0.7846\n",
      "Epoch 1288/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8207 - acc: 0.8227 - val_loss: 0.9008 - val_acc: 0.7837\n",
      "Epoch 1289/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8204 - acc: 0.8218 - val_loss: 0.9005 - val_acc: 0.7837\n",
      "Epoch 1290/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8201 - acc: 0.8224 - val_loss: 0.9003 - val_acc: 0.7833\n",
      "Epoch 1291/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8197 - acc: 0.8224 - val_loss: 0.9000 - val_acc: 0.7842\n",
      "Epoch 1292/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8195 - acc: 0.8230 - val_loss: 0.8997 - val_acc: 0.7842\n",
      "Epoch 1293/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 0.8191 - acc: 0.8225 - val_loss: 0.8995 - val_acc: 0.7842\n",
      "Epoch 1294/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8188 - acc: 0.8230 - val_loss: 0.8991 - val_acc: 0.7825\n",
      "Epoch 1295/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8185 - acc: 0.8221 - val_loss: 0.8989 - val_acc: 0.7850\n",
      "Epoch 1296/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8182 - acc: 0.8228 - val_loss: 0.8986 - val_acc: 0.7821\n",
      "Epoch 1297/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8179 - acc: 0.8225 - val_loss: 0.8983 - val_acc: 0.7846\n",
      "Epoch 1298/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8176 - acc: 0.8221 - val_loss: 0.8981 - val_acc: 0.7842\n",
      "Epoch 1299/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8172 - acc: 0.8226 - val_loss: 0.8977 - val_acc: 0.7837\n",
      "Epoch 1300/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8169 - acc: 0.8230 - val_loss: 0.8974 - val_acc: 0.7825\n",
      "Epoch 1301/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8166 - acc: 0.8228 - val_loss: 0.8972 - val_acc: 0.7842\n",
      "Epoch 1302/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8163 - acc: 0.8227 - val_loss: 0.8968 - val_acc: 0.7829\n",
      "Epoch 1303/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8159 - acc: 0.8231 - val_loss: 0.8966 - val_acc: 0.7842\n",
      "Epoch 1304/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8156 - acc: 0.8225 - val_loss: 0.8964 - val_acc: 0.7837\n",
      "Epoch 1305/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8153 - acc: 0.8233 - val_loss: 0.8961 - val_acc: 0.7846\n",
      "Epoch 1306/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8150 - acc: 0.8229 - val_loss: 0.8958 - val_acc: 0.7846\n",
      "Epoch 1307/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8148 - acc: 0.8230 - val_loss: 0.8955 - val_acc: 0.7842\n",
      "Epoch 1308/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8144 - acc: 0.8231 - val_loss: 0.8954 - val_acc: 0.7846\n",
      "Epoch 1309/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8141 - acc: 0.8230 - val_loss: 0.8950 - val_acc: 0.7850\n",
      "Epoch 1310/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8138 - acc: 0.8231 - val_loss: 0.8947 - val_acc: 0.7846\n",
      "Epoch 1311/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8135 - acc: 0.8231 - val_loss: 0.8945 - val_acc: 0.7850\n",
      "Epoch 1312/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8131 - acc: 0.8229 - val_loss: 0.8942 - val_acc: 0.7842\n",
      "Epoch 1313/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8129 - acc: 0.8231 - val_loss: 0.8939 - val_acc: 0.7842\n",
      "Epoch 1314/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8125 - acc: 0.8233 - val_loss: 0.8936 - val_acc: 0.7842\n",
      "Epoch 1315/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8123 - acc: 0.8242 - val_loss: 0.8933 - val_acc: 0.7842\n",
      "Epoch 1316/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8120 - acc: 0.8234 - val_loss: 0.8930 - val_acc: 0.7833\n",
      "Epoch 1317/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8116 - acc: 0.8239 - val_loss: 0.8928 - val_acc: 0.7846\n",
      "Epoch 1318/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8113 - acc: 0.8232 - val_loss: 0.8926 - val_acc: 0.7850\n",
      "Epoch 1319/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8110 - acc: 0.8239 - val_loss: 0.8922 - val_acc: 0.7833\n",
      "Epoch 1320/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8107 - acc: 0.8241 - val_loss: 0.8920 - val_acc: 0.7846\n",
      "Epoch 1321/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8104 - acc: 0.8230 - val_loss: 0.8918 - val_acc: 0.7850\n",
      "Epoch 1322/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8101 - acc: 0.8245 - val_loss: 0.8915 - val_acc: 0.7842\n",
      "Epoch 1323/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8098 - acc: 0.8236 - val_loss: 0.8912 - val_acc: 0.7842\n",
      "Epoch 1324/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8095 - acc: 0.8242 - val_loss: 0.8910 - val_acc: 0.7846\n",
      "Epoch 1325/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8092 - acc: 0.8243 - val_loss: 0.8907 - val_acc: 0.7837\n",
      "Epoch 1326/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8089 - acc: 0.8240 - val_loss: 0.8904 - val_acc: 0.7837\n",
      "Epoch 1327/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8086 - acc: 0.8224 - val_loss: 0.8902 - val_acc: 0.7842\n",
      "Epoch 1328/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8083 - acc: 0.8244 - val_loss: 0.8899 - val_acc: 0.7842\n",
      "Epoch 1329/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8081 - acc: 0.8237 - val_loss: 0.8896 - val_acc: 0.7842\n",
      "Epoch 1330/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 0.8077 - acc: 0.8243 - val_loss: 0.8893 - val_acc: 0.7842\n",
      "Epoch 1331/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 0.8074 - acc: 0.8239 - val_loss: 0.8891 - val_acc: 0.7846\n",
      "Epoch 1332/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8070 - acc: 0.8239 - val_loss: 0.8889 - val_acc: 0.7850\n",
      "Epoch 1333/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 0.8068 - acc: 0.8240 - val_loss: 0.8886 - val_acc: 0.7850\n",
      "Epoch 1334/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 0.8065 - acc: 0.8241 - val_loss: 0.8883 - val_acc: 0.7850\n",
      "Val loss: 0.9019,Val acc: 0.7854\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VeW99/3PLzvzHEiAQIAERBCQyYg41KFOqFVr5VQcTqt3LXdtrdrh3NW2x7b2OfejPT3W2uOx1dbWp7eVemhV6o1aqzhPgAICCgRECBEIYUgIGfe+nj/WTtgJO5ANWdk77O/79cora7j2Wr+9IOu3rmutdV3mnENERKS3UuIdgIiIDCxKHCIiEhMlDhERiYkSh4iIxESJQ0REYqLEISIiMVHiEBGRmChxiIhITJQ4REQkJqnxDiBWxcXFrry8PN5hiIgMKMuWLdvpnCvpi20NuMRRXl7O0qVL4x2GiMiAYmaf9NW21FQlIiIxUeIQEZGYKHGIiEhMlDhERCQmShwiIhITJQ4REYmJEoeIiMRkwL3HISJyzAgFwTlobYC0bNhbDSkBaN0PaxfBzvWQkQvBNhgxA0adCiXj4x21EoeISKfWRu8E3rwHUtJg7xZoa4L2FkjL8soEW6FuA6RnA+Yt37MZtrwLWUXeiT8jDxp3wq6NYAZ7tkBaJny6AjLyIXcotO6Dhk97H9t7j8Lse5Q4RESOiHMHfu/dDC4EoRDs2+6d6Nv2Q+1ab76x1lufOxTSc7z17/4GRp8On7zhbaeowruqr6/2J96UNAi1Qc4QyB8OBWVeksos8GodKQEoneYll9yhUFQODdsgJdVLUG1NcMKlkD/Cn/hipMQhIv7pOCk2bIPmesCBBaC9Gba84504d2/yfkLt3pV7w6eQOwzyhnknfBeEmhXeFXogHSwFGmqOPraOpAHePrKKvMRRVAF5pdC0C3Z9DNOugfV/h5EzoXA0lE6B9DwvEQRbIbvY+16BDBg60UtAqZnejwt6J3+zo483gfiaOMxsNvBLIAD81jl3d7f1o4BHgcJwmdudc4v8jElEYtDeCqnpXlONc1Dzvnel3LIX6mu85W1NsH8n7P7EW9dYC7s/9k7++7Z5J/tga2z73bXR+11UDm3N3nYyCqCgxDupl1VCIM2LKT0bCkZ5ycQCkFXoXdVnDfJO3qF2r/lp2GQvjswCL/mkZXtJzVfH5vNHviUOMwsADwDnA9XAEjNb6JxbE1Hsh8ATzrkHzWwisAgo9ysmkaTU0gCY127fsg8+eR0yC70bsbVrvSv8jYsPvY2UVO8EHIvBY70TfE6xd4IfMcM7YTfu9Jpq9m2Hwcd5MTXUwKjTvKaawcd58VqKl7QAgu0QUANJovDzX2ImUOWc2whgZvOBy4HIxOGA/PB0AdAH9U+RY0zTnvBJvwHeuN9rvmlr8k6k7a2w7lnvKnrIRO+EvO7vXo3gaGXkQ0s9jDgJhp3otb3X13g/067xagPpud4+07K8E71fTTJKGgnFz3+NEcCWiPlq4JRuZX4M/N3MvgnkAOf5GI9IfHRcLYeC3kl36zKv+eaTN6BgpPe4ZX0NbH4bNrzonaCdg8Ydvd9H817Y/BakZnlX6TklXpNRwUgYVAHb13hX/2Une1f8DTUw+gwoHgfFx8O2ld6N2/QcyBvqtfeL9MDPxBHt0sN1m78a+INz7j/M7FTgj2Y22TkX6rIhs3nAPIBRo0b5EqxITEJB72ZtRj6se95rYtm/Cza9Dkt/d3Tb3rcdhkzqmjjySr1axYTPHXhCaPg0yB3i3YwtPv7orvYLEuNpHRkY/Ewc1cDIiPkyDm6K+gowG8A595aZZQLFQJdLLefcQ8BDAJWVld2Tj4h/9u3w7gGsfhKW/cG7UdvedGTbshQYOhm2r4K0HBg1C6Z8EUomeFf6Vf/wagSlU/vhpq3IkfMzcSwBxplZBbAVmAtc063MZuBc4A9mdgKQCdT6GJMkM+e8p2paGrzfoaD3NNC65737CCkBeOs/vbKpmV6ZrpXf6AIZMHUuZA+G/XXeY5tDTvCe6tm9Ccac3bvawOCxR/HlRPqPb4nDOdduZjcDz+M9avuIc261md0FLHXOLQS+AzxsZt/Ca8a63jmnGoXEprkeMvO9F8BC7d7Jum2/V1tY9xysf8F7SSwW7c1QNhOq34WKs7xHPDcshnO+7704lj24d807gyqO6CtJfAVDjmDIkZ7qPU67q9F7nHhQTjof72xk3fYGavY08ZlxJTS3Bane3cTbG+vISEvhmpmjuOe5j2hqDTIoJ4O0gLFzXwsbdzYya8xgavY08fJa7/p4eEEmZ4wr5oml1YwfmocZjCnJoS3oePfjXextauO6WaMYlJPBh5/Wc83MUZwzYUjcjksHG2jn6crKSqcxx5NQKAQ713kvhe2vgw//5j3xs/nt8ItcxsG30A7BAjDlKhgywatVTL3ae0ktPQfqt3rJ4hh7aSsZtbaHSAsYZkZzW5D6pjb2NLWRFkhhdc1emlqDZKenkp+Vyjsbd/HOx3UUZKXz6vpaWtt7UdvsRxXFOfyvC8dz0YmlR/R5M1vmnKvsi1j0jJskDudgyW+9F7NKJsDTX4faj3r7Ye9X7jDIL/WeHJo5z3tBrfIGLyGEwm/xpmVG30TeMO938bij/irS95rbgixcUcOFk4ZRtaOBktxMRhRl8XrVTr78yLsAfPv84wmkGK+tr2X5lj00t/XdyT89NaVLMslKC3D80FxWVHuPPv/Ps8YwpjiH16vqGD80l0E5GUwekc+G2n0UZqWTGjCy0wPUN7dTkpvB/S+u52tnjyVgxq9eqmJ4YSbHDcnl2lNGA/Dxzn3kZaaRmmJkp6eSlZ44971U45D4CbZ7j5A+cxvUVfXuM8NO9F5eyx4Ew2d4TyANO9FLNCNm+Buv9KlQyGEGZsaO+maa2oLsamxlVU09C5dvZdLwAp5ZWUPIHWgq6isjCrOoKM7h071NfOWMMSzfspuinHSKstNZu62BsSU5XDBpGCMKs8hKC5CSYp0xd0x3cM5hA6B2qhqHDBztrbBrA2x9z2sCWvYH70Z0W2PvPv/Zf/VuPAfbvMdRswf5Gm6yam0PEXKOjNQUmtqC7GxopSArjYLsNHbUN7OjoYVdja1kpQcIhRx5mWlU795PU1uQp97fypA8rxZXkJ3GB9V7eWtjHQAThuXxSd1+yotzcM6xc18rO/e19CqmJZt297gu8up/aH4GN392HGtq9nLF9DJeXVdLTkYqsycPo7GlndGDs8lJP3Cq637iB7jmlN495h/tswMhafQ1JQ45Os17vfcX8kphzdPwyj0w6QpY+WevS+reyB0KEz8PYz/rdRKHQeHIw34sWTjn2LKriRXVezihNI/t9S00NLfz/ubdlORlsKG2kez0ADsaWvjbihqumD6C/a3tpKcGSAsYr67bSUmed3M1xSAU0chQnJtO5ehBPLd6my+xf7StAYAPP60HvOadDtnpAfa3BjvnUwwunDSM4twMbvxMBf/4cAdjSnIYWZTFjoYWZowqIjPt8M01Myt0ceE3NVVJbBrCJ5hX/927HxGrEZXw5YWAhcczSG6rtu4lLzOVV9fV8q9Pr453OGSkptAS0Y6fFvCupk8dW8zabfUML8xiwrB8huRlkJ6aQkFWGnub2rhg4lDqm9sYVpBFfVMbuRmppAaMnIxUgkGveSc/88B1auRV+ua6/YwoyiIQ5Wpe+o6aqsR/oZD3HkNDDXz0f72nkJ6/o3efHXmK9xLbpCtg9Gn+xhkH67Y3MGpQNj94chVnjy9h5z6vGSfFjC2794ODDbX7GFuSy1/f39rls8W5GUwans+uxlY+2Bp7f1JTRxayYssezjy+hGtmjmRQTgY5GQFW19QzaXg+dftayckIEAx5D4WNGpTdeZVet6+FkrwMcjNSaWwNkpUWoL6pjcLsNKDvmlxGFGbFVH7UYF1ADDSqcYj3NNP21fDQ2V5ndaNP895/6I3h0+G48+C0W8JPLrVDaoav4fYH5xwt7SEWLKvmyfe3MqWsgN+/scnXfZ47YQhmxmfGFTN5RAEji7IYkt/DE2AiMVKNQ46Mc97wlm/8EopGe2MWLPmdN3ZCh5a2npPGlKvgsl95HfQ1fOp9vrsE7ipjR30z+VlpZKSmUN/Uzq79razd1sBf3qumONdLdo+/G/1FwWWfHHyjdlh+JiV5GVw4aSinjh3M3qY2mlpDDCvI4PiheWSkBjDzHiNNTUkhKz1Ac1uQjNSUpLyhKscOJY5jWet+2LnW6yNp4Te98Y57Y9bXvRvV2z6AmV/1xk/uLlrS6EehkCPkHKkB783etmAIAxpbg/zudS8R3v/ieqaUFbCy+ui7GJ978kguPrGU/3q5ihtOr2BiaT4jB/WuiSUtcGAwn97c3BVJdEocx5LWRm+Etj9c4t2E3nqYJr0TLoWx53qfm3yltyw/4q3Ucef7F2svBUOOusYWhuRl8kldIy99tIOHX91IXWMrZjC2JJft9c3s3Bf9Of9DJY2i7DSG5mdy/NA8hhVksrJ6Dz+8ZCIpZkwcnh/1+fwzjy/p0+8nMhApcQxkoSDUbYCPnoEV873aRYfuSSN7sPdW9Yx/hlO+lnDdaTjnqN3Xwuqt9exraef7f/2AhpbDjzi3uqa+x3V3XDSB0sIs3qzayU8/P7nzyn9fSzsZqSldagLRqDlJJDoljoFmzxb4z5MP37X3oLFw7r96w3AOnRzXRNHaHuKTukbqm9v41UtVfLyzkcumDueFNds7n/OP1YRheVw6dTipKUZFcQ51ja3MOamMzbv2M7Ykt0vZy6Z2bVbLzdB/e5Gjob+ggeTvP4Q3f3WIAgZfegrKz4SUQ19N+ykYcrxetZOHXt3AG1V1Ucv86qWeuxg5bexgxpbk8vnpw5kwLB+H14VhIMUOe4+ge9IQkb6nxJHIgu3w08GHLjP5Shg5C06c06/dcdTta2FbfTN/eGMTr66v5dpTRvPnJVvYuufQNaGHv1TJmpp66hpb+B+nV1CSl0GKWUJ14CYih6bEkWiC7d7Qo6mZ8Ldbei533PnwuXuh0N+hdJ1zNLeFWLu9gf/5x6Vsr28hJz1AY0RXEQD3vrDuoM/ec+WJ/G3Fp9x+0QQmDMvrfALq/IlDfY1ZRPylxJEoQkF49nuw5OHo64dPh9l3e4ML+dAM5Zyjasc+jhuSy7rt+3j83c384c1NUctGJo3powq5/rRyxg/Lo6I4h4xUr+bQ0YvoVSdrjHiRY40SR7xteRc2vuLdu2jp9ujoqTdDYy1c/gAE0vp0tx1vRn+wdS+vravl/kPccwDISQ9w4eRhXDy5lBPLChh6mDeao/UiKiLHBiWOeHEOHr0UNr128LrP/QImz/GGQ+1jdfu8nlUff3czv3l1Y9QylaOLGJybzvkTh3Hp1FL2twQpzE7T46kiAihx9K+G7d7b2ENOgJf/98FJY9p1cMFP++wm98bafeRmpJKTkcof3/6Enz33UZcutbt7/rYzKSvKIqfb46odzU8iIuBz4jCz2cAvgQDwW+fc3d3W/wI4JzybDQxxzhX6GVPcfLQI5l8dfV3ZyXDSDTD92iPevHOON6rqaA+F+Ot7W1m+ZQ+bd+0/5GdOKM3nwWtnUF6cc8T7FZHk41viMLMA8ABwPlANLDGzhc65NR1lnHPfiij/TWC6X/HEjXPwys+8GkakYSdCfhmsexa+9LTXs2xMm3U8+f5WRg3K5pmVn/Z4I7vD0PwMvnP+eL548kha20O89NEOLpw0VM1PIhIzP2scM4Eq59xGADObD1wOrOmh/NXAj3yMp//V13i9z77284PXfe1177dzvX6re39rO6+uq+WVdTt77MUVYEheBn/66iwaW9qZUlZwUHJIT01h9uRhvf4aIiKR/EwcI4DIsUOrgVOiFTSz0UAF8FIP6+cB8wBGjRpAj3fee8LBywLpcOOLB+Z7mTTeqNrJtb99p8f1qSnGhZOHcdu54xg3NEpvtiIifcTPxBHtjNjTrdm5wALnXDDaSufcQ8BD4A3k1Dfh+aS53hs5LyXKob1lOQyq6PWmqnY0cOfTq3lzw8Hddlw9cyRfOrWcLbv2c+4JQzXspoj0Gz8TRzUwMmK+DKjpoexc4Bs+xtI/QkG4e+TBy/OGw9zHep00/vj2J/zrU6uirvvqZyr47oXjO590OqG07x/ZFRE5FD8TxxJgnJlVAFvxksM13QuZ2XigCHjLx1j6x3uPHrwsPQ9uW3nYF/j+e+kWVm3dy9rtDby9cVeXdaeOGcwvr57GkDwNIyoi8edb4nDOtZvZzcDzeI/jPuKcW21mdwFLnXMLw0WvBua7gTb4eaS2Znj/j7DouweWffM9GDz2kB8Lhhy/f+Nj/rbyU1Zs2dNl3W3njaO5LcS3zh+n9yhEJKH4+h6Hc24RsKjbsju7zf/Yzxj6xYIbYG3E1zz5xkMmjf2t7bywZju3zl9+0LppIwv50qmj+cKMMj8iFRE5anpz/Gg51zVpTJ4Dl/xHlyLNbUF+vHA1s8YM5rY/H5wswHsqqup/X+xnpCIifUKJ42g4B/8xvuuyOb/rMvubVzbw/z77EQDzl2zpsu6aU0bx40snAd67FSIiA4ESx5F64U5445c9rq7evZ8n39vKf3Qbp8IMHr1hJjV7mpg7cwC9kyIiEqbEcSSa6w9OGqffBmd9D4D2YIgz7ll80MfGlOTw0nfO7ocARUT8o8RxJP50Vdf5W1dCQRmbd7fw2Lsf8ptXDnRXft4JQ/jPa2YcdqxsEZGBQonjSGx+s8tssGAUy7fs5soHu76K8uJ3zmJsSW5/RiYi4jsljlgs+R1kdOsHquJMHlhcddCY2xdOGqqkISLHJCWOWPzfb3edP/dOHreLuPeZA0nDDL513vHccu64fg5ORKR/KHEchT2Tb+COew40Tz30zydxwSR1Vy4ixza9PHAUpt3T9Z6GkoaIJAPVOHqraXeX2VezzoVmb/r7F09g3pmH7pdKRORYoRpHb712oBuRfd/4gOt33wBATnqAr35mTLyiEhHpd0ocvdG0B978lTc9+nTuemU3ofChm1JWqHG7RSSpKHEczos/hf/zhc7ZxjmP88TS6s75k0YXxSMqEZG40T2Ow3nt511mJ/3b653TT33jdE4cUdDfEYmIxJUSRwyub/2Xzulfzp3GtJGFcYxGRCQ+1FTVS3tP/wEvh6YD8PN/msrl00bEOSIRkfhQ4jiUYHvnZEPecZ3TFcXZ8YhGRCQh+Jo4zGy2ma01syozu72HMl80szVmttrM/uRnPDGrP3ATvKWlpXN6aH5mPKIREUkIvt3jMLMA8ABwPlANLDGzhc65NRFlxgF3AKc753ab2RC/4jkiDds7J2uDWZ3TQ/KUOEQkeflZ45gJVDnnNjrnWoH5wOXdynwVeMA5txvAObfDx3hiU7cBHvfG3XhvwneZ+/c0ACqKczTMq4gkNT/PgCOAyEG2q8PLIh0PHG9mb5jZ22Y228d4YrN2UWc3I99fUdy5ePF3z45TQCIiicHPx3GjvU7toux/HHA2UAa8ZmaTnXN7umzIbB4wD2DUqH4apzv1QHNUIxkA/OjSif2zbxGRBOZnjaMaGBkxXwbURCnztHOuzTn3MbAWL5F04Zx7yDlX6ZyrLCkp8S3gLqpe7JxsdukA3HB6Rf/sW0QkgfmZOJYA48yswszSgbnAwm5lngLOATCzYrymq40kgnXPArAmNJo6CvjdlyvjHJCISGLwLXE459qBm4HngQ+BJ5xzq83sLjO7LFzseaDOzNYAi4F/cc7V+RXTkbii9SeESFHXIiIiYb52OeKcWwQs6rbszohpB3w7/JMY6j+Feyd0zraRyvI7z6cwOz2OQYmIJA49V9rdx692mQ2RoqQhIhJBiaO7gPp9FBE5FCWO7izQZXbpD8+LUyAiIolJiaO7lK41juLcjDgFIiKSmJQ4urMDh+Tl0bfGMRARkcSkxNFdsLVzcvwEvSkuItKdEkd3wTYAfhaYR+msq+IcjIhI4lHi6C5c41idPRMsWndbIiLJTYkjUrANnv46ANnZWYcpLCKSnJQ4Ir3ys87JfamD4hiIiEjiUuKItGczAM0ujdc27I5zMCIiiUmJI1KoHYBm0vnCjO5jTomICChxdLVqAQCtpHH3F6bEORgRkcSkxBFFi0vTuOIiIj3Q2TGKPwQvjHcIIiIJS4kjisCpX4t3CCIiCUuJI4qrTtHY4iIiPVHiiEI94oqI9MzXxGFms81srZlVmdntUdZfb2a1ZrY8/HOjn/EcijeKLdS4QeRnajAnEZGe+JY4zCwAPABcBEwErjazaN3N/tk5Ny3881u/4jmc3fvbaHUBXsv8LKY+qkREeuRnjWMmUOWc2+icawXmA5f7uL+jUv/Bc6RbkJPGDI13KCIiCc3PxDEC2BIxXx1e1t2VZrbSzBaY2Ugf4zmk8uf+GYDU4ZPjFYKIyIDgZ+KI1t7jus3/DSh3zk0B/gE8GnVDZvPMbKmZLa2tre3jMLvKH368r9sXERno/Ewc1UBkDaIMqIks4Jyrc861hGcfBk6KtiHn3EPOuUrnXGVJSYkvwXYoHDzM1+2LiAx0fiaOJcA4M6sws3RgLrAwsoCZlUbMXgZ86GM8vZKSUxzvEEREEppvz50659rN7GbgeSAAPOKcW21mdwFLnXMLgVvM7DKgHdgFXO9XPIezI20EVW4Ep6VlxisEEZEBoVeJw8yuAF5yzu0NzxcCZzvnnjrU55xzi4BF3ZbdGTF9B3BHrEH7ISXYQktGYbzDEBFJeL1tqvpRR9IAcM7tAX7kT0jxkeZasDQNFysicji9TRzRyh1Tr1enu1ZS0rPjHYaISMLrbeJYamb3mtlYMxtjZr8AlvkZWH966r1qMlwrLZYe71BERBJebxPHN4FW4M/AE0AT8A2/gupvT7y7gRRz7GhSVyMiIofTq+Ym51wjcFAnhceK0fkpsA0GFeTHOxQRkYTXqxqHmb0QfpKqY77IzJ73L6z+NXmI10R15sRRcY5ERCTx9bapqjj8JBUAzrndwBB/QoqDtiYA0jJ1c1xE5HB6mzhCZtZ5OW5m5Rzc79SAldriPWkcyCqIcyQiIomvt4/U/gB43cxeCc+fCczzJ6T+d9XyLwGQkq9+qkREDqe3N8efM7NKvGSxHHga78mqgW//rs5JKyqPXxwiIgNEb7scuRG4Fa+H2+XALOAt4LP+hdZPQu0APOou4cvq4FBE5LB6e4/jVuBk4BPn3DnAdMDfgTH6S7ANgE1WFudAREQGht4mjmbnXDOAmWU45z4CxvsXVj8KeYmjzQXiHIiIyMDQ25vj1eH3OJ4CXjCz3XQblGmg2rOviUKgoS3ekYiIDAy9vTl+RXjyx2a2GCgAnvMtqn7UvnszAEFU4xAR6Y2Ye7h1zr1y+FIDR/FfvwhAmxKHiEiv+Dl07IByXElOvEMQERkQlDjCLp6kR3FFRHpDiSMslVC8QxARGRB8TRxmNtvM1ppZlZn12C27mc0xMxd+Oz0uMgJKHCIiveFb4jCzAPAAcBEwEbjazCZGKZcH3AK841csvVFeqNH/RER6w88ax0ygyjm30TnXCswHLo9S7qfAz4BmH2M5vLzhcd29iMhA4WfiGAFsiZivDi/rZGbTgZHOuWcOtSEzm2dmS81saW1t3/Z08kHemd7E8Rf06XZFRI5VfiaOaAN4d47hYWYpwC+A7xxuQ865h5xzlc65ypKSkr6LMBTixIZX+UT9VImI9JqfiaMaGBkxX0bXbkrygMnAy2a2Ca/H3YX9eoN89V8BGO2q+22XIiIDnZ+JYwkwzswqzCwdmAss7FjpnNvrnCt2zpU758qBt4HLnHNLfYypi7q6Hf21KxGRY4ZvicM51w7cDDwPfAg84ZxbbWZ3mdllfu03FvVN6tlQRCRWMfdVFQvn3CJgUbdld/ZQ9mw/Y4mmpV3vboiIxCqp3xxvVeIQEYlZUicO1ThERGKX1ImjNajEISISq6ROHC7YHu8QREQGnKROHIS8xNF67VNxDkREZOBI6sThQkEAAmUnxTkSEZGBI6kTB+GmqpSAho0VEemtpE4cznk3xy3F19dZRESOKUmdODrucaDEISLSa0mdODrucWBJfRhERGKS3GfMUJAgBhatB3gREYkmuROHCxJCN8ZFRGKR1InDhYIEk/sQiIjELLnPmqEgoSQ/BCIisUrqs+aufU0Ene5viIjEIqkTR8v+fQcGQRcRkV5J6hcYrk5dHO8QREQGnOStcTjVNUREjoSvicPMZpvZWjOrMrPbo6z/mpl9YGbLzex1M5voZzyRQs31/bUrEZFjim+Jw8wCwAPARcBE4OooieFPzrkTnXPTgJ8B9/oVT3dtn67pr12JiBxT/KxxzASqnHMbnXOtwHzg8sgCzrnIy/4c6L971burP+qvXYmIHFP8TBwjgC0R89XhZV2Y2TfMbANejeMWH+Pp4vW12/prVyIixxQ/E0e0FyQOqlE45x5wzo0Fvgf8MOqGzOaZ2VIzW1pbW9snwZUXpffJdkREko2fiaMaGBkxXwbUHKL8fODz0VY45x5yzlU65ypLSkr6JLgU53WpXve53/XJ9kREkoWfiWMJMM7MKswsHZgLLIwsYGbjImYvAdb7GE8XLtgGQPvIM/prlyIixwTfXgB0zrWb2c3A80AAeMQ5t9rM7gKWOucWAjeb2XlAG7Ab+LJf8Rwk5CWOlNS0ftuliMixwNc3x51zi4BF3ZbdGTF9q5/7P5TR2/4OQCBV9zpERGKRtG+OF9d773EE0pQ4RERikbSJo0MgoIGcRERikfSJIzVF3aqLiMQi6RNHisYbFxGJSdInDtU4RERik7SJI+SM5aExpChxiIjEJGkTxx5yWBEaG+8wREQGnKRNHKkECaInqkREYpXEiSNEmxKHiEjMkjhxtKvGISJyBJIzcThHugVV4xAROQJJmTiCwSAAY4cWxTkSEZGBJykTR1tbCwDF+dlxjkREZOBJysTR2uolDguoS3URkVglZeJob/PG4rCAr73Ki4gck5I0cbQCqnGIiByJpEwcbZ01DiUOEZFYJWXiCIZrHIFUNVWJiMTK18RhZrPNbK2ZVZkfV0okAAAQaklEQVTZ7VHWf9vM1pjZSjN70cxG+xlPh/b2jqYqjf4nIhIr3xKHmQWAB4CLgInA1WY2sVux94FK59wUYAHwM7/iidTe7jVVpejmuIhIzPysccwEqpxzG51zrcB84PLIAs65xc65/eHZt4EyH+Pp1HFzPCVV9zhERGLl5yX3CGBLxHw1cMohyn8FeNbHeDoNWfEgAAHVOETirq2tjerqapqbm+MdyjEhMzOTsrIy0tL8uzD288wZbYQkF7Wg2XVAJXBWD+vnAfMARo0addSBFX/8NADprvWotyUiR6e6upq8vDzKy8sxDeV8VJxz1NXVUV1dTUVFhW/78bOpqhoYGTFfBtR0L2Rm5wE/AC5zzrVE25Bz7iHnXKVzrrKkpKTPAsxEVzgi8dbc3MzgwYOVNPqAmTF48GDfa29+Jo4lwDgzqzCzdGAusDCygJlNB36DlzR2+BhLVBnR85SI9DMljb7TH8fSt8ThnGsHbgaeBz4EnnDOrTazu8zssnCxfwdygf82s+VmtrCHzfWpoHktdCklx/fH7kTkGJKbmwtATU0Nc+bMiVrm7LPPZunSpYfczn333cf+/fs75y+++GL27NnTd4H6yNe7w865RcCibsvujJg+z8/992RL8ZkM2/EaqePPj8fuReQYMHz4cBYsWHDEn7/vvvu47rrryM72euletGjRYT6ROJLyzXFrb+JDN5rsNA3kJJLsvve97/Ff//VfnfM//vGP+clPfsK5557LjBkzOPHEE3n66acP+tymTZuYPHkyAE1NTcydO5cpU6Zw1VVX0dTU1FnupptuorKykkmTJvGjH/0IgPvvv5+amhrOOecczjnnHADKy8vZuXMnAPfeey+TJ09m8uTJ3HfffZ37O+GEE/jqV7/KpEmTuOCCC7rspz8l5fOohY0b+ZTBpAaSMm+KJKyf/G01a2rq+3SbE4fn86NLJ/W4fu7cudx22218/etfB+CJJ57gueee41vf+hb5+fns3LmTWbNmcdlll/V4/+DBBx8kOzublStXsnLlSmbMmNG57t/+7d8YNGgQwWCQc889l5UrV3LLLbdw7733snjxYoqLi7tsa9myZfz+97/nnXfewTnHKaecwllnnUVRURHr16/n8ccf5+GHH+aLX/wif/nLX7juuuv64CjFJvnOnJ+uoKB1O7NS1sQ7EhFJANOnT2fHjh3U1NSwYsUKioqKKC0t5fvf/z5TpkzhvPPOY+vWrWzfvr3Hbbz66qudJ/ApU6YwZcqUznVPPPEEM2bMYPr06axevZo1aw597nn99de54ooryMnJITc3ly984Qu89tprAFRUVDBt2jQATjrpJDZt2nSU3/7IJF+NY8+Ww5cRkbg4VM3AT3PmzGHBggVs27aNuXPn8thjj1FbW8uyZctIS0ujvLz8sI+4RquNfPzxx/z85z9nyZIlFBUVcf311x92O85Ffd0NgIyMjM7pQCAQt6aq5KtxpGu4WBHpau7cucyfP58FCxYwZ84c9u7dy5AhQ0hLS2Px4sV88sknh/z8mWeeyWOPPQbAqlWrWLlyJQD19fXk5ORQUFDA9u3befbZA51j5OXl0dDQEHVbTz31FPv376exsZEnn3ySz3zmM334bY9e8tU4AhmHLyMiSWXSpEk0NDQwYsQISktLufbaa7n00kuprKxk2rRpTJgw4ZCfv+mmm7jhhhuYMmUK06ZNY+bMmQBMnTqV6dOnM2nSJMaMGcPpp5/e+Zl58+Zx0UUXUVpayuLFizuXz5gxg+uvv75zGzfeeCPTp0+PW7NUNHaoalEiqqysdId7PvqQPn4VHr2ULZnjGXn7u30XmIgckQ8//JATTjgh3mEcU6IdUzNb5pyr7IvtJ11TVTDcpfob4/4lzpGIiAxMSZc4mpq9m0nZmWqyEhE5EkmXOPY3eU805GRnxTkSEZGBKekSR3OL17FhZoZqHCIiRyLpEkeo2XsrNS1diUNE5EgkXeIof+N2ANLT0uMciYjIwJR0iaNDhjo4FBFgz549XTo57K2B1A16X0vaxJGaW3z4QiJyzOspcQSDwUN+btGiRRQWFvoVVkJLujfHl4fGsMflUZFTEO9QRCQB3H777WzYsIFp06aRlpZGbm4upaWlLF++nDVr1vD5z3+eLVu20NzczK233sq8efMArxv0pUuXsm/fPi666CLOOOMM3nzzTUaMGMHTTz9NVtax++Rm8iSO9hbYtoppKRtZFJxJppqqRBLPs7fDtg/6dpvDToSL7u5x9d13382qVatYvnw5L7/8MpdccgmrVq2ioqICgEceeYRBgwbR1NTEySefzJVXXsngwYO7bCNRujvvL8nTVPX6ffDbzwJQmbKOofmZcQ5IRBLRzJkzO5MGeIMuTZ06lVmzZrFlyxbWr19/0GcSpbvz/pI8NY6hEzsnazNHMySOoYhIDw5RM+gvOTk5ndMvv/wy//jHP3jrrbfIzs7m7LPPjtoteqJ0d95ffK1xmNlsM1trZlVmdnuU9Wea2Xtm1m5m0Ud97ysVZ8HUa9hr+Twy9Ie+7kpEBo6eujcH2Lt3L0VFRWRnZ/PRRx/x9ttv93N0icm3GoeZBYAHgPOBamCJmS10zkUOf7UZuB74rl9xdMrMhyse5OK1/8TMnEG+705EBobBgwdz+umnM3nyZLKyshg6dGjnutmzZ/PrX/+aKVOmMH78eGbNmhXHSBOHn01VM4Eq59xGADObD1wOdCYO59ym8LqQj3EA8MSSLfz6lQ1s3dPE2JKcw39ARJLGn/70p6jLMzIyugy+FKnjPkZxcTGrVq3qXP7d7/p/HRxvfiaOEUDkOK3VwClHsiEzmwfMAxg1atQRBVOYncaE0jxOGTOIOSeNPKJtiIiIv4nj4AF44YhGjXLOPQQ8BN5ATkeyjQsmDeOCScOO5KMiIhLBz5vj1UDkpX0ZUOPj/kREpB/4mTiWAOPMrMLM0oG5wEIf9yciA9RAG8I6kfXHsfQtcTjn2oGbgeeBD4EnnHOrzewuM7sMwMxONrNq4J+A35jZar/iEZHElJmZSV1dnZJHH3DOUVdXR2amvy8420D7x6qsrHRLly6Ndxgi0kfa2tqorq6O+mKdxC4zM5OysjLS0tK6LDezZc65yr7YR/K8OS4iCSktLa1LFx+S+JKnryoREekTShwiIhITJQ4REYnJgLs5bma1wCdH+PFiYGcfhtNfFHf/GYgxg+LuTwMxZoDxzrm8vtjQgLs57pwrOdLPmtnSvnqqoD8p7v4zEGMGxd2fBmLM4MXdV9tSU5WIiMREiUNERGKSbInjoXgHcIQUd/8ZiDGD4u5PAzFm6MO4B9zNcRERia9kq3GIiMhRSprEcbjxz+PFzEaa2WIz+9DMVpvZreHlg8zsBTNbH/5dFF5uZnZ/+HusNLMZcY4/YGbvm9kz4fkKM3snHPefwz0jY2YZ4fmq8PryOMZcaGYLzOyj8HE/NdGPt5l9K/z/Y5WZPW5mmYl4rM3sETPbYWarIpbFfGzN7Mvh8uvN7Mtxivvfw/9HVprZk2ZWGLHujnDca83swojl/XqeiRZ3xLrvmpkzs+LwfN8db+fcMf8DBIANwBggHVgBTIx3XOHYSoEZ4ek8YB0wEfgZcHt4+e3APeHpi4Fn8QbKmgW8E+f4vw38CXgmPP8EMDc8/WvgpvD014Ffh6fnAn+OY8yPAjeGp9OBwkQ+3nijaX4MZEUc4+sT8VgDZwIzgFURy2I6tsAgYGP4d1F4uigOcV8ApIan74mIe2L4HJIBVITPLYF4nGeixR1ePhKvZ/JPgOK+Pt79+gcQrx/gVOD5iPk7gDviHVcPsT4NnA+sBUrDy0qBteHp3wBXR5TvLBeHWMuAF4HPAs+E/0PujPhj6zzu4f/Ep4anU8PlLA4x54dPwtZtecIebw4MwzwofOyeAS5M1GMNlHc7Acd0bIGrgd9ELO9Srr/i7rbuCuCx8HSX80fH8Y7XeSZa3MACYCqwiQOJo8+Od7I0VUUb/3xEnGLpUbhJYTrwDjDUOfcpQPj3kHCxRPou9wH/CwiF5wcDe5w3Fgt0ja0z7vD6veHy/W0MUAv8PtzE9lszyyGBj7dzbivwc2Az8CnesVtG4h/rDrEe27gf8yj+B97VOiR43OaNd7TVObei26o+iztZEkefjX/uFzPLBf4C3Oacqz9U0SjL+v27mNnngB3OuWWRi6MUdb1Y159S8ar2DzrnpgONeM0nPYl73OF7ApfjNYsMB3KAiw4RV9xj7qWe4kyo+M3sB0A78FjHoijFEiJuM8sGfgDcGW11lGVHFHeyJI6EHv/czNLwksZjzrm/hhdvN7PS8PpSYEd4eaJ8l9OBy8xsEzAfr7nqPqDQzDq6somMrTPu8PoCYFd/BhwRR7Vz7p3w/AK8RJLIx/s84GPnXK1zrg34K3AaiX+sO8R6bBPhmAPeTWPgc8C1LtyOQ2LHPRbvAmNF+G+zDHjPzIYdIr6Y406WxJGw45+bmQG/Az50zt0bsWoh0PF0w5fx7n10LP9S+AmJWcDejmaA/uScu8M5V+acK8c7ni85564FFgNzeoi74/vMCZfv96tI59w2YIuZjQ8vOhdYQ2If783ALDPLDv9/6Yg5oY91hFiP7fPABWZWFK5tXRBe1q/MbDbwPeAy59z+iFULgbnhp9cqgHHAuyTAecY594Fzbohzrjz8t1mN9/DNNvryePt94yZRfvCeKFiH99TDD+IdT0RcZ+BVC1cCy8M/F+O1Sb8IrA//HhQub8AD4e/xAVCZAN/hbA48VTUG74+oCvhvICO8PDM8XxVePyaO8U4DloaP+VN4T5Ik9PEGfgJ8BKwC/oj3RE/CHWvgcbz7MG3hk9ZXjuTY4t1TqAr/3BCnuKvw2v47/i5/HVH+B+G41wIXRSzv1/NMtLi7rd/EgZvjfXa89ea4iIjEJFmaqkREpI8ocYiISEyUOEREJCZKHCIiEhMlDhERiYkSh0iYmQXNbHnET5/1bmpm5dF6MBUZiFIPX0QkaTQ556bFOwiRRKcah8hhmNkmM7vHzN4N/xwXXj7azF4Mj23wopmNCi8fGh6/YUX457TwpgJm9rB542r83cyywuVvMbM14e3Mj9PXFOk1JQ6RA7K6NVVdFbGu3jk3E/hPvD65CE//f865KXgd4N0fXn4/8IpzbipeP1irw8vHAQ845yYBe4Arw8tvB6aHt/M1v76cSF/Rm+MiYWa2zzmXG2X5JuCzzrmN4Q4ptznnBpvZTrxxJtrCyz91zhWbWS1Q5pxridhGOfCCc25ceP57QJpz7v8xs+eAfXjdnzzlnNvn81cVOSqqcYj0juthuqcy0bRETAc5cI/xErw+hE4ClkX0eCuSkJQ4RHrnqojfb4Wn38TrARXgWuD18PSLwE3QOSZ7fk8bNbMUYKRzbjHeoFiFwEG1HpFEoisbkQOyzGx5xPxzzrmOR3IzzOwdvIutq8PLbgEeMbN/wRtV8Ibw8luBh8zsK3g1i5vwejCNJgD8HzMrwOu99BfOuT199o1EfKB7HCKHEb7HUemc2xnvWEQSgZqqREQkJqpxiIhITFTjEBGRmChxiIhITJQ4REQkJkocIiISEyUOERGJiRKHiIjE5P8HRveTPLtyok4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd8FVX+//HXJ52EBBKSECCE0EuoITQpUpRmQ0VEkFURWdRdy66ubrF9t/xcdVnUFRUUlSKIgGJBUJCqFBNqqKEFQkkhQAoESHJ+f8wFAiaQQG7m3uTzfDzuI/fOnDv3k1HuOzNz5hwxxqCUUkqVlofdBSillHIvGhxKKaXKRINDKaVUmWhwKKWUKhMNDqWUUmWiwaGUUqpMNDiUUkqViQaHUkqpMtHgUEopVSZedhdQVqGhoSY6OtruMpRSyq0kJCRkGGPCymNbbhcc0dHRxMfH212GUkq5FRFJLq9t6akqpZRSZaLBoZRSqkw0OJRSSpWJ213jUEpVLufOnSMlJYW8vDy7S6kU/Pz8iIyMxNvb22mfocGhlLJVSkoKgYGBREdHIyJ2l+PWjDEcO3aMlJQUGjZs6LTP0VNVSilb5eXlUatWLQ2NciAi1KpVy+lHbxocSinbaWiUn4rYl1UmOM6k72XP1N9h8s/aXYpSSrm1KhMc69auovHeaWz7eoLdpSil3Fj16tUBOHz4MEOHDi22Te/eva96o/KECRM4derUhdeDBw/mxIkT5VeoE1WZ4Og2cCQbvdsRuelNso+n2l2OUsrN1a1blzlz5lzz+y8PjgULFlCzZs3yKM3pqkxweHl5Uu221wkwp9gx/Vm7y1FKuYjnnnuOiRMnXnj98ssv88orr9CvXz9iY2Np06YN8+fP/9X79u/fT+vWrQE4ffo0w4cPp23bttx7772cPn36QrtHH32UuLg4YmJieOmllwB46623OHz4MH369KFPnz6ANZxSRkYGAOPHj6d169a0bt2aCRMmXPi8li1b8sgjjxATE0P//v0v+ZyKVKW64zZv24XVq+6hS+pstscvpWVcH7tLUkoV8crXW9l2OKtct9mqbhAv3RZT4vrhw4fz1FNP8dhjjwEwe/ZsFi5cyNNPP01QUBAZGRl07dqV22+/vcQLz++++y7+/v5s3ryZzZs3Exsbe2HdP//5T0JCQigoKKBfv35s3ryZJ554gvHjx7N06VJCQ0Mv2VZCQgIfffQRa9euxRhDly5duPHGGwkODiYpKYmZM2cyefJkhg0bxty5c7n//vvLYS+VTZU54jivzf2vckxq4vndM5w9e87ucpRSNuvQoQNpaWkcPnyYTZs2ERwcTJ06dfjLX/5C27Ztuemmmzh06BCpqSWf4l6xYsWFL/C2bdvStm3bC+tmz55NbGwsHTp0YOvWrWzbtu2K9axatYo777yTgIAAqlevzl133cXKlSsBaNiwIe3btwegY8eO7N+//zp/+2tTpY44AKoHhbCv6wu0WfMHln3+H3qPfN7ukpRSDlc6MnCmoUOHMmfOHI4ePcrw4cOZMWMG6enpJCQk4O3tTXR09FXvjSjuaGTfvn288cYb/PLLLwQHB/Pggw9edTvGmBLX+fr6Xnju6elp26mqKnfEAdBmwGh2VmtP+11vkXyg3EYaVkq5qeHDhzNr1izmzJnD0KFDOXnyJOHh4Xh7e7N06VKSk6/8PdGrVy9mzJgBQGJiIps3bwYgKyuLgIAAatSoQWpqKt99992F9wQGBpKdnV3str788ktOnTpFbm4uX3zxBT179izH3/b6VcngQITQYW8TIHkcmPn0FRNeKVX5xcTEkJ2dTb169ahTpw4jR44kPj6euLg4ZsyYQYsWLa74/kcffZScnBzatm3La6+9RufOnQFo164dHTp0ICYmhtGjR9O9e/cL7xk7diyDBg26cHH8vNjYWB588EE6d+5Mly5dGDNmDB06dCj/X/o6iLt9acbFxZnymshpy7Q/0WbP+yzvMpkbBw0rl20qpcpm+/bttGzZ0u4yKpXi9qmIJBhj4spj+1XziMMh5t5XOOJZl4ZrXyDjuHvceKOUUnZzWnCISH0RWSoi20Vkq4g8WUybkSKy2fH4WUTaOaue4nj4VKNg8HiiOEr89L9V5EcrpZTbcuYRRz7wR2NMS6Ar8LiItLqszT7gRmNMW+DvwCQn1lOsyI6D2B4+mL4Zn7Ly51UV/fFKKeV2nBYcxpgjxpj1jufZwHag3mVtfjbGHHe8XANEOqueK2ly/5vkefhT/ftnOJ6jk8kopdSVVMg1DhGJBjoAa6/Q7GHguyusdxrvoHByer5IB7azaPobdpSglFJuw+nBISLVgbnAU8aYYscSEJE+WMHxXAnrx4pIvIjEp6enO6XOun0eISWoA4OOvMPy9Vud8hlKKVUZODU4RMQbKzRmGGPmldCmLfABcIcx5lhxbYwxk4wxccaYuLCwMGcVS/iI9/CXs5z6+nlOntLhSJSqCk6cOHHJIIel5U7DoJc3Z/aqEuBDYLsxZnwJbaKAecAoY8wuZ9VSWj4RLTge+ziDzApmzfrE7nKUUhWgpOAoKCi44vvcaRj08ubMI47uwCigr4hsdDwGi8g4ERnnaPMiUAuY6FhfPnf2XYfwQX8h068+A/a/xrJEHY5Eqcru+eefZ8+ePbRv355OnTrRp08fRowYQZs2bQAYMmQIHTt2JCYmhkmTLnb8PD8MuisNd15RnDbIoTFmFXDFyW+NMWOAMc6q4Zp4+1H97rcJmTGEH+e9QofG71OjmrfdVSlVNXz3PBzdUr7bjGgDg14tcfWrr75KYmIiGzduZNmyZdxyyy0kJibSsGFDAKZMmUJISAinT5+mU6dO3H333dSqVeuSbbjKcOcVpUrfOV4Sn6Z9yGx6N/cXfMkHc7+1uxylVAXq3LnzhdAAa9Kldu3a0bVrVw4ePEhSUtKv3uMqw51XlCo3rHpphQx5jdP//YEbd/2TZdu70LtlHbtLUqryu8KRQUUJCAi48HzZsmUsXryY1atX4+/vT+/evYsdFt1VhjuvKHrEUZKAULwGv0qcxy42zHmNrDztZaVUZVTS8OYAJ0+eJDg4GH9/f3bs2MGaNWsquDrXpMFxBd4dRnAysg/j8qfz/heL7S5HKeUEtWrVonv37rRu3Zpnn332knUDBw4kPz+ftm3b8sILL9C1a1ebqnQtVXpY9VI5eYi8tzqx8VwUp0d8SZ8WERX32UpVATqsevnTYdXtVqMengP/RVeP7ayZ/QYZOWfsrkgppWylwVEK3nEPkBvZk98XTOO1WT/ojIFKqSpNg6M0RAgYOhFfLw9uTX6V6Wv0xkClypP+MVZ+KmJfanCUVs0ovAb8nV6eW9ix4B2SUovvhaGUKhs/Pz+OHTum4VEOjDEcO3YMPz8/p36O3sdRBhI3mrNb5vLng9N59NMb+OD3t+Pr5Wl3WUq5tcjISFJSUnDWyNdVjZ+fH5GRzp3aSIOjLDw88LnzHTzfuYGHMifwxsJm/PXWGLurUsqteXt7X3KntnJ9eqqqrEIa4XnzS/T13EjGz9NYlZRhd0VKKVWhNDiuReffUhDZhVd8pvHPz5aSmXvW7oqUUqrCaHBcCw8PPIdMpLrnOZ47+w7PzdmkF/aUUlWGBse1Cm2CR/9/0NtjAxG7pjPrl4N2V6SUUhVCg+N6dH4E06Q/L3h/yoyvv2dPeo7dFSmllNNpcFwPEWTIO3hVC+Q/nm/xzMxfOJtfaHdVSinlVM6cc7y+iCwVke0islVEniymjYjIWyKyW0Q2i0iss+pxmurheAyZSHOSGZg2mfE/2D51ulJKOZUzjzjygT8aY1oCXYHHRaTVZW0GAU0dj7HAu06sx3maD4S4h/mt17ckrvySn/doF12lVOXltOAwxhwxxqx3PM8GtgP1Lmt2BzDVWNYANUXEPafa6/8PCms1ZYLv+7w8axUnTmkXXaVU5VQh1zhEJBroAKy9bFU9oGh3pBR+HS7uwccfj6EfEiLZ/OHMO/xl3mbtoquUqpScHhwiUh2YCzxljMm6fHUxb/nVt62IjBWReBGJd+nxbOq0w6PfCwz0WEfA9s/4PCHF7oqUUqrcOTU4RMQbKzRmGGPmFdMkBahf5HUkcPjyRsaYScaYOGNMXFhYmHOKLS/dfo+J7snffabywfzFbD9yeVYqpZR7c2avKgE+BLYbY8aX0Owr4DeO3lVdgZPGmCPOqqlCeHggd76Hj68f473e4XfT1nLy9Dm7q1JKqXLjzCOO7sAooK+IbHQ8BovIOBEZ52izANgL7AYmA485sZ6KUyMSj9sm0NokMST7U/44eyOFhXq9QylVOThtWHVjzCqKv4ZRtI0BHndWDbaKuROSfuDxjTMZtqM1E5fV5Hd9m9pdlVJKXTe9c9yZBv0bCY7i/eqTmPTDRlbscuEL+0opVUoaHM7kG4jc9QEh+en8t/p0npi1gYOZp+yuSimlrosGh7PV74Tc+Bz9zi2jf+FKHpuxnrxzBXZXpZRS10yDoyL0/CPU78I/vT8i89BuXpq/1e6KlFLqmmlwVARPL7jzfbwFZoV9xOfxycxad8DuqpRS6ppocFSUkIYw+HXqZ2/k37UX8+L8rWw6eMLuqpRSqsw0OCpSu+HQ+m6GZk3l5oAkHpuxXucrV0q5HQ2OiiQCt72JhDRigudbmJxUnpi5gQK9OVAp5UY0OCqabyAMm4r3uRy+qD2F1btTGf/DTrurUkqpUtPgsEPtGLh1PLWPrWNy/e95Z+kevt961O6qlFKqVDQ47NJ+BMT+hr7p03gobCd/nL2JfRm5dlellFJXpcFhp0GvQUQbXjj7JpEeGYyblsCps/l2V6WUUlekwWEn72pwzyd4UMhnIe+zL+04z8/dojMHKqVcmgaH3Wo1hjveIejYJuY0+pavNh1m0oq9dlellFIl0uBwBa1uh66P0/bQZ7wQvZ1XF+5g8bZUu6tSSqliaXC4iptfgfpdGH1sPIPDj/PkrA067axSyiVpcLgKT2+45xPEtzpv8jp1fPMY80k86dln7K5MKaUuocHhSoLqwLBpeGUf4ovaUziee5rfTovXYdiVUi7FacEhIlNEJE1EEktYX0NEvhaRTSKyVUQeclYtbiWqCwx+ncCU5XzdainrD5zgmc836ZzlSimX4cwjjo+BgVdY/ziwzRjTDugN/EdEfJxYj/uIewg6PkjjnZOZ3PEA32w+wmuLdFgSpZRrcFpwGGNWAJlXagIEiogA1R1t9e638wa9BvW7cNOu/+PZNqd5b/keZqxNtrsqpZSy9RrH/4CWwGFgC/CkMabQxnpci5cvDJuG+NfisaN/487GwgtfJrJ0R5rdlSmlqjg7g2MAsBGoC7QH/iciQcU1FJGxIhIvIvHp6ekVWaO9AmvDfbOQM9m8UfAq7SN8ePzT9SQeOml3ZUqpKszO4HgImGcsu4F9QIviGhpjJhlj4owxcWFhYRVapO0iWsPQKXimbuHTWh8R7OfJ6I9/4dCJ03ZXppSqouwMjgNAPwARqQ00B3SsjeI0GwD9/4Hf7m/5KmYZp88WMPqjXzh5+pzdlSmlqiBndsedCawGmotIiog8LCLjRGSco8nfgRtEZAuwBHjOGJPhrHrcXtfHoOOD1NrwP+besJ+9GTk8MlXv8VBKVTxxt5FY4+LiTHx8vN1l2KPgHEy/C5JXs6r7FO7/wZOBMRG8MzIWTw+xuzqllAsTkQRjTFx5bEvvHHcnnt4wbCoEN6BH/JO81jeQhVuP8tJXiToUu1KqwmhwuJtqwTBiNmAYtusZnugexvQ1B3hryW67K1NKVREaHO6oVmO4dzpk7uXp4//ing4R/HfxLqat0RsElVLOp8HhrqJ7wG0TkL1LedV/Oje1COPF+Yl8s/mw3ZUppSo5L7sLUNehw/2QsQvPn97k3f7NGJnXnqc/24i/jyd9W9S2uzqlVCWlRxzurt/L0OJWvH/4Cx/3yKRFRBDjpq9nVZL2bFZKOYcGh7vz8IC7JkFEW/znj2HGQE8ahQYwZuovrN17zO7qlFKVkAZHZeATACM/h+q1CZo3gk/vCqVezWqM/vgX1h84bnd1SqlKRoOjsqgeDqPmgXgQMu9eZt3XkNBAXx6Ysk4HRVRKlSsNjsokpJF15JF7jLCvRvLpqFYE+Xkz6sO17DyabXd1SqlKQoOjsqkXC/dOhbTt1Fs0hk9Ht8fHy4ORH6xhT3qO3dUppSoBDY7KqMlNcMc7sG8FDZY8zoyHOgIwcvJako/l2lycUsrdaXBUVu2Gw+A3YOcCmqx8kumjO3Imv4Dhk9awP0PDQyl17TQ4KrPOj8CAf8G2+bRY/Sc+fbgTZ/ILGT5pDfs0PJRS10iDo7Lr9jj0ewm2fE7L+L8xc0xnzhUUMnzSavbqNQ+l1DXQ4KgKev4BbnweNkynecIrfDqmC/kFhuGT1pCUqr2tlFJlo8FRVfR+Hro/BfEf0nzjv5j1SBcMcO+kNXqfh1KqTJw5dewUEUkTkcQrtOktIhtFZKuILHdWLQoQgZtetqagXfsuTbf8h9lju+Ln5cGIyWv0DnOlVKk584jjY2BgSStFpCYwEbjdGBMD3OPEWhRY4THgXxD3MPw0gYaJbzN7XDeCA3wY9cFaVu/Rsa2UUlfntOAwxqwAMq/QZAQwzxhzwNE+zVm1qCJErG667e+H5a8Smfgun/+2G3VrVuOBj9axZHuq3RUqpVxcqYJDRJ4UkSCxfCgi60Wk/3V+djMgWESWiUiCiPzmOrenSsvDA25/C9oMgyX/R/jWD/nst91oERHIb6clMH/jIbsrVEq5sNIecYw2xmQB/YEw4CHg1ev8bC+gI3ALMAB4QUSaFddQRMaKSLyIxKenp1/nxyoAPDxhyLvQ6g5Y9BdCtn7CjDFd6NggmKc+28i01fvtrlAp5aJKGxzi+DkY+MgYs6nIsmuVAiw0xuQaYzKAFUC74hoaYyYZY+KMMXFhYWHX+bHqAk8vuPtDaD4YFjxD4LaZfDK6M/1a1OaF+VuZsHgXxhi7q1RKuZjSBkeCiHyPFRyLRCQQKLzOz54P9BQRLxHxB7oA269zm6qsPL3hno+t8a2+egK/bXN47/5Y7o6NZMLiJJ6ds5mz+df7n1opVZmUds7xh4H2wF5jzCkRCcE6XVUiEZkJ9AZCRSQFeAnwBjDGvGeM2S4iC4HNWCH0gTGmxK67yom8fOHe6fDpMPhyHF6eXrxxz13UD6nGhMVJHD5xmnfv70iNat52V6qUcgFSmlMRItId2GiMyRWR+4FY4E1jTLKzC7xcXFyciY+Pr+iPrRrO5sKMe+DAarjtLYgdxdyEFJ6ft5kGtQL46MFO1A/xt7tKpdQ1EJEEY0xceWyrtKeq3gVOiUg74E9AMjC1PApQLsQnAEbOgUa94avfwZp3ubtjJFNHdyEtK487J/7ExoMn7K5SKWWz0gZHvrEOTe7AOtJ4Ewh0XlnKNj7+cN8saHkbLHwelr9Ot0YhzHvsBqr5eDJ80moWJh61u0qllI1KGxzZIvJnYBTwrYh44rheoSohL18Y+jG0uw+W/gN+eIEmYdX54rHutIgI4tEZCXywcq/2uFKqiiptcNwLnMG6n+MoUA943WlVKft5esEdE6HTI/Dz2/DN04T6ezHzka4MaBXBP77dzktfbSW/QHtcKVXVlCo4HGExA6ghIrcCecYYvcZR2Xl4wODXoccfIOEj+OK3VPMsZOLIWMb2asTU1cmMnZZA7pl8uytVSlWg0g45MgxYhzUQ4TBgrYgMdWZhykWIwE0vWSPrbvkcPhuFR0Eefxnckr8Pac2ynWkMe381qVl5dleqlKogpT1V9VegkzHmAWPMb4DOwAvOK0u5nB5Pwy3/gV0L4ZPb4VQmo7o24MMHOrEvI5ch7/zE9iNZdleplKoApQ0Oj8tGrz1WhveqyqLTGBj2CRzZBB/2h+P76dMinM/HdaPQGO55b7WOrqtUFVDaL/+FIrJIRB4UkQeBb4EFzitLuaxWd8Bv5kNuOnxwMxzeSEzdGnz5eHca1PJnzNR43lqSRGGh9rhSqrIq7cXxZ4FJQFusgQgnGWOec2ZhyoU16AYPf2912/34Fti9hDo1qjH30RsY0r4e43/YxWMz1pOjF82VqpRKNeSIK9EhR1xI1hGYMRTSd8Dtb0P7ERhj+HDVPv61YDtNwqvz/qg4GoYG2F2pUlVehQ05IiLZIpJVzCNbRPRKaFUXVAceWgANboAvH4Wl/w8BxvRsZA1Tkn2G299epXeaK1XJXDE4jDGBxpigYh6BxpigiipSuTC/GjByLrQbActfhS9+C/ln6NE0lG9+34NGYQGMm57AvxZs15sFlaoktGeUun5ePjBkIvT9G2z+DKYOgVOZRAb7M3tcN0Z1bcCkFXsZMXktaXq/h1JuT4NDlQ8R6PWsNaPgoQT4oB9k7MbXy5O/D2nNm8Pbs+XQSQa/tYqf92TYXa1S6jpocKjy1WYoPPgN5GXBB30haTEAd7Svx/zfdSeomhf3f7CWCYt3UaBddpVySxocqvzV7wyP/Ag1ouDTe2DVBDCGZrUD+fp3PRjSoR4TFicx8oM1OlSJUm5Ig0M5R3ADeHiRdcPg4pdg7hg4e4oAXy/GD2vPG/e0Y9PBkwycsIKFiUfsrlYpVQZOCw4RmSIiaSJyxXnERaSTiBTooImVkE8ADP0I+r0EiXNhSn84cQCAoR0j+eaJHkQG+zNu+nqe+XwT2XnnbC5YKVUazjzi+BgYeKUGjgmh/g0scmIdyk4i0PMPMGI2HD8Ak3rDvpUANA6rzrzHbuD3fZswb30Kg95cyS/7M+2tVyl1VU4LDmPMCuBq3wK/B+YCaVdpp9xds/7WdQ//WjD1Dlg7CYzB29ODP/ZvzufjuuEhwrD3V/PvhTs4m6/3fCjlqmy7xiEi9YA7gfdK0XasiMSLSHx6errzi1POEdoExiyBpv3hu2etu83P5gLQsUEIC57syT0dI3l32R7unPgTSanZNheslCqOnRfHJwDPGWMKrtbQGDPJGBNnjIkLCwurgNKU0/gFwfBPofefYdMsmNwP0ncCUN3Xi9eGtuP9UR05cjKPW99excc/7dORdpVyMXYGRxwwS0T2A0OBiSIyxMZ6VEXx8IDez8Ooedbw7JP6wObPL6weEBPBwqd60q1xLV7+ehsPfLROu+0q5UJsCw5jTENjTLQxJhqYAzxmjPnSrnqUDRr3hXEroU5bmDcGvnkazlkBER7ox0cPduLvQ1rzy/5Mbhq/nNnxB3G30ZyVqoyc2R13JrAaaC4iKSLysIiME5FxzvpM5YaC6sID30D3pyB+Cnx4MxzbA4CIMKprA757shctI4L405zN/GbKOlKOn7K5aKWqNp2PQ7mOnQut0XULzsKAf0LHh6zuvEBhoWHG2mRe/W4HAM8NasH9XRrg4SF2VqyU26iw+TiUqlDNB8Jjq6F+F+u01afDINuaw9zDQxjVLZpFT/citkEwL87fyvBJa9iTnmNz0UpVPRocyrUE1YX758Gg12HfCpjYFbZ9dWF1ZLA/U0d35vWhbdlxNItBE1by5uIkzuRftXOeUqqcaHAo1+PhAV3Gwm9XQs0omD0KvngU8k4C1rWPe+Lqs/iPNzKgdQT/XbyLQRNW8vNuHa5dqYqgwaFcV1gzGLMYev0JNs+Cd3vA/lUXVocH+vH2fR34ZHRn8gsNIz5Yy1OzNpCWrV13lXImDQ7l2jy9oe9fYfT34OkFH98K378A+WcuNLmxWRjfP92LJ/o2YcGWo/R7Yzkf/7RPp6pVykm0V5VyH2dz4fu/Wd12w2PgrkkQ0fqSJvsycnlxfiIrkzJoWSeIl29rRZdGtWwqWCnXob2qVNXkEwC3/tcaaTc3HSb3gZ/ehMKLF8YbhgYwdXRnJo6MJev0Oe6dtIYnZm7g8InTNhauVOWiRxzKPeUeg6+fgB3fQIPuMORda/KoIk6fLeDd5Xt4b/kePATG3diYsb0a4e/jZVPRStmnPI84NDiU+zIGNs2EBX+yXg/6N7QfceGmwfMOZp7i1e928O2WI4QH+vLUTc0YFheJl6cecKuqQ4NDg0MVdTzZGqI9+SdocjPc8p9fHX0AxO/P5F8LtrP+wAkahwXw3MAW3NyqNiJ697mq/DQ4NDjU5QoLYN1kWPJ/gIE+f4Uu46yeWEUYY1i0NZXXFu5gb0YunaKD+fPglsRGBdtTt1IVRINDg0OV5MRBWPAM7FoIddrBbW9C3Q6/anauoJDPfjnIhMVJZOScYVDrCJ4d0JxGYdVtKFop59Pg0OBQV2IMbJsP3/3J6n3Veax1BOIX9KumuWfymbxyL5NW7OVMfiEjOkfxRL+mhAX62lC4Us6jwaHBoUoj76R16uqXDyEwwhpxN+auX108B0jPPsNbS5L4dN0B/Lw8eKRXIx7p2YgAX+2BpSoHDQ4NDlUWKfHWaLtHN0PDG2HwG9ZwJsXYm57D64t28l3iUUICfBh3YyNGdY2mmo9nBRetVPnS4NDgUGVVWGDdcb7k73DuFHR7zBoDy7f4axobDhxn/A+7WJmUQVigL4/3bsx9XaLw9dIAUe5Jg0ODQ12rnHRY/BJsnAGBdeDm/4M29xR7+gpg3b5M3vh+J+v2ZVKnhh+P9m7MsLj6+HlrgCj34hbBISJTgFuBNGNM62LWjwSec7zMAR41xmy62nY1OFS5OLjOunh+eIM1cdTAV6FebLFNjTH8tPsYExbvIj75OOGBvozt1YgRXaL0LnTlNtwlOHphBcLUEoLjBmC7Mea4iAwCXjbGdLnadjU4VLkpLLSOPJa8YvW+ansv9HsRakQW29wYw+q9x3h7yW5W7z1GrQAfHu7ZkFFdGxDo513BxStVNm4RHAAiEg18U1xwXNYuGEg0xtS72jY1OFS5y8uCVeNh9UTrlFW3x6HH0+AbWOJb4vdn8vaPu1m+K51APy/u79qAh7pHEx7oV4GFK1V6lTE4ngFaGGPGXG2bGhzKaU4csC6eb5kNAWHQ5y/Q4Te/uvu8qC0pJ3lv+R4WJB7B28ODO9rXZXSPhrSs8+t7RpSyU6UKDhHpA0wEehhjjpXQZiwwFiAqKqpjcnJy+Rer1HmHEmDR3+DAzxBo8UaeAAAWbElEQVTW0rqA3vTmEi+ggzUPyJRV+5iTkMLpcwXc0LgWD/doSJ/m4Xh46FhYyn6VJjhEpC3wBTDIGLOrNNvUIw5VIYyxhmz/4UXI3GsN3d7vJYi68mW4E6fOMnPdQT75eT9Hs/JoGBrAQ92jGdoxUi+kK1tViuAQkSjgR+A3xpifS7tNDQ5VofLPwoapsPw1yEmF5oOh7wtQu9UV33auoJDvEo/y4ap9bDp4giA/L+7rEsUD3aKpW7NaBRWv1EVuERwiMhPoDYQCqcBLgDeAMeY9EfkAuBs4f94pvzS/lAaHssXZXFj7Hqx6E85kQeu7oPefIbTpFd9mjGH9geNMWbWf7xKPICIMblOH0d2j6aAj8qoK5BbB4SwaHMpWpzJh9f9gzXuQf9rqwtvrWajV+KpvTTl+ik9+3s+sdQfJPpNPbFRNRvdoyICYCLx1UinlZBocGhzKbrkZ1nzn6yZDwVlr5sFezxY7gdTlcs7k83n8QT76aT8HMk8RHujL8M5RjOgcRUQN7c6rnEODQ4NDuYrsVFj1X2scLFMAbYdD9ydLHESxqIJCw/JdaUxbncyyXel4iHBTy3BGdGlAzyah2htLlSsNDg0O5WqyDltHIAmfQH4etLzVuomwXsdSvf3AsVPMWJvM5wkpZOaepV7NagzvVJ+7O0bqxXRVLjQ4NDiUq8rNgLXvw7r3rflAGvaCHn+ARr2veB/IeWfyC/hhWyoz1x3gp93HrBvZG9XirthIBraOoLrOD6KukQaHBodydWeyIeFjWP0OZB+BOu2tI5CWt4FH6UbWPZh5ii82HGLe+hT2HztFNW9PBraO4K7YetzQOBRPPZWlykCDQ4NDuYv8M7BplnUaK3MP1GpiXQNpey94lW56WqtL7wnmrU/h602HycrLp3aQL0M61OOuDpE0jyh5TC2lztPg0OBQ7qawALZ/BSvHWzMRBta1BlPs+GCJk0kVJ+9cAUt3pDF3/SGW7Uwjv9DQul4Qd3WI5Pb2dQmtrnOlq+JpcGhwKHdlDOz50eqJtX8l+NW0wqPzIyUO516SYzln+HrTYeZtOMTmlJN4egg3Ngvjrth63NSytk42pS6hwaHBoSqDg7/Az2/Cjm8BgVa3Q9fHILJTqS6kF5WUms28DYf4Yv0hjmblEejnxS1t6jCwdQQ3NA7Fx0tvMKzqNDg0OFRlcjwZfpkMCVPhzEmoGwtdH4VWQ8DLp0ybKig0rNl7jLnrU1iUeJTcswUE+nnRt0U4A2IiuLFZGAHaM6tK0uDQ4FCV0Zkc2DTT6s57LAmqR0DsKOgwqlR3pF8u71wBP+3OYNHWoyzenkZm7ll8vTzo2TSMATG1uallbYIDyhZMyn1pcGhwqMqssBD2LLECZPdia1njPhD7gDU6bxmPQgDyCwqJTz7OwsSjfL/1KIdP5uHpIXSODmFg6wj6x9SmTg290bAy0+DQ4FBVxYmDsGE6bJgGWYesmQnb3WeFSGiTa9qkMYbEQ1ks3HqERVtT2Z2WA0C7yBr0j4lgYOsIGoeVvqeXcg8aHBocqqopLIDdS2D9J7DzO2tcrAY9oOMD0PJ28L72wRF3p+WwaKt1JLIp5SQATcKrMyCmNgNiImhTrwZSxov1yvVocGhwqKos+yhsnAHrp8Lx/VaX3nbDraOQq0wwdTWHT5zmh22pLEw8yrr9mRQUGurVrMbNrawQ6RQdjJcOAe+WNDg0OJSyroXsX2ENrLj9ayg8Z3XljX3AmmjKJ+C6Nn889yyLt6eyaOtRViRlcDa/kEA/L3o1DePG5mH0bhZGeJAOA+8uNDg0OJS6VO4xq0fW+k8gYxf4BEKbodDhfmuE3us81ZR7Jp8Vu9JZujONZTvTScs+A0BM3SBubBZGj6ahdGwQjK+X3nToqjQ4NDiUKp4xcGCNFSBbv7CGeA+Ohjb3WI+w5uXwEYZtR7JYtjOd5TvTSThwnIJCg5+3B52iQ+jZNJTuTUJpGRGkc4q4ELcIDhGZAtwKpBljWhezXoA3gcHAKeBBY8z6q21Xg0OpUso7Cdu/gS2zYd8KMIUQ0dYKkNZ3Q4165fIx2XnnWLs3k1W7M/hpdwZJjl5aIQE+3NC41oUgiQz2L5fPU9fGXYKjF5ADTC0hOAYDv8cKji7Am8aYLlfbrgaHUtcg+6h1BLLlcziUAAg06G6dzmp1B/iHlNtHpWblsSrJCpFVuzMunNaKruVPj6ah9GgSSrdGodTw9y63z1RX5xbBASAi0cA3JQTH+8AyY8xMx+udQG9jzJErbVODQ6nrdGwPJM6FzbOtO9Q9vKHJTVaINB903RfVizLGsDsth1W7M1iVlMGavcfIPVuAh0CbejXo3iSUHk1DiY0K1kEZnayyBMc3wKvGmFWO10uA54wxv0oFERkLjAWIiorqmJyc7LSalaoyjLGGeN/yOWyZC9mHwdsfmt5sjZPVbEC5hgjAuYJCNh08cSFINhw8QUGhwcfLg/aRNencMITODUOIbRCssx2Ws8oSHN8C/++y4PiTMSbhStvUIw6lnKCwEA78bJ3O2vYV5KaBVzUrRGKGQNMBZZo3pLTOXx9Zu+8Y6/Zlkng4i4JCg6eH0LpuEJ0bhhAXHUJsVDBhgTrXyPWoLMGhp6qUckWFBXBgNWz90pp8KicVvPygcV9ocQs0GwgBoU756Jwz+axPPs66fZms25fJxpQTnM0vBKBBLX86RgUT2yCYjg2CaVY7UKfPLYPKEhy3AL/j4sXxt4wxna+2TQ0OpSpQYQEcXAvb5lvzhpw8COIB9btaIdJiMIQ0ctrHn8kvIPFQFuuTj5OQfJz45ONk5FgX26v7etEhqiYdHUHSvn5NAv30gntJ3CI4RGQm0BsIBVKBlwBvAGPMe47uuP8DBmJ1x32ouOsbl9PgUMom56+J7FhghUjqFmt5eCsrRJoPhrodrvtmwyuXYDiYeZqEA5kkJB8nIfkEO49mUWisj21eO5CODYKJjQqmfVRNGtYK0HtJHNwiOJxFg0MpF3F8/8UQOfCzdZ9IYF1o0hca94NGvcu1m29JsvPOsengSeKTrTDZeOAE2WfyAQj086JtZA3aRdakbWRN2tevSUSNqjlMigaHBodSriX3GCQtskbu3bvcmskQgXqxVog07muNo+Xp/J5SBYWGPek5bDhwnE0pJ9mccoIdR7LJL7S+68IDfR0hUoOYejWIqRtEeGDlDxMNDg0OpVxXQT4cXm8NA7/nRzgUbx2N+AZBw15WiDTpZw2FUkHyzhWw7UgWmw6eYHPKSTYdPMHejNwL68MDfYmpG0RM3RoXftYPqVaphpPX4NDgUMp9nD5uHYXs+dF6nDxoLQ9pbAVI474Q3dMp3X2v5OTpc2w7nMXWwycdP7PYnZ5DgePIJNDPi1Z1LoZJ63o1aBwW4LbDymtwaHAo5Z6MgYwkR4gsgf2r4Nwp6+71qK7WFLmN+1ljanlU/Bd03rkCdh7NZqsjULYezmLH0Szyzlldgn29PGgREUirC0cmQTSPCMTfx/VvVtTg0OBQqnLIP2ON5rvHcVrrqKOnln/oxRBp3BcCa9tXYkEhezNyrSA5lHUhVLLy8i+0iQyuRrPagTQNr05Tx88m4dUJcKG73zU4NDiUqpyyU2Hv0ountXLTreW1W1+8NlK/63VNlVsejDGkHD/N1sNZ7ErNJikth6TUbPam53K2oPBCu3o1q9GsdnWa1Q6kSfjFn3YEigaHBodSlV9hoXWvyJ4frQvtB9ZYsxx6VYMG3SC6h3VtpG4H8HSNG//yCwpJzjxFUqoVJElpOewqIVCaFhMozhyfS4NDg0OpqudMDiT/ZIXI/pWQts1a7u0P9btAdHdrqPi6sbYfkVwuv6CQA5mn2JWaw+60bHal5pCUlsOe9JwLQ6qAFShWkFw85dW0dmC5BIoGhwaHUio3wwqS/ausx/kg8fS1pstt0A2iukH9zuBXw95aS5BfUMjB46fZlZrNbsfRSVJqDrsvC5S6NfxoWjuQu2LrcUf7a5uAS4NDg0MpdblTmdbprOSfrEEaj2yCwnxArGskUV2tI5P6naBmA6cOjXK9CgoNBzNPXXL9ZFdqDnfF1mNMz2sbG0yDQ4NDKXU1Z3MhJd4KkeSfrZkPz1rT2lK9tnUkEtnZCpM67Vzu9FZ5K8/gcJ2+YkopVZ58AqDRjdYDrDva07ZByjo46Hhs/9pa5+ljhUf9LtbQKPU7Q2Adlz4qsZMecSilqq6cNEj5xRo6/uA6OLwB8vOsdQHhULe9FSh12kGd9lAj0m3DRI84lFKqPFQPd8wrcov1Ov+sdRPioXjrGsnhjVYvLlNgrfevdWmQ1GlnjbnlpmFyrTQ4lFLqPC8fiOxoPc47dxpSt8KRjRfD5Of/WfeUgNVj65IwaW9NbmXDkCkVRYNDKaWuxLsaRMZZj/Pyz1jXS84HyZFNsHYSFFizE+ITCHXaXnpkEtoUPDzt+R3KmQaHUkqVlZevdcd63Q5w/uCk4Byk77g0TOI/gvzT1npvf4hoc2mYhLWokDlKypuz5xwfCLwJeAIfGGNevWx9FPAJUNPR5nljzIIrbVMvjiul3EZBPhxLujRMjm6+2C3Yyw9qx1waJuGtrFNm5cwt7uMQEU9gF3AzkAL8AtxnjNlWpM0kYIMx5l0RaQUsMMZEX2m7GhxKKbdWWAiZexxhssH6eWSzY9ZErCHma7eyQiSiLYS3tMLkOqfhdZdeVZ2B3caYvQAiMgu4A9hWpI0BghzPawCHnViPUkrZz8PDut4R2hTaDLWWGQPH9116ZLL9a1g/9eL7qkfADb+DG35vT91FODM46gEHi7xOAbpc1uZl4HsR+T0QANzkxHqUUso1iVg9sUIaQcyd1jJjIPsIpG6zLsSnbbNuSnQBzgyO4jo2X35e7D7gY2PMf0SkGzBNRFobYwqLNhKRscBYgKioKKcUq5RSLkUEgupaj6au9Te1MzsapwD1i7yO5Nenoh4GZgMYY1YDfkDo5RsyxkwyxsQZY+LCwsKcVK5SSqnScGZw/AI0FZGGIuIDDAe+uqzNAaAfgIi0xAqOdCfWpJRS6jo5LTiMMfnA74BFwHZgtjFmq4j8n4jc7mj2R+AREdkEzAQeNO42eJZSSlUxTr3zxHFPxoLLlr1Y5Pk2oLsza1BKKVW+Ku9gKkoppZxCg0MppVSZaHAopZQqEw0OpZRSZeJ2MwCKSDqQfI1vDwUyyrGciqJ1Vxx3rBm07orkjjUDNDfGBJbHhtxuPF9jzDXfASgi8eU1yFdF0rorjjvWDFp3RXLHmsGqu7y2paeqlFJKlYkGh1JKqTKpasExye4CrpHWXXHcsWbQuiuSO9YM5Vi3210cV0opZa+qdsShlFLqOlWZ4BCRgSKyU0R2i8jzdtdznojUF5GlIrJdRLaKyJOO5SEi8oOIJDl+BjuWi4i85fg9NotIrM31e4rIBhH5xvG6oYisddT9mWNkZETE1/F6t2N9tI011xSROSKyw7Hfu7n6/haRpx3/fySKyEwR8XPFfS0iU0QkTUQSiywr874VkQcc7ZNE5AGb6n7d8f/IZhH5QkRqFln3Z0fdO0VkQJHlFfo9U1zdRdY9IyJGREIdr8tvfxtjKv0D8AT2AI0AH2AT0Mruuhy11QFiHc8DseZpbwW8BjzvWP488G/H88HAd1gTZXUF1tpc/x+AT4FvHK9nA8Mdz98DHnU8fwx4z/F8OPCZjTV/AoxxPPcBarry/saaTXMfUK3IPn7QFfc10AuIBRKLLCvTvgVCgL2On8GO58E21N0f8HI8/3eRuls5vkN8gYaO7xZPO75niqvbsbw+1sjkyUBoee/vCv0HYNcD6AYsKvL6z8Cf7a6rhFrnAzcDO4E6jmV1gJ2O5+8D9xVpf6GdDbVGAkuAvsA3jv8hM4r8Y7uw3x3/E3dzPPdytBMbag5yfAnLZctddn9zcRrmEMe++wYY4Kr7Goi+7Au4TPsWa2bQ94ssv6RdRdV92bo7gRmO55d8f5zf33Z9zxRXNzAHaAfs52JwlNv+riqnqoqb/7yeTbWUyHFKoQOwFqhtjDkC4PgZ7mjmSr/LBOBPwPmpfmsBJ4w1FwtcWtuFuh3rTzraV7RGWJOFfeQ4xfaBiATgwvvbGHMIeANr4rMjWPsuAdff1+eVdd/avs+LMRrrr3Vw8brFmu/okDFm02Wryq3uqhIcpZn/3FYiUh2YCzxljMm6UtNillX47yIitwJpxpiEoouLaWpKsa4ieWEd2r9rjOkA5GKdPimJ7XU7rgncgXVapC4QAAy6Ql2211xKJdXpUvWLyF+BfGDG+UXFNHOJukXEH/gr8GJxq4tZdk11V5XgKM3857YREW+s0JhhjJnnWJwqInUc6+sAaY7lrvK7dAduF5H9wCys01UTgJoicn4om6K1Xajbsb4GkFmRBRepI8UYs9bxeg5WkLjy/r4J2GeMSTfGnAPmATfg+vv6vLLuW1fY54B10Ri4FRhpHOdxcO26G2P9gbHJ8W8zElgvIhFXqK/MdVeV4CjN/Oe2EBEBPgS2G2PGF1n1FXC+d8MDWNc+zi//jaOHRFfg5PnTABXJGPNnY0ykMSYaa3/+aIwZCSwFhpZQ9/nfZ6ijfYX/FWmMOQocFJHmjkX9gG249v4+AHQVEX/H/y/na3bpfV1EWfftIqC/iAQ7jrb6O5ZVKBEZCDwH3G6MOVVk1VfAcEfvtYZAU2AdLvA9Y4zZYowJN8ZEO/5tpmB1vjlKee5vZ1+4cZUHVo+CXVi9Hv5qdz1F6uqBdVi4GdjoeAzGOie9BEhy/AxxtBfgHcfvsQWIc4HfoTcXe1U1wvpHtBv4HPB1LPdzvN7tWN/IxnrbA/GOff4lVk8Sl97fwCvADiARmIbVo8fl9jUwE+s6zDnHl9bD17Jvsa4p7HY8HrKp7t1Y5/7P/7t8r0j7vzrq3gkMKrK8Qr9niqv7svX7uXhxvNz2t945rpRSqkyqyqkqpZRS5USDQymlVJlocCillCoTDQ6llFJlosGhlFKqTDQ4lHIQkQIR2VjkUW6jm4pIdHEjmCrljryu3kSpKuO0Maa93UUo5er0iEOpqxCR/SLybxFZ53g0cSxvICJLHHMbLBGRKMfy2o75GzY5Hjc4NuUpIpPFmlfjexGp5mj/hIhsc2xnlk2/plKlpsGh1EXVLjtVdW+RdVnGmM7A/7DG5MLxfKoxpi3WAHhvOZa/BSw3xrTDGgdrq2N5U+AdY0wMcAK427H8eaCDYzvjnPXLKVVe9M5xpRxEJMcYU72Y5fuBvsaYvY4BKY8aY2qJSAbWPBPnHMuPGGNCRSQdiDTGnCmyjWjgB2NMU8fr5wBvY8w/RGQhkIM1/MmXxpgcJ/+qSl0XPeJQqnRMCc9LalOcM0WeF3DxGuMtWGMIdQQSiox4q5RL0uBQqnTuLfJzteP5z1gjoAKMBFY5ni8BHoULc7IHlbRREfEA6htjlmJNilUT+NVRj1KuRP+yUeqiaiKyscjrhcaY811yfUVkLdYfW/c5lj0BTBGRZ7FmFXzIsfxJYJKIPIx1ZPEo1gimxfEEpotIDazRS/9rjDlRbr+RUk6g1ziUugrHNY44Y0yG3bUo5Qr0VJVSSqky0SMOpZRSZaJHHEoppcpEg0MppVSZaHAopZQqEw0OpZRSZaLBoZRSqkw0OJRSSpXJ/weKY6nuG7qB/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  DATASET MRD  ----------\n",
      "(9600, 28, 28, 1) train samples\n",
      "(2400, 28, 28, 1) validation samples\n",
      "(50000, 28, 28, 1) test samples\n",
      "\n",
      "\tTraining model:\n",
      "logreg\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 2.2999 - acc: 0.1506 - val_loss: 2.2966 - val_acc: 0.2154\n",
      "Epoch 2/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2939 - acc: 0.2077 - val_loss: 2.2911 - val_acc: 0.2071\n",
      "Epoch 3/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2883 - acc: 0.1929 - val_loss: 2.2856 - val_acc: 0.2162\n",
      "Epoch 4/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2829 - acc: 0.2239 - val_loss: 2.2802 - val_acc: 0.2396\n",
      "Epoch 5/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2776 - acc: 0.2379 - val_loss: 2.2750 - val_acc: 0.2483\n",
      "Epoch 6/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 2.2723 - acc: 0.2360 - val_loss: 2.2697 - val_acc: 0.2537\n",
      "Epoch 7/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2671 - acc: 0.2661 - val_loss: 2.2647 - val_acc: 0.2650\n",
      "Epoch 8/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2620 - acc: 0.2772 - val_loss: 2.2597 - val_acc: 0.2708\n",
      "Epoch 9/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2569 - acc: 0.2799 - val_loss: 2.2545 - val_acc: 0.2875\n",
      "Epoch 10/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2519 - acc: 0.3046 - val_loss: 2.2496 - val_acc: 0.2900\n",
      "Epoch 11/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2468 - acc: 0.3089 - val_loss: 2.2446 - val_acc: 0.3067\n",
      "Epoch 12/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2419 - acc: 0.3129 - val_loss: 2.2397 - val_acc: 0.3113\n",
      "Epoch 13/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2370 - acc: 0.3218 - val_loss: 2.2348 - val_acc: 0.3246\n",
      "Epoch 14/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2320 - acc: 0.3292 - val_loss: 2.2301 - val_acc: 0.3283\n",
      "Epoch 15/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2272 - acc: 0.3273 - val_loss: 2.2252 - val_acc: 0.3325\n",
      "Epoch 16/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 2.2224 - acc: 0.3300 - val_loss: 2.2204 - val_acc: 0.3400\n",
      "Epoch 17/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 2.2176 - acc: 0.3390 - val_loss: 2.2157 - val_acc: 0.3396\n",
      "Epoch 18/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2129 - acc: 0.3408 - val_loss: 2.2110 - val_acc: 0.3400\n",
      "Epoch 19/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2082 - acc: 0.3457 - val_loss: 2.2064 - val_acc: 0.3475\n",
      "Epoch 20/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2035 - acc: 0.3428 - val_loss: 2.2018 - val_acc: 0.3421\n",
      "Epoch 21/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1989 - acc: 0.3493 - val_loss: 2.1972 - val_acc: 0.3475\n",
      "Epoch 22/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1942 - acc: 0.3497 - val_loss: 2.1926 - val_acc: 0.3508\n",
      "Epoch 23/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1896 - acc: 0.3520 - val_loss: 2.1882 - val_acc: 0.3542\n",
      "Epoch 24/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1851 - acc: 0.3550 - val_loss: 2.1836 - val_acc: 0.3529\n",
      "Epoch 25/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1806 - acc: 0.3608 - val_loss: 2.1792 - val_acc: 0.3596\n",
      "Epoch 26/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1761 - acc: 0.3577 - val_loss: 2.1748 - val_acc: 0.3583\n",
      "Epoch 27/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1716 - acc: 0.3605 - val_loss: 2.1703 - val_acc: 0.3608\n",
      "Epoch 28/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1673 - acc: 0.3691 - val_loss: 2.1660 - val_acc: 0.3638\n",
      "Epoch 29/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1629 - acc: 0.3667 - val_loss: 2.1617 - val_acc: 0.3675\n",
      "Epoch 30/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1585 - acc: 0.3658 - val_loss: 2.1573 - val_acc: 0.3675\n",
      "Epoch 31/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1542 - acc: 0.3677 - val_loss: 2.1531 - val_acc: 0.3754\n",
      "Epoch 32/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1499 - acc: 0.3732 - val_loss: 2.1488 - val_acc: 0.3792\n",
      "Epoch 33/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1456 - acc: 0.3774 - val_loss: 2.1447 - val_acc: 0.3800\n",
      "Epoch 34/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1414 - acc: 0.3786 - val_loss: 2.1405 - val_acc: 0.3792\n",
      "Epoch 35/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1372 - acc: 0.3792 - val_loss: 2.1364 - val_acc: 0.3817\n",
      "Epoch 36/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1330 - acc: 0.3784 - val_loss: 2.1323 - val_acc: 0.3821\n",
      "Epoch 37/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1289 - acc: 0.3842 - val_loss: 2.1281 - val_acc: 0.3829\n",
      "Epoch 38/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1248 - acc: 0.3824 - val_loss: 2.1241 - val_acc: 0.3833\n",
      "Epoch 39/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1207 - acc: 0.3850 - val_loss: 2.1201 - val_acc: 0.3883\n",
      "Epoch 40/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1167 - acc: 0.3892 - val_loss: 2.1161 - val_acc: 0.3875\n",
      "Epoch 41/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1127 - acc: 0.3936 - val_loss: 2.1121 - val_acc: 0.3912\n",
      "Epoch 42/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1086 - acc: 0.3898 - val_loss: 2.1082 - val_acc: 0.3883\n",
      "Epoch 43/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 2.1046 - acc: 0.3912 - val_loss: 2.1043 - val_acc: 0.3912\n",
      "Epoch 44/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1007 - acc: 0.3959 - val_loss: 2.1003 - val_acc: 0.3967\n",
      "Epoch 45/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0968 - acc: 0.3959 - val_loss: 2.0966 - val_acc: 0.3958\n",
      "Epoch 46/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0929 - acc: 0.3992 - val_loss: 2.0927 - val_acc: 0.3971\n",
      "Epoch 47/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0891 - acc: 0.3995 - val_loss: 2.0889 - val_acc: 0.4000\n",
      "Epoch 48/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.0852 - acc: 0.4032 - val_loss: 2.0851 - val_acc: 0.4004\n",
      "Epoch 49/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0814 - acc: 0.4029 - val_loss: 2.0814 - val_acc: 0.3983\n",
      "Epoch 50/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 2.0776 - acc: 0.4057 - val_loss: 2.0776 - val_acc: 0.4050\n",
      "Epoch 51/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 2.0739 - acc: 0.4031 - val_loss: 2.0740 - val_acc: 0.4012\n",
      "Epoch 52/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.0701 - acc: 0.4084 - val_loss: 2.0703 - val_acc: 0.4058\n",
      "Epoch 53/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0665 - acc: 0.4083 - val_loss: 2.0666 - val_acc: 0.4062\n",
      "Epoch 54/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0628 - acc: 0.4131 - val_loss: 2.0630 - val_acc: 0.4087\n",
      "Epoch 55/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0591 - acc: 0.4095 - val_loss: 2.0595 - val_acc: 0.4067\n",
      "Epoch 56/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 2.0555 - acc: 0.4118 - val_loss: 2.0558 - val_acc: 0.4100\n",
      "Epoch 57/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0519 - acc: 0.4127 - val_loss: 2.0523 - val_acc: 0.4096\n",
      "Epoch 58/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0483 - acc: 0.4157 - val_loss: 2.0489 - val_acc: 0.4104\n",
      "Epoch 59/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0448 - acc: 0.4164 - val_loss: 2.0453 - val_acc: 0.4104\n",
      "Epoch 60/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0413 - acc: 0.4176 - val_loss: 2.0419 - val_acc: 0.4117\n",
      "Epoch 61/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0378 - acc: 0.4181 - val_loss: 2.0384 - val_acc: 0.4158\n",
      "Epoch 62/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0343 - acc: 0.4194 - val_loss: 2.0350 - val_acc: 0.4146\n",
      "Epoch 63/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0308 - acc: 0.4202 - val_loss: 2.0315 - val_acc: 0.4167\n",
      "Epoch 64/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0274 - acc: 0.4189 - val_loss: 2.0283 - val_acc: 0.4163\n",
      "Epoch 65/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0240 - acc: 0.4221 - val_loss: 2.0249 - val_acc: 0.4163\n",
      "Epoch 66/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0206 - acc: 0.4240 - val_loss: 2.0215 - val_acc: 0.4196\n",
      "Epoch 67/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0172 - acc: 0.4235 - val_loss: 2.0183 - val_acc: 0.4208\n",
      "Epoch 68/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0139 - acc: 0.4224 - val_loss: 2.0149 - val_acc: 0.4204\n",
      "Epoch 69/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0106 - acc: 0.4231 - val_loss: 2.0116 - val_acc: 0.4217\n",
      "Epoch 70/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0073 - acc: 0.4254 - val_loss: 2.0084 - val_acc: 0.4233\n",
      "Epoch 71/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0040 - acc: 0.4270 - val_loss: 2.0052 - val_acc: 0.4246\n",
      "Epoch 72/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0008 - acc: 0.4284 - val_loss: 2.0021 - val_acc: 0.4233\n",
      "Epoch 73/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9975 - acc: 0.4288 - val_loss: 1.9989 - val_acc: 0.4233\n",
      "Epoch 74/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9943 - acc: 0.4293 - val_loss: 1.9958 - val_acc: 0.4229\n",
      "Epoch 75/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9911 - acc: 0.4310 - val_loss: 1.9926 - val_acc: 0.4250\n",
      "Epoch 76/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9879 - acc: 0.4307 - val_loss: 1.9895 - val_acc: 0.4221\n",
      "Epoch 77/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9848 - acc: 0.4302 - val_loss: 1.9864 - val_acc: 0.4246\n",
      "Epoch 78/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9817 - acc: 0.4333 - val_loss: 1.9833 - val_acc: 0.4242\n",
      "Epoch 79/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9786 - acc: 0.4325 - val_loss: 1.9803 - val_acc: 0.4233\n",
      "Epoch 80/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9755 - acc: 0.4351 - val_loss: 1.9773 - val_acc: 0.4275\n",
      "Epoch 81/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9724 - acc: 0.4340 - val_loss: 1.9742 - val_acc: 0.4267\n",
      "Epoch 82/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9694 - acc: 0.4351 - val_loss: 1.9713 - val_acc: 0.4304\n",
      "Epoch 83/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9663 - acc: 0.4367 - val_loss: 1.9683 - val_acc: 0.4283\n",
      "Epoch 84/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9633 - acc: 0.4372 - val_loss: 1.9653 - val_acc: 0.4308\n",
      "Epoch 85/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9603 - acc: 0.4384 - val_loss: 1.9624 - val_acc: 0.4354\n",
      "Epoch 86/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.9573 - acc: 0.4387 - val_loss: 1.9595 - val_acc: 0.4329\n",
      "Epoch 87/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.9544 - acc: 0.4380 - val_loss: 1.9566 - val_acc: 0.4329\n",
      "Epoch 88/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.9514 - acc: 0.4386 - val_loss: 1.9536 - val_acc: 0.4321\n",
      "Epoch 89/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9485 - acc: 0.4409 - val_loss: 1.9508 - val_acc: 0.4342\n",
      "Epoch 90/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9456 - acc: 0.4426 - val_loss: 1.9479 - val_acc: 0.4363\n",
      "Epoch 91/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9427 - acc: 0.4408 - val_loss: 1.9451 - val_acc: 0.4338\n",
      "Epoch 92/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9399 - acc: 0.4428 - val_loss: 1.9423 - val_acc: 0.4333\n",
      "Epoch 93/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9370 - acc: 0.4404 - val_loss: 1.9395 - val_acc: 0.4354\n",
      "Epoch 94/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9342 - acc: 0.4428 - val_loss: 1.9367 - val_acc: 0.4358\n",
      "Epoch 95/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9314 - acc: 0.4442 - val_loss: 1.9340 - val_acc: 0.4375\n",
      "Epoch 96/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9286 - acc: 0.4458 - val_loss: 1.9312 - val_acc: 0.4367\n",
      "Epoch 97/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9258 - acc: 0.4465 - val_loss: 1.9285 - val_acc: 0.4400\n",
      "Epoch 98/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9230 - acc: 0.4468 - val_loss: 1.9258 - val_acc: 0.4396\n",
      "Epoch 99/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9203 - acc: 0.4470 - val_loss: 1.9230 - val_acc: 0.4383\n",
      "Epoch 100/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9176 - acc: 0.4481 - val_loss: 1.9204 - val_acc: 0.4408\n",
      "Epoch 101/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9149 - acc: 0.4494 - val_loss: 1.9178 - val_acc: 0.4417\n",
      "Epoch 102/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9122 - acc: 0.4497 - val_loss: 1.9152 - val_acc: 0.4387\n",
      "Epoch 103/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.9095 - acc: 0.4500 - val_loss: 1.9126 - val_acc: 0.4400\n",
      "Epoch 104/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9068 - acc: 0.4506 - val_loss: 1.9099 - val_acc: 0.4404\n",
      "Epoch 105/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.9042 - acc: 0.4502 - val_loss: 1.9074 - val_acc: 0.4396\n",
      "Epoch 106/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.9016 - acc: 0.4510 - val_loss: 1.9048 - val_acc: 0.4400\n",
      "Epoch 107/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8989 - acc: 0.4524 - val_loss: 1.9022 - val_acc: 0.4425\n",
      "Epoch 108/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8963 - acc: 0.4522 - val_loss: 1.8997 - val_acc: 0.4429\n",
      "Epoch 109/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8938 - acc: 0.4534 - val_loss: 1.8971 - val_acc: 0.4437\n",
      "Epoch 110/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8912 - acc: 0.4535 - val_loss: 1.8946 - val_acc: 0.4425\n",
      "Epoch 111/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8887 - acc: 0.4544 - val_loss: 1.8923 - val_acc: 0.4437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8861 - acc: 0.4540 - val_loss: 1.8897 - val_acc: 0.4442\n",
      "Epoch 113/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8836 - acc: 0.4550 - val_loss: 1.8873 - val_acc: 0.4442\n",
      "Epoch 114/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.8812 - acc: 0.4553 - val_loss: 1.8848 - val_acc: 0.4450\n",
      "Epoch 115/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.8786 - acc: 0.4561 - val_loss: 1.8824 - val_acc: 0.4462\n",
      "Epoch 116/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.8762 - acc: 0.4564 - val_loss: 1.8800 - val_acc: 0.4467\n",
      "Epoch 117/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.8737 - acc: 0.4562 - val_loss: 1.8777 - val_acc: 0.4471\n",
      "Epoch 118/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8713 - acc: 0.4561 - val_loss: 1.8752 - val_acc: 0.4471\n",
      "Epoch 119/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8689 - acc: 0.4565 - val_loss: 1.8729 - val_acc: 0.4479\n",
      "Epoch 120/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8665 - acc: 0.4573 - val_loss: 1.8705 - val_acc: 0.4471\n",
      "Epoch 121/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8641 - acc: 0.4576 - val_loss: 1.8681 - val_acc: 0.4492\n",
      "Epoch 122/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8617 - acc: 0.4584 - val_loss: 1.8658 - val_acc: 0.4483\n",
      "Epoch 123/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8593 - acc: 0.4571 - val_loss: 1.8635 - val_acc: 0.4492\n",
      "Epoch 124/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8570 - acc: 0.4607 - val_loss: 1.8612 - val_acc: 0.4492\n",
      "Epoch 125/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8546 - acc: 0.4597 - val_loss: 1.8589 - val_acc: 0.4500\n",
      "Epoch 126/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8523 - acc: 0.4625 - val_loss: 1.8566 - val_acc: 0.4492\n",
      "Epoch 127/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8500 - acc: 0.4622 - val_loss: 1.8544 - val_acc: 0.4492\n",
      "Epoch 128/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.8477 - acc: 0.4618 - val_loss: 1.8521 - val_acc: 0.4512\n",
      "Epoch 129/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8454 - acc: 0.4616 - val_loss: 1.8499 - val_acc: 0.4487\n",
      "Epoch 130/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8432 - acc: 0.4619 - val_loss: 1.8477 - val_acc: 0.4517\n",
      "Epoch 131/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8409 - acc: 0.4623 - val_loss: 1.8456 - val_acc: 0.4521\n",
      "Epoch 132/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8387 - acc: 0.4625 - val_loss: 1.8434 - val_acc: 0.4529\n",
      "Epoch 133/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8364 - acc: 0.4633 - val_loss: 1.8412 - val_acc: 0.4537\n",
      "Epoch 134/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8342 - acc: 0.4644 - val_loss: 1.8390 - val_acc: 0.4529\n",
      "Epoch 135/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8320 - acc: 0.4631 - val_loss: 1.8369 - val_acc: 0.4558\n",
      "Epoch 136/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.8299 - acc: 0.4630 - val_loss: 1.8348 - val_acc: 0.4550\n",
      "Epoch 137/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.8277 - acc: 0.4646 - val_loss: 1.8327 - val_acc: 0.4554\n",
      "Epoch 138/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.8255 - acc: 0.4651 - val_loss: 1.8305 - val_acc: 0.4567\n",
      "Epoch 139/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8234 - acc: 0.4647 - val_loss: 1.8285 - val_acc: 0.4550\n",
      "Epoch 140/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.8212 - acc: 0.4656 - val_loss: 1.8264 - val_acc: 0.4571\n",
      "Epoch 141/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8191 - acc: 0.4671 - val_loss: 1.8242 - val_acc: 0.4583\n",
      "Epoch 142/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8171 - acc: 0.4656 - val_loss: 1.8223 - val_acc: 0.4579\n",
      "Epoch 143/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8149 - acc: 0.4669 - val_loss: 1.8202 - val_acc: 0.4592\n",
      "Epoch 144/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8129 - acc: 0.4663 - val_loss: 1.8182 - val_acc: 0.4600\n",
      "Epoch 145/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8108 - acc: 0.4654 - val_loss: 1.8163 - val_acc: 0.4575\n",
      "Epoch 146/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8087 - acc: 0.4660 - val_loss: 1.8141 - val_acc: 0.4600\n",
      "Epoch 147/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8067 - acc: 0.4676 - val_loss: 1.8123 - val_acc: 0.4592\n",
      "Epoch 148/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.8047 - acc: 0.4697 - val_loss: 1.8103 - val_acc: 0.4604\n",
      "Epoch 149/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8026 - acc: 0.4690 - val_loss: 1.8083 - val_acc: 0.4600\n",
      "Epoch 150/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.8006 - acc: 0.4702 - val_loss: 1.8063 - val_acc: 0.4612\n",
      "Epoch 151/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7986 - acc: 0.4701 - val_loss: 1.8043 - val_acc: 0.4612\n",
      "Epoch 152/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7967 - acc: 0.4697 - val_loss: 1.8024 - val_acc: 0.4633\n",
      "Epoch 153/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7946 - acc: 0.4692 - val_loss: 1.8004 - val_acc: 0.4633\n",
      "Epoch 154/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7927 - acc: 0.4718 - val_loss: 1.7986 - val_acc: 0.4629\n",
      "Epoch 155/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7907 - acc: 0.4710 - val_loss: 1.7967 - val_acc: 0.4629\n",
      "Epoch 156/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7888 - acc: 0.4721 - val_loss: 1.7948 - val_acc: 0.4625\n",
      "Epoch 157/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.7869 - acc: 0.4732 - val_loss: 1.7929 - val_acc: 0.4642\n",
      "Epoch 158/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.7849 - acc: 0.4727 - val_loss: 1.7910 - val_acc: 0.4646\n",
      "Epoch 159/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7830 - acc: 0.4730 - val_loss: 1.7891 - val_acc: 0.4642\n",
      "Epoch 160/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7811 - acc: 0.4734 - val_loss: 1.7874 - val_acc: 0.4637\n",
      "Epoch 161/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7792 - acc: 0.4752 - val_loss: 1.7856 - val_acc: 0.4658\n",
      "Epoch 162/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7774 - acc: 0.4748 - val_loss: 1.7837 - val_acc: 0.4662\n",
      "Epoch 163/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7755 - acc: 0.4764 - val_loss: 1.7819 - val_acc: 0.4654\n",
      "Epoch 164/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7736 - acc: 0.4746 - val_loss: 1.7801 - val_acc: 0.4654\n",
      "Epoch 165/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7718 - acc: 0.4755 - val_loss: 1.7782 - val_acc: 0.4675\n",
      "Epoch 166/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7699 - acc: 0.4752 - val_loss: 1.7765 - val_acc: 0.4679\n",
      "Epoch 167/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7681 - acc: 0.4771 - val_loss: 1.7747 - val_acc: 0.4688\n",
      "Epoch 168/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7663 - acc: 0.4785 - val_loss: 1.7729 - val_acc: 0.4683\n",
      "Epoch 169/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7645 - acc: 0.4776 - val_loss: 1.7712 - val_acc: 0.4688\n",
      "Epoch 170/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7627 - acc: 0.4789 - val_loss: 1.7694 - val_acc: 0.4683\n",
      "Epoch 171/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7609 - acc: 0.4786 - val_loss: 1.7677 - val_acc: 0.4688\n",
      "Epoch 172/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7592 - acc: 0.4794 - val_loss: 1.7660 - val_acc: 0.4688\n",
      "Epoch 173/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7574 - acc: 0.4790 - val_loss: 1.7642 - val_acc: 0.4700\n",
      "Epoch 174/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7556 - acc: 0.4786 - val_loss: 1.7626 - val_acc: 0.4692\n",
      "Epoch 175/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7539 - acc: 0.4801 - val_loss: 1.7609 - val_acc: 0.4708\n",
      "Epoch 176/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7521 - acc: 0.4807 - val_loss: 1.7592 - val_acc: 0.4696\n",
      "Epoch 177/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7504 - acc: 0.4811 - val_loss: 1.7575 - val_acc: 0.4704\n",
      "Epoch 178/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7487 - acc: 0.4803 - val_loss: 1.7558 - val_acc: 0.4708\n",
      "Epoch 179/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.7470 - acc: 0.4817 - val_loss: 1.7542 - val_acc: 0.4708\n",
      "Epoch 180/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7453 - acc: 0.4827 - val_loss: 1.7526 - val_acc: 0.4708\n",
      "Epoch 181/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7435 - acc: 0.4816 - val_loss: 1.7510 - val_acc: 0.4713\n",
      "Epoch 182/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.7419 - acc: 0.4823 - val_loss: 1.7492 - val_acc: 0.4704\n",
      "Epoch 183/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.7402 - acc: 0.4820 - val_loss: 1.7477 - val_acc: 0.4713\n",
      "Epoch 184/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.7386 - acc: 0.4811 - val_loss: 1.7461 - val_acc: 0.4721\n",
      "Epoch 185/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7369 - acc: 0.4840 - val_loss: 1.7444 - val_acc: 0.4721\n",
      "Epoch 186/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7353 - acc: 0.4831 - val_loss: 1.7429 - val_acc: 0.4725\n",
      "Epoch 187/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7336 - acc: 0.4835 - val_loss: 1.7413 - val_acc: 0.4717\n",
      "Epoch 188/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7320 - acc: 0.4847 - val_loss: 1.7397 - val_acc: 0.4721\n",
      "Epoch 189/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7304 - acc: 0.4853 - val_loss: 1.7382 - val_acc: 0.4725\n",
      "Epoch 190/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7289 - acc: 0.4851 - val_loss: 1.7365 - val_acc: 0.4717\n",
      "Epoch 191/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7272 - acc: 0.4851 - val_loss: 1.7351 - val_acc: 0.4733\n",
      "Epoch 192/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7256 - acc: 0.4857 - val_loss: 1.7335 - val_acc: 0.4729\n",
      "Epoch 193/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7240 - acc: 0.4852 - val_loss: 1.7320 - val_acc: 0.4729\n",
      "Epoch 194/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7225 - acc: 0.4862 - val_loss: 1.7304 - val_acc: 0.4725\n",
      "Epoch 195/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.7209 - acc: 0.4872 - val_loss: 1.7289 - val_acc: 0.4733\n",
      "Epoch 196/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.7193 - acc: 0.4864 - val_loss: 1.7274 - val_acc: 0.4729\n",
      "Epoch 197/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.7178 - acc: 0.4871 - val_loss: 1.7259 - val_acc: 0.4721\n",
      "Epoch 198/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7162 - acc: 0.4875 - val_loss: 1.7244 - val_acc: 0.4721\n",
      "Epoch 199/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7147 - acc: 0.4861 - val_loss: 1.7230 - val_acc: 0.4754\n",
      "Epoch 200/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7132 - acc: 0.4873 - val_loss: 1.7215 - val_acc: 0.4737\n",
      "Epoch 201/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7117 - acc: 0.4874 - val_loss: 1.7200 - val_acc: 0.4738\n",
      "Epoch 202/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7101 - acc: 0.4870 - val_loss: 1.7185 - val_acc: 0.4737\n",
      "Epoch 203/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7086 - acc: 0.4889 - val_loss: 1.7171 - val_acc: 0.4758\n",
      "Epoch 204/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7072 - acc: 0.4878 - val_loss: 1.7157 - val_acc: 0.4758\n",
      "Epoch 205/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7057 - acc: 0.4894 - val_loss: 1.7142 - val_acc: 0.4775\n",
      "Epoch 206/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7042 - acc: 0.4885 - val_loss: 1.7128 - val_acc: 0.4771\n",
      "Epoch 207/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.7027 - acc: 0.4880 - val_loss: 1.7113 - val_acc: 0.4771\n",
      "Epoch 208/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.7012 - acc: 0.4890 - val_loss: 1.7100 - val_acc: 0.4779\n",
      "Epoch 209/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6998 - acc: 0.4900 - val_loss: 1.7086 - val_acc: 0.4771\n",
      "Epoch 210/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6984 - acc: 0.4898 - val_loss: 1.7072 - val_acc: 0.4767\n",
      "Epoch 211/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6969 - acc: 0.4895 - val_loss: 1.7058 - val_acc: 0.4775\n",
      "Epoch 212/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6955 - acc: 0.4888 - val_loss: 1.7043 - val_acc: 0.4767\n",
      "Epoch 213/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6940 - acc: 0.4904 - val_loss: 1.7030 - val_acc: 0.4779\n",
      "Epoch 214/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6926 - acc: 0.4909 - val_loss: 1.7016 - val_acc: 0.4763\n",
      "Epoch 215/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6912 - acc: 0.4896 - val_loss: 1.7003 - val_acc: 0.4771\n",
      "Epoch 216/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6898 - acc: 0.4915 - val_loss: 1.6989 - val_acc: 0.4775\n",
      "Epoch 217/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6884 - acc: 0.4924 - val_loss: 1.6975 - val_acc: 0.4767\n",
      "Epoch 218/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6871 - acc: 0.4921 - val_loss: 1.6961 - val_acc: 0.4783\n",
      "Epoch 219/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6856 - acc: 0.4917 - val_loss: 1.6948 - val_acc: 0.4767\n",
      "Epoch 220/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6842 - acc: 0.4914 - val_loss: 1.6935 - val_acc: 0.4783\n",
      "Epoch 221/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6829 - acc: 0.4929 - val_loss: 1.6922 - val_acc: 0.4792\n",
      "Epoch 222/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6815 - acc: 0.4913 - val_loss: 1.6909 - val_acc: 0.4788\n",
      "Epoch 223/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6802 - acc: 0.4929 - val_loss: 1.6895 - val_acc: 0.4800\n",
      "Epoch 224/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6788 - acc: 0.4942 - val_loss: 1.6884 - val_acc: 0.4775\n",
      "Epoch 225/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.6775 - acc: 0.4936 - val_loss: 1.6871 - val_acc: 0.4792\n",
      "Epoch 226/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6761 - acc: 0.4927 - val_loss: 1.6856 - val_acc: 0.4813\n",
      "Epoch 227/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6748 - acc: 0.4940 - val_loss: 1.6845 - val_acc: 0.4783\n",
      "Epoch 228/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.6735 - acc: 0.4934 - val_loss: 1.6832 - val_acc: 0.4792\n",
      "Epoch 229/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.6722 - acc: 0.4947 - val_loss: 1.6819 - val_acc: 0.4788\n",
      "Epoch 230/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6709 - acc: 0.4939 - val_loss: 1.6807 - val_acc: 0.4804\n",
      "Epoch 231/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6696 - acc: 0.4948 - val_loss: 1.6793 - val_acc: 0.4808\n",
      "Epoch 232/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6683 - acc: 0.4941 - val_loss: 1.6782 - val_acc: 0.4804\n",
      "Epoch 233/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6670 - acc: 0.4966 - val_loss: 1.6770 - val_acc: 0.4792\n",
      "Epoch 234/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6657 - acc: 0.4955 - val_loss: 1.6757 - val_acc: 0.4821\n",
      "Epoch 235/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6644 - acc: 0.4945 - val_loss: 1.6746 - val_acc: 0.4796\n",
      "Epoch 236/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6632 - acc: 0.4960 - val_loss: 1.6732 - val_acc: 0.4821\n",
      "Epoch 237/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6619 - acc: 0.4966 - val_loss: 1.6721 - val_acc: 0.4804\n",
      "Epoch 238/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6606 - acc: 0.4968 - val_loss: 1.6708 - val_acc: 0.4821\n",
      "Epoch 239/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6594 - acc: 0.4961 - val_loss: 1.6696 - val_acc: 0.4829\n",
      "Epoch 240/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6582 - acc: 0.4969 - val_loss: 1.6683 - val_acc: 0.4833\n",
      "Epoch 241/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6569 - acc: 0.4970 - val_loss: 1.6672 - val_acc: 0.4813\n",
      "Epoch 242/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6557 - acc: 0.4981 - val_loss: 1.6660 - val_acc: 0.4821\n",
      "Epoch 243/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6544 - acc: 0.4981 - val_loss: 1.6649 - val_acc: 0.4821\n",
      "Epoch 244/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6532 - acc: 0.4977 - val_loss: 1.6636 - val_acc: 0.4821\n",
      "Epoch 245/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6520 - acc: 0.4982 - val_loss: 1.6625 - val_acc: 0.4825\n",
      "Epoch 246/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6508 - acc: 0.4981 - val_loss: 1.6614 - val_acc: 0.4821\n",
      "Epoch 247/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6496 - acc: 0.4980 - val_loss: 1.6602 - val_acc: 0.4838\n",
      "Epoch 248/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6484 - acc: 0.4989 - val_loss: 1.6590 - val_acc: 0.4817\n",
      "Epoch 249/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6472 - acc: 0.4983 - val_loss: 1.6578 - val_acc: 0.4850\n",
      "Epoch 250/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6460 - acc: 0.4994 - val_loss: 1.6568 - val_acc: 0.4838\n",
      "Epoch 251/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6448 - acc: 0.4993 - val_loss: 1.6556 - val_acc: 0.4850\n",
      "Epoch 252/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.6437 - acc: 0.4999 - val_loss: 1.6545 - val_acc: 0.4850\n",
      "Epoch 253/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6425 - acc: 0.4996 - val_loss: 1.6534 - val_acc: 0.4833\n",
      "Epoch 254/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6413 - acc: 0.4993 - val_loss: 1.6523 - val_acc: 0.4842\n",
      "Epoch 255/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6402 - acc: 0.4997 - val_loss: 1.6512 - val_acc: 0.4842\n",
      "Epoch 256/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6390 - acc: 0.4995 - val_loss: 1.6500 - val_acc: 0.4838\n",
      "Epoch 257/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6378 - acc: 0.5001 - val_loss: 1.6489 - val_acc: 0.4850\n",
      "Epoch 258/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6367 - acc: 0.5003 - val_loss: 1.6478 - val_acc: 0.4854\n",
      "Epoch 259/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6356 - acc: 0.5003 - val_loss: 1.6467 - val_acc: 0.4854\n",
      "Epoch 260/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6345 - acc: 0.5003 - val_loss: 1.6456 - val_acc: 0.4846\n",
      "Epoch 261/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6333 - acc: 0.5008 - val_loss: 1.6445 - val_acc: 0.4858\n",
      "Epoch 262/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.6323 - acc: 0.5018 - val_loss: 1.6434 - val_acc: 0.4867\n",
      "Epoch 263/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.6311 - acc: 0.5012 - val_loss: 1.6424 - val_acc: 0.4854\n",
      "Epoch 264/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.6300 - acc: 0.5023 - val_loss: 1.6414 - val_acc: 0.4858\n",
      "Epoch 265/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.6288 - acc: 0.5021 - val_loss: 1.6403 - val_acc: 0.4858\n",
      "Epoch 266/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.6277 - acc: 0.5017 - val_loss: 1.6392 - val_acc: 0.4867\n",
      "Epoch 267/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.6267 - acc: 0.5018 - val_loss: 1.6382 - val_acc: 0.4858\n",
      "Epoch 268/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.6256 - acc: 0.5018 - val_loss: 1.6371 - val_acc: 0.4871\n",
      "Epoch 269/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.6245 - acc: 0.5024 - val_loss: 1.6362 - val_acc: 0.4854\n",
      "Epoch 270/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.6234 - acc: 0.5023 - val_loss: 1.6350 - val_acc: 0.4883\n",
      "Epoch 271/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.6223 - acc: 0.5030 - val_loss: 1.6340 - val_acc: 0.4867\n",
      "Epoch 272/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.6212 - acc: 0.5025 - val_loss: 1.6330 - val_acc: 0.4879\n",
      "Epoch 273/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.6202 - acc: 0.5022 - val_loss: 1.6319 - val_acc: 0.4883\n",
      "Epoch 274/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.6191 - acc: 0.5040 - val_loss: 1.6309 - val_acc: 0.4875\n",
      "Epoch 275/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.6181 - acc: 0.5027 - val_loss: 1.6300 - val_acc: 0.4879\n",
      "Epoch 276/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.6170 - acc: 0.5042 - val_loss: 1.6290 - val_acc: 0.4875\n",
      "Epoch 277/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.6160 - acc: 0.5044 - val_loss: 1.6279 - val_acc: 0.4896\n",
      "Epoch 278/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.6149 - acc: 0.5047 - val_loss: 1.6270 - val_acc: 0.4879\n",
      "Epoch 279/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.6139 - acc: 0.5047 - val_loss: 1.6259 - val_acc: 0.4879\n",
      "Epoch 280/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.6128 - acc: 0.5047 - val_loss: 1.6249 - val_acc: 0.4892\n",
      "Epoch 281/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.6119 - acc: 0.5051 - val_loss: 1.6240 - val_acc: 0.4896\n",
      "Epoch 282/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.6108 - acc: 0.5048 - val_loss: 1.6230 - val_acc: 0.4888\n",
      "Epoch 283/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.6098 - acc: 0.5047 - val_loss: 1.6220 - val_acc: 0.4892\n",
      "Epoch 284/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.6088 - acc: 0.5060 - val_loss: 1.6210 - val_acc: 0.4908\n",
      "Epoch 285/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6078 - acc: 0.5047 - val_loss: 1.6201 - val_acc: 0.4900\n",
      "Epoch 286/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6068 - acc: 0.5045 - val_loss: 1.6191 - val_acc: 0.4888\n",
      "Epoch 287/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.6058 - acc: 0.5052 - val_loss: 1.6181 - val_acc: 0.4904\n",
      "Epoch 288/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.6048 - acc: 0.5055 - val_loss: 1.6172 - val_acc: 0.4879\n",
      "Epoch 289/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.6038 - acc: 0.5058 - val_loss: 1.6163 - val_acc: 0.4900\n",
      "Epoch 290/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6028 - acc: 0.5058 - val_loss: 1.6154 - val_acc: 0.4888\n",
      "Epoch 291/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.6018 - acc: 0.5060 - val_loss: 1.6144 - val_acc: 0.4896\n",
      "Epoch 292/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.6008 - acc: 0.5059 - val_loss: 1.6135 - val_acc: 0.4892\n",
      "Epoch 293/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.5999 - acc: 0.5056 - val_loss: 1.6125 - val_acc: 0.4888\n",
      "Epoch 294/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5989 - acc: 0.5065 - val_loss: 1.6116 - val_acc: 0.4900\n",
      "Epoch 295/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5979 - acc: 0.5070 - val_loss: 1.6107 - val_acc: 0.4904\n",
      "Epoch 296/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5970 - acc: 0.5080 - val_loss: 1.6097 - val_acc: 0.4921\n",
      "Epoch 297/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5960 - acc: 0.5068 - val_loss: 1.6089 - val_acc: 0.4900\n",
      "Epoch 298/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5950 - acc: 0.5072 - val_loss: 1.6080 - val_acc: 0.4896\n",
      "Epoch 299/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5941 - acc: 0.5077 - val_loss: 1.6070 - val_acc: 0.4913\n",
      "Epoch 300/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5932 - acc: 0.5064 - val_loss: 1.6061 - val_acc: 0.4917\n",
      "Epoch 301/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5922 - acc: 0.5082 - val_loss: 1.6052 - val_acc: 0.4921\n",
      "Epoch 302/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5913 - acc: 0.5080 - val_loss: 1.6044 - val_acc: 0.4912\n",
      "Epoch 303/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5903 - acc: 0.5083 - val_loss: 1.6035 - val_acc: 0.4917\n",
      "Epoch 304/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5894 - acc: 0.5085 - val_loss: 1.6025 - val_acc: 0.4921\n",
      "Epoch 305/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5885 - acc: 0.5084 - val_loss: 1.6016 - val_acc: 0.4921\n",
      "Epoch 306/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5876 - acc: 0.5093 - val_loss: 1.6008 - val_acc: 0.4937\n",
      "Epoch 307/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5866 - acc: 0.5092 - val_loss: 1.5999 - val_acc: 0.4933\n",
      "Epoch 308/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5857 - acc: 0.5090 - val_loss: 1.5990 - val_acc: 0.4917\n",
      "Epoch 309/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5848 - acc: 0.5101 - val_loss: 1.5982 - val_acc: 0.4912\n",
      "Epoch 310/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5839 - acc: 0.5090 - val_loss: 1.5973 - val_acc: 0.4929\n",
      "Epoch 311/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5830 - acc: 0.5091 - val_loss: 1.5965 - val_acc: 0.4925\n",
      "Epoch 312/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5821 - acc: 0.5109 - val_loss: 1.5956 - val_acc: 0.4933\n",
      "Epoch 313/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5812 - acc: 0.5106 - val_loss: 1.5948 - val_acc: 0.4933\n",
      "Epoch 314/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5803 - acc: 0.5105 - val_loss: 1.5939 - val_acc: 0.4933\n",
      "Epoch 315/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5795 - acc: 0.5114 - val_loss: 1.5931 - val_acc: 0.4933\n",
      "Epoch 316/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5786 - acc: 0.5115 - val_loss: 1.5923 - val_acc: 0.4933\n",
      "Epoch 317/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5777 - acc: 0.5103 - val_loss: 1.5914 - val_acc: 0.4933\n",
      "Epoch 318/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5769 - acc: 0.5100 - val_loss: 1.5906 - val_acc: 0.4925\n",
      "Epoch 319/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5760 - acc: 0.5110 - val_loss: 1.5896 - val_acc: 0.4942\n",
      "Epoch 320/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5751 - acc: 0.5121 - val_loss: 1.5888 - val_acc: 0.4942\n",
      "Epoch 321/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5743 - acc: 0.5123 - val_loss: 1.5880 - val_acc: 0.4950\n",
      "Epoch 322/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5734 - acc: 0.5109 - val_loss: 1.5873 - val_acc: 0.4942\n",
      "Epoch 323/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5725 - acc: 0.5117 - val_loss: 1.5864 - val_acc: 0.4954\n",
      "Epoch 324/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5717 - acc: 0.5123 - val_loss: 1.5857 - val_acc: 0.4950\n",
      "Epoch 325/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5708 - acc: 0.5128 - val_loss: 1.5848 - val_acc: 0.4946\n",
      "Epoch 326/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5700 - acc: 0.5125 - val_loss: 1.5840 - val_acc: 0.4950\n",
      "Epoch 327/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5691 - acc: 0.5122 - val_loss: 1.5832 - val_acc: 0.4958\n",
      "Epoch 328/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5683 - acc: 0.5125 - val_loss: 1.5824 - val_acc: 0.4962\n",
      "Epoch 329/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5675 - acc: 0.5139 - val_loss: 1.5816 - val_acc: 0.4967\n",
      "Epoch 330/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.5666 - acc: 0.5135 - val_loss: 1.5808 - val_acc: 0.4950\n",
      "Epoch 331/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.5658 - acc: 0.5142 - val_loss: 1.5801 - val_acc: 0.4962\n",
      "Epoch 332/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.5650 - acc: 0.5124 - val_loss: 1.5793 - val_acc: 0.4946\n",
      "Epoch 333/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.5641 - acc: 0.5139 - val_loss: 1.5785 - val_acc: 0.4967\n",
      "Epoch 334/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.5633 - acc: 0.5149 - val_loss: 1.5777 - val_acc: 0.4967\n",
      "Epoch 335/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.5625 - acc: 0.5144 - val_loss: 1.5770 - val_acc: 0.4946\n",
      "Epoch 336/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5617 - acc: 0.5136 - val_loss: 1.5762 - val_acc: 0.4950\n",
      "Epoch 337/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5609 - acc: 0.5135 - val_loss: 1.5754 - val_acc: 0.4954\n",
      "Epoch 338/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5601 - acc: 0.5138 - val_loss: 1.5747 - val_acc: 0.4950\n",
      "Epoch 339/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5593 - acc: 0.5144 - val_loss: 1.5740 - val_acc: 0.4946\n",
      "Epoch 340/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5585 - acc: 0.5142 - val_loss: 1.5732 - val_acc: 0.4967\n",
      "Epoch 341/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5578 - acc: 0.5141 - val_loss: 1.5724 - val_acc: 0.4971\n",
      "Epoch 342/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.5569 - acc: 0.5143 - val_loss: 1.5718 - val_acc: 0.4954\n",
      "Epoch 343/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5562 - acc: 0.5135 - val_loss: 1.5710 - val_acc: 0.4958\n",
      "Epoch 344/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5554 - acc: 0.5147 - val_loss: 1.5703 - val_acc: 0.4962\n",
      "Epoch 345/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5546 - acc: 0.5140 - val_loss: 1.5695 - val_acc: 0.4967\n",
      "Epoch 346/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5539 - acc: 0.5155 - val_loss: 1.5687 - val_acc: 0.4967\n",
      "Epoch 347/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.5531 - acc: 0.5145 - val_loss: 1.5680 - val_acc: 0.4975\n",
      "Epoch 348/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5523 - acc: 0.5150 - val_loss: 1.5673 - val_acc: 0.4971\n",
      "Epoch 349/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.5515 - acc: 0.5144 - val_loss: 1.5665 - val_acc: 0.4958\n",
      "Epoch 350/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5507 - acc: 0.5149 - val_loss: 1.5658 - val_acc: 0.4958\n",
      "Epoch 351/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5500 - acc: 0.5152 - val_loss: 1.5651 - val_acc: 0.4967\n",
      "Epoch 352/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5492 - acc: 0.5153 - val_loss: 1.5645 - val_acc: 0.4962\n",
      "Epoch 353/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5485 - acc: 0.5150 - val_loss: 1.5637 - val_acc: 0.4962\n",
      "Epoch 354/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.5478 - acc: 0.5157 - val_loss: 1.5629 - val_acc: 0.4975\n",
      "Epoch 355/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.5470 - acc: 0.5151 - val_loss: 1.5622 - val_acc: 0.4979\n",
      "Epoch 356/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5462 - acc: 0.5168 - val_loss: 1.5615 - val_acc: 0.4975\n",
      "Epoch 357/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5455 - acc: 0.5165 - val_loss: 1.5609 - val_acc: 0.4971\n",
      "Epoch 358/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5447 - acc: 0.5151 - val_loss: 1.5602 - val_acc: 0.4975\n",
      "Epoch 359/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5440 - acc: 0.5167 - val_loss: 1.5594 - val_acc: 0.4979\n",
      "Epoch 360/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5433 - acc: 0.5156 - val_loss: 1.5588 - val_acc: 0.4962\n",
      "Epoch 361/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5425 - acc: 0.5166 - val_loss: 1.5581 - val_acc: 0.4979\n",
      "Epoch 362/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5418 - acc: 0.5161 - val_loss: 1.5574 - val_acc: 0.4983\n",
      "Epoch 363/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5411 - acc: 0.5165 - val_loss: 1.5567 - val_acc: 0.4992\n",
      "Epoch 364/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.5403 - acc: 0.5166 - val_loss: 1.5560 - val_acc: 0.4992\n",
      "Epoch 365/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5397 - acc: 0.5164 - val_loss: 1.5553 - val_acc: 0.4992\n",
      "Epoch 366/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5389 - acc: 0.5167 - val_loss: 1.5547 - val_acc: 0.4987\n",
      "Epoch 367/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5382 - acc: 0.5172 - val_loss: 1.5539 - val_acc: 0.4987\n",
      "Epoch 368/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5375 - acc: 0.5171 - val_loss: 1.5533 - val_acc: 0.4992\n",
      "Epoch 369/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5368 - acc: 0.5176 - val_loss: 1.5526 - val_acc: 0.4992\n",
      "Epoch 370/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5361 - acc: 0.5168 - val_loss: 1.5520 - val_acc: 0.4987\n",
      "Epoch 371/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5354 - acc: 0.5174 - val_loss: 1.5513 - val_acc: 0.5000\n",
      "Epoch 372/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5347 - acc: 0.5182 - val_loss: 1.5506 - val_acc: 0.5000\n",
      "Epoch 373/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5340 - acc: 0.5182 - val_loss: 1.5500 - val_acc: 0.4996\n",
      "Epoch 374/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.5333 - acc: 0.5186 - val_loss: 1.5493 - val_acc: 0.4992\n",
      "Epoch 375/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5326 - acc: 0.5177 - val_loss: 1.5486 - val_acc: 0.4996\n",
      "Epoch 376/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5319 - acc: 0.5179 - val_loss: 1.5480 - val_acc: 0.5004\n",
      "Epoch 377/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.5312 - acc: 0.5189 - val_loss: 1.5473 - val_acc: 0.5004\n",
      "Epoch 378/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5305 - acc: 0.5187 - val_loss: 1.5467 - val_acc: 0.5000\n",
      "Epoch 379/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5298 - acc: 0.5185 - val_loss: 1.5460 - val_acc: 0.5000\n",
      "Epoch 380/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5291 - acc: 0.5183 - val_loss: 1.5454 - val_acc: 0.4987\n",
      "Epoch 381/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5285 - acc: 0.5187 - val_loss: 1.5448 - val_acc: 0.4996\n",
      "Epoch 382/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5278 - acc: 0.5190 - val_loss: 1.5441 - val_acc: 0.5000\n",
      "Epoch 383/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5271 - acc: 0.5191 - val_loss: 1.5435 - val_acc: 0.5004\n",
      "Epoch 384/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5264 - acc: 0.5187 - val_loss: 1.5429 - val_acc: 0.5000\n",
      "Epoch 385/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5257 - acc: 0.5181 - val_loss: 1.5422 - val_acc: 0.5000\n",
      "Epoch 386/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5251 - acc: 0.5194 - val_loss: 1.5416 - val_acc: 0.5000\n",
      "Epoch 387/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5244 - acc: 0.5192 - val_loss: 1.5409 - val_acc: 0.5008\n",
      "Epoch 388/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5238 - acc: 0.5190 - val_loss: 1.5404 - val_acc: 0.5000\n",
      "Epoch 389/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5231 - acc: 0.5187 - val_loss: 1.5398 - val_acc: 0.5004\n",
      "Epoch 390/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5225 - acc: 0.5185 - val_loss: 1.5392 - val_acc: 0.5004\n",
      "Epoch 391/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5218 - acc: 0.5192 - val_loss: 1.5385 - val_acc: 0.5008\n",
      "Epoch 392/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5211 - acc: 0.5186 - val_loss: 1.5379 - val_acc: 0.5000\n",
      "Epoch 393/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5205 - acc: 0.5192 - val_loss: 1.5373 - val_acc: 0.5013\n",
      "Epoch 394/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5198 - acc: 0.5195 - val_loss: 1.5366 - val_acc: 0.5013\n",
      "Epoch 395/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5192 - acc: 0.5197 - val_loss: 1.5360 - val_acc: 0.5013\n",
      "Epoch 396/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5185 - acc: 0.5196 - val_loss: 1.5354 - val_acc: 0.5013\n",
      "Epoch 397/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5179 - acc: 0.5194 - val_loss: 1.5348 - val_acc: 0.5013\n",
      "Epoch 398/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5173 - acc: 0.5193 - val_loss: 1.5342 - val_acc: 0.5017\n",
      "Epoch 399/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5166 - acc: 0.5198 - val_loss: 1.5337 - val_acc: 0.5013\n",
      "Epoch 400/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5160 - acc: 0.5189 - val_loss: 1.5330 - val_acc: 0.5021\n",
      "Epoch 401/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5154 - acc: 0.5194 - val_loss: 1.5324 - val_acc: 0.5021\n",
      "Epoch 402/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5147 - acc: 0.5205 - val_loss: 1.5318 - val_acc: 0.5029\n",
      "Epoch 403/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5141 - acc: 0.5200 - val_loss: 1.5312 - val_acc: 0.5029\n",
      "Epoch 404/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5135 - acc: 0.5190 - val_loss: 1.5306 - val_acc: 0.5025\n",
      "Epoch 405/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5129 - acc: 0.5196 - val_loss: 1.5301 - val_acc: 0.5021\n",
      "Epoch 406/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5123 - acc: 0.5198 - val_loss: 1.5295 - val_acc: 0.5021\n",
      "Epoch 407/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5116 - acc: 0.5198 - val_loss: 1.5289 - val_acc: 0.5025\n",
      "Epoch 408/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5110 - acc: 0.5204 - val_loss: 1.5283 - val_acc: 0.5025\n",
      "Epoch 409/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5104 - acc: 0.5210 - val_loss: 1.5278 - val_acc: 0.5017\n",
      "Epoch 410/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5098 - acc: 0.5204 - val_loss: 1.5272 - val_acc: 0.5033\n",
      "Epoch 411/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5092 - acc: 0.5206 - val_loss: 1.5265 - val_acc: 0.5038\n",
      "Epoch 412/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5085 - acc: 0.5201 - val_loss: 1.5260 - val_acc: 0.5029\n",
      "Epoch 413/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5080 - acc: 0.5196 - val_loss: 1.5254 - val_acc: 0.5033\n",
      "Epoch 414/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.5073 - acc: 0.5202 - val_loss: 1.5249 - val_acc: 0.5029\n",
      "Epoch 415/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5067 - acc: 0.5209 - val_loss: 1.5243 - val_acc: 0.5042\n",
      "Epoch 416/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.5061 - acc: 0.5210 - val_loss: 1.5238 - val_acc: 0.5038\n",
      "Epoch 417/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5055 - acc: 0.5204 - val_loss: 1.5233 - val_acc: 0.5046\n",
      "Epoch 418/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5050 - acc: 0.5216 - val_loss: 1.5228 - val_acc: 0.5033\n",
      "Epoch 419/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5044 - acc: 0.5206 - val_loss: 1.5221 - val_acc: 0.5046\n",
      "Epoch 420/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5038 - acc: 0.5212 - val_loss: 1.5215 - val_acc: 0.5046\n",
      "Epoch 421/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5032 - acc: 0.5211 - val_loss: 1.5210 - val_acc: 0.5046\n",
      "Epoch 422/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5026 - acc: 0.5214 - val_loss: 1.5204 - val_acc: 0.5050\n",
      "Epoch 423/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5020 - acc: 0.5210 - val_loss: 1.5199 - val_acc: 0.5050\n",
      "Epoch 424/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.5014 - acc: 0.5215 - val_loss: 1.5193 - val_acc: 0.5063\n",
      "Epoch 425/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.5009 - acc: 0.5220 - val_loss: 1.5188 - val_acc: 0.5054\n",
      "Epoch 426/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.5003 - acc: 0.5216 - val_loss: 1.5183 - val_acc: 0.5050\n",
      "Epoch 427/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4997 - acc: 0.5220 - val_loss: 1.5177 - val_acc: 0.5058\n",
      "Epoch 428/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4991 - acc: 0.5226 - val_loss: 1.5171 - val_acc: 0.5058\n",
      "Epoch 429/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4985 - acc: 0.5228 - val_loss: 1.5166 - val_acc: 0.5046\n",
      "Epoch 430/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4980 - acc: 0.5225 - val_loss: 1.5161 - val_acc: 0.5054\n",
      "Epoch 431/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4974 - acc: 0.5224 - val_loss: 1.5156 - val_acc: 0.5067\n",
      "Epoch 432/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4969 - acc: 0.5230 - val_loss: 1.5150 - val_acc: 0.5050\n",
      "Epoch 433/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4963 - acc: 0.5220 - val_loss: 1.5145 - val_acc: 0.5058\n",
      "Epoch 434/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4957 - acc: 0.5228 - val_loss: 1.5140 - val_acc: 0.5063\n",
      "Epoch 435/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4951 - acc: 0.5230 - val_loss: 1.5135 - val_acc: 0.5071\n",
      "Epoch 436/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4946 - acc: 0.5226 - val_loss: 1.5129 - val_acc: 0.5071\n",
      "Epoch 437/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4940 - acc: 0.5239 - val_loss: 1.5123 - val_acc: 0.5075\n",
      "Epoch 438/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4935 - acc: 0.5234 - val_loss: 1.5119 - val_acc: 0.5067\n",
      "Epoch 439/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4929 - acc: 0.5236 - val_loss: 1.5114 - val_acc: 0.5075\n",
      "Epoch 440/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4924 - acc: 0.5232 - val_loss: 1.5109 - val_acc: 0.5079\n",
      "Epoch 441/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4919 - acc: 0.5228 - val_loss: 1.5103 - val_acc: 0.5079\n",
      "Epoch 442/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4913 - acc: 0.5234 - val_loss: 1.5099 - val_acc: 0.5071\n",
      "Epoch 443/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4907 - acc: 0.5248 - val_loss: 1.5093 - val_acc: 0.5075\n",
      "Epoch 444/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4902 - acc: 0.5249 - val_loss: 1.5088 - val_acc: 0.5067\n",
      "Epoch 445/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4896 - acc: 0.5250 - val_loss: 1.5084 - val_acc: 0.5071\n",
      "Epoch 446/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4891 - acc: 0.5242 - val_loss: 1.5078 - val_acc: 0.5071\n",
      "Epoch 447/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4886 - acc: 0.5245 - val_loss: 1.5074 - val_acc: 0.5075\n",
      "Epoch 448/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4880 - acc: 0.5249 - val_loss: 1.5068 - val_acc: 0.5075\n",
      "Epoch 449/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4875 - acc: 0.5248 - val_loss: 1.5064 - val_acc: 0.5075\n",
      "Epoch 450/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4870 - acc: 0.5248 - val_loss: 1.5059 - val_acc: 0.5079\n",
      "Epoch 451/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4864 - acc: 0.5251 - val_loss: 1.5054 - val_acc: 0.5071\n",
      "Epoch 452/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4859 - acc: 0.5255 - val_loss: 1.5049 - val_acc: 0.5088\n",
      "Epoch 453/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4854 - acc: 0.5251 - val_loss: 1.5045 - val_acc: 0.5092\n",
      "Epoch 454/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4848 - acc: 0.5249 - val_loss: 1.5039 - val_acc: 0.5079\n",
      "Epoch 455/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4843 - acc: 0.5251 - val_loss: 1.5034 - val_acc: 0.5083\n",
      "Epoch 456/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4838 - acc: 0.5258 - val_loss: 1.5028 - val_acc: 0.5075\n",
      "Epoch 457/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4833 - acc: 0.5257 - val_loss: 1.5024 - val_acc: 0.5083\n",
      "Epoch 458/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4828 - acc: 0.5250 - val_loss: 1.5020 - val_acc: 0.5083\n",
      "Epoch 459/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4823 - acc: 0.5253 - val_loss: 1.5014 - val_acc: 0.5088\n",
      "Epoch 460/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4817 - acc: 0.5254 - val_loss: 1.5010 - val_acc: 0.5079\n",
      "Epoch 461/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4812 - acc: 0.5257 - val_loss: 1.5005 - val_acc: 0.5083\n",
      "Epoch 462/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4807 - acc: 0.5256 - val_loss: 1.5000 - val_acc: 0.5083\n",
      "Epoch 463/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4802 - acc: 0.5257 - val_loss: 1.4995 - val_acc: 0.5088\n",
      "Epoch 464/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4797 - acc: 0.5258 - val_loss: 1.4991 - val_acc: 0.5092\n",
      "Epoch 465/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4791 - acc: 0.5260 - val_loss: 1.4987 - val_acc: 0.5096\n",
      "Epoch 466/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4787 - acc: 0.5264 - val_loss: 1.4980 - val_acc: 0.5096\n",
      "Epoch 467/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4782 - acc: 0.5256 - val_loss: 1.4977 - val_acc: 0.5092\n",
      "Epoch 468/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4777 - acc: 0.5271 - val_loss: 1.4972 - val_acc: 0.5092\n",
      "Epoch 469/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4771 - acc: 0.5262 - val_loss: 1.4967 - val_acc: 0.5088\n",
      "Epoch 470/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4767 - acc: 0.5266 - val_loss: 1.4962 - val_acc: 0.5096\n",
      "Epoch 471/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4762 - acc: 0.5262 - val_loss: 1.4958 - val_acc: 0.5100\n",
      "Epoch 472/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4757 - acc: 0.5272 - val_loss: 1.4953 - val_acc: 0.5104\n",
      "Epoch 473/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4752 - acc: 0.5268 - val_loss: 1.4949 - val_acc: 0.5104\n",
      "Epoch 474/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4747 - acc: 0.5268 - val_loss: 1.4945 - val_acc: 0.5104\n",
      "Epoch 475/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4742 - acc: 0.5270 - val_loss: 1.4939 - val_acc: 0.5100\n",
      "Epoch 476/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4737 - acc: 0.5267 - val_loss: 1.4935 - val_acc: 0.5104\n",
      "Epoch 477/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4732 - acc: 0.5262 - val_loss: 1.4931 - val_acc: 0.5092\n",
      "Epoch 478/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4727 - acc: 0.5270 - val_loss: 1.4926 - val_acc: 0.5104\n",
      "Epoch 479/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4722 - acc: 0.5266 - val_loss: 1.4922 - val_acc: 0.5092\n",
      "Epoch 480/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4718 - acc: 0.5270 - val_loss: 1.4917 - val_acc: 0.5121\n",
      "Epoch 481/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4713 - acc: 0.5271 - val_loss: 1.4912 - val_acc: 0.5108\n",
      "Epoch 482/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4708 - acc: 0.5277 - val_loss: 1.4908 - val_acc: 0.5121\n",
      "Epoch 483/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4703 - acc: 0.5273 - val_loss: 1.4903 - val_acc: 0.5108\n",
      "Epoch 484/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.4698 - acc: 0.5279 - val_loss: 1.4899 - val_acc: 0.5104\n",
      "Epoch 485/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4693 - acc: 0.5270 - val_loss: 1.4895 - val_acc: 0.5117\n",
      "Epoch 486/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4689 - acc: 0.5270 - val_loss: 1.4890 - val_acc: 0.5129\n",
      "Epoch 487/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4684 - acc: 0.5278 - val_loss: 1.4886 - val_acc: 0.5108\n",
      "Epoch 488/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4680 - acc: 0.5276 - val_loss: 1.4882 - val_acc: 0.5117\n",
      "Epoch 489/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4675 - acc: 0.5277 - val_loss: 1.4877 - val_acc: 0.5117\n",
      "Epoch 490/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4670 - acc: 0.5277 - val_loss: 1.4873 - val_acc: 0.5129\n",
      "Epoch 491/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4665 - acc: 0.5270 - val_loss: 1.4869 - val_acc: 0.5117\n",
      "Epoch 492/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4661 - acc: 0.5281 - val_loss: 1.4864 - val_acc: 0.5129\n",
      "Epoch 493/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4656 - acc: 0.5278 - val_loss: 1.4860 - val_acc: 0.5133\n",
      "Epoch 494/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4651 - acc: 0.5288 - val_loss: 1.4856 - val_acc: 0.5133\n",
      "Epoch 495/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4647 - acc: 0.5279 - val_loss: 1.4852 - val_acc: 0.5142\n",
      "Epoch 496/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4642 - acc: 0.5279 - val_loss: 1.4847 - val_acc: 0.5142\n",
      "Epoch 497/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4638 - acc: 0.5282 - val_loss: 1.4843 - val_acc: 0.5133\n",
      "Epoch 498/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4633 - acc: 0.5291 - val_loss: 1.4839 - val_acc: 0.5138\n",
      "Epoch 499/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4629 - acc: 0.5282 - val_loss: 1.4835 - val_acc: 0.5142\n",
      "Epoch 500/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4624 - acc: 0.5286 - val_loss: 1.4830 - val_acc: 0.5146\n",
      "Epoch 501/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4619 - acc: 0.5281 - val_loss: 1.4827 - val_acc: 0.5133\n",
      "Epoch 502/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4615 - acc: 0.5289 - val_loss: 1.4822 - val_acc: 0.5138\n",
      "Epoch 503/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.4611 - acc: 0.5285 - val_loss: 1.4818 - val_acc: 0.5146\n",
      "Epoch 504/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4606 - acc: 0.5289 - val_loss: 1.4814 - val_acc: 0.5167\n",
      "Epoch 505/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4602 - acc: 0.5282 - val_loss: 1.4810 - val_acc: 0.5154\n",
      "Epoch 506/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4597 - acc: 0.5285 - val_loss: 1.4805 - val_acc: 0.5154\n",
      "Epoch 507/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4593 - acc: 0.5286 - val_loss: 1.4801 - val_acc: 0.5158\n",
      "Epoch 508/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4588 - acc: 0.5288 - val_loss: 1.4797 - val_acc: 0.5154\n",
      "Epoch 509/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4584 - acc: 0.5290 - val_loss: 1.4794 - val_acc: 0.5150\n",
      "Epoch 510/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4579 - acc: 0.5294 - val_loss: 1.4790 - val_acc: 0.5158\n",
      "Epoch 511/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4575 - acc: 0.5284 - val_loss: 1.4786 - val_acc: 0.5158\n",
      "Epoch 512/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4571 - acc: 0.5292 - val_loss: 1.4781 - val_acc: 0.5162\n",
      "Epoch 513/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4566 - acc: 0.5294 - val_loss: 1.4777 - val_acc: 0.5162\n",
      "Epoch 514/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4562 - acc: 0.5288 - val_loss: 1.4773 - val_acc: 0.5154\n",
      "Epoch 515/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4557 - acc: 0.5291 - val_loss: 1.4769 - val_acc: 0.5162\n",
      "Epoch 516/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4553 - acc: 0.5291 - val_loss: 1.4765 - val_acc: 0.5162\n",
      "Epoch 517/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4549 - acc: 0.5295 - val_loss: 1.4762 - val_acc: 0.5154\n",
      "Epoch 518/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4545 - acc: 0.5292 - val_loss: 1.4756 - val_acc: 0.5154\n",
      "Epoch 519/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4540 - acc: 0.5290 - val_loss: 1.4754 - val_acc: 0.5158\n",
      "Epoch 520/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4536 - acc: 0.5291 - val_loss: 1.4750 - val_acc: 0.5162\n",
      "Epoch 521/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4532 - acc: 0.5293 - val_loss: 1.4746 - val_acc: 0.5171\n",
      "Epoch 522/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4528 - acc: 0.5296 - val_loss: 1.4742 - val_acc: 0.5171\n",
      "Epoch 523/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4523 - acc: 0.5297 - val_loss: 1.4739 - val_acc: 0.5175\n",
      "Epoch 524/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4519 - acc: 0.5295 - val_loss: 1.4734 - val_acc: 0.5171\n",
      "Epoch 525/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4515 - acc: 0.5292 - val_loss: 1.4730 - val_acc: 0.5167\n",
      "Epoch 526/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4511 - acc: 0.5303 - val_loss: 1.4727 - val_acc: 0.5167\n",
      "Epoch 527/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4507 - acc: 0.5295 - val_loss: 1.4723 - val_acc: 0.5175\n",
      "Epoch 528/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4502 - acc: 0.5303 - val_loss: 1.4719 - val_acc: 0.5167\n",
      "Epoch 529/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4498 - acc: 0.5295 - val_loss: 1.4716 - val_acc: 0.5179\n",
      "Epoch 530/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4494 - acc: 0.5297 - val_loss: 1.4711 - val_acc: 0.5171\n",
      "Epoch 531/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4490 - acc: 0.5306 - val_loss: 1.4707 - val_acc: 0.5175\n",
      "Epoch 532/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4486 - acc: 0.5297 - val_loss: 1.4704 - val_acc: 0.5162\n",
      "Epoch 533/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4482 - acc: 0.5302 - val_loss: 1.4700 - val_acc: 0.5171\n",
      "Epoch 534/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4478 - acc: 0.5301 - val_loss: 1.4697 - val_acc: 0.5171\n",
      "Epoch 535/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4474 - acc: 0.5300 - val_loss: 1.4692 - val_acc: 0.5171\n",
      "Epoch 536/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4470 - acc: 0.5302 - val_loss: 1.4688 - val_acc: 0.5162\n",
      "Epoch 537/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4466 - acc: 0.5307 - val_loss: 1.4685 - val_acc: 0.5175\n",
      "Epoch 538/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4462 - acc: 0.5302 - val_loss: 1.4682 - val_acc: 0.5171\n",
      "Epoch 539/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4458 - acc: 0.5305 - val_loss: 1.4677 - val_acc: 0.5167\n",
      "Epoch 540/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4454 - acc: 0.5305 - val_loss: 1.4674 - val_acc: 0.5167\n",
      "Epoch 541/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4450 - acc: 0.5306 - val_loss: 1.4670 - val_acc: 0.5167\n",
      "Epoch 542/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4446 - acc: 0.5311 - val_loss: 1.4667 - val_acc: 0.5167\n",
      "Epoch 543/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4442 - acc: 0.5304 - val_loss: 1.4663 - val_acc: 0.5179\n",
      "Epoch 544/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4437 - acc: 0.5310 - val_loss: 1.4659 - val_acc: 0.5171\n",
      "Epoch 545/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4434 - acc: 0.5314 - val_loss: 1.4656 - val_acc: 0.5171\n",
      "Epoch 546/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4430 - acc: 0.5309 - val_loss: 1.4652 - val_acc: 0.5175\n",
      "Epoch 547/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4426 - acc: 0.5302 - val_loss: 1.4649 - val_acc: 0.5179\n",
      "Epoch 548/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4422 - acc: 0.5307 - val_loss: 1.4645 - val_acc: 0.5175\n",
      "Epoch 549/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4418 - acc: 0.5308 - val_loss: 1.4642 - val_acc: 0.5175\n",
      "Epoch 550/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4414 - acc: 0.5310 - val_loss: 1.4638 - val_acc: 0.5167\n",
      "Epoch 551/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4410 - acc: 0.5303 - val_loss: 1.4634 - val_acc: 0.5183\n",
      "Epoch 552/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4407 - acc: 0.5316 - val_loss: 1.4630 - val_acc: 0.5183\n",
      "Epoch 553/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4403 - acc: 0.5312 - val_loss: 1.4627 - val_acc: 0.5183\n",
      "Epoch 554/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4399 - acc: 0.5310 - val_loss: 1.4623 - val_acc: 0.5183\n",
      "Epoch 555/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4395 - acc: 0.5317 - val_loss: 1.4620 - val_acc: 0.5188\n",
      "Epoch 556/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4391 - acc: 0.5310 - val_loss: 1.4617 - val_acc: 0.5179\n",
      "Epoch 557/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4387 - acc: 0.5309 - val_loss: 1.4613 - val_acc: 0.5183\n",
      "Epoch 558/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4383 - acc: 0.5319 - val_loss: 1.4609 - val_acc: 0.5183\n",
      "Epoch 559/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4379 - acc: 0.5314 - val_loss: 1.4606 - val_acc: 0.5183\n",
      "Epoch 560/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4376 - acc: 0.5319 - val_loss: 1.4602 - val_acc: 0.5188\n",
      "Epoch 561/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4372 - acc: 0.5311 - val_loss: 1.4600 - val_acc: 0.5188\n",
      "Epoch 562/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4368 - acc: 0.5321 - val_loss: 1.4595 - val_acc: 0.5183\n",
      "Epoch 563/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4365 - acc: 0.5317 - val_loss: 1.4592 - val_acc: 0.5188\n",
      "Epoch 564/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4361 - acc: 0.5323 - val_loss: 1.4589 - val_acc: 0.5175\n",
      "Epoch 565/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4357 - acc: 0.5326 - val_loss: 1.4585 - val_acc: 0.5179\n",
      "Epoch 566/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4353 - acc: 0.5326 - val_loss: 1.4582 - val_acc: 0.5188\n",
      "Epoch 567/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4350 - acc: 0.5319 - val_loss: 1.4578 - val_acc: 0.5175\n",
      "Epoch 568/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4346 - acc: 0.5322 - val_loss: 1.4576 - val_acc: 0.5192\n",
      "Epoch 569/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4342 - acc: 0.5315 - val_loss: 1.4572 - val_acc: 0.5188\n",
      "Epoch 570/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4338 - acc: 0.5327 - val_loss: 1.4568 - val_acc: 0.5179\n",
      "Epoch 571/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4334 - acc: 0.5320 - val_loss: 1.4565 - val_acc: 0.5192\n",
      "Epoch 572/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4331 - acc: 0.5328 - val_loss: 1.4562 - val_acc: 0.5183\n",
      "Epoch 573/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4327 - acc: 0.5325 - val_loss: 1.4558 - val_acc: 0.5188\n",
      "Epoch 574/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4323 - acc: 0.5327 - val_loss: 1.4555 - val_acc: 0.5183\n",
      "Epoch 575/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4320 - acc: 0.5335 - val_loss: 1.4552 - val_acc: 0.5183\n",
      "Epoch 576/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4316 - acc: 0.5326 - val_loss: 1.4549 - val_acc: 0.5188\n",
      "Epoch 577/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4313 - acc: 0.5331 - val_loss: 1.4545 - val_acc: 0.5188\n",
      "Epoch 578/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4309 - acc: 0.5321 - val_loss: 1.4542 - val_acc: 0.5192\n",
      "Epoch 579/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4305 - acc: 0.5330 - val_loss: 1.4539 - val_acc: 0.5192\n",
      "Epoch 580/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4302 - acc: 0.5331 - val_loss: 1.4535 - val_acc: 0.5188\n",
      "Epoch 581/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4298 - acc: 0.5335 - val_loss: 1.4533 - val_acc: 0.5188\n",
      "Epoch 582/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4295 - acc: 0.5330 - val_loss: 1.4529 - val_acc: 0.5192\n",
      "Epoch 583/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4291 - acc: 0.5333 - val_loss: 1.4526 - val_acc: 0.5196\n",
      "Epoch 584/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4288 - acc: 0.5333 - val_loss: 1.4522 - val_acc: 0.5196\n",
      "Epoch 585/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4284 - acc: 0.5339 - val_loss: 1.4519 - val_acc: 0.5188\n",
      "Epoch 586/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4280 - acc: 0.5342 - val_loss: 1.4517 - val_acc: 0.5188\n",
      "Epoch 587/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4277 - acc: 0.5339 - val_loss: 1.4513 - val_acc: 0.5192\n",
      "Epoch 588/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4274 - acc: 0.5332 - val_loss: 1.4510 - val_acc: 0.5192\n",
      "Epoch 589/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4270 - acc: 0.5337 - val_loss: 1.4506 - val_acc: 0.5192\n",
      "Epoch 590/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4266 - acc: 0.5348 - val_loss: 1.4504 - val_acc: 0.5200\n",
      "Epoch 591/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4263 - acc: 0.5344 - val_loss: 1.4500 - val_acc: 0.5196\n",
      "Epoch 592/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4259 - acc: 0.5351 - val_loss: 1.4497 - val_acc: 0.5208\n",
      "Epoch 593/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4256 - acc: 0.5342 - val_loss: 1.4495 - val_acc: 0.5196\n",
      "Epoch 594/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4253 - acc: 0.5344 - val_loss: 1.4491 - val_acc: 0.5188\n",
      "Epoch 595/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4249 - acc: 0.5340 - val_loss: 1.4488 - val_acc: 0.5200\n",
      "Epoch 596/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4246 - acc: 0.5341 - val_loss: 1.4484 - val_acc: 0.5208\n",
      "Epoch 597/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4242 - acc: 0.5346 - val_loss: 1.4482 - val_acc: 0.5208\n",
      "Epoch 598/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4239 - acc: 0.5348 - val_loss: 1.4478 - val_acc: 0.5204\n",
      "Epoch 599/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4235 - acc: 0.5343 - val_loss: 1.4475 - val_acc: 0.5208\n",
      "Epoch 600/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4232 - acc: 0.5336 - val_loss: 1.4473 - val_acc: 0.5204\n",
      "Epoch 601/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4229 - acc: 0.5352 - val_loss: 1.4469 - val_acc: 0.5200\n",
      "Epoch 602/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4225 - acc: 0.5347 - val_loss: 1.4466 - val_acc: 0.5204\n",
      "Epoch 603/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4222 - acc: 0.5350 - val_loss: 1.4462 - val_acc: 0.5204\n",
      "Epoch 604/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4218 - acc: 0.5348 - val_loss: 1.4460 - val_acc: 0.5204\n",
      "Epoch 605/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4215 - acc: 0.5346 - val_loss: 1.4457 - val_acc: 0.5204\n",
      "Epoch 606/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4212 - acc: 0.5348 - val_loss: 1.4455 - val_acc: 0.5204\n",
      "Epoch 607/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4208 - acc: 0.5350 - val_loss: 1.4451 - val_acc: 0.5212\n",
      "Epoch 608/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4205 - acc: 0.5357 - val_loss: 1.4448 - val_acc: 0.5200\n",
      "Epoch 609/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4202 - acc: 0.5352 - val_loss: 1.4445 - val_acc: 0.5208\n",
      "Epoch 610/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4198 - acc: 0.5359 - val_loss: 1.4442 - val_acc: 0.5208\n",
      "Epoch 611/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4195 - acc: 0.5345 - val_loss: 1.4439 - val_acc: 0.5200\n",
      "Epoch 612/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4192 - acc: 0.5356 - val_loss: 1.4436 - val_acc: 0.5208\n",
      "Epoch 613/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4188 - acc: 0.5353 - val_loss: 1.4433 - val_acc: 0.5204\n",
      "Epoch 614/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4185 - acc: 0.5355 - val_loss: 1.4429 - val_acc: 0.5204\n",
      "Epoch 615/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4182 - acc: 0.5350 - val_loss: 1.4427 - val_acc: 0.5204\n",
      "Epoch 616/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4178 - acc: 0.5352 - val_loss: 1.4424 - val_acc: 0.5204\n",
      "Epoch 617/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4176 - acc: 0.5355 - val_loss: 1.4421 - val_acc: 0.5204\n",
      "Epoch 618/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4172 - acc: 0.5367 - val_loss: 1.4418 - val_acc: 0.5204\n",
      "Epoch 619/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4169 - acc: 0.5360 - val_loss: 1.4415 - val_acc: 0.5200\n",
      "Epoch 620/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4166 - acc: 0.5359 - val_loss: 1.4412 - val_acc: 0.5192\n",
      "Epoch 621/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4163 - acc: 0.5353 - val_loss: 1.4410 - val_acc: 0.5208\n",
      "Epoch 622/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4159 - acc: 0.5359 - val_loss: 1.4407 - val_acc: 0.5204\n",
      "Epoch 623/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4156 - acc: 0.5357 - val_loss: 1.4404 - val_acc: 0.5212\n",
      "Epoch 624/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4153 - acc: 0.5358 - val_loss: 1.4401 - val_acc: 0.5208\n",
      "Epoch 625/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4150 - acc: 0.5358 - val_loss: 1.4398 - val_acc: 0.5217\n",
      "Epoch 626/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4147 - acc: 0.5365 - val_loss: 1.4395 - val_acc: 0.5212\n",
      "Epoch 627/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4143 - acc: 0.5364 - val_loss: 1.4393 - val_acc: 0.5217\n",
      "Epoch 628/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4140 - acc: 0.5366 - val_loss: 1.4389 - val_acc: 0.5225\n",
      "Epoch 629/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4137 - acc: 0.5365 - val_loss: 1.4387 - val_acc: 0.5212\n",
      "Epoch 630/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4134 - acc: 0.5366 - val_loss: 1.4384 - val_acc: 0.5221\n",
      "Epoch 631/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4131 - acc: 0.5368 - val_loss: 1.4381 - val_acc: 0.5212\n",
      "Epoch 632/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4128 - acc: 0.5364 - val_loss: 1.4379 - val_acc: 0.5208\n",
      "Epoch 633/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4125 - acc: 0.5361 - val_loss: 1.4376 - val_acc: 0.5225\n",
      "Epoch 634/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4121 - acc: 0.5367 - val_loss: 1.4373 - val_acc: 0.5217\n",
      "Epoch 635/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4118 - acc: 0.5369 - val_loss: 1.4370 - val_acc: 0.5229\n",
      "Epoch 636/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4115 - acc: 0.5364 - val_loss: 1.4368 - val_acc: 0.5221\n",
      "Epoch 637/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4112 - acc: 0.5367 - val_loss: 1.4364 - val_acc: 0.5221\n",
      "Epoch 638/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4109 - acc: 0.5363 - val_loss: 1.4362 - val_acc: 0.5229\n",
      "Epoch 639/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4106 - acc: 0.5370 - val_loss: 1.4359 - val_acc: 0.5233\n",
      "Epoch 640/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4103 - acc: 0.5374 - val_loss: 1.4357 - val_acc: 0.5233\n",
      "Epoch 641/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4100 - acc: 0.5370 - val_loss: 1.4354 - val_acc: 0.5233\n",
      "Epoch 642/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4097 - acc: 0.5378 - val_loss: 1.4351 - val_acc: 0.5237\n",
      "Epoch 643/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4094 - acc: 0.5376 - val_loss: 1.4348 - val_acc: 0.5233\n",
      "Epoch 644/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4091 - acc: 0.5378 - val_loss: 1.4346 - val_acc: 0.5233\n",
      "Epoch 645/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4088 - acc: 0.5372 - val_loss: 1.4342 - val_acc: 0.5233\n",
      "Epoch 646/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4085 - acc: 0.5370 - val_loss: 1.4340 - val_acc: 0.5225\n",
      "Epoch 647/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4082 - acc: 0.5378 - val_loss: 1.4337 - val_acc: 0.5229\n",
      "Epoch 648/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.4079 - acc: 0.5376 - val_loss: 1.4335 - val_acc: 0.5229\n",
      "Epoch 649/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4076 - acc: 0.5382 - val_loss: 1.4331 - val_acc: 0.5242\n",
      "Epoch 650/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4073 - acc: 0.5374 - val_loss: 1.4329 - val_acc: 0.5229\n",
      "Epoch 651/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4070 - acc: 0.5374 - val_loss: 1.4326 - val_acc: 0.5237\n",
      "Epoch 652/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4067 - acc: 0.5381 - val_loss: 1.4324 - val_acc: 0.5242\n",
      "Epoch 653/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4064 - acc: 0.5378 - val_loss: 1.4321 - val_acc: 0.5242\n",
      "Epoch 654/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4061 - acc: 0.5377 - val_loss: 1.4318 - val_acc: 0.5237\n",
      "Epoch 655/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.4058 - acc: 0.5381 - val_loss: 1.4316 - val_acc: 0.5237\n",
      "Epoch 656/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4055 - acc: 0.5379 - val_loss: 1.4313 - val_acc: 0.5233\n",
      "Epoch 657/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.4052 - acc: 0.5379 - val_loss: 1.4311 - val_acc: 0.5246\n",
      "Epoch 658/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.4049 - acc: 0.5379 - val_loss: 1.4308 - val_acc: 0.5233\n",
      "Epoch 659/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.4046 - acc: 0.5383 - val_loss: 1.4306 - val_acc: 0.5246\n",
      "Epoch 660/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.4043 - acc: 0.5382 - val_loss: 1.4302 - val_acc: 0.5246\n",
      "Epoch 661/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.4040 - acc: 0.5378 - val_loss: 1.4300 - val_acc: 0.5246\n",
      "Epoch 662/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.4038 - acc: 0.5382 - val_loss: 1.4298 - val_acc: 0.5250\n",
      "Epoch 663/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.4035 - acc: 0.5381 - val_loss: 1.4295 - val_acc: 0.5246\n",
      "Epoch 664/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.4032 - acc: 0.5381 - val_loss: 1.4293 - val_acc: 0.5254\n",
      "Epoch 665/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.4029 - acc: 0.5382 - val_loss: 1.4291 - val_acc: 0.5246\n",
      "Epoch 666/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.4026 - acc: 0.5382 - val_loss: 1.4287 - val_acc: 0.5242\n",
      "Epoch 667/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.4023 - acc: 0.5380 - val_loss: 1.4285 - val_acc: 0.5246\n",
      "Epoch 668/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.4020 - acc: 0.5379 - val_loss: 1.4283 - val_acc: 0.5242\n",
      "Epoch 669/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.4017 - acc: 0.5382 - val_loss: 1.4280 - val_acc: 0.5267\n",
      "Epoch 670/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4015 - acc: 0.5380 - val_loss: 1.4278 - val_acc: 0.5254\n",
      "Epoch 671/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4012 - acc: 0.5381 - val_loss: 1.4275 - val_acc: 0.5254\n",
      "Epoch 672/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.4009 - acc: 0.5384 - val_loss: 1.4272 - val_acc: 0.5254\n",
      "Epoch 673/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4006 - acc: 0.5383 - val_loss: 1.4269 - val_acc: 0.5258\n",
      "Epoch 674/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.4003 - acc: 0.5384 - val_loss: 1.4268 - val_acc: 0.5258\n",
      "Epoch 675/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.4001 - acc: 0.5381 - val_loss: 1.4266 - val_acc: 0.5262\n",
      "Epoch 676/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3998 - acc: 0.5383 - val_loss: 1.4263 - val_acc: 0.5254\n",
      "Epoch 677/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3995 - acc: 0.5384 - val_loss: 1.4260 - val_acc: 0.5254\n",
      "Epoch 678/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3992 - acc: 0.5385 - val_loss: 1.4256 - val_acc: 0.5267\n",
      "Epoch 679/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3989 - acc: 0.5390 - val_loss: 1.4254 - val_acc: 0.5258\n",
      "Epoch 680/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3987 - acc: 0.5391 - val_loss: 1.4252 - val_acc: 0.5271\n",
      "Epoch 681/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3984 - acc: 0.5384 - val_loss: 1.4251 - val_acc: 0.5262\n",
      "Epoch 682/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3981 - acc: 0.5386 - val_loss: 1.4247 - val_acc: 0.5267\n",
      "Epoch 683/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3978 - acc: 0.5383 - val_loss: 1.4245 - val_acc: 0.5267\n",
      "Epoch 684/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3975 - acc: 0.5393 - val_loss: 1.4243 - val_acc: 0.5267\n",
      "Epoch 685/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3973 - acc: 0.5389 - val_loss: 1.4241 - val_acc: 0.5271\n",
      "Epoch 686/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3971 - acc: 0.5384 - val_loss: 1.4239 - val_acc: 0.5258\n",
      "Epoch 687/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3967 - acc: 0.5385 - val_loss: 1.4236 - val_acc: 0.5267\n",
      "Epoch 688/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3965 - acc: 0.5390 - val_loss: 1.4232 - val_acc: 0.5275\n",
      "Epoch 689/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3962 - acc: 0.5392 - val_loss: 1.4230 - val_acc: 0.5271\n",
      "Epoch 690/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3959 - acc: 0.5391 - val_loss: 1.4228 - val_acc: 0.5279\n",
      "Epoch 691/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3957 - acc: 0.5392 - val_loss: 1.4226 - val_acc: 0.5271\n",
      "Epoch 692/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3954 - acc: 0.5390 - val_loss: 1.4223 - val_acc: 0.5283\n",
      "Epoch 693/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3951 - acc: 0.5395 - val_loss: 1.4221 - val_acc: 0.5279\n",
      "Epoch 694/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3948 - acc: 0.5392 - val_loss: 1.4219 - val_acc: 0.5283\n",
      "Epoch 695/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3946 - acc: 0.5396 - val_loss: 1.4217 - val_acc: 0.5271\n",
      "Epoch 696/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3943 - acc: 0.5401 - val_loss: 1.4214 - val_acc: 0.5267\n",
      "Epoch 697/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3940 - acc: 0.5397 - val_loss: 1.4213 - val_acc: 0.5279\n",
      "Epoch 698/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3938 - acc: 0.5399 - val_loss: 1.4209 - val_acc: 0.5287\n",
      "Epoch 699/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3935 - acc: 0.5394 - val_loss: 1.4208 - val_acc: 0.5279\n",
      "Epoch 700/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3933 - acc: 0.5395 - val_loss: 1.4205 - val_acc: 0.5283\n",
      "Epoch 701/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3930 - acc: 0.5404 - val_loss: 1.4203 - val_acc: 0.5287\n",
      "Epoch 702/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3927 - acc: 0.5398 - val_loss: 1.4201 - val_acc: 0.5263\n",
      "Epoch 703/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3925 - acc: 0.5398 - val_loss: 1.4199 - val_acc: 0.5263\n",
      "Epoch 704/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3922 - acc: 0.5400 - val_loss: 1.4196 - val_acc: 0.5271\n",
      "Epoch 705/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3920 - acc: 0.5399 - val_loss: 1.4193 - val_acc: 0.5287\n",
      "Epoch 706/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3917 - acc: 0.5399 - val_loss: 1.4191 - val_acc: 0.5283\n",
      "Epoch 707/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3915 - acc: 0.5401 - val_loss: 1.4189 - val_acc: 0.5279\n",
      "Epoch 708/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.3912 - acc: 0.5403 - val_loss: 1.4187 - val_acc: 0.5283\n",
      "Epoch 709/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3909 - acc: 0.5405 - val_loss: 1.4184 - val_acc: 0.5287\n",
      "Epoch 710/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3906 - acc: 0.5408 - val_loss: 1.4183 - val_acc: 0.5292\n",
      "Epoch 711/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3904 - acc: 0.5408 - val_loss: 1.4181 - val_acc: 0.5283\n",
      "Epoch 712/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3902 - acc: 0.5403 - val_loss: 1.4177 - val_acc: 0.5288\n",
      "Epoch 713/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3899 - acc: 0.5408 - val_loss: 1.4176 - val_acc: 0.5296\n",
      "Epoch 714/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3896 - acc: 0.5408 - val_loss: 1.4173 - val_acc: 0.5304\n",
      "Epoch 715/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3894 - acc: 0.5408 - val_loss: 1.4171 - val_acc: 0.5296\n",
      "Epoch 716/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3891 - acc: 0.5413 - val_loss: 1.4169 - val_acc: 0.5304\n",
      "Epoch 717/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3889 - acc: 0.5405 - val_loss: 1.4167 - val_acc: 0.5283\n",
      "Epoch 718/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3886 - acc: 0.5407 - val_loss: 1.4164 - val_acc: 0.5312\n",
      "Epoch 719/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3884 - acc: 0.5413 - val_loss: 1.4161 - val_acc: 0.5288\n",
      "Epoch 720/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3881 - acc: 0.5413 - val_loss: 1.4160 - val_acc: 0.5304\n",
      "Epoch 721/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3878 - acc: 0.5421 - val_loss: 1.4158 - val_acc: 0.5308\n",
      "Epoch 722/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3876 - acc: 0.5415 - val_loss: 1.4155 - val_acc: 0.5308\n",
      "Epoch 723/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3873 - acc: 0.5414 - val_loss: 1.4153 - val_acc: 0.5296\n",
      "Epoch 724/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3871 - acc: 0.5416 - val_loss: 1.4151 - val_acc: 0.5308\n",
      "Epoch 725/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3869 - acc: 0.5414 - val_loss: 1.4149 - val_acc: 0.5313\n",
      "Epoch 726/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3866 - acc: 0.5417 - val_loss: 1.4147 - val_acc: 0.5313\n",
      "Epoch 727/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3863 - acc: 0.5415 - val_loss: 1.4145 - val_acc: 0.5304\n",
      "Epoch 728/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3861 - acc: 0.5426 - val_loss: 1.4142 - val_acc: 0.5313\n",
      "Epoch 729/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3859 - acc: 0.5422 - val_loss: 1.4140 - val_acc: 0.5317\n",
      "Epoch 730/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3856 - acc: 0.5413 - val_loss: 1.4137 - val_acc: 0.5313\n",
      "Epoch 731/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3854 - acc: 0.5414 - val_loss: 1.4136 - val_acc: 0.5308\n",
      "Epoch 732/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3851 - acc: 0.5431 - val_loss: 1.4134 - val_acc: 0.5308\n",
      "Epoch 733/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3849 - acc: 0.5423 - val_loss: 1.4132 - val_acc: 0.5308\n",
      "Epoch 734/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3847 - acc: 0.5415 - val_loss: 1.4130 - val_acc: 0.5308\n",
      "Epoch 735/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3844 - acc: 0.5425 - val_loss: 1.4127 - val_acc: 0.5313\n",
      "Epoch 736/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3841 - acc: 0.5424 - val_loss: 1.4125 - val_acc: 0.5313\n",
      "Epoch 737/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3839 - acc: 0.5424 - val_loss: 1.4123 - val_acc: 0.5317\n",
      "Epoch 738/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3837 - acc: 0.5419 - val_loss: 1.4121 - val_acc: 0.5308\n",
      "Epoch 739/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3834 - acc: 0.5431 - val_loss: 1.4119 - val_acc: 0.5313\n",
      "Epoch 740/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3832 - acc: 0.5424 - val_loss: 1.4117 - val_acc: 0.5317\n",
      "Epoch 741/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3829 - acc: 0.5427 - val_loss: 1.4115 - val_acc: 0.5313\n",
      "Epoch 742/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3827 - acc: 0.5429 - val_loss: 1.4113 - val_acc: 0.5317\n",
      "Epoch 743/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3825 - acc: 0.5432 - val_loss: 1.4112 - val_acc: 0.5308\n",
      "Epoch 744/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3822 - acc: 0.5433 - val_loss: 1.4109 - val_acc: 0.5317\n",
      "Epoch 745/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3820 - acc: 0.5430 - val_loss: 1.4106 - val_acc: 0.5313\n",
      "Epoch 746/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3818 - acc: 0.5435 - val_loss: 1.4104 - val_acc: 0.5313\n",
      "Epoch 747/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3815 - acc: 0.5432 - val_loss: 1.4102 - val_acc: 0.5308\n",
      "Epoch 748/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3813 - acc: 0.5429 - val_loss: 1.4100 - val_acc: 0.5317\n",
      "Epoch 749/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3810 - acc: 0.5430 - val_loss: 1.4099 - val_acc: 0.5317\n",
      "Epoch 750/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3808 - acc: 0.5432 - val_loss: 1.4096 - val_acc: 0.5317\n",
      "Epoch 751/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3806 - acc: 0.5438 - val_loss: 1.4094 - val_acc: 0.5317\n",
      "Epoch 752/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3804 - acc: 0.5431 - val_loss: 1.4092 - val_acc: 0.5313\n",
      "Epoch 753/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3801 - acc: 0.5441 - val_loss: 1.4090 - val_acc: 0.5321\n",
      "Epoch 754/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3799 - acc: 0.5434 - val_loss: 1.4088 - val_acc: 0.5317\n",
      "Epoch 755/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3797 - acc: 0.5442 - val_loss: 1.4086 - val_acc: 0.5325\n",
      "Epoch 756/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3794 - acc: 0.5436 - val_loss: 1.4084 - val_acc: 0.5317\n",
      "Epoch 757/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3792 - acc: 0.5440 - val_loss: 1.4083 - val_acc: 0.5321\n",
      "Epoch 758/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3790 - acc: 0.5433 - val_loss: 1.4080 - val_acc: 0.5321\n",
      "Epoch 759/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3787 - acc: 0.5444 - val_loss: 1.4078 - val_acc: 0.5321\n",
      "Epoch 760/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3785 - acc: 0.5444 - val_loss: 1.4076 - val_acc: 0.5317\n",
      "Epoch 761/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3783 - acc: 0.5432 - val_loss: 1.4074 - val_acc: 0.5313\n",
      "Epoch 762/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3780 - acc: 0.5443 - val_loss: 1.4072 - val_acc: 0.5325\n",
      "Epoch 763/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3778 - acc: 0.5441 - val_loss: 1.4070 - val_acc: 0.5321\n",
      "Epoch 764/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3776 - acc: 0.5441 - val_loss: 1.4068 - val_acc: 0.5321\n",
      "Epoch 765/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3774 - acc: 0.5436 - val_loss: 1.4066 - val_acc: 0.5321\n",
      "Epoch 766/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3772 - acc: 0.5440 - val_loss: 1.4064 - val_acc: 0.5325\n",
      "Epoch 767/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3769 - acc: 0.5444 - val_loss: 1.4063 - val_acc: 0.5317\n",
      "Epoch 768/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3767 - acc: 0.5434 - val_loss: 1.4061 - val_acc: 0.5317\n",
      "Epoch 769/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3765 - acc: 0.5439 - val_loss: 1.4058 - val_acc: 0.5317\n",
      "Epoch 770/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3762 - acc: 0.5439 - val_loss: 1.4057 - val_acc: 0.5321\n",
      "Epoch 771/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3760 - acc: 0.5447 - val_loss: 1.4055 - val_acc: 0.5321\n",
      "Epoch 772/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3758 - acc: 0.5443 - val_loss: 1.4053 - val_acc: 0.5325\n",
      "Epoch 773/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3756 - acc: 0.5449 - val_loss: 1.4051 - val_acc: 0.5321\n",
      "Epoch 774/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3753 - acc: 0.5443 - val_loss: 1.4049 - val_acc: 0.5321\n",
      "Epoch 775/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3751 - acc: 0.5441 - val_loss: 1.4046 - val_acc: 0.5321\n",
      "Epoch 776/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3749 - acc: 0.5445 - val_loss: 1.4045 - val_acc: 0.5329\n",
      "Epoch 777/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3747 - acc: 0.5438 - val_loss: 1.4043 - val_acc: 0.5325\n",
      "Epoch 778/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3744 - acc: 0.5448 - val_loss: 1.4041 - val_acc: 0.5317\n",
      "Epoch 779/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3742 - acc: 0.5451 - val_loss: 1.4039 - val_acc: 0.5329\n",
      "Epoch 780/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3740 - acc: 0.5451 - val_loss: 1.4037 - val_acc: 0.5325\n",
      "Epoch 781/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3738 - acc: 0.5446 - val_loss: 1.4035 - val_acc: 0.5329\n",
      "Epoch 782/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3736 - acc: 0.5447 - val_loss: 1.4034 - val_acc: 0.5329\n",
      "Epoch 783/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3734 - acc: 0.5453 - val_loss: 1.4032 - val_acc: 0.5329\n",
      "Epoch 784/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3731 - acc: 0.5451 - val_loss: 1.4030 - val_acc: 0.5338\n",
      "Epoch 785/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3729 - acc: 0.5450 - val_loss: 1.4028 - val_acc: 0.5333\n",
      "Epoch 786/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3727 - acc: 0.5449 - val_loss: 1.4026 - val_acc: 0.5321\n",
      "Epoch 787/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3725 - acc: 0.5452 - val_loss: 1.4024 - val_acc: 0.5329\n",
      "Epoch 788/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3723 - acc: 0.5455 - val_loss: 1.4023 - val_acc: 0.5325\n",
      "Epoch 789/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3720 - acc: 0.5451 - val_loss: 1.4020 - val_acc: 0.5333\n",
      "Epoch 790/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3718 - acc: 0.5451 - val_loss: 1.4019 - val_acc: 0.5329\n",
      "Epoch 791/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3716 - acc: 0.5457 - val_loss: 1.4018 - val_acc: 0.5333\n",
      "Epoch 792/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3714 - acc: 0.5459 - val_loss: 1.4015 - val_acc: 0.5325\n",
      "Epoch 793/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3712 - acc: 0.5448 - val_loss: 1.4013 - val_acc: 0.5329\n",
      "Epoch 794/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3710 - acc: 0.5453 - val_loss: 1.4011 - val_acc: 0.5333\n",
      "Epoch 795/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3708 - acc: 0.5461 - val_loss: 1.4009 - val_acc: 0.5329\n",
      "Epoch 796/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3706 - acc: 0.5453 - val_loss: 1.4009 - val_acc: 0.5325\n",
      "Epoch 797/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3703 - acc: 0.5452 - val_loss: 1.4006 - val_acc: 0.5329\n",
      "Epoch 798/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3701 - acc: 0.5448 - val_loss: 1.4005 - val_acc: 0.5329\n",
      "Epoch 799/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3699 - acc: 0.5454 - val_loss: 1.4002 - val_acc: 0.5329\n",
      "Epoch 800/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3697 - acc: 0.5455 - val_loss: 1.4000 - val_acc: 0.5329\n",
      "Epoch 801/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3695 - acc: 0.5454 - val_loss: 1.3998 - val_acc: 0.5329\n",
      "Epoch 802/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3693 - acc: 0.5456 - val_loss: 1.3997 - val_acc: 0.5333\n",
      "Epoch 803/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3691 - acc: 0.5456 - val_loss: 1.3995 - val_acc: 0.5329\n",
      "Epoch 804/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3689 - acc: 0.5453 - val_loss: 1.3993 - val_acc: 0.5329\n",
      "Epoch 805/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 1.3687 - acc: 0.5464 - val_loss: 1.3991 - val_acc: 0.5325\n",
      "Epoch 806/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3684 - acc: 0.5455 - val_loss: 1.3990 - val_acc: 0.5329\n",
      "Epoch 807/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3683 - acc: 0.5457 - val_loss: 1.3989 - val_acc: 0.5321\n",
      "Epoch 808/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3680 - acc: 0.5457 - val_loss: 1.3986 - val_acc: 0.5333\n",
      "Epoch 809/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3678 - acc: 0.5459 - val_loss: 1.3984 - val_acc: 0.5329\n",
      "Epoch 810/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3676 - acc: 0.5454 - val_loss: 1.3983 - val_acc: 0.5329\n",
      "Epoch 811/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.3674 - acc: 0.5458 - val_loss: 1.3981 - val_acc: 0.5342\n",
      "Epoch 812/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3672 - acc: 0.5473 - val_loss: 1.3979 - val_acc: 0.5338\n",
      "Epoch 813/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3670 - acc: 0.5461 - val_loss: 1.3977 - val_acc: 0.5317\n",
      "Epoch 814/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3668 - acc: 0.5466 - val_loss: 1.3976 - val_acc: 0.5321\n",
      "Epoch 815/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3666 - acc: 0.5461 - val_loss: 1.3974 - val_acc: 0.5321\n",
      "Epoch 816/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3664 - acc: 0.5461 - val_loss: 1.3973 - val_acc: 0.5333\n",
      "Epoch 817/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3662 - acc: 0.5461 - val_loss: 1.3971 - val_acc: 0.5329\n",
      "Epoch 818/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.3660 - acc: 0.5464 - val_loss: 1.3969 - val_acc: 0.5342\n",
      "Epoch 819/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.3658 - acc: 0.5463 - val_loss: 1.3967 - val_acc: 0.5342\n",
      "Epoch 820/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.3656 - acc: 0.5461 - val_loss: 1.3965 - val_acc: 0.5333\n",
      "Epoch 821/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.3654 - acc: 0.5465 - val_loss: 1.3963 - val_acc: 0.5337\n",
      "Epoch 822/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.3652 - acc: 0.5469 - val_loss: 1.3962 - val_acc: 0.5337\n",
      "Epoch 823/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.3650 - acc: 0.5464 - val_loss: 1.3960 - val_acc: 0.5337\n",
      "Epoch 824/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.3648 - acc: 0.5466 - val_loss: 1.3958 - val_acc: 0.5346\n",
      "Epoch 825/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.3646 - acc: 0.5474 - val_loss: 1.3957 - val_acc: 0.5346\n",
      "Epoch 826/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.3644 - acc: 0.5470 - val_loss: 1.3955 - val_acc: 0.5329\n",
      "Epoch 827/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.3642 - acc: 0.5464 - val_loss: 1.3953 - val_acc: 0.5337\n",
      "Epoch 828/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.3640 - acc: 0.5467 - val_loss: 1.3951 - val_acc: 0.5342\n",
      "Epoch 829/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3638 - acc: 0.5460 - val_loss: 1.3951 - val_acc: 0.5342\n",
      "Epoch 830/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3636 - acc: 0.5461 - val_loss: 1.3949 - val_acc: 0.5346\n",
      "Epoch 831/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.3634 - acc: 0.5457 - val_loss: 1.3947 - val_acc: 0.5342\n",
      "Epoch 832/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3632 - acc: 0.5467 - val_loss: 1.3946 - val_acc: 0.5342\n",
      "Epoch 833/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.3630 - acc: 0.5470 - val_loss: 1.3943 - val_acc: 0.5337\n",
      "Epoch 834/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.3628 - acc: 0.5464 - val_loss: 1.3942 - val_acc: 0.5346\n",
      "Epoch 835/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 1.3626 - acc: 0.5464 - val_loss: 1.3940 - val_acc: 0.5342\n",
      "Epoch 836/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.3624 - acc: 0.5463 - val_loss: 1.3938 - val_acc: 0.5342\n",
      "Epoch 837/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.3622 - acc: 0.5471 - val_loss: 1.3937 - val_acc: 0.5350\n",
      "Epoch 838/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.3620 - acc: 0.5467 - val_loss: 1.3936 - val_acc: 0.5337\n",
      "Epoch 839/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.3618 - acc: 0.5470 - val_loss: 1.3934 - val_acc: 0.5346\n",
      "Epoch 840/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.3616 - acc: 0.5470 - val_loss: 1.3932 - val_acc: 0.5350\n",
      "Epoch 841/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.3614 - acc: 0.5479 - val_loss: 1.3930 - val_acc: 0.5350\n",
      "Epoch 842/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.3613 - acc: 0.5465 - val_loss: 1.3928 - val_acc: 0.5346\n",
      "Epoch 843/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3610 - acc: 0.5465 - val_loss: 1.3926 - val_acc: 0.5342\n",
      "Epoch 844/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3608 - acc: 0.5480 - val_loss: 1.3926 - val_acc: 0.5358\n",
      "Epoch 845/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3606 - acc: 0.5468 - val_loss: 1.3924 - val_acc: 0.5358\n",
      "Epoch 846/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3604 - acc: 0.5469 - val_loss: 1.3922 - val_acc: 0.5342\n",
      "Epoch 847/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3603 - acc: 0.5470 - val_loss: 1.3921 - val_acc: 0.5358\n",
      "Epoch 848/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3601 - acc: 0.5478 - val_loss: 1.3918 - val_acc: 0.5342\n",
      "Epoch 849/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3599 - acc: 0.5476 - val_loss: 1.3918 - val_acc: 0.5350\n",
      "Epoch 850/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3597 - acc: 0.5473 - val_loss: 1.3915 - val_acc: 0.5346\n",
      "Epoch 851/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3595 - acc: 0.5470 - val_loss: 1.3914 - val_acc: 0.5342\n",
      "Epoch 852/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3593 - acc: 0.5474 - val_loss: 1.3912 - val_acc: 0.5346\n",
      "Epoch 853/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.3591 - acc: 0.5479 - val_loss: 1.3911 - val_acc: 0.5350\n",
      "Epoch 854/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.3589 - acc: 0.5474 - val_loss: 1.3908 - val_acc: 0.5346\n",
      "Epoch 855/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.3588 - acc: 0.5479 - val_loss: 1.3908 - val_acc: 0.5346\n",
      "Epoch 856/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.3586 - acc: 0.5476 - val_loss: 1.3906 - val_acc: 0.5342\n",
      "Epoch 857/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.3583 - acc: 0.5479 - val_loss: 1.3904 - val_acc: 0.5350\n",
      "Epoch 858/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.3582 - acc: 0.5474 - val_loss: 1.3902 - val_acc: 0.5350\n",
      "Epoch 859/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.3580 - acc: 0.5475 - val_loss: 1.3901 - val_acc: 0.5342\n",
      "Epoch 860/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.3578 - acc: 0.5469 - val_loss: 1.3898 - val_acc: 0.5346\n",
      "Epoch 861/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3576 - acc: 0.5486 - val_loss: 1.3898 - val_acc: 0.5350\n",
      "Epoch 862/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.3574 - acc: 0.5481 - val_loss: 1.3896 - val_acc: 0.5350\n",
      "Epoch 863/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3572 - acc: 0.5476 - val_loss: 1.3895 - val_acc: 0.5346\n",
      "Epoch 864/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3571 - acc: 0.5478 - val_loss: 1.3893 - val_acc: 0.5346\n",
      "Epoch 865/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.3569 - acc: 0.5481 - val_loss: 1.3891 - val_acc: 0.5350\n",
      "Epoch 866/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3567 - acc: 0.5483 - val_loss: 1.3891 - val_acc: 0.5354\n",
      "Epoch 867/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3565 - acc: 0.5479 - val_loss: 1.3889 - val_acc: 0.5354\n",
      "Epoch 868/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.3563 - acc: 0.5476 - val_loss: 1.3888 - val_acc: 0.5350\n",
      "Epoch 869/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3562 - acc: 0.5477 - val_loss: 1.3886 - val_acc: 0.5354\n",
      "Epoch 870/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3560 - acc: 0.5482 - val_loss: 1.3884 - val_acc: 0.5350\n",
      "Epoch 871/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3558 - acc: 0.5487 - val_loss: 1.3883 - val_acc: 0.5350\n",
      "Epoch 872/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3556 - acc: 0.5486 - val_loss: 1.3881 - val_acc: 0.5342\n",
      "Epoch 873/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3554 - acc: 0.5480 - val_loss: 1.3881 - val_acc: 0.5342\n",
      "Epoch 874/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3552 - acc: 0.5482 - val_loss: 1.3878 - val_acc: 0.5350\n",
      "Epoch 875/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3550 - acc: 0.5476 - val_loss: 1.3876 - val_acc: 0.5350\n",
      "Epoch 876/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3549 - acc: 0.5486 - val_loss: 1.3875 - val_acc: 0.5354\n",
      "Epoch 877/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3547 - acc: 0.5491 - val_loss: 1.3873 - val_acc: 0.5350\n",
      "Epoch 878/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3545 - acc: 0.5479 - val_loss: 1.3872 - val_acc: 0.5350\n",
      "Epoch 879/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3543 - acc: 0.5477 - val_loss: 1.3871 - val_acc: 0.5346\n",
      "Epoch 880/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3541 - acc: 0.5487 - val_loss: 1.3869 - val_acc: 0.5346\n",
      "Epoch 881/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3540 - acc: 0.5483 - val_loss: 1.3868 - val_acc: 0.5342\n",
      "Epoch 882/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3538 - acc: 0.5495 - val_loss: 1.3865 - val_acc: 0.5346\n",
      "Epoch 883/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3536 - acc: 0.5486 - val_loss: 1.3865 - val_acc: 0.5350\n",
      "Epoch 884/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3534 - acc: 0.5483 - val_loss: 1.3863 - val_acc: 0.5350\n",
      "Epoch 885/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3532 - acc: 0.5480 - val_loss: 1.3861 - val_acc: 0.5346\n",
      "Epoch 886/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3531 - acc: 0.5490 - val_loss: 1.3860 - val_acc: 0.5337\n",
      "Epoch 887/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.3529 - acc: 0.5489 - val_loss: 1.3859 - val_acc: 0.5354\n",
      "Epoch 888/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3527 - acc: 0.5477 - val_loss: 1.3857 - val_acc: 0.5350\n",
      "Epoch 889/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.3526 - acc: 0.5493 - val_loss: 1.3856 - val_acc: 0.5350\n",
      "Epoch 890/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3524 - acc: 0.5486 - val_loss: 1.3854 - val_acc: 0.5346\n",
      "Epoch 891/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.3522 - acc: 0.5485 - val_loss: 1.3853 - val_acc: 0.5358\n",
      "Epoch 892/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3520 - acc: 0.5495 - val_loss: 1.3852 - val_acc: 0.5358\n",
      "Epoch 893/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3518 - acc: 0.5484 - val_loss: 1.3851 - val_acc: 0.5350\n",
      "Epoch 894/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.3517 - acc: 0.5483 - val_loss: 1.3848 - val_acc: 0.5346\n",
      "Val loss: 1.3926,Val acc: 0.5358\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  DATASET MRDBI  ----------\n",
      "(9600, 28, 28, 1) train samples\n",
      "(2400, 28, 28, 1) validation samples\n",
      "(50000, 28, 28, 1) test samples\n",
      "\n",
      "\tTraining model:\n",
      "logreg\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 2.3016 - acc: 0.1136 - val_loss: 2.3016 - val_acc: 0.1154\n",
      "Epoch 2/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2995 - acc: 0.1175 - val_loss: 2.3013 - val_acc: 0.1154\n",
      "Epoch 3/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2982 - acc: 0.1175 - val_loss: 2.3007 - val_acc: 0.1154\n",
      "Epoch 4/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2972 - acc: 0.1175 - val_loss: 2.3000 - val_acc: 0.1154\n",
      "Epoch 5/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2962 - acc: 0.1175 - val_loss: 2.2990 - val_acc: 0.1154\n",
      "Epoch 6/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2952 - acc: 0.1175 - val_loss: 2.2982 - val_acc: 0.1154\n",
      "Epoch 7/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2942 - acc: 0.1175 - val_loss: 2.2972 - val_acc: 0.1154\n",
      "Epoch 8/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.2932 - acc: 0.1175 - val_loss: 2.2960 - val_acc: 0.1158\n",
      "Epoch 9/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.2922 - acc: 0.1175 - val_loss: 2.2952 - val_acc: 0.1158\n",
      "Epoch 10/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2912 - acc: 0.1180 - val_loss: 2.2938 - val_acc: 0.1162\n",
      "Epoch 11/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2903 - acc: 0.1182 - val_loss: 2.2931 - val_acc: 0.1183\n",
      "Epoch 12/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2892 - acc: 0.1192 - val_loss: 2.2922 - val_acc: 0.1183\n",
      "Epoch 13/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2883 - acc: 0.1201 - val_loss: 2.2914 - val_acc: 0.1217\n",
      "Epoch 14/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2873 - acc: 0.1224 - val_loss: 2.2902 - val_acc: 0.1221\n",
      "Epoch 15/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2863 - acc: 0.1215 - val_loss: 2.2897 - val_acc: 0.1225\n",
      "Epoch 16/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2853 - acc: 0.1244 - val_loss: 2.2884 - val_acc: 0.1237\n",
      "Epoch 17/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2844 - acc: 0.1237 - val_loss: 2.2876 - val_acc: 0.1250\n",
      "Epoch 18/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2834 - acc: 0.1251 - val_loss: 2.2865 - val_acc: 0.1275\n",
      "Epoch 19/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 2.2825 - acc: 0.1325 - val_loss: 2.2857 - val_acc: 0.1304\n",
      "Epoch 20/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.2815 - acc: 0.1296 - val_loss: 2.2846 - val_acc: 0.1313\n",
      "Epoch 21/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2806 - acc: 0.1369 - val_loss: 2.2837 - val_acc: 0.1350\n",
      "Epoch 22/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2796 - acc: 0.1325 - val_loss: 2.2827 - val_acc: 0.1367\n",
      "Epoch 23/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2786 - acc: 0.1331 - val_loss: 2.2818 - val_acc: 0.1400\n",
      "Epoch 24/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2776 - acc: 0.1412 - val_loss: 2.2808 - val_acc: 0.1446\n",
      "Epoch 25/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2767 - acc: 0.1444 - val_loss: 2.2799 - val_acc: 0.1450\n",
      "Epoch 26/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2758 - acc: 0.1453 - val_loss: 2.2789 - val_acc: 0.1488\n",
      "Epoch 27/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2748 - acc: 0.1478 - val_loss: 2.2782 - val_acc: 0.1500\n",
      "Epoch 28/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2739 - acc: 0.1482 - val_loss: 2.2771 - val_acc: 0.1504\n",
      "Epoch 29/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2730 - acc: 0.1477 - val_loss: 2.2763 - val_acc: 0.1537\n",
      "Epoch 30/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2721 - acc: 0.1537 - val_loss: 2.2755 - val_acc: 0.1533\n",
      "Epoch 31/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2711 - acc: 0.1621 - val_loss: 2.2742 - val_acc: 0.1629\n",
      "Epoch 32/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2702 - acc: 0.1586 - val_loss: 2.2735 - val_acc: 0.1562\n",
      "Epoch 33/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2693 - acc: 0.1641 - val_loss: 2.2728 - val_acc: 0.1600\n",
      "Epoch 34/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2684 - acc: 0.1621 - val_loss: 2.2719 - val_acc: 0.1638\n",
      "Epoch 35/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2675 - acc: 0.1616 - val_loss: 2.2710 - val_acc: 0.1617\n",
      "Epoch 36/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2666 - acc: 0.1698 - val_loss: 2.2701 - val_acc: 0.1683\n",
      "Epoch 37/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2657 - acc: 0.1756 - val_loss: 2.2689 - val_acc: 0.1733\n",
      "Epoch 38/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2648 - acc: 0.1750 - val_loss: 2.2683 - val_acc: 0.1721\n",
      "Epoch 39/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2639 - acc: 0.1725 - val_loss: 2.2675 - val_acc: 0.1771\n",
      "Epoch 40/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2630 - acc: 0.1896 - val_loss: 2.2665 - val_acc: 0.1792\n",
      "Epoch 41/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2622 - acc: 0.1759 - val_loss: 2.2658 - val_acc: 0.1775\n",
      "Epoch 42/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2612 - acc: 0.1834 - val_loss: 2.2647 - val_acc: 0.1846\n",
      "Epoch 43/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2603 - acc: 0.1866 - val_loss: 2.2638 - val_acc: 0.1879\n",
      "Epoch 44/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2595 - acc: 0.1905 - val_loss: 2.2628 - val_acc: 0.1863\n",
      "Epoch 45/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2586 - acc: 0.1868 - val_loss: 2.2621 - val_acc: 0.1912\n",
      "Epoch 46/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2577 - acc: 0.1890 - val_loss: 2.2613 - val_acc: 0.1971\n",
      "Epoch 47/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2568 - acc: 0.1959 - val_loss: 2.2604 - val_acc: 0.1958\n",
      "Epoch 48/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2559 - acc: 0.1903 - val_loss: 2.2597 - val_acc: 0.1925\n",
      "Epoch 49/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2550 - acc: 0.1954 - val_loss: 2.2586 - val_acc: 0.1983\n",
      "Epoch 50/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2542 - acc: 0.2014 - val_loss: 2.2576 - val_acc: 0.2021\n",
      "Epoch 51/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2533 - acc: 0.2074 - val_loss: 2.2570 - val_acc: 0.2004\n",
      "Epoch 52/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2524 - acc: 0.1976 - val_loss: 2.2559 - val_acc: 0.2062\n",
      "Epoch 53/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2515 - acc: 0.2076 - val_loss: 2.2552 - val_acc: 0.2058\n",
      "Epoch 54/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2507 - acc: 0.2017 - val_loss: 2.2541 - val_acc: 0.2071\n",
      "Epoch 55/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2497 - acc: 0.2047 - val_loss: 2.2535 - val_acc: 0.2062\n",
      "Epoch 56/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2489 - acc: 0.2100 - val_loss: 2.2527 - val_acc: 0.2125\n",
      "Epoch 57/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2481 - acc: 0.2097 - val_loss: 2.2518 - val_acc: 0.2075\n",
      "Epoch 58/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2472 - acc: 0.2109 - val_loss: 2.2509 - val_acc: 0.2150\n",
      "Epoch 59/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2463 - acc: 0.2136 - val_loss: 2.2501 - val_acc: 0.2133\n",
      "Epoch 60/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2455 - acc: 0.2206 - val_loss: 2.2494 - val_acc: 0.2162\n",
      "Epoch 61/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2446 - acc: 0.2203 - val_loss: 2.2484 - val_acc: 0.2142\n",
      "Epoch 62/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2438 - acc: 0.2173 - val_loss: 2.2473 - val_acc: 0.2167\n",
      "Epoch 63/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2428 - acc: 0.2229 - val_loss: 2.2467 - val_acc: 0.2196\n",
      "Epoch 64/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2422 - acc: 0.2219 - val_loss: 2.2458 - val_acc: 0.2233\n",
      "Epoch 65/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2412 - acc: 0.2214 - val_loss: 2.2451 - val_acc: 0.2225\n",
      "Epoch 66/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2404 - acc: 0.2302 - val_loss: 2.2441 - val_acc: 0.2242\n",
      "Epoch 67/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2395 - acc: 0.2227 - val_loss: 2.2434 - val_acc: 0.2196\n",
      "Epoch 68/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2387 - acc: 0.2317 - val_loss: 2.2425 - val_acc: 0.2225\n",
      "Epoch 69/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2378 - acc: 0.2296 - val_loss: 2.2421 - val_acc: 0.2242\n",
      "Epoch 70/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2370 - acc: 0.2318 - val_loss: 2.2409 - val_acc: 0.2233\n",
      "Epoch 71/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2362 - acc: 0.2343 - val_loss: 2.2401 - val_acc: 0.2233\n",
      "Epoch 72/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2353 - acc: 0.2315 - val_loss: 2.2395 - val_acc: 0.2263\n",
      "Epoch 73/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2345 - acc: 0.2359 - val_loss: 2.2386 - val_acc: 0.2258\n",
      "Epoch 74/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2337 - acc: 0.2341 - val_loss: 2.2380 - val_acc: 0.2300\n",
      "Epoch 75/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2329 - acc: 0.2319 - val_loss: 2.2370 - val_acc: 0.2287\n",
      "Epoch 76/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2320 - acc: 0.2440 - val_loss: 2.2362 - val_acc: 0.2292\n",
      "Epoch 77/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2312 - acc: 0.2332 - val_loss: 2.2353 - val_acc: 0.2279\n",
      "Epoch 78/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2304 - acc: 0.2350 - val_loss: 2.2348 - val_acc: 0.2313\n",
      "Epoch 79/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2296 - acc: 0.2424 - val_loss: 2.2338 - val_acc: 0.2367\n",
      "Epoch 80/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2287 - acc: 0.2467 - val_loss: 2.2328 - val_acc: 0.2371\n",
      "Epoch 81/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2279 - acc: 0.2465 - val_loss: 2.2319 - val_acc: 0.2350\n",
      "Epoch 82/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2271 - acc: 0.2429 - val_loss: 2.2313 - val_acc: 0.2338\n",
      "Epoch 83/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2262 - acc: 0.2433 - val_loss: 2.2305 - val_acc: 0.2354\n",
      "Epoch 84/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2254 - acc: 0.2473 - val_loss: 2.2298 - val_acc: 0.2367\n",
      "Epoch 85/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2247 - acc: 0.2530 - val_loss: 2.2290 - val_acc: 0.2379\n",
      "Epoch 86/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2239 - acc: 0.2506 - val_loss: 2.2284 - val_acc: 0.2354\n",
      "Epoch 87/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2230 - acc: 0.2435 - val_loss: 2.2274 - val_acc: 0.2400\n",
      "Epoch 88/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2223 - acc: 0.2426 - val_loss: 2.2267 - val_acc: 0.2358\n",
      "Epoch 89/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 2.2214 - acc: 0.2530 - val_loss: 2.2258 - val_acc: 0.2412\n",
      "Epoch 90/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 2.2207 - acc: 0.2456 - val_loss: 2.2252 - val_acc: 0.2400\n",
      "Epoch 91/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2200 - acc: 0.2598 - val_loss: 2.2245 - val_acc: 0.2504\n",
      "Epoch 92/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.2191 - acc: 0.2458 - val_loss: 2.2235 - val_acc: 0.2375\n",
      "Epoch 93/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2183 - acc: 0.2499 - val_loss: 2.2227 - val_acc: 0.2521\n",
      "Epoch 94/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2175 - acc: 0.2605 - val_loss: 2.2221 - val_acc: 0.2446\n",
      "Epoch 95/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 2.2168 - acc: 0.2542 - val_loss: 2.2214 - val_acc: 0.2508\n",
      "Epoch 96/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 2.2159 - acc: 0.2582 - val_loss: 2.2207 - val_acc: 0.2479\n",
      "Epoch 97/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.2151 - acc: 0.2535 - val_loss: 2.2196 - val_acc: 0.2512\n",
      "Epoch 98/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2143 - acc: 0.2586 - val_loss: 2.2190 - val_acc: 0.2500\n",
      "Epoch 99/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2136 - acc: 0.2600 - val_loss: 2.2182 - val_acc: 0.2542\n",
      "Epoch 100/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2128 - acc: 0.2558 - val_loss: 2.2176 - val_acc: 0.2504\n",
      "Epoch 101/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2121 - acc: 0.2560 - val_loss: 2.2166 - val_acc: 0.2558\n",
      "Epoch 102/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2113 - acc: 0.2672 - val_loss: 2.2162 - val_acc: 0.2587\n",
      "Epoch 103/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2106 - acc: 0.2643 - val_loss: 2.2154 - val_acc: 0.2529\n",
      "Epoch 104/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2097 - acc: 0.2595 - val_loss: 2.2145 - val_acc: 0.2571\n",
      "Epoch 105/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2090 - acc: 0.2597 - val_loss: 2.2139 - val_acc: 0.2562\n",
      "Epoch 106/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2082 - acc: 0.2686 - val_loss: 2.2132 - val_acc: 0.2608\n",
      "Epoch 107/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2075 - acc: 0.2658 - val_loss: 2.2124 - val_acc: 0.2633\n",
      "Epoch 108/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 2.2067 - acc: 0.2645 - val_loss: 2.2117 - val_acc: 0.2646\n",
      "Epoch 109/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2059 - acc: 0.2686 - val_loss: 2.2108 - val_acc: 0.2612\n",
      "Epoch 110/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.2052 - acc: 0.2614 - val_loss: 2.2101 - val_acc: 0.2604\n",
      "Epoch 111/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2045 - acc: 0.2716 - val_loss: 2.2094 - val_acc: 0.2617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 2.2037 - acc: 0.2660 - val_loss: 2.2087 - val_acc: 0.2696\n",
      "Epoch 113/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.2030 - acc: 0.2645 - val_loss: 2.2078 - val_acc: 0.2621\n",
      "Epoch 114/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.2022 - acc: 0.2716 - val_loss: 2.2071 - val_acc: 0.2650\n",
      "Epoch 115/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2015 - acc: 0.2722 - val_loss: 2.2063 - val_acc: 0.2667\n",
      "Epoch 116/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.2007 - acc: 0.2704 - val_loss: 2.2058 - val_acc: 0.2696\n",
      "Epoch 117/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.2000 - acc: 0.2714 - val_loss: 2.2052 - val_acc: 0.2683\n",
      "Epoch 118/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1993 - acc: 0.2677 - val_loss: 2.2042 - val_acc: 0.2683\n",
      "Epoch 119/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1985 - acc: 0.2785 - val_loss: 2.2035 - val_acc: 0.2708\n",
      "Epoch 120/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1977 - acc: 0.2768 - val_loss: 2.2031 - val_acc: 0.2733\n",
      "Epoch 121/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1970 - acc: 0.2683 - val_loss: 2.2022 - val_acc: 0.2662\n",
      "Epoch 122/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1963 - acc: 0.2761 - val_loss: 2.2014 - val_acc: 0.2704\n",
      "Epoch 123/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1955 - acc: 0.2725 - val_loss: 2.2006 - val_acc: 0.2671\n",
      "Epoch 124/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1947 - acc: 0.2728 - val_loss: 2.2002 - val_acc: 0.2742\n",
      "Epoch 125/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1940 - acc: 0.2742 - val_loss: 2.1994 - val_acc: 0.2725\n",
      "Epoch 126/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1933 - acc: 0.2739 - val_loss: 2.1987 - val_acc: 0.2717\n",
      "Epoch 127/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 2.1926 - acc: 0.2814 - val_loss: 2.1979 - val_acc: 0.2729\n",
      "Epoch 128/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 2.1919 - acc: 0.2794 - val_loss: 2.1972 - val_acc: 0.2717\n",
      "Epoch 129/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.1912 - acc: 0.2747 - val_loss: 2.1966 - val_acc: 0.2687\n",
      "Epoch 130/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 2.1904 - acc: 0.2785 - val_loss: 2.1961 - val_acc: 0.2746\n",
      "Epoch 131/50000\n",
      "9600/9600 [==============================] - 0s 26us/step - loss: 2.1897 - acc: 0.2732 - val_loss: 2.1952 - val_acc: 0.2750\n",
      "Epoch 132/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1891 - acc: 0.2783 - val_loss: 2.1946 - val_acc: 0.2742\n",
      "Epoch 133/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1883 - acc: 0.2794 - val_loss: 2.1938 - val_acc: 0.2771\n",
      "Epoch 134/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1875 - acc: 0.2805 - val_loss: 2.1931 - val_acc: 0.2779\n",
      "Epoch 135/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1869 - acc: 0.2814 - val_loss: 2.1923 - val_acc: 0.2729\n",
      "Epoch 136/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1862 - acc: 0.2833 - val_loss: 2.1916 - val_acc: 0.2746\n",
      "Epoch 137/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1855 - acc: 0.2817 - val_loss: 2.1911 - val_acc: 0.2771\n",
      "Epoch 138/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1848 - acc: 0.2772 - val_loss: 2.1905 - val_acc: 0.2775\n",
      "Epoch 139/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1840 - acc: 0.2804 - val_loss: 2.1898 - val_acc: 0.2754\n",
      "Epoch 140/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1833 - acc: 0.2828 - val_loss: 2.1892 - val_acc: 0.2771\n",
      "Epoch 141/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1826 - acc: 0.2834 - val_loss: 2.1883 - val_acc: 0.2808\n",
      "Epoch 142/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1819 - acc: 0.2846 - val_loss: 2.1881 - val_acc: 0.2767\n",
      "Epoch 143/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1812 - acc: 0.2847 - val_loss: 2.1872 - val_acc: 0.2725\n",
      "Epoch 144/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1805 - acc: 0.2886 - val_loss: 2.1864 - val_acc: 0.2750\n",
      "Epoch 145/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1798 - acc: 0.2859 - val_loss: 2.1858 - val_acc: 0.2787\n",
      "Epoch 146/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1791 - acc: 0.2838 - val_loss: 2.1851 - val_acc: 0.2758\n",
      "Epoch 147/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1784 - acc: 0.2824 - val_loss: 2.1843 - val_acc: 0.2771\n",
      "Epoch 148/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1777 - acc: 0.2840 - val_loss: 2.1837 - val_acc: 0.2796\n",
      "Epoch 149/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1770 - acc: 0.2864 - val_loss: 2.1831 - val_acc: 0.2783\n",
      "Epoch 150/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 2.1763 - acc: 0.2881 - val_loss: 2.1823 - val_acc: 0.2758\n",
      "Epoch 151/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1756 - acc: 0.2874 - val_loss: 2.1817 - val_acc: 0.2821\n",
      "Epoch 152/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1749 - acc: 0.2878 - val_loss: 2.1810 - val_acc: 0.2812\n",
      "Epoch 153/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1743 - acc: 0.2886 - val_loss: 2.1804 - val_acc: 0.2804\n",
      "Epoch 154/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1734 - acc: 0.2893 - val_loss: 2.1796 - val_acc: 0.2817\n",
      "Epoch 155/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1728 - acc: 0.2867 - val_loss: 2.1788 - val_acc: 0.2800\n",
      "Epoch 156/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1722 - acc: 0.2898 - val_loss: 2.1782 - val_acc: 0.2804\n",
      "Epoch 157/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1714 - acc: 0.2901 - val_loss: 2.1774 - val_acc: 0.2833\n",
      "Epoch 158/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1707 - acc: 0.2901 - val_loss: 2.1769 - val_acc: 0.2825\n",
      "Epoch 159/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1700 - acc: 0.2903 - val_loss: 2.1764 - val_acc: 0.2837\n",
      "Epoch 160/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 2.1693 - acc: 0.2893 - val_loss: 2.1756 - val_acc: 0.2833\n",
      "Epoch 161/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.1686 - acc: 0.2924 - val_loss: 2.1750 - val_acc: 0.2829\n",
      "Epoch 162/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1680 - acc: 0.2922 - val_loss: 2.1744 - val_acc: 0.2850\n",
      "Epoch 163/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1673 - acc: 0.2899 - val_loss: 2.1737 - val_acc: 0.2850\n",
      "Epoch 164/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1666 - acc: 0.2946 - val_loss: 2.1730 - val_acc: 0.2858\n",
      "Epoch 165/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1659 - acc: 0.2922 - val_loss: 2.1726 - val_acc: 0.2825\n",
      "Epoch 166/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1652 - acc: 0.2932 - val_loss: 2.1720 - val_acc: 0.2854\n",
      "Epoch 167/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1646 - acc: 0.2935 - val_loss: 2.1713 - val_acc: 0.2808\n",
      "Epoch 168/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1639 - acc: 0.2918 - val_loss: 2.1705 - val_acc: 0.2779\n",
      "Epoch 169/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 2.1633 - acc: 0.2939 - val_loss: 2.1699 - val_acc: 0.2850\n",
      "Epoch 170/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.1625 - acc: 0.2922 - val_loss: 2.1693 - val_acc: 0.2825\n",
      "Epoch 171/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1619 - acc: 0.2979 - val_loss: 2.1685 - val_acc: 0.2858\n",
      "Epoch 172/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1612 - acc: 0.2923 - val_loss: 2.1679 - val_acc: 0.2833\n",
      "Epoch 173/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1606 - acc: 0.2942 - val_loss: 2.1671 - val_acc: 0.2821\n",
      "Epoch 174/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1599 - acc: 0.2965 - val_loss: 2.1667 - val_acc: 0.2887\n",
      "Epoch 175/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1592 - acc: 0.2943 - val_loss: 2.1660 - val_acc: 0.2825\n",
      "Epoch 176/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1585 - acc: 0.2942 - val_loss: 2.1655 - val_acc: 0.2908\n",
      "Epoch 177/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1579 - acc: 0.2963 - val_loss: 2.1647 - val_acc: 0.2842\n",
      "Epoch 178/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1572 - acc: 0.2963 - val_loss: 2.1641 - val_acc: 0.2842\n",
      "Epoch 179/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1566 - acc: 0.2981 - val_loss: 2.1635 - val_acc: 0.2850\n",
      "Epoch 180/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1559 - acc: 0.2954 - val_loss: 2.1628 - val_acc: 0.2842\n",
      "Epoch 181/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1552 - acc: 0.2999 - val_loss: 2.1623 - val_acc: 0.2850\n",
      "Epoch 182/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1546 - acc: 0.2977 - val_loss: 2.1617 - val_acc: 0.2867\n",
      "Epoch 183/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1539 - acc: 0.2969 - val_loss: 2.1612 - val_acc: 0.2846\n",
      "Epoch 184/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1533 - acc: 0.2970 - val_loss: 2.1604 - val_acc: 0.2900\n",
      "Epoch 185/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1527 - acc: 0.3029 - val_loss: 2.1599 - val_acc: 0.2858\n",
      "Epoch 186/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1519 - acc: 0.2976 - val_loss: 2.1592 - val_acc: 0.2842\n",
      "Epoch 187/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1513 - acc: 0.2963 - val_loss: 2.1586 - val_acc: 0.2883\n",
      "Epoch 188/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.1507 - acc: 0.2972 - val_loss: 2.1581 - val_acc: 0.2867\n",
      "Epoch 189/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1501 - acc: 0.2979 - val_loss: 2.1574 - val_acc: 0.2854\n",
      "Epoch 190/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1494 - acc: 0.2998 - val_loss: 2.1566 - val_acc: 0.2871\n",
      "Epoch 191/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1488 - acc: 0.3004 - val_loss: 2.1561 - val_acc: 0.2892\n",
      "Epoch 192/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1482 - acc: 0.2989 - val_loss: 2.1554 - val_acc: 0.2879\n",
      "Epoch 193/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1475 - acc: 0.3004 - val_loss: 2.1549 - val_acc: 0.2900\n",
      "Epoch 194/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1469 - acc: 0.3007 - val_loss: 2.1546 - val_acc: 0.2912\n",
      "Epoch 195/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1462 - acc: 0.3008 - val_loss: 2.1537 - val_acc: 0.2879\n",
      "Epoch 196/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1455 - acc: 0.3009 - val_loss: 2.1532 - val_acc: 0.2904\n",
      "Epoch 197/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1450 - acc: 0.3025 - val_loss: 2.1523 - val_acc: 0.2871\n",
      "Epoch 198/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1443 - acc: 0.3023 - val_loss: 2.1521 - val_acc: 0.2908\n",
      "Epoch 199/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1437 - acc: 0.3006 - val_loss: 2.1512 - val_acc: 0.2883\n",
      "Epoch 200/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1431 - acc: 0.3022 - val_loss: 2.1509 - val_acc: 0.2858\n",
      "Epoch 201/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1424 - acc: 0.3001 - val_loss: 2.1502 - val_acc: 0.2900\n",
      "Epoch 202/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1419 - acc: 0.3045 - val_loss: 2.1497 - val_acc: 0.2912\n",
      "Epoch 203/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1412 - acc: 0.3047 - val_loss: 2.1487 - val_acc: 0.2925\n",
      "Epoch 204/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1406 - acc: 0.3026 - val_loss: 2.1484 - val_acc: 0.2896\n",
      "Epoch 205/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1400 - acc: 0.3064 - val_loss: 2.1478 - val_acc: 0.2879\n",
      "Epoch 206/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1394 - acc: 0.3046 - val_loss: 2.1474 - val_acc: 0.2925\n",
      "Epoch 207/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1387 - acc: 0.3022 - val_loss: 2.1467 - val_acc: 0.2900\n",
      "Epoch 208/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1381 - acc: 0.3053 - val_loss: 2.1461 - val_acc: 0.2921\n",
      "Epoch 209/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1375 - acc: 0.3049 - val_loss: 2.1455 - val_acc: 0.2921\n",
      "Epoch 210/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1368 - acc: 0.3088 - val_loss: 2.1450 - val_acc: 0.2925\n",
      "Epoch 211/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1362 - acc: 0.3050 - val_loss: 2.1443 - val_acc: 0.2883\n",
      "Epoch 212/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1357 - acc: 0.3062 - val_loss: 2.1439 - val_acc: 0.2942\n",
      "Epoch 213/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1351 - acc: 0.3051 - val_loss: 2.1431 - val_acc: 0.2921\n",
      "Epoch 214/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1345 - acc: 0.3086 - val_loss: 2.1426 - val_acc: 0.2946\n",
      "Epoch 215/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1339 - acc: 0.3073 - val_loss: 2.1417 - val_acc: 0.2896\n",
      "Epoch 216/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1332 - acc: 0.3068 - val_loss: 2.1417 - val_acc: 0.2921\n",
      "Epoch 217/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1326 - acc: 0.3057 - val_loss: 2.1409 - val_acc: 0.2921\n",
      "Epoch 218/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1320 - acc: 0.3082 - val_loss: 2.1404 - val_acc: 0.2958\n",
      "Epoch 219/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1314 - acc: 0.3062 - val_loss: 2.1396 - val_acc: 0.2929\n",
      "Epoch 220/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1308 - acc: 0.3084 - val_loss: 2.1393 - val_acc: 0.2921\n",
      "Epoch 221/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1302 - acc: 0.3120 - val_loss: 2.1385 - val_acc: 0.2950\n",
      "Epoch 222/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1296 - acc: 0.3088 - val_loss: 2.1381 - val_acc: 0.2962\n",
      "Epoch 223/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1290 - acc: 0.3103 - val_loss: 2.1372 - val_acc: 0.2937\n",
      "Epoch 224/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1284 - acc: 0.3088 - val_loss: 2.1369 - val_acc: 0.2946\n",
      "Epoch 225/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1279 - acc: 0.3119 - val_loss: 2.1364 - val_acc: 0.2942\n",
      "Epoch 226/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1273 - acc: 0.3105 - val_loss: 2.1360 - val_acc: 0.2900\n",
      "Epoch 227/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1267 - acc: 0.3107 - val_loss: 2.1354 - val_acc: 0.2925\n",
      "Epoch 228/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1261 - acc: 0.3081 - val_loss: 2.1348 - val_acc: 0.2917\n",
      "Epoch 229/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1255 - acc: 0.3117 - val_loss: 2.1342 - val_acc: 0.2962\n",
      "Epoch 230/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1249 - acc: 0.3136 - val_loss: 2.1336 - val_acc: 0.2950\n",
      "Epoch 231/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.1243 - acc: 0.3117 - val_loss: 2.1331 - val_acc: 0.2958\n",
      "Epoch 232/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1238 - acc: 0.3091 - val_loss: 2.1324 - val_acc: 0.2929\n",
      "Epoch 233/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1231 - acc: 0.3107 - val_loss: 2.1318 - val_acc: 0.2975\n",
      "Epoch 234/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1226 - acc: 0.3141 - val_loss: 2.1316 - val_acc: 0.2958\n",
      "Epoch 235/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1220 - acc: 0.3109 - val_loss: 2.1308 - val_acc: 0.2937\n",
      "Epoch 236/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1213 - acc: 0.3126 - val_loss: 2.1303 - val_acc: 0.2967\n",
      "Epoch 237/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1208 - acc: 0.3126 - val_loss: 2.1298 - val_acc: 0.2925\n",
      "Epoch 238/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.1202 - acc: 0.3130 - val_loss: 2.1292 - val_acc: 0.2946\n",
      "Epoch 239/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1197 - acc: 0.3132 - val_loss: 2.1290 - val_acc: 0.2938\n",
      "Epoch 240/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1191 - acc: 0.3141 - val_loss: 2.1283 - val_acc: 0.2958\n",
      "Epoch 241/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1185 - acc: 0.3123 - val_loss: 2.1277 - val_acc: 0.2942\n",
      "Epoch 242/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1179 - acc: 0.3136 - val_loss: 2.1271 - val_acc: 0.2942\n",
      "Epoch 243/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1174 - acc: 0.3147 - val_loss: 2.1268 - val_acc: 0.2925\n",
      "Epoch 244/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1168 - acc: 0.3140 - val_loss: 2.1258 - val_acc: 0.2937\n",
      "Epoch 245/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1162 - acc: 0.3160 - val_loss: 2.1257 - val_acc: 0.2938\n",
      "Epoch 246/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1157 - acc: 0.3123 - val_loss: 2.1250 - val_acc: 0.2933\n",
      "Epoch 247/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1152 - acc: 0.3129 - val_loss: 2.1244 - val_acc: 0.2933\n",
      "Epoch 248/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1146 - acc: 0.3160 - val_loss: 2.1241 - val_acc: 0.2979\n",
      "Epoch 249/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1140 - acc: 0.3153 - val_loss: 2.1235 - val_acc: 0.2963\n",
      "Epoch 250/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1135 - acc: 0.3172 - val_loss: 2.1229 - val_acc: 0.2963\n",
      "Epoch 251/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1129 - acc: 0.3168 - val_loss: 2.1225 - val_acc: 0.2979\n",
      "Epoch 252/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1123 - acc: 0.3157 - val_loss: 2.1218 - val_acc: 0.2987\n",
      "Epoch 253/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1118 - acc: 0.3148 - val_loss: 2.1211 - val_acc: 0.2954\n",
      "Epoch 254/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1112 - acc: 0.3165 - val_loss: 2.1209 - val_acc: 0.2962\n",
      "Epoch 255/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1107 - acc: 0.3156 - val_loss: 2.1205 - val_acc: 0.2950\n",
      "Epoch 256/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1101 - acc: 0.3140 - val_loss: 2.1198 - val_acc: 0.2958\n",
      "Epoch 257/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1095 - acc: 0.3154 - val_loss: 2.1192 - val_acc: 0.2971\n",
      "Epoch 258/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1090 - acc: 0.3172 - val_loss: 2.1189 - val_acc: 0.3042\n",
      "Epoch 259/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1084 - acc: 0.3193 - val_loss: 2.1182 - val_acc: 0.2971\n",
      "Epoch 260/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.1079 - acc: 0.3192 - val_loss: 2.1177 - val_acc: 0.2962\n",
      "Epoch 261/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1073 - acc: 0.3180 - val_loss: 2.1173 - val_acc: 0.2967\n",
      "Epoch 262/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1068 - acc: 0.3168 - val_loss: 2.1168 - val_acc: 0.2950\n",
      "Epoch 263/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1062 - acc: 0.3179 - val_loss: 2.1161 - val_acc: 0.2967\n",
      "Epoch 264/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1057 - acc: 0.3174 - val_loss: 2.1156 - val_acc: 0.2967\n",
      "Epoch 265/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1051 - acc: 0.3184 - val_loss: 2.1153 - val_acc: 0.2992\n",
      "Epoch 266/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1047 - acc: 0.3177 - val_loss: 2.1149 - val_acc: 0.2988\n",
      "Epoch 267/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.1040 - acc: 0.3202 - val_loss: 2.1141 - val_acc: 0.2954\n",
      "Epoch 268/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1035 - acc: 0.3183 - val_loss: 2.1137 - val_acc: 0.2975\n",
      "Epoch 269/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1029 - acc: 0.3206 - val_loss: 2.1131 - val_acc: 0.3021\n",
      "Epoch 270/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1025 - acc: 0.3189 - val_loss: 2.1128 - val_acc: 0.3050\n",
      "Epoch 271/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1019 - acc: 0.3173 - val_loss: 2.1123 - val_acc: 0.3025\n",
      "Epoch 272/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1014 - acc: 0.3228 - val_loss: 2.1116 - val_acc: 0.3013\n",
      "Epoch 273/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1008 - acc: 0.3208 - val_loss: 2.1113 - val_acc: 0.3025\n",
      "Epoch 274/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.1003 - acc: 0.3191 - val_loss: 2.1107 - val_acc: 0.2992\n",
      "Epoch 275/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0997 - acc: 0.3215 - val_loss: 2.1102 - val_acc: 0.3004\n",
      "Epoch 276/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0992 - acc: 0.3226 - val_loss: 2.1096 - val_acc: 0.3017\n",
      "Epoch 277/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0986 - acc: 0.3217 - val_loss: 2.1093 - val_acc: 0.3000\n",
      "Epoch 278/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0982 - acc: 0.3196 - val_loss: 2.1087 - val_acc: 0.3013\n",
      "Epoch 279/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0976 - acc: 0.3218 - val_loss: 2.1082 - val_acc: 0.3021\n",
      "Epoch 280/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0971 - acc: 0.3221 - val_loss: 2.1076 - val_acc: 0.2983\n",
      "Epoch 281/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0966 - acc: 0.3226 - val_loss: 2.1073 - val_acc: 0.3017\n",
      "Epoch 282/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0961 - acc: 0.3214 - val_loss: 2.1068 - val_acc: 0.2988\n",
      "Epoch 283/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0955 - acc: 0.3219 - val_loss: 2.1064 - val_acc: 0.3033\n",
      "Epoch 284/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0950 - acc: 0.3229 - val_loss: 2.1055 - val_acc: 0.3013\n",
      "Epoch 285/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0945 - acc: 0.3231 - val_loss: 2.1053 - val_acc: 0.3025\n",
      "Epoch 286/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0939 - acc: 0.3225 - val_loss: 2.1047 - val_acc: 0.3021\n",
      "Epoch 287/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0935 - acc: 0.3230 - val_loss: 2.1042 - val_acc: 0.3029\n",
      "Epoch 288/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0929 - acc: 0.3220 - val_loss: 2.1038 - val_acc: 0.3029\n",
      "Epoch 289/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0925 - acc: 0.3217 - val_loss: 2.1035 - val_acc: 0.3042\n",
      "Epoch 290/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0919 - acc: 0.3244 - val_loss: 2.1031 - val_acc: 0.3025\n",
      "Epoch 291/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0914 - acc: 0.3232 - val_loss: 2.1025 - val_acc: 0.3050\n",
      "Epoch 292/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0909 - acc: 0.3239 - val_loss: 2.1015 - val_acc: 0.3042\n",
      "Epoch 293/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0903 - acc: 0.3247 - val_loss: 2.1014 - val_acc: 0.3046\n",
      "Epoch 294/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0898 - acc: 0.3241 - val_loss: 2.1009 - val_acc: 0.3033\n",
      "Epoch 295/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0892 - acc: 0.3261 - val_loss: 2.1002 - val_acc: 0.3029\n",
      "Epoch 296/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0888 - acc: 0.3249 - val_loss: 2.0998 - val_acc: 0.3033\n",
      "Epoch 297/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0884 - acc: 0.3250 - val_loss: 2.0997 - val_acc: 0.3025\n",
      "Epoch 298/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0878 - acc: 0.3283 - val_loss: 2.0990 - val_acc: 0.3038\n",
      "Epoch 299/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0873 - acc: 0.3230 - val_loss: 2.0987 - val_acc: 0.3013\n",
      "Epoch 300/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0868 - acc: 0.3256 - val_loss: 2.0981 - val_acc: 0.3046\n",
      "Epoch 301/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0862 - acc: 0.3265 - val_loss: 2.0976 - val_acc: 0.3029\n",
      "Epoch 302/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 2.0857 - acc: 0.3251 - val_loss: 2.0973 - val_acc: 0.3042\n",
      "Epoch 303/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0852 - acc: 0.3232 - val_loss: 2.0968 - val_acc: 0.3054\n",
      "Epoch 304/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0847 - acc: 0.3259 - val_loss: 2.0963 - val_acc: 0.3050\n",
      "Epoch 305/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0843 - acc: 0.3263 - val_loss: 2.0960 - val_acc: 0.3038\n",
      "Epoch 306/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0838 - acc: 0.3297 - val_loss: 2.0956 - val_acc: 0.3042\n",
      "Epoch 307/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0833 - acc: 0.3241 - val_loss: 2.0949 - val_acc: 0.3046\n",
      "Epoch 308/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0828 - acc: 0.3266 - val_loss: 2.0943 - val_acc: 0.3029\n",
      "Epoch 309/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0822 - acc: 0.3261 - val_loss: 2.0940 - val_acc: 0.3058\n",
      "Epoch 310/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0817 - acc: 0.3269 - val_loss: 2.0935 - val_acc: 0.3050\n",
      "Epoch 311/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0813 - acc: 0.3270 - val_loss: 2.0931 - val_acc: 0.3050\n",
      "Epoch 312/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0807 - acc: 0.3277 - val_loss: 2.0929 - val_acc: 0.3021\n",
      "Epoch 313/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0802 - acc: 0.3276 - val_loss: 2.0922 - val_acc: 0.3042\n",
      "Epoch 314/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0798 - acc: 0.3269 - val_loss: 2.0918 - val_acc: 0.3042\n",
      "Epoch 315/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0792 - acc: 0.3295 - val_loss: 2.0913 - val_acc: 0.3025\n",
      "Epoch 316/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0787 - acc: 0.3271 - val_loss: 2.0906 - val_acc: 0.3058\n",
      "Epoch 317/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0783 - acc: 0.3257 - val_loss: 2.0905 - val_acc: 0.3046\n",
      "Epoch 318/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0778 - acc: 0.3272 - val_loss: 2.0900 - val_acc: 0.3054\n",
      "Epoch 319/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0773 - acc: 0.3284 - val_loss: 2.0895 - val_acc: 0.3067\n",
      "Epoch 320/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0768 - acc: 0.3282 - val_loss: 2.0892 - val_acc: 0.3067\n",
      "Epoch 321/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0763 - acc: 0.3285 - val_loss: 2.0886 - val_acc: 0.3042\n",
      "Epoch 322/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0759 - acc: 0.3287 - val_loss: 2.0883 - val_acc: 0.3071\n",
      "Epoch 323/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.0754 - acc: 0.3300 - val_loss: 2.0877 - val_acc: 0.3075\n",
      "Epoch 324/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0749 - acc: 0.3301 - val_loss: 2.0873 - val_acc: 0.3042\n",
      "Epoch 325/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0744 - acc: 0.3287 - val_loss: 2.0869 - val_acc: 0.3042\n",
      "Epoch 326/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0739 - acc: 0.3297 - val_loss: 2.0863 - val_acc: 0.3058\n",
      "Epoch 327/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0734 - acc: 0.3275 - val_loss: 2.0860 - val_acc: 0.3054\n",
      "Epoch 328/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0729 - acc: 0.3289 - val_loss: 2.0855 - val_acc: 0.3058\n",
      "Epoch 329/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0725 - acc: 0.3279 - val_loss: 2.0851 - val_acc: 0.3038\n",
      "Epoch 330/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0720 - acc: 0.3302 - val_loss: 2.0846 - val_acc: 0.3067\n",
      "Epoch 331/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 2.0715 - acc: 0.3279 - val_loss: 2.0844 - val_acc: 0.3058\n",
      "Epoch 332/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0711 - acc: 0.3331 - val_loss: 2.0839 - val_acc: 0.3067\n",
      "Epoch 333/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0707 - acc: 0.3316 - val_loss: 2.0834 - val_acc: 0.3038\n",
      "Epoch 334/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0701 - acc: 0.3328 - val_loss: 2.0829 - val_acc: 0.3046\n",
      "Epoch 335/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0697 - acc: 0.3305 - val_loss: 2.0826 - val_acc: 0.3075\n",
      "Epoch 336/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.0692 - acc: 0.3307 - val_loss: 2.0822 - val_acc: 0.3071\n",
      "Epoch 337/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0687 - acc: 0.3303 - val_loss: 2.0816 - val_acc: 0.3046\n",
      "Epoch 338/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0682 - acc: 0.3312 - val_loss: 2.0813 - val_acc: 0.3075\n",
      "Epoch 339/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0678 - acc: 0.3295 - val_loss: 2.0805 - val_acc: 0.3042\n",
      "Epoch 340/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0673 - acc: 0.3295 - val_loss: 2.0805 - val_acc: 0.3083\n",
      "Epoch 341/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0668 - acc: 0.3339 - val_loss: 2.0799 - val_acc: 0.3067\n",
      "Epoch 342/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0664 - acc: 0.3333 - val_loss: 2.0795 - val_acc: 0.3063\n",
      "Epoch 343/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0659 - acc: 0.3320 - val_loss: 2.0792 - val_acc: 0.3079\n",
      "Epoch 344/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0654 - acc: 0.3311 - val_loss: 2.0787 - val_acc: 0.3079\n",
      "Epoch 345/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0650 - acc: 0.3305 - val_loss: 2.0783 - val_acc: 0.3062\n",
      "Epoch 346/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0646 - acc: 0.3306 - val_loss: 2.0778 - val_acc: 0.3083\n",
      "Epoch 347/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0641 - acc: 0.3333 - val_loss: 2.0775 - val_acc: 0.3083\n",
      "Epoch 348/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0636 - acc: 0.3328 - val_loss: 2.0769 - val_acc: 0.3083\n",
      "Epoch 349/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0632 - acc: 0.3321 - val_loss: 2.0766 - val_acc: 0.3075\n",
      "Epoch 350/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0627 - acc: 0.3326 - val_loss: 2.0762 - val_acc: 0.3083\n",
      "Epoch 351/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0622 - acc: 0.3327 - val_loss: 2.0758 - val_acc: 0.3071\n",
      "Epoch 352/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0618 - acc: 0.3324 - val_loss: 2.0755 - val_acc: 0.3096\n",
      "Epoch 353/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0613 - acc: 0.3319 - val_loss: 2.0750 - val_acc: 0.3092\n",
      "Epoch 354/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0609 - acc: 0.3349 - val_loss: 2.0745 - val_acc: 0.3079\n",
      "Epoch 355/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0604 - acc: 0.3346 - val_loss: 2.0740 - val_acc: 0.3088\n",
      "Epoch 356/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0599 - acc: 0.3311 - val_loss: 2.0738 - val_acc: 0.3087\n",
      "Epoch 357/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0595 - acc: 0.3333 - val_loss: 2.0735 - val_acc: 0.3108\n",
      "Epoch 358/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0591 - acc: 0.3353 - val_loss: 2.0728 - val_acc: 0.3108\n",
      "Epoch 359/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0586 - acc: 0.3341 - val_loss: 2.0723 - val_acc: 0.3100\n",
      "Epoch 360/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0582 - acc: 0.3336 - val_loss: 2.0721 - val_acc: 0.3117\n",
      "Epoch 361/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0577 - acc: 0.3315 - val_loss: 2.0717 - val_acc: 0.3088\n",
      "Epoch 362/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0573 - acc: 0.3342 - val_loss: 2.0713 - val_acc: 0.3121\n",
      "Epoch 363/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0568 - acc: 0.3339 - val_loss: 2.0708 - val_acc: 0.3108\n",
      "Epoch 364/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0564 - acc: 0.3353 - val_loss: 2.0706 - val_acc: 0.3113\n",
      "Epoch 365/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0559 - acc: 0.3337 - val_loss: 2.0698 - val_acc: 0.3079\n",
      "Epoch 366/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0555 - acc: 0.3334 - val_loss: 2.0694 - val_acc: 0.3108\n",
      "Epoch 367/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0550 - acc: 0.3365 - val_loss: 2.0692 - val_acc: 0.3121\n",
      "Epoch 368/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0546 - acc: 0.3349 - val_loss: 2.0688 - val_acc: 0.3121\n",
      "Epoch 369/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0541 - acc: 0.3355 - val_loss: 2.0686 - val_acc: 0.3125\n",
      "Epoch 370/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0537 - acc: 0.3351 - val_loss: 2.0679 - val_acc: 0.3129\n",
      "Epoch 371/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0533 - acc: 0.3356 - val_loss: 2.0677 - val_acc: 0.3113\n",
      "Epoch 372/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0528 - acc: 0.3356 - val_loss: 2.0673 - val_acc: 0.3129\n",
      "Epoch 373/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0524 - acc: 0.3351 - val_loss: 2.0671 - val_acc: 0.3117\n",
      "Epoch 374/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0519 - acc: 0.3352 - val_loss: 2.0664 - val_acc: 0.3137\n",
      "Epoch 375/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0516 - acc: 0.3367 - val_loss: 2.0661 - val_acc: 0.3133\n",
      "Epoch 376/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0511 - acc: 0.3371 - val_loss: 2.0656 - val_acc: 0.3117\n",
      "Epoch 377/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0507 - acc: 0.3359 - val_loss: 2.0650 - val_acc: 0.3137\n",
      "Epoch 378/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0502 - acc: 0.3365 - val_loss: 2.0647 - val_acc: 0.3129\n",
      "Epoch 379/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0498 - acc: 0.3360 - val_loss: 2.0645 - val_acc: 0.3138\n",
      "Epoch 380/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0493 - acc: 0.3368 - val_loss: 2.0638 - val_acc: 0.3133\n",
      "Epoch 381/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0489 - acc: 0.3382 - val_loss: 2.0636 - val_acc: 0.3137\n",
      "Epoch 382/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0485 - acc: 0.3354 - val_loss: 2.0633 - val_acc: 0.3142\n",
      "Epoch 383/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0481 - acc: 0.3369 - val_loss: 2.0629 - val_acc: 0.3129\n",
      "Epoch 384/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0477 - acc: 0.3358 - val_loss: 2.0624 - val_acc: 0.3133\n",
      "Epoch 385/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0472 - acc: 0.3366 - val_loss: 2.0621 - val_acc: 0.3167\n",
      "Epoch 386/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0468 - acc: 0.3372 - val_loss: 2.0617 - val_acc: 0.3142\n",
      "Epoch 387/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0464 - acc: 0.3382 - val_loss: 2.0615 - val_acc: 0.3108\n",
      "Epoch 388/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0460 - acc: 0.3368 - val_loss: 2.0609 - val_acc: 0.3150\n",
      "Epoch 389/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0455 - acc: 0.3378 - val_loss: 2.0606 - val_acc: 0.3150\n",
      "Epoch 390/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0450 - acc: 0.3373 - val_loss: 2.0604 - val_acc: 0.3121\n",
      "Epoch 391/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0447 - acc: 0.3379 - val_loss: 2.0600 - val_acc: 0.3146\n",
      "Epoch 392/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0443 - acc: 0.3355 - val_loss: 2.0596 - val_acc: 0.3133\n",
      "Epoch 393/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0438 - acc: 0.3385 - val_loss: 2.0592 - val_acc: 0.3125\n",
      "Epoch 394/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0434 - acc: 0.3377 - val_loss: 2.0588 - val_acc: 0.3162\n",
      "Epoch 395/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0430 - acc: 0.3399 - val_loss: 2.0587 - val_acc: 0.3150\n",
      "Epoch 396/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0426 - acc: 0.3386 - val_loss: 2.0584 - val_acc: 0.3129\n",
      "Epoch 397/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0421 - acc: 0.3386 - val_loss: 2.0576 - val_acc: 0.3129\n",
      "Epoch 398/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0417 - acc: 0.3374 - val_loss: 2.0574 - val_acc: 0.3137\n",
      "Epoch 399/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0413 - acc: 0.3400 - val_loss: 2.0568 - val_acc: 0.3158\n",
      "Epoch 400/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0409 - acc: 0.3382 - val_loss: 2.0566 - val_acc: 0.3133\n",
      "Epoch 401/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0405 - acc: 0.3380 - val_loss: 2.0563 - val_acc: 0.3150\n",
      "Epoch 402/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0401 - acc: 0.3416 - val_loss: 2.0556 - val_acc: 0.3167\n",
      "Epoch 403/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0397 - acc: 0.3391 - val_loss: 2.0552 - val_acc: 0.3137\n",
      "Epoch 404/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0393 - acc: 0.3373 - val_loss: 2.0550 - val_acc: 0.3154\n",
      "Epoch 405/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0389 - acc: 0.3408 - val_loss: 2.0547 - val_acc: 0.3150\n",
      "Epoch 406/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0384 - acc: 0.3412 - val_loss: 2.0543 - val_acc: 0.3137\n",
      "Epoch 407/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0380 - acc: 0.3417 - val_loss: 2.0542 - val_acc: 0.3167\n",
      "Epoch 408/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0377 - acc: 0.3425 - val_loss: 2.0537 - val_acc: 0.3150\n",
      "Epoch 409/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0372 - acc: 0.3412 - val_loss: 2.0534 - val_acc: 0.3154\n",
      "Epoch 410/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0367 - acc: 0.3392 - val_loss: 2.0530 - val_acc: 0.3163\n",
      "Epoch 411/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0364 - acc: 0.3394 - val_loss: 2.0526 - val_acc: 0.3133\n",
      "Epoch 412/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0359 - acc: 0.3422 - val_loss: 2.0521 - val_acc: 0.3138\n",
      "Epoch 413/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0355 - acc: 0.3405 - val_loss: 2.0517 - val_acc: 0.3162\n",
      "Epoch 414/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0352 - acc: 0.3404 - val_loss: 2.0512 - val_acc: 0.3158\n",
      "Epoch 415/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0348 - acc: 0.3408 - val_loss: 2.0511 - val_acc: 0.3150\n",
      "Epoch 416/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0343 - acc: 0.3416 - val_loss: 2.0506 - val_acc: 0.3171\n",
      "Epoch 417/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0339 - acc: 0.3412 - val_loss: 2.0505 - val_acc: 0.3162\n",
      "Epoch 418/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0335 - acc: 0.3418 - val_loss: 2.0500 - val_acc: 0.3158\n",
      "Epoch 419/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0331 - acc: 0.3424 - val_loss: 2.0496 - val_acc: 0.3150\n",
      "Epoch 420/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0328 - acc: 0.3415 - val_loss: 2.0495 - val_acc: 0.3171\n",
      "Epoch 421/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0324 - acc: 0.3387 - val_loss: 2.0487 - val_acc: 0.3183\n",
      "Epoch 422/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0321 - acc: 0.3408 - val_loss: 2.0485 - val_acc: 0.3179\n",
      "Epoch 423/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0315 - acc: 0.3444 - val_loss: 2.0481 - val_acc: 0.3175\n",
      "Epoch 424/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0311 - acc: 0.3410 - val_loss: 2.0477 - val_acc: 0.3167\n",
      "Epoch 425/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0307 - acc: 0.3416 - val_loss: 2.0474 - val_acc: 0.3183\n",
      "Epoch 426/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0303 - acc: 0.3419 - val_loss: 2.0472 - val_acc: 0.3183\n",
      "Epoch 427/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0299 - acc: 0.3434 - val_loss: 2.0466 - val_acc: 0.3188\n",
      "Epoch 428/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0295 - acc: 0.3453 - val_loss: 2.0464 - val_acc: 0.3175\n",
      "Epoch 429/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0292 - acc: 0.3421 - val_loss: 2.0460 - val_acc: 0.3167\n",
      "Epoch 430/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 2.0287 - acc: 0.3430 - val_loss: 2.0457 - val_acc: 0.3175\n",
      "Epoch 431/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0284 - acc: 0.3446 - val_loss: 2.0454 - val_acc: 0.3196\n",
      "Epoch 432/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0279 - acc: 0.3418 - val_loss: 2.0448 - val_acc: 0.3192\n",
      "Epoch 433/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0276 - acc: 0.3435 - val_loss: 2.0448 - val_acc: 0.3183\n",
      "Epoch 434/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0272 - acc: 0.3423 - val_loss: 2.0446 - val_acc: 0.3187\n",
      "Epoch 435/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0267 - acc: 0.3434 - val_loss: 2.0437 - val_acc: 0.3179\n",
      "Epoch 436/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0264 - acc: 0.3441 - val_loss: 2.0436 - val_acc: 0.3179\n",
      "Epoch 437/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0260 - acc: 0.3434 - val_loss: 2.0433 - val_acc: 0.3158\n",
      "Epoch 438/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0256 - acc: 0.3443 - val_loss: 2.0429 - val_acc: 0.3179\n",
      "Epoch 439/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0253 - acc: 0.3412 - val_loss: 2.0426 - val_acc: 0.3179\n",
      "Epoch 440/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0249 - acc: 0.3449 - val_loss: 2.0420 - val_acc: 0.3183\n",
      "Epoch 441/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0244 - acc: 0.3438 - val_loss: 2.0418 - val_acc: 0.3183\n",
      "Epoch 442/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0241 - acc: 0.3431 - val_loss: 2.0418 - val_acc: 0.3175\n",
      "Epoch 443/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0237 - acc: 0.3447 - val_loss: 2.0409 - val_acc: 0.3171\n",
      "Epoch 444/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0233 - acc: 0.3452 - val_loss: 2.0409 - val_acc: 0.3188\n",
      "Epoch 445/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0229 - acc: 0.3447 - val_loss: 2.0407 - val_acc: 0.3171\n",
      "Epoch 446/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0226 - acc: 0.3449 - val_loss: 2.0401 - val_acc: 0.3208\n",
      "Epoch 447/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0222 - acc: 0.3445 - val_loss: 2.0399 - val_acc: 0.3175\n",
      "Epoch 448/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0218 - acc: 0.3432 - val_loss: 2.0395 - val_acc: 0.3187\n",
      "Epoch 449/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0214 - acc: 0.3447 - val_loss: 2.0391 - val_acc: 0.3171\n",
      "Epoch 450/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0210 - acc: 0.3444 - val_loss: 2.0387 - val_acc: 0.3183\n",
      "Epoch 451/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0207 - acc: 0.3455 - val_loss: 2.0383 - val_acc: 0.3196\n",
      "Epoch 452/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0203 - acc: 0.3460 - val_loss: 2.0381 - val_acc: 0.3204\n",
      "Epoch 453/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0199 - acc: 0.3446 - val_loss: 2.0378 - val_acc: 0.3208\n",
      "Epoch 454/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0195 - acc: 0.3459 - val_loss: 2.0373 - val_acc: 0.3171\n",
      "Epoch 455/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0191 - acc: 0.3453 - val_loss: 2.0369 - val_acc: 0.3162\n",
      "Epoch 456/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0187 - acc: 0.3461 - val_loss: 2.0369 - val_acc: 0.3208\n",
      "Epoch 457/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0184 - acc: 0.3458 - val_loss: 2.0366 - val_acc: 0.3175\n",
      "Epoch 458/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0180 - acc: 0.3456 - val_loss: 2.0361 - val_acc: 0.3188\n",
      "Epoch 459/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0176 - acc: 0.3458 - val_loss: 2.0357 - val_acc: 0.3188\n",
      "Epoch 460/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0172 - acc: 0.3468 - val_loss: 2.0354 - val_acc: 0.3208\n",
      "Epoch 461/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0169 - acc: 0.3469 - val_loss: 2.0350 - val_acc: 0.3212\n",
      "Epoch 462/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0165 - acc: 0.3435 - val_loss: 2.0348 - val_acc: 0.3229\n",
      "Epoch 463/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0161 - acc: 0.3465 - val_loss: 2.0347 - val_acc: 0.3200\n",
      "Epoch 464/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0158 - acc: 0.3460 - val_loss: 2.0343 - val_acc: 0.3196\n",
      "Epoch 465/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0154 - acc: 0.3466 - val_loss: 2.0340 - val_acc: 0.3192\n",
      "Epoch 466/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0150 - acc: 0.3456 - val_loss: 2.0335 - val_acc: 0.3208\n",
      "Epoch 467/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0146 - acc: 0.3447 - val_loss: 2.0330 - val_acc: 0.3200\n",
      "Epoch 468/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0142 - acc: 0.3471 - val_loss: 2.0329 - val_acc: 0.3204\n",
      "Epoch 469/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0138 - acc: 0.3463 - val_loss: 2.0326 - val_acc: 0.3208\n",
      "Epoch 470/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0136 - acc: 0.3453 - val_loss: 2.0320 - val_acc: 0.3212\n",
      "Epoch 471/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0132 - acc: 0.3481 - val_loss: 2.0319 - val_acc: 0.3208\n",
      "Epoch 472/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0128 - acc: 0.3477 - val_loss: 2.0316 - val_acc: 0.3183\n",
      "Epoch 473/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0124 - acc: 0.3470 - val_loss: 2.0312 - val_acc: 0.3196\n",
      "Epoch 474/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0121 - acc: 0.3479 - val_loss: 2.0309 - val_acc: 0.3204\n",
      "Epoch 475/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0117 - acc: 0.3468 - val_loss: 2.0306 - val_acc: 0.3217\n",
      "Epoch 476/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0113 - acc: 0.3447 - val_loss: 2.0303 - val_acc: 0.3212\n",
      "Epoch 477/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0110 - acc: 0.3476 - val_loss: 2.0298 - val_acc: 0.3200\n",
      "Epoch 478/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0107 - acc: 0.3504 - val_loss: 2.0295 - val_acc: 0.3229\n",
      "Epoch 479/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0102 - acc: 0.3471 - val_loss: 2.0293 - val_acc: 0.3196\n",
      "Epoch 480/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0099 - acc: 0.3480 - val_loss: 2.0290 - val_acc: 0.3192\n",
      "Epoch 481/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0094 - acc: 0.3481 - val_loss: 2.0287 - val_acc: 0.3200\n",
      "Epoch 482/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0091 - acc: 0.3498 - val_loss: 2.0283 - val_acc: 0.3187\n",
      "Epoch 483/50000\n",
      "9600/9600 [==============================] - 0s 15us/step - loss: 2.0088 - acc: 0.3481 - val_loss: 2.0281 - val_acc: 0.3200\n",
      "Epoch 484/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0084 - acc: 0.3480 - val_loss: 2.0276 - val_acc: 0.3196\n",
      "Epoch 485/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0080 - acc: 0.3463 - val_loss: 2.0274 - val_acc: 0.3212\n",
      "Epoch 486/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0077 - acc: 0.3472 - val_loss: 2.0270 - val_acc: 0.3212\n",
      "Epoch 487/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0073 - acc: 0.3474 - val_loss: 2.0268 - val_acc: 0.3208\n",
      "Epoch 488/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0070 - acc: 0.3475 - val_loss: 2.0267 - val_acc: 0.3212\n",
      "Epoch 489/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0066 - acc: 0.3493 - val_loss: 2.0262 - val_acc: 0.3196\n",
      "Epoch 490/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0063 - acc: 0.3493 - val_loss: 2.0260 - val_acc: 0.3217\n",
      "Epoch 491/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0059 - acc: 0.3489 - val_loss: 2.0257 - val_acc: 0.3217\n",
      "Epoch 492/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 2.0055 - acc: 0.3498 - val_loss: 2.0253 - val_acc: 0.3196\n",
      "Epoch 493/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 2.0052 - acc: 0.3474 - val_loss: 2.0248 - val_acc: 0.3204\n",
      "Epoch 494/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0049 - acc: 0.3491 - val_loss: 2.0246 - val_acc: 0.3200\n",
      "Epoch 495/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0045 - acc: 0.3490 - val_loss: 2.0242 - val_acc: 0.3221\n",
      "Epoch 496/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0041 - acc: 0.3500 - val_loss: 2.0238 - val_acc: 0.3187\n",
      "Epoch 497/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0037 - acc: 0.3490 - val_loss: 2.0236 - val_acc: 0.3196\n",
      "Epoch 498/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0035 - acc: 0.3497 - val_loss: 2.0233 - val_acc: 0.3204\n",
      "Epoch 499/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0031 - acc: 0.3492 - val_loss: 2.0230 - val_acc: 0.3217\n",
      "Epoch 500/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0027 - acc: 0.3488 - val_loss: 2.0227 - val_acc: 0.3204\n",
      "Epoch 501/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0024 - acc: 0.3500 - val_loss: 2.0224 - val_acc: 0.3192\n",
      "Epoch 502/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 2.0020 - acc: 0.3497 - val_loss: 2.0221 - val_acc: 0.3208\n",
      "Epoch 503/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 2.0017 - acc: 0.3490 - val_loss: 2.0217 - val_acc: 0.3196\n",
      "Epoch 504/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.0013 - acc: 0.3502 - val_loss: 2.0214 - val_acc: 0.3217\n",
      "Epoch 505/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 2.0009 - acc: 0.3508 - val_loss: 2.0213 - val_acc: 0.3212\n",
      "Epoch 506/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0006 - acc: 0.3497 - val_loss: 2.0210 - val_acc: 0.3196\n",
      "Epoch 507/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 2.0002 - acc: 0.3493 - val_loss: 2.0206 - val_acc: 0.3233\n",
      "Epoch 508/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9999 - acc: 0.3497 - val_loss: 2.0203 - val_acc: 0.3208\n",
      "Epoch 509/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9995 - acc: 0.3504 - val_loss: 2.0197 - val_acc: 0.3204\n",
      "Epoch 510/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9992 - acc: 0.3501 - val_loss: 2.0196 - val_acc: 0.3204\n",
      "Epoch 511/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.9989 - acc: 0.3497 - val_loss: 2.0192 - val_acc: 0.3212\n",
      "Epoch 512/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9986 - acc: 0.3500 - val_loss: 2.0191 - val_acc: 0.3212\n",
      "Epoch 513/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9982 - acc: 0.3526 - val_loss: 2.0188 - val_acc: 0.3233\n",
      "Epoch 514/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9978 - acc: 0.3504 - val_loss: 2.0187 - val_acc: 0.3204\n",
      "Epoch 515/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9975 - acc: 0.3492 - val_loss: 2.0183 - val_acc: 0.3212\n",
      "Epoch 516/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9971 - acc: 0.3501 - val_loss: 2.0181 - val_acc: 0.3217\n",
      "Epoch 517/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9968 - acc: 0.3510 - val_loss: 2.0175 - val_acc: 0.3233\n",
      "Epoch 518/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9965 - acc: 0.3496 - val_loss: 2.0171 - val_acc: 0.3187\n",
      "Epoch 519/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9962 - acc: 0.3525 - val_loss: 2.0170 - val_acc: 0.3188\n",
      "Epoch 520/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9959 - acc: 0.3495 - val_loss: 2.0166 - val_acc: 0.3208\n",
      "Epoch 521/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9955 - acc: 0.3501 - val_loss: 2.0162 - val_acc: 0.3217\n",
      "Epoch 522/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9952 - acc: 0.3505 - val_loss: 2.0162 - val_acc: 0.3237\n",
      "Epoch 523/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.9949 - acc: 0.3499 - val_loss: 2.0157 - val_acc: 0.3200\n",
      "Epoch 524/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.9945 - acc: 0.3524 - val_loss: 2.0157 - val_acc: 0.3237\n",
      "Epoch 525/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9941 - acc: 0.3513 - val_loss: 2.0149 - val_acc: 0.3212\n",
      "Epoch 526/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9938 - acc: 0.3513 - val_loss: 2.0151 - val_acc: 0.3217\n",
      "Epoch 527/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9934 - acc: 0.3506 - val_loss: 2.0147 - val_acc: 0.3200\n",
      "Epoch 528/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9931 - acc: 0.3510 - val_loss: 2.0143 - val_acc: 0.3225\n",
      "Epoch 529/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9927 - acc: 0.3507 - val_loss: 2.0141 - val_acc: 0.3250\n",
      "Epoch 530/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9924 - acc: 0.3517 - val_loss: 2.0139 - val_acc: 0.3237\n",
      "Epoch 531/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9921 - acc: 0.3513 - val_loss: 2.0136 - val_acc: 0.3233\n",
      "Epoch 532/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9918 - acc: 0.3507 - val_loss: 2.0130 - val_acc: 0.3229\n",
      "Epoch 533/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9915 - acc: 0.3515 - val_loss: 2.0128 - val_acc: 0.3229\n",
      "Epoch 534/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9912 - acc: 0.3508 - val_loss: 2.0126 - val_acc: 0.3246\n",
      "Epoch 535/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9907 - acc: 0.3517 - val_loss: 2.0124 - val_acc: 0.3254\n",
      "Epoch 536/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9904 - acc: 0.3516 - val_loss: 2.0118 - val_acc: 0.3246\n",
      "Epoch 537/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9902 - acc: 0.3511 - val_loss: 2.0115 - val_acc: 0.3217\n",
      "Epoch 538/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.9898 - acc: 0.3499 - val_loss: 2.0115 - val_acc: 0.3208\n",
      "Epoch 539/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9895 - acc: 0.3514 - val_loss: 2.0113 - val_acc: 0.3229\n",
      "Epoch 540/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9892 - acc: 0.3521 - val_loss: 2.0108 - val_acc: 0.3225\n",
      "Epoch 541/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9888 - acc: 0.3525 - val_loss: 2.0106 - val_acc: 0.3208\n",
      "Epoch 542/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9886 - acc: 0.3520 - val_loss: 2.0104 - val_acc: 0.3217\n",
      "Epoch 543/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9882 - acc: 0.3526 - val_loss: 2.0099 - val_acc: 0.3217\n",
      "Epoch 544/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.9879 - acc: 0.3521 - val_loss: 2.0097 - val_acc: 0.3242\n",
      "Epoch 545/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9875 - acc: 0.3520 - val_loss: 2.0097 - val_acc: 0.3212\n",
      "Epoch 546/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9873 - acc: 0.3508 - val_loss: 2.0092 - val_acc: 0.3229\n",
      "Epoch 547/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9869 - acc: 0.3545 - val_loss: 2.0090 - val_acc: 0.3250\n",
      "Epoch 548/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9865 - acc: 0.3517 - val_loss: 2.0087 - val_acc: 0.3229\n",
      "Epoch 549/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9863 - acc: 0.3532 - val_loss: 2.0085 - val_acc: 0.3204\n",
      "Epoch 550/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9859 - acc: 0.3518 - val_loss: 2.0081 - val_acc: 0.3233\n",
      "Epoch 551/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9856 - acc: 0.3521 - val_loss: 2.0078 - val_acc: 0.3233\n",
      "Epoch 552/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9853 - acc: 0.3503 - val_loss: 2.0077 - val_acc: 0.3238\n",
      "Epoch 553/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9850 - acc: 0.3518 - val_loss: 2.0073 - val_acc: 0.3246\n",
      "Epoch 554/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.9846 - acc: 0.3549 - val_loss: 2.0071 - val_acc: 0.3242\n",
      "Epoch 555/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9844 - acc: 0.3532 - val_loss: 2.0069 - val_acc: 0.3221\n",
      "Epoch 556/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9841 - acc: 0.3522 - val_loss: 2.0064 - val_acc: 0.3200\n",
      "Epoch 557/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9837 - acc: 0.3525 - val_loss: 2.0063 - val_acc: 0.3225\n",
      "Epoch 558/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9833 - acc: 0.3507 - val_loss: 2.0060 - val_acc: 0.3204\n",
      "Epoch 559/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9831 - acc: 0.3528 - val_loss: 2.0057 - val_acc: 0.3233\n",
      "Epoch 560/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9827 - acc: 0.3519 - val_loss: 2.0053 - val_acc: 0.3246\n",
      "Epoch 561/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9825 - acc: 0.3519 - val_loss: 2.0053 - val_acc: 0.3262\n",
      "Epoch 562/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9821 - acc: 0.3530 - val_loss: 2.0050 - val_acc: 0.3254\n",
      "Epoch 563/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9818 - acc: 0.3526 - val_loss: 2.0046 - val_acc: 0.3258\n",
      "Epoch 564/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9815 - acc: 0.3530 - val_loss: 2.0043 - val_acc: 0.3250\n",
      "Epoch 565/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9812 - acc: 0.3533 - val_loss: 2.0041 - val_acc: 0.3242\n",
      "Epoch 566/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9809 - acc: 0.3529 - val_loss: 2.0038 - val_acc: 0.3246\n",
      "Epoch 567/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9806 - acc: 0.3546 - val_loss: 2.0035 - val_acc: 0.3254\n",
      "Epoch 568/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9804 - acc: 0.3533 - val_loss: 2.0034 - val_acc: 0.3242\n",
      "Epoch 569/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9800 - acc: 0.3523 - val_loss: 2.0029 - val_acc: 0.3254\n",
      "Epoch 570/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9797 - acc: 0.3542 - val_loss: 2.0027 - val_acc: 0.3238\n",
      "Epoch 571/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9795 - acc: 0.3540 - val_loss: 2.0025 - val_acc: 0.3254\n",
      "Epoch 572/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9791 - acc: 0.3538 - val_loss: 2.0023 - val_acc: 0.3229\n",
      "Epoch 573/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9787 - acc: 0.3527 - val_loss: 2.0017 - val_acc: 0.3254\n",
      "Epoch 574/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9784 - acc: 0.3559 - val_loss: 2.0016 - val_acc: 0.3246\n",
      "Epoch 575/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9781 - acc: 0.3553 - val_loss: 2.0012 - val_acc: 0.3229\n",
      "Epoch 576/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9778 - acc: 0.3532 - val_loss: 2.0011 - val_acc: 0.3258\n",
      "Epoch 577/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9775 - acc: 0.3521 - val_loss: 2.0010 - val_acc: 0.3242\n",
      "Epoch 578/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9772 - acc: 0.3555 - val_loss: 2.0006 - val_acc: 0.3246\n",
      "Epoch 579/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9770 - acc: 0.3548 - val_loss: 2.0003 - val_acc: 0.3225\n",
      "Epoch 580/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9766 - acc: 0.3540 - val_loss: 2.0002 - val_acc: 0.3250\n",
      "Epoch 581/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9763 - acc: 0.3541 - val_loss: 1.9995 - val_acc: 0.3267\n",
      "Epoch 582/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9760 - acc: 0.3548 - val_loss: 1.9994 - val_acc: 0.3254\n",
      "Epoch 583/50000\n",
      "9600/9600 [==============================] - 0s 24us/step - loss: 1.9757 - acc: 0.3556 - val_loss: 1.9991 - val_acc: 0.3263\n",
      "Epoch 584/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9754 - acc: 0.3551 - val_loss: 1.9992 - val_acc: 0.3271\n",
      "Epoch 585/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9751 - acc: 0.3535 - val_loss: 1.9988 - val_acc: 0.3254\n",
      "Epoch 586/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9748 - acc: 0.3541 - val_loss: 1.9985 - val_acc: 0.3242\n",
      "Epoch 587/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9745 - acc: 0.3541 - val_loss: 1.9983 - val_acc: 0.3254\n",
      "Epoch 588/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9742 - acc: 0.3549 - val_loss: 1.9980 - val_acc: 0.3258\n",
      "Epoch 589/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9739 - acc: 0.3546 - val_loss: 1.9975 - val_acc: 0.3263\n",
      "Epoch 590/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9736 - acc: 0.3553 - val_loss: 1.9974 - val_acc: 0.3258\n",
      "Epoch 591/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9733 - acc: 0.3541 - val_loss: 1.9974 - val_acc: 0.3246\n",
      "Epoch 592/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9730 - acc: 0.3547 - val_loss: 1.9970 - val_acc: 0.3242\n",
      "Epoch 593/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9727 - acc: 0.3540 - val_loss: 1.9968 - val_acc: 0.3250\n",
      "Epoch 594/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9724 - acc: 0.3555 - val_loss: 1.9966 - val_acc: 0.3267\n",
      "Epoch 595/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9721 - acc: 0.3558 - val_loss: 1.9962 - val_acc: 0.3254\n",
      "Epoch 596/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9720 - acc: 0.3569 - val_loss: 1.9962 - val_acc: 0.3233\n",
      "Epoch 597/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9716 - acc: 0.3547 - val_loss: 1.9959 - val_acc: 0.3237\n",
      "Epoch 598/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9712 - acc: 0.3549 - val_loss: 1.9955 - val_acc: 0.3254\n",
      "Epoch 599/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9709 - acc: 0.3559 - val_loss: 1.9953 - val_acc: 0.3267\n",
      "Epoch 600/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9705 - acc: 0.3568 - val_loss: 1.9949 - val_acc: 0.3258\n",
      "Epoch 601/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9703 - acc: 0.3549 - val_loss: 1.9947 - val_acc: 0.3258\n",
      "Epoch 602/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9701 - acc: 0.3533 - val_loss: 1.9945 - val_acc: 0.3262\n",
      "Epoch 603/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9697 - acc: 0.3555 - val_loss: 1.9941 - val_acc: 0.3262\n",
      "Epoch 604/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9694 - acc: 0.3555 - val_loss: 1.9940 - val_acc: 0.3271\n",
      "Epoch 605/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9692 - acc: 0.3555 - val_loss: 1.9938 - val_acc: 0.3271\n",
      "Epoch 606/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9688 - acc: 0.3557 - val_loss: 1.9936 - val_acc: 0.3263\n",
      "Epoch 607/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9685 - acc: 0.3555 - val_loss: 1.9934 - val_acc: 0.3242\n",
      "Epoch 608/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9683 - acc: 0.3571 - val_loss: 1.9930 - val_acc: 0.3263\n",
      "Epoch 609/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9680 - acc: 0.3541 - val_loss: 1.9928 - val_acc: 0.3279\n",
      "Epoch 610/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9676 - acc: 0.3568 - val_loss: 1.9923 - val_acc: 0.3271\n",
      "Epoch 611/50000\n",
      "9600/9600 [==============================] - 0s 21us/step - loss: 1.9674 - acc: 0.3557 - val_loss: 1.9924 - val_acc: 0.3271\n",
      "Epoch 612/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9671 - acc: 0.3555 - val_loss: 1.9923 - val_acc: 0.3258\n",
      "Epoch 613/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9668 - acc: 0.3554 - val_loss: 1.9918 - val_acc: 0.3267\n",
      "Epoch 614/50000\n",
      "9600/9600 [==============================] - 0s 23us/step - loss: 1.9665 - acc: 0.3549 - val_loss: 1.9916 - val_acc: 0.3254\n",
      "Epoch 615/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.9662 - acc: 0.3566 - val_loss: 1.9913 - val_acc: 0.3267\n",
      "Epoch 616/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9659 - acc: 0.3585 - val_loss: 1.9911 - val_acc: 0.3263\n",
      "Epoch 617/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.9656 - acc: 0.3563 - val_loss: 1.9909 - val_acc: 0.3271\n",
      "Epoch 618/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9653 - acc: 0.3558 - val_loss: 1.9905 - val_acc: 0.3271\n",
      "Epoch 619/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9650 - acc: 0.3570 - val_loss: 1.9903 - val_acc: 0.3271\n",
      "Epoch 620/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9648 - acc: 0.3561 - val_loss: 1.9900 - val_acc: 0.3271\n",
      "Epoch 621/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9645 - acc: 0.3577 - val_loss: 1.9897 - val_acc: 0.3275\n",
      "Epoch 622/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9641 - acc: 0.3573 - val_loss: 1.9896 - val_acc: 0.3246\n",
      "Epoch 623/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9639 - acc: 0.3567 - val_loss: 1.9893 - val_acc: 0.3279\n",
      "Epoch 624/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9636 - acc: 0.3568 - val_loss: 1.9890 - val_acc: 0.3263\n",
      "Epoch 625/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9633 - acc: 0.3560 - val_loss: 1.9888 - val_acc: 0.3258\n",
      "Epoch 626/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9630 - acc: 0.3577 - val_loss: 1.9886 - val_acc: 0.3267\n",
      "Epoch 627/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9628 - acc: 0.3552 - val_loss: 1.9882 - val_acc: 0.3304\n",
      "Epoch 628/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9624 - acc: 0.3573 - val_loss: 1.9879 - val_acc: 0.3267\n",
      "Epoch 629/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9622 - acc: 0.3584 - val_loss: 1.9876 - val_acc: 0.3283\n",
      "Epoch 630/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9619 - acc: 0.3591 - val_loss: 1.9874 - val_acc: 0.3292\n",
      "Epoch 631/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9616 - acc: 0.3574 - val_loss: 1.9875 - val_acc: 0.3254\n",
      "Epoch 632/50000\n",
      "9600/9600 [==============================] - 0s 19us/step - loss: 1.9613 - acc: 0.3575 - val_loss: 1.9871 - val_acc: 0.3267\n",
      "Epoch 633/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.9610 - acc: 0.3571 - val_loss: 1.9868 - val_acc: 0.3267\n",
      "Epoch 634/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9608 - acc: 0.3603 - val_loss: 1.9867 - val_acc: 0.3275\n",
      "Epoch 635/50000\n",
      "9600/9600 [==============================] - 0s 17us/step - loss: 1.9605 - acc: 0.3570 - val_loss: 1.9863 - val_acc: 0.3275\n",
      "Epoch 636/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9602 - acc: 0.3572 - val_loss: 1.9862 - val_acc: 0.3283\n",
      "Epoch 637/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9600 - acc: 0.3574 - val_loss: 1.9860 - val_acc: 0.3267\n",
      "Epoch 638/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9596 - acc: 0.3593 - val_loss: 1.9857 - val_acc: 0.3283\n",
      "Epoch 639/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9593 - acc: 0.3599 - val_loss: 1.9854 - val_acc: 0.3292\n",
      "Epoch 640/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9591 - acc: 0.3588 - val_loss: 1.9851 - val_acc: 0.3279\n",
      "Epoch 641/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9588 - acc: 0.3591 - val_loss: 1.9850 - val_acc: 0.3258\n",
      "Epoch 642/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9585 - acc: 0.3577 - val_loss: 1.9848 - val_acc: 0.3271\n",
      "Epoch 643/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9582 - acc: 0.3598 - val_loss: 1.9846 - val_acc: 0.3271\n",
      "Epoch 644/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9580 - acc: 0.3582 - val_loss: 1.9843 - val_acc: 0.3267\n",
      "Epoch 645/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9577 - acc: 0.3578 - val_loss: 1.9842 - val_acc: 0.3212\n",
      "Epoch 646/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9574 - acc: 0.3585 - val_loss: 1.9839 - val_acc: 0.3279\n",
      "Epoch 647/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9571 - acc: 0.3577 - val_loss: 1.9837 - val_acc: 0.3292\n",
      "Epoch 648/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9568 - acc: 0.3584 - val_loss: 1.9835 - val_acc: 0.3271\n",
      "Epoch 649/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9566 - acc: 0.3593 - val_loss: 1.9832 - val_acc: 0.3267\n",
      "Epoch 650/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9563 - acc: 0.3589 - val_loss: 1.9829 - val_acc: 0.3262\n",
      "Epoch 651/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9560 - acc: 0.3590 - val_loss: 1.9828 - val_acc: 0.3267\n",
      "Epoch 652/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9558 - acc: 0.3607 - val_loss: 1.9824 - val_acc: 0.3296\n",
      "Epoch 653/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9555 - acc: 0.3571 - val_loss: 1.9823 - val_acc: 0.3267\n",
      "Epoch 654/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9552 - acc: 0.3597 - val_loss: 1.9821 - val_acc: 0.3258\n",
      "Epoch 655/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9550 - acc: 0.3577 - val_loss: 1.9816 - val_acc: 0.3275\n",
      "Epoch 656/50000\n",
      "9600/9600 [==============================] - 0s 18us/step - loss: 1.9546 - acc: 0.3583 - val_loss: 1.9814 - val_acc: 0.3271\n",
      "Epoch 657/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9544 - acc: 0.3615 - val_loss: 1.9815 - val_acc: 0.3258\n",
      "Epoch 658/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9541 - acc: 0.3600 - val_loss: 1.9810 - val_acc: 0.3275\n",
      "Epoch 659/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9538 - acc: 0.3590 - val_loss: 1.9809 - val_acc: 0.3267\n",
      "Epoch 660/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9535 - acc: 0.3617 - val_loss: 1.9804 - val_acc: 0.3283\n",
      "Epoch 661/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9533 - acc: 0.3601 - val_loss: 1.9803 - val_acc: 0.3279\n",
      "Epoch 662/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9530 - acc: 0.3590 - val_loss: 1.9801 - val_acc: 0.3300\n",
      "Epoch 663/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9527 - acc: 0.3594 - val_loss: 1.9797 - val_acc: 0.3275\n",
      "Epoch 664/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9525 - acc: 0.3597 - val_loss: 1.9797 - val_acc: 0.3267\n",
      "Epoch 665/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9522 - acc: 0.3595 - val_loss: 1.9793 - val_acc: 0.3287\n",
      "Epoch 666/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9519 - acc: 0.3620 - val_loss: 1.9791 - val_acc: 0.3250\n",
      "Epoch 667/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9517 - acc: 0.3600 - val_loss: 1.9791 - val_acc: 0.3267\n",
      "Epoch 668/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9514 - acc: 0.3603 - val_loss: 1.9787 - val_acc: 0.3267\n",
      "Epoch 669/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9512 - acc: 0.3614 - val_loss: 1.9787 - val_acc: 0.3296\n",
      "Epoch 670/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9508 - acc: 0.3599 - val_loss: 1.9785 - val_acc: 0.3267\n",
      "Epoch 671/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9506 - acc: 0.3612 - val_loss: 1.9785 - val_acc: 0.3275\n",
      "Epoch 672/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9504 - acc: 0.3625 - val_loss: 1.9777 - val_acc: 0.3283\n",
      "Epoch 673/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9501 - acc: 0.3592 - val_loss: 1.9779 - val_acc: 0.3267\n",
      "Epoch 674/50000\n",
      "9600/9600 [==============================] - 0s 16us/step - loss: 1.9498 - acc: 0.3604 - val_loss: 1.9774 - val_acc: 0.3271\n",
      "Epoch 675/50000\n",
      "9600/9600 [==============================] - 0s 25us/step - loss: 1.9495 - acc: 0.3605 - val_loss: 1.9772 - val_acc: 0.3271\n",
      "Epoch 676/50000\n",
      "9600/9600 [==============================] - 0s 22us/step - loss: 1.9492 - acc: 0.3604 - val_loss: 1.9770 - val_acc: 0.3263\n",
      "Epoch 677/50000\n",
      "9600/9600 [==============================] - 0s 20us/step - loss: 1.9490 - acc: 0.3603 - val_loss: 1.9766 - val_acc: 0.3263\n",
      "Val loss: 1.9882,Val acc: 0.3304\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd8VFX6+PHPk94LIdQACRB6JxQFBQQRVLChYlm72HXt+tO1bXN1xbJrV3btLuIXCxZsIKB0xEiVUBNagEASSJ85vz/OZNLJAJlMyvN+veaVe8+9d/LMvJJ55tzTxBiDUkop5Qk/XweglFKq8dCkoZRSymOaNJRSSnlMk4ZSSimPadJQSinlMU0aSimlPKZJQymllMc0aSillPKYJg2llFIeC/B1AHWlZcuWJjEx0ddhKKVUo7Jy5cr9xph4T89vMkkjMTGRFStW+DoMpZRqVERk+7Gcr7enlFJKeUyThlJKKY9p0lBKKeWxJtOmUZ3i4mIyMjIoKCjwdShNRkhICAkJCQQGBvo6FKWUDzTppJGRkUFkZCSJiYmIiK/DafSMMRw4cICMjAySkpJ8HY5Sygea9O2pgoIC4uLiNGHUEREhLi5Oa25KNWNNOmkAmjDqmL6fSjVvTT5pKKVUk+F0gtNht9d9CgePaYhFndCk0cBEREQAsGvXLqZMmVLtOaNHj651IONzzz1HXl6ee//MM8/k0KFDdReoUsp7HMVgDKz9BOY+BO+cDwU5MPMP8Ne2MOtamHkF/N+0eg+tSTeEN2bt2rVj1qxZx339c889x+WXX05YWBgAX375ZV2FppQ6EY4S+PwOOOlmKC6A0BjIPwTx3SE4AkoK4S+toM8FsObjsuuWvQob5tjtNa7PhvQl8Gxf6DIaJv+rXsLXmoaX3X///bz00kvu/ccee4zHH3+csWPHMmjQIPr27cunn35a5bpt27bRp08fAPLz85k6dSr9+vXj4osvJj8/333eTTfdREpKCr179+bRRx8F4IUXXmDXrl2MGTOGMWPGAHaalf379wMwffp0+vTpQ58+fXjuuefcv69nz55cf/319O7dm/Hjx1f4PUqpY7B1YdltpFKOYvj6/8GPT8Lqd+HlEfDGafCvQfbnjDNg6as2YUDFhAHww1+q/10xHSEgpO5fQw2aTU3j8c/Xsm5XTp0+Z692UTw6qfdRz5k6dSp//OMfufnmmwGYOXMmX3/9NXfeeSdRUVHs37+f4cOHM3ny5BobmV9++WXCwsJITU0lNTWVQYMGuY/99a9/pUWLFjgcDsaOHUtqaiq3334706dPZ968ebRs2bLCc61cuZL//Oc/LF26FGMMw4YNY9SoUcTGxrJp0yY++OADXn/9dS666CI+/vhjLr/88hN8l5RqYoyByv+rBTkgfram8PtceP8iGPsoGAfEdIKAYPuhv//38k9U8Tn2roGv7qv6+2IToX0KFOdB8unQ/1L7fHt+g80/wIg7qsbjRc0mafjKwIEDyczMZNeuXezbt4/Y2Fjatm3LnXfeyYIFC/Dz82Pnzp3s3buXNm3aVPscCxYs4PbbbwegX79+9OvXz31s5syZvPbaa5SUlLB7927WrVtX4XhlixYt4rzzziM8PByA888/n4ULFzJ58mSSkpIYMGAAAIMHD2bbtm119C4o1QjsWQMtu0FAkN13OsGv0s2YnavgP2fC8JvsraJr5kJQODzZwR4f9QDkZ9nt7x+v/Xf2OgeGXA/z/26TTu5umPo+fPso/P4VDLoSznoG/KsZTNu2n33Us2aTNGqrEXjTlClTmDVrFnv27GHq1Km899577Nu3j5UrVxIYGEhiYmKtYx+qq4Vs3bqVf/7znyxfvpzY2FiuuuqqWp/HGFPjseDgYPe2v7+/3p5SjVtRHgTZNj3WzoYuYyEkquI5h3bY2zs5u+GVERAcBWEt4LQ/2QbofhdCt4nw3aPQYZi9feQshkXT7fVPVRrk+uOTVePodY7t6QQwdBqMeQj2bbBtF51GgH8AJJ1S8Zopb0LuHojrcuLvQx3TNo16MHXqVD788ENmzZrFlClTyM7OplWrVgQGBjJv3jy2bz96t7lTTz2V9957D4A1a9aQmpoKQE5ODuHh4URHR7N3716++uor9zWRkZHk5uZW+1yffPIJeXl5HDlyhNmzZ3PKKadUOU+pRm37YvhbW9jwJezfBB9dBbOuqXjOstfhub7wWAxM72nLCnPg4Db4+Fo4vAd+/hf890zIWA6L/20TRmUdhpVtt+0P4a3g4nfhxp/g0UNw0dtw1wboOQlG3mUbvjsOh86jbMKoTlB4g0wY4OWahohMAJ4H/IE3jDFPVjp+I3AL4AAOA9OMMetEJBFYD2x0nbrEGHOjN2P1pt69e5Obm0v79u1p27Ytl112GZMmTSIlJYUBAwbQo0ePo15/0003cfXVV9OvXz8GDBjA0KFDAejfvz8DBw6kd+/edO7cmREjRrivmTZtGhMnTqRt27bMmzfPXT5o0CCuuuoq93Ncd911DBw4UG9FqYZn50pIXw7Db7Qf/pFtbE3g0HboOrbq+Y4SWPISbJkPjiJb9uElMPAPdjvtW3jpZLudubbchdXUvjuPtjWEbx6BNn2h59k2yXQeBeP/Yhu1v7jL1mAu+wiK82HhdDj9CdveUPnOQFRbm0iaADna7YoTemIRf+B34HQgA1gOXGKMWVfunChjTI5rezJwszFmgitpzDHG9PH096WkpJjKYxfWr19Pz549T/SlqEr0fVVek50BUe3th+7jLWxD8pVz4K2z7fHYRFsTGHQlbJkHfoGQtRniku01FRqaa9H9LHvNhjkw8Wk4sAmWvQaR7eDu9fackqKyNo7KigsgZ2eDrRF4SkRWGmNSPD3fmzWNoUCaMWYLgIh8CJwDuJNGacJwCafalK+UapT2roPZ0+CCN+HIfkgsqwmzZT7EdbWD1+K72w/frQvt+IPkM+y+cXVZLU0YYBMGwKq3Kv6uA5vsz56TYPDV8O75dj/pVNi6wHZJHXYD/PS8PeeMv0OMq/G6pNDWDgBG3V/xeWtKGACBIY0+YRwPbyaN9kB6uf0MYFjlk0TkFuAuIAg4rdyhJBH5BcgBHjbGLKzm2mnANICOHTvWXeRKqeNjjH34+cG8v9puoS/aW6HcvREy18E75x39OTbNPfrx89+AkgKIagch0eAfBEWHbbvFuMftB/l9W8FZAuHxMP9J6D4B2vS3jdqdTqr4fAFlHUAIr9hFXVXlzaRRXcfhKjUJY8yLwIsicinwMHAlsBvoaIw5ICKDgU9EpHelmgnGmNeA18DenqrrF6CUqkVxvv0WL2J7+6ydDV8/YI8FhFY896Xh0KpX1eeITYSgSGjZ1dYS9m2EvlNsN9PdqZCzC1r1tOMUOgytOZZ7yt2aCmtRtj3mwbLtyglDHTNvJo0MoEO5/QRg11HO/xB4GcAYUwgUurZXishmoBtw9AmXlFLeYwxs+haM03YZLTgEi561x2KT4ODWiueXlOuy3e9iSP0fbP8Jxj4CQRGw6m24YWHVsRCdR5Vtl7+lpRoEbyaN5UCyiCQBO4GpwKXlTxCRZGOM62YkZwGbXOXxQJYxxiEinYFkYIsXY1Wq+Skpst/mv3nYNj53O6PsHv3hTDuyuTgP0r6HQX+AXz8sm/uosvIJI6INtBtoB6f1vQjOftbeTtr/u21LKP22P+wG774+5RVeSxrGmBIRuRWYi+1yO8MYs1ZEngBWGGM+A24VkXFAMXAQe2sK4FTgCREpwXbHvdEYk+WtWJVqdvKy7MC0U++14w8A5j4Iox+0o5Mrq9zOcMo9djTyzCvs/sg7ba2j38WQcq0t+/0rGHCJnVojOAKmzffWq1H1yGtdbutbQ+1ye+jQId5//3333FOeOvPMM3n//feJiYnxUmTHryG8r8pDqTNtg7F/kG1PCI6ANf8HeQfgy3s8e44bFsCrp9rtO1JtG0Zka7v/49Mw7y/wyEHbGF1+xHVhLgRH1u3rUXXuWLvcatLwsm3btnH22WezZs2aCuUOhwN/f38fRXViGsL7qo5i/Rz47SPodHLFCfDCWtr2iPxaKu3nvgyf3GS3p/0I7QbY6TYCQiEi3ntxK59oSOM0FPDAAw+wefNmBgwYQGBgIBEREbRt25bVq1ezbt06zj33XNLT0ykoKOCOO+5g2jS7qEpiYiIrVqzg8OHDTJw4kZEjR/Lzzz/Tvn17Pv30U0JDQ2v5zapZ2bHUNkwf3guf3WbL1n1S8Zw8OzU+wVF2ugywPZcuettOfbH7V0gYAuFxkLHCtku0sxNYEqNd2pXVfJLGVw/YPuN1qU1fmFjNBGXlPPnkk6xZs4bVq1czf/58zjrrLNasWUNSkp3obMaMGbRo0YL8/HyGDBnCBRdcQFxcXIXn0CnLlVvuHghtYQedHc6EiFaQtQVmjK/+/Ot+sGs1gJ1CO+UaQOB51+yod/xadm5U27Lts6d7JXzV+DWfpNFADB061J0wwC6YNHv2bADS09PZtGlTlaShU5Y3c04H7FoNLZLgme7Q90KI7wE//Ln2a9v2szWJkGg7nxLYrrO9z7M9m5Q6Rs0nadRSI6gvpetYAMyfP5/vvvuOxYsXExYWxujRo6ud2lynLG9mDu2AOXfB5BfsFBcL/mlXeiv120fVX3fBm/DjUzD0etj6IxzeZ7vU9jqn4nkicOF/vRa+atqaT9LwkZqmKAfIzs4mNjaWsLAwNmzYwJIlS+o5OuVTToedlTU8Hpa8DJfOhNQP4dtH7PHptXQ2uHQmBIbCW5Og+5l2FHXfKfbY0Ou9G7tqtjRpeFlcXBwjRoygT58+hIaG0rp1a/exCRMm8Morr9CvXz+6d+/O8OHDfRipqlN5WRAaa7/VG2On0e48xk6Wt3OVbWTeudIOrCv1TLeKzxEUAT3OtgPjxv8ZojvYacF3/QLJ4+2aCwBXfAptB9Tfa1PNmna5VcdM39daFB2Bv7Wz29fPsz2USld4m/Q8fH5H7c/R+3y48D9eC1GpUtrlVilfy84o237nXDsFeKmaEkbn0Xa68OgOcOcaWztRqgHS5V6V8sTedZC5vmw/Lwty99rtkkL47HZ470Lbrfu/5dZ/KMi2t6HATssNdizEAzvg/m1w9VfQbpCtgYx7DC750J5TzZrwqvH6fW8uiQ98wW8Z2RXKjTFUd7dn7a5ssvPLlpZdvzuHp77egDEGh9OwdMsBr8dckyZf0zDGIPoPWGeayu3MWjmK7brQnVzLg77smmTvMdc//fMDoDAbrvzczt76i6t306Zvyp7jD7PtILl5f7X7578Km+fZ9oyQaFvW6WSY5lqOd+Sd3n1NyquO9lkzd80eACb9exF3juvG7WO7Mn/jPl6cl0af9tE8Nrk3qRmHmPraEt69bhjnv/QzQxJj+ejGkyl2OJn4vF1OaP3uHBJiw3hnyXbuPaM7lw7tSGz4URaK8oIm3aaxdetWIiMjiYuL08RRB4wxHDhwgNzc3ApjTZqkuQ/Zifxu/MnO2fRErC2/dQV8cjNkLKt4fqeRsH1RxbKH9trV3XJ22dpIiyb+njUxmTkF7M0ppG9CdJVjpZ+bB/OKWbz5ABEhAdzy3ioeOqsnF6d0YOehfBZvOcCandm8vXg7YUH+5BU53NeP7NqSRWn73fsPn9WT79bvZcmWLAZ1jGHVjkMATB3SgQ+Xp1OTIH8/PrllBL3aRdV4Tm107qlyiouLycjIqHbsgzo+ISEhJCQkEBgY6OtQvOf3ufC+a+Cbf7Dtvlo6E2x1LvsYksfZ8RWzb7JrQCQMtWWqXjidBj8/z74YPj13AyUOw62ndSUi2N5sERGcTsNPm/czLCmOsdPnk55lx0PNuCqFL1L3cMVJnbjyP8t45OxefLgsnQNHCsnMLSS3oMRrr8tTV5zUiSfO6XNc12rSUOp45e6B/EPwUpVViSu6aTE4i2HGRFt7uOmn+olPuaVn5fHS/DT+dHYvHv5kDWmZh5l5w0mEBNpJQA8eKeLJrzbw4Jk9KHEa0jIPM7xzHFv2Hea0Z34EIMBPKHGe2OdfxxZh5Bc72JdbSEqnWFZsP+g+9tY1Q7lyRlmN9KKUBLYdyGPZ1izun9CDUd3iKXY4ueyNpRwutIknpVMsneLCcTidfLK6bM26b+48ldBAf055yt7K/OO4ZE7qHMfGvbnM25BJy4hgnr6w/3G9Bu09pdSxcDrgQBpEtLZTdNTmnBehtWvJ0rvWgV/z/hcq/dJZV7d/nU7Dgk37GNUtngNHisg4mE9kSAB+IhzMK+Kh2WuY1L8te7IL+GBZOpv2HnZ/UH+3fi9n92vHw5/8xrtLdtj4MKzacYi0zMO8fNkgVmfY2z6d4sLYfiDvqLG8cvkgbnx3FQB3juvGs9/9XuH4/HtG07FFGB+vyuDeWalM6NOG964fxg/rMzm5a0uiQwO5fWwyL3y/idTHxhMVEkh2XjHLtmUxrmcr93u28k/jmLUyg4dmryEqNJBnLrIf/n87vy8BrlUNgwLsz2cv7k9GVj63jU0GYFjnOK44KfFE3/ZjojUN1TwUF8Dz/WHIdbAnFYbfZEdhZyyH3N0Vzx10JUx4Ev5WbgK/05+wg+0GXwV+jXNKe2/459yNvL5wC+ufmFDh9pDTaViUtp8rZixj/j2jSWxZNn1OscOJw2nYl1vI4cISureOdHcW+79VO7n7o1956oJ+/HteGjuyqv9gH5rUgmVbq07xXr49oCbje7XmlcsH8/XaPYQF+fPvH9Iq1BBKbXvyLDbtzeVIkYP+CdF8s24vMaGBXDFjGdeMTOL+CT0AcDgNX63ZzYTebQjwr9gh1RhDidMQ6H/0jqrfrtvL9W+v4JTklrxzbS013TqmNQ2lKnM6bCP14T12wSCA9Z+VHfcLAKfrvnTp+hEANy+xU4ZjICyu2XaD3br/CA6nk66tIknPyuNgXhEHDhcxqGMs/56XBsD3GzIJD/ZnTupu+raP5pcdB5m5wo5XWbYti5aRwdwz81fSD+axdlcO0aGB7i6lPdpEkhgXzoEjhSzfZj+8X5pfc8IAWLY1i4tTOjCqezxhQf7cOyuVfbmF1SaMh8/qydpdOcz+ZSdgE46fn3BmX/ulYHT3VvyUtp/QIH8E+HnzARJi7dIDya3LFpE6o3cbANY+fkaF5ODvJ5zdr121cYoIgf61/92EBPq5z2/oNGmopif/IIi/XUVu77qy7rKV9b0QWnS2S5ce2Qf71pclDIBWzWfUe05BMau2H2RUt/gqH1xj/jkfgEX3j3HfUweIDi3rDHH92zXX8u+blcp9s1IrlJUfg7BhTy4b9lScn21bLbeOAJJbR7g/+O+f0IN7PrLTvA/oEENMWCABfsJ36zMZ2DEWEXEnjc7x4VWea0TXlu7tgR1jj/p7K9cm6sKwpDguHJzAbacl1/lz1zVNGqppcTrh5RF2qdGbF1efMGIT4eA2O5guOsGWRbe3j2ZiyRb7bXrB7/tZttUOFCtteJ1140m0igzhp837cZRrKB75j3kVniM7v5je7aII9Pdjdbr9hv/I2b14Ys46APf9/FJRIQE8Oqk3d3/0K0eTGBfGjaO6MLp7K9bszCbjYB6Pfb6OFuFBnNm3DeN7teHjVRlcMCjBfc2UwQlM7t8OEdvALSIUljhY+Pt+BneKJbl1BKvTDzE0qQVjurc6gXfOO4IC/I67Ibu+aZuGavzWfw6xSdCmj53M77XRNZ97xt9h8JV2netG3DZR4nDW+I3X6TQ4jL2PXlTidDeiOpyGr9fsIbl1BOOfXXBcvze5VQSbMg+79/996UDO6N2G+Rv3Mbp7PA6nof/j33Dz6K7cMS6ZA4cLeW3BFvKLHTxydi8C/P1wOA1OY8gvdvCnT9Zw9+nd2Z2dT6e4cFpFBiNS8TbNrkP5PDT7Ny4YnFDjbSB1/LTLrWoeivPh53/Ztogf/2HLQqLt4kQZy8tmhA2Ohov+C0f223UoLp3Z6Nsm0jJzGTd9AW9emcLYnq0pKHZw36xUbjutKzkFJbw8P43v1mfywfXDueT1JfRtH82gjjF88dtu9h8uqvJ8p/VoxQ8bMpl+UX96tInizBfs6OO7T+/GM99W7DE0++aTOe+lnwF48vy+TB1adRlYh9PgJ43j/rzSpOHrMFR9cDrgxWFwYFP1xzuPtosMHc6EeA+60TYixhjeXbKdP326FrC9hVISW/Dagi1EhgR4PNAsJNCPb+8cRdaRIrq1jmTVjoOc3MXOnHDByz8TGRLAf68eitNp3N/8SwfQzVqZwaG8Iq47pbM3X6qqJ5o0VNPyw1/tB//H18IfPoFti2DhPyuek3gKdDujbG2KCU/aLrWNXFGJk5yCYv48Zx17sgtYujWrynQUxyIk0I97z+hBdn4x/dpHM65X69ovUk2edrlVjVvGCpskDm6DwDBY8FTZsXfOrf6a05+A9oMg5VpY8SYMvrpeQq1Lxhi27j9CxsF8hibZmsP0SreGAI8TxjkD2tEmKoQu8REEBgiPfrqWd64dRv8OMXUdumpmNGmohiP/ELwxFgLDofhI9edMfAo2fGFrEunLoDDHzhoLEBQGJ99Wf/HWkeXbsrhr5mr3XEc1uSglgb+f34+V2w/y+sItfLvOTs3es20UE3q3oUurcAZ0iCEhNqzKtecNTKhSptTx0KShGo79rm/WNSWMAZfBsBvsA6D7xPqJy0u+W7eX7m0iuendVew/XFjhWP+EaJ44pw9vL97O1SMSOZRXzMld4vDzEzs4Tewo4h/uHkXn+AgfvQLVHGnSUL7z2e3QbYKtOYy8E5a+WvO5XU+Hc1+qv9jqUNaRIpZuOcCQpBas353Dr+mHyDpSzIyfttZ4TUKLMPp3iOGZGm4npSS2YNuTZ3krZKVqpElD+UZeFqx6yz4AVr9bdqzdIDuW4vM7bE+oYTdCpxG+iLJW2XnFpO3L5eX5m7n3jB50bxNJTkExTqdhTupuvkjdzeJaVllrHxPKnNtG8vbi7QQH+vHkVxsYqG0PqoHSpKHqV84u+GAqDL2h5nNKV7LrfT4EBNuHD2XnFxMVEsChvGK+35DJ+QPb4zCGD5bt4KmvN7qntS5yGHq0ieS1BVuO+nyndovn57T9xEcG8/Llg92jqu8YZ6eQGNwplsG1TGWhlK9ol1tVfw5uhzfGwZHMqsci20HuLrj6a+hUw1xRHjDGkFNQUmFeJIB7PvqViX3aMLZn9d1MjTHM/mUnz3zzO49M6sUZvduQmVvAB0vTeXF+GimdYvl9by77DxfRLyGasT1aV5kquza3j00mJ7+Y207rSlyEbxOhUqUa1DgNEZkAPA/4A28YY56sdPxG4BbAARwGphlj1rmOPQhc6zp2uzFm7tF+lyaNBiIvC8JaVH9s9k3w6/sVy7qeDgMuhZ6T7bQeJziK+O3F23jk07UsvG8MHVrYXkSZOQUM/dv3ABXaAYwxzFqZwRl92jD9m9/578/b3MdO7RbPgt/31fr7RnePZ/7Gms8L8vejyOGkc3w4P9w9+rhek1Le1GDGaYiIP/AicDqQASwXkc9Kk4LL+8aYV1znTwamAxNEpBcwFegNtAO+E5FuxpjjG9Wk6sfWhfDW2WXLn5b6+kE7tUfG8ornX/Am9J1SpyF8kWrXxth+IM+dNNbuynEff2j2b/xxXDdWbMsit6CE+z5O5d5KM7ACFRLG4E6x9E+Iqbbh+r9XD2XDnhxCA/1JyzxM11YRzFyRzoiuLVmzM5tpp3Zh6/4jxIY14eVxVbPizTaNoUCaMWYLgIh8CJwDuJOGMSan3PnhQGm15xzgQ2NMIbBVRNJcz7fYi/GqE5W+1P7c+iN0Oc0ubrT+M1hSqdfT2Edtj6kup3ktlGKH0739+96yabffW7qD95buqHJ+/w4xDE2MZVL/drQID+K/P23jjUU2Sbxz7VDCggK48uROBPr7ccHLPzMsqQVjetjZUnu0iQKgU5ydcvveM+ziPCd3sdNtJ7WsOhW3Uo2VN5NGeyC93H4GUGVJKhG5BbgLCAJKP0XaA0sqXdt85q1ubJxOmHOHXccCwDjhPxPKkkhMJzt5IEDSKDjlLvvwoqwjdmK+/YcL7ZKhwQFEhQay81DVAXR3juvmboQu9fDZvUhsGU7PtlGEBdl/k9KksPjBsV6NXamGzJtJo7qb01UaUIwxLwIvisilwMPAlZ5eKyLTgGkAHTtWnW1TeUlJERQdLmu72DQXVr1ddnxPalnCSDwFrpoDRUcgdSYkn16noWTnFZNf7OCumav547hu7vKDeUWs2ZnN2f9aBECvtlFMv7g/E55bSKvIYDJzywbT3Xpa12qf+/Lhneo0VqWaAm8mjQygQ7n9BGDXUc7/EHj5WK41xrwGvAa2IfxEglXH4ONr7BoWjx6C4jzbhba8ra61GkbeCcNcEwcGhUPK8c0J9b/lO/hlxyHuPL0braNCKhzr/8Q37u32Menu21Ib9uSyZX/ZyPL2saH0aBPFnNtG0qttFF/8tpvbPviFJ87pjb+fTuGtlKe8mTSWA8kikgTsxDZsX1r+BBFJNsaUzm99FlC6/RnwvohMxzaEJwPLvBirOhbrP7c/H48B/xq6jg65zq6M56FDeUV8/usuAv39+HnzAV64ZCDLtmZx6/ur3LWCD5en8+zF/SkqcXLxkI6UlGu3APhoZYZ7e1a5bYBure1UG33aRwMwqX87JvXXBX2UOlZeSxrGmBIRuRWYi+1yO8MYs1ZEngBWGGM+A24VkXFAMXAQe2sK13kzsY3mJcAt2nPKx9KXQ2E2dB1XsdxRbs6ke1w5/5d37ShuT542K4+5a/ewfFsWc9fudZf3S4hm1Y6DFW4jAdz5P7tUaOuoELq2sokgwE9oGRHMnpwCAF66bBA3v7cKgAsHJ/DRyowKa0ArpY6fDu5TnnnMfkMnLA7yKk2LceXndq3tFse2KM+hvCIGPPFtjcfbx4RW23Bd2bvXDqNvQjRf/bab2PAgzujdhtSMQ6zZmcMlQzuQlnmY5NaRxxSbUs1FgxmnoZoIpwNmXVO2Xz5hBITCNV+VTU1eiwOHC7nu7RWEBvqz/UAeh/KqLj0KMDSxBcu2ZVVIGL3bRbnHW0zu347PfrVNXAmxofRsG0l0aGChvoB8AAAbOklEQVSFpUf7JcTQL8HO36QJQ6m6o0lDHV36Ulj3SdXyqPYUXPQ/3toUxrWtnQT4+1U5ZeehfG58ZyV/OKkTOfnF7M0p4Jcdh2r8VS3Cg0hqGc571w8j+aGvABjVLZ4nzulNu5hQftiQSUxoIIM7xdK9TSRTBidUaRhXSnmXJg1VlTE2UXz3OBwsNwp68FVw+p8hIAQCgnjpm4288MMGYsODuCilA9O/2UjGwXymXzyA/CIHd/1vNb/tzOa+akZcV2fFQ+Pwq9ST6d+XDiQyxI6mPqN3G3f5LWOq7yarlPIuTRoKlr4GR/bBaQ9B2newdrZtzC5v+M0w4g4IsaOfM3MKeOGHNABy8osB3PtdWkWwblcOS7dm1fgr20aHsDvbNlzfcGpn8oocFRLGW9cMJdBf3AlDKdUwaNJQ8NW99ufgK+HdCyoeeyQLCnMhtOL6DvM2ls1UW+I07unBAZ6eu7HGX3XlSZ14a/F2/nFBP/blFjJrZQYPntmzynmjusUfxwtRSnmbJo3mrnzvuQX/tD97TrJjMQLD7cyzoTHM25hJelYek/q1Y29uAR8sK5shpqDYwWWvL6GyW8d05dqRSTz8yRq++M1OJHjj6C5cd0pn92SCFwzWtauVakw0aTR3m38o2175H7uuxUXvQEG2u3jGoq08McfOM/nIp2urPMVz322qUhYU4McVJ3ciNjyIFy8bxHnr9vLu0u20jgyp0m6hlGo8NGk0R/kHYfGLtp3iy3sgMMxOBwJ2ASQRCI1h5op07pv1k8dPGxUSQE5BCV3iw3nn2mG0iizr2TSuV2vG9ap+ASSlVOOhSaM5WvQs/PQ8rHzLrqL3h9mw/E3YMIf0+NF8vWALwzvHVej11CU+nM37jlT7dAvvG0NYkD9xEcFk5xfj7ydEBOufllJNkf5nNweb58E758Jtq+yo7e2uZUmOZJIZ0ZP8mGF0Oqs3tOrFnzZ1Zn7aevelAzrE8NofBhMdFsiE5xay1TUJ4NUjElm5/SCPnN3L3T4BVFlmVSnVtFQdkaWano12oBypM+3iRxllcz/OOdSJG99dBZGteTfscn7ZmVfh0icv6EurqBCCA/x5dFIvd/mjk3rz2a0jSUmsYWlXpVSTpDWNpmrOXXbtiu4T7XxRAD/aJdrzY5IJiWyJpC9mnenE+t05JD7whfvSIYmx3DKmK4ayVekAereLrs9XoJRqgLSm0RQZAyveLFvnIr/iILtH941m7Z7DAGx3Vm2cPlLoYHT3Vozp3qpCeXyknQZ9dHcdQ6FUc6U1jaaouNzMsG+fC+EVpwXfYVpzx+EruN7/C1abqtNx7HVNMV6d3x4bT3CAf52FqpRqXDRpNEWFuWXbW+ZhxL/C+rm7TBw7TGseKJlW4bL/d2YP1u3K4cKUDtREp/VQqnnTpNEUFR2usCvGQXFQDIFFdobZvSYWgO/uOpV1u3O5/YNf6BIfzrRTu9R7qEqpxkWTRlNRdMQO2kudCQfSqhwem/soQ/02cFfr1SQ548jMLaRrq0hyCuycUSmdtBeUUqp2mjSaivcvhm0Lqz10UsG/2E0cOxytOWfivXya1MI95dTADjE8e3F/JvRuW4/BKqUaK+091VTUkDAyTQzjTxrk3m8VacdchATaxmwR4byBCYQGaeO2Uqp2mjQau1nXwN9rbrh2IogIKZ1sO0YrV7dZpZQ6Hnp7qrFaPwd2roA1H1c59LFjJBf4L+J7x0Cml0yhe0Exb145hBXbs4gND/JBsEqppkKTRmP1v8tqPPR54sOMOz2Sa1/aDsAr47oRHRbI2J46y6xS6sRo0miCxvVuR3THTvzn6lYM6hirkwgqpeqMtmk0VlHVr3j3aslZnNTFzjU1pnsrTRhKqTqlSaOxCimbPPCZ4ikAFJhA/l5yGUlx4b6KSinVxGnSaCycTvjlXSgpAkcJOIrch7Yb21ax2NmLByf20OVUlVJeo20ajcHSV+Gr++z2/k3w03MVDrdp046pOc9y1phh3DBKpwJRSnmPJo3GoDRhQIWEUWgCmGcGEdV1OO9NGIy/1jCUUl6mt6casVcck7ix6I+0bNlKE4ZSql5o0mjEjpgQgAprdCullDdp0mikZpaM4gvHcABO6hzn42iUUs2FV5OGiEwQkY0ikiYiD1Rz/C4RWSciqSLyvYh0KnfMISKrXY/PvBlng1RSCEtegUM7qj18X8kN7CSeU5Jbam8ppVS98VrSEBF/4EVgItALuEREelU67RcgxRjTD5gFPFXuWL4xZoDrMdlbcTZYq9+Hr++H5/pWKN551jtMLPy7e/+aEUn1HZlSqhnzZu+poUCaMWYLgIh8CJwDrCs9wRgzr9z5S4DLvRhP4+IsqbZ4xMf+gK2QrfrT6bTQCQiVUvXIm7en2gPp5fYzXGU1uRb4qtx+iIisEJElInKuNwJs0PIO1HpKbJhOEaKUql/erGlUd6PdVHuiyOVACjCqXHFHY8wuEekM/CAivxljNle6bhowDaBjx451E3VDkbunxkMXpSTw1JT+9RiMUkpZ3qxpZADlVwdKAHZVPklExgEPAZONMYWl5caYXa6fW4D5wMDK1xpjXjPGpBhjUuLj4+s2el/J3gkr34Ls9CqHDpoIAG47Lbm+o1JKKcC7NY3lQLKIJAE7ganApeVPEJGBwKvABGNMZrnyWCDPGFMoIi2BEVRsJG+6Fv8blrxU7aFtpg1Th3TQcRlKKZ/xqKYhIueJSHS5/Zja2hmMMSXArcBcYD0w0xizVkSeEJHS3lBPAxHAR5W61vYEVojIr8A84EljzDqaMqcT0pfDwe3VHl7pTOamojuICNaZX5RSviPGVNvMUPEkkdXGmAGVyn4xxlS5ZeQrKSkpZsWKFb4O4/j9/C/45uGKZe0Hw86V/O5sz/iipwFIfWw8USHaAK6UqhsistIYk+Lp+Z62aVR3nn7lrUt711bcb9MXJj0PwCqnbcMYkhirCUMp5VOefvCvEJHp2MF6BrgNWOm1qJojKZeXxz4Cp9yNMYZn+3/Bq0v3AeBBpVAppbzK05rGbUAR8D9gJpAP3OKtoJqncj2UQ1sA8Pbi7bywNJtC7AA+zRlKKV/zqKZhjDkCVJk7StUhKZc0wuLIKyrh0c8q3rLypP1JKaW8ydPeU9+KSEy5/VgRmeu9sJqhcknj6YX7+fuXG6qcMjRJZ7NVSvmWp20aLY0xh0p3jDEHRaSVl2Jqfr7/M6x62737zbZiNm2t2PX2+7tH0UnHZyilfMzTNg2niLjn6RCRRPQWe93IWAEL/1mhaL+JAsBPoEOLUObcNpIu8REE+OvyJ0op3/K0pvEQsEhEfnTtn4przid1gt4YW6XoIDZprP/zBIID/Os7IqWUqpGnDeFfi0gKNlGsBj7F9qBSJyL1oypFfyh6gA+nDadTXJgmDKVUg+NR0hCR64A7sJMOrgaGA4uB07wXWhO3Zw3833Xu3fx2w1keM5GFq5J5tlUELSOCfRicUkpVz9PbU3cAQ4AlxpgxItIDeNx7YTUDr4xwb667cAFnvpMBQGigP3G6sJJSqoHytGW1wBhTACAiwcaYDUB374XVjMQls6GghXs3v9iBiK75rZRqmDytaWS4xml8AnwrIgepZm0MdRxOuYuFG+0qfackt2R8r9Y+DkgppWrmaUP4ea7Nx0RkHhANfO21qJq6EvdaU+wvCWH2LzsBeOfaYb6KSCmlPHLMM9UaY36s/Sx1VAXZ7s2n5+0EOnPfBL3bp5Rq+HS0WH1zFLPujevdu+kH8wC4dmSSryJSSimPadKob7tW0+vQfPfu784OPHtxfx2ToZRqFDRp1KctP2JmjHfvji18mjvPG8F5AxN8GJRSSnlOV9+rT+s+RYwTgNNKXmCLaUlSXLiPg1JKKc9p0qhP5RrA/3bVRHYcLOSkLjrduVKq8dCkUY9KDu9zv+GDk1oyvKveHVRKNS76qVVPCoodbNm2nZXOZK6KeIVAneZcKdUI6SdXPfnXD5uIMtlsdrZjT0B7X4ejlFLHRZNGPXA4Dd+vySCOHPYRzd/P7+vrkJRS6rhom0Y9eHPRFgL2rycw2MElk8+iRcdYX4eklFLHRWsa9WDTnmzuDZgJQIvkk3wcjVJKHT9NGvWg35HFjPJPJc3ZDmI7+TocpZQ6bpo0vKkgBzZ9R9+D3wFwU/EffRyQUkqdGG3T8KYZEyBzLQOAPBNMQvIAX0eklFInRGsa3pS51r2ZE9iSN68a6sNglFLqxGlNo560btUa8dNlXJVSjZtXaxoiMkFENopImog8UM3xu0RknYikisj3ItKp3LErRWST63GlN+OsDxLWovaTlFKqgfNa0hARf+BFYCLQC7hERHpVOu0XIMUY0w+YBTzlurYF8CgwDBgKPCoijWpwQ1GJs2JBlI4CV0o1ft6saQwF0owxW4wxRcCHwDnlTzDGzDPG5Ll2lwClC0ucAXxrjMkyxhwEvgUmeDHWOpe+J7NiwWl/8k0gSilVh7yZNNoD6eX2M1xlNbkW+OpYrhWRaSKyQkRW7Nu37wTDrVu70zeX7XQ8GSLifReMUkrVEW8mjepafU21J4pcDqQATx/LtcaY14wxKcaYlPj4hvOh7HAaDuzZ7uswlFKqznkzaWQAHcrtJwC7Kp8kIuOAh4DJxpjCY7m2oTrr+QWkrlhUVjDyTt8Fo5RSdcibSWM5kCwiSSISBEwFPit/gogMBF7FJozyjQBzgfEiEutqAB/vKmsUTt7/EX8KfM/uPLgTuo0/+gVKKdVIeG2chjGmRERuxX7Y+wMzjDFrReQJYIUx5jPs7agI4CMRAdhhjJlsjMkSkT9jEw/AE8aYLG/FWpcKSxyc5reqrCA4wnfBKKVUHfPq4D5jzJfAl5XKHim3Pe4o184AZngvOu/IzCmkRMdMKqWaKJ1GpI7tySmgGH9fh6GUUl6hX4nritMBJYVEL3maIf6raj9fKaUaIU0adeWz22D1e3QrX3b5x76KRimlvEJvT9WV1e9V2DX9LoKuNTbZKKVUo6RJw0ukdR9fh6CUUnVOk4YX/BY6BIbe4OswlFKqzmnS8IK+t38EgSG+DkMppeqcJg1vCG1Us7grpZTHNGkopZTymCaNOmMn5nXqW6qUasL0E66OOMW+lSV+wT6ORCmlvEeTRh0pXd21kEDfBqKUUl6kSaMOOEtK3KtGBYWE+TQWpZTyJk0adaBkxgQCxQFA8ODLfByNUkp5jyaNE2UMQbvssh+50d1hzMM+DkgppbxHk8aJKsxxb4bl7QQ/fUuVUk2XfsKdIEfOXvd2wcTnfRiJUkp5nyaNE5SdmQ7A+z3+RfigKT6ORimlvEuTxgk6tG8nAF0TO/s4EqWU8j5NGicoL3s/ALEtW/s4EqWU8j5NGieo+EgWADFxrXwciVJKeZ8mjRPkOJJFvgkiNirS16EopZTXadI4AcU/v0zKrvfIJoIAf30rlVJNn37SHafXvvmFwG8eAKBE30alVDOhn3bHacii69zbQZT4MBKllKo/mjSO00C/NPd27hnP+TASpZSqP5o0TtDP9KfLyef5OgyllKoXmjSO02ZnWwDeCb7Ex5EopVT90aRxnPxw8qnjZDIi+vo6FKWUqjeaNI5TrBwh24TzzEX9fR2KUkrVG68mDRGZICIbRSRNRB6o5vipIrJKREpEZEqlYw4RWe16fObNOI/V73uyieQIXTq2p1trHdSnlGo+vJY0RMQfeBGYCPQCLhGRXpVO2wFcBbxfzVPkG2MGuB6TvRXn8fho0W/4iyE8VuebUko1LwFefO6hQJoxZguAiHwInAOsKz3BGLPNdczpxTjqXPa+DAD6de/m40iUUqp+efP2VHsgvdx+hqvMUyEiskJElojIuXUb2vFLy8xld8YOAPwitaahlGpevFnTkGrKzDFc39EYs0tEOgM/iMhvxpjNFX6ByDRgGkDHjh2PP9Jj8Pz3aZwasNbuRGjSUEo1L96saWQAHcrtJwC7PL3YGLPL9XMLMB8YWM05rxljUowxKfHx8ScWrYeKNs3nevnE7kTodOhKqebFm0ljOZAsIkkiEgRMBTzqBSUisSIS7NpuCYygXFuIr2TnFzOsaIndGf0ghMb4NiCllKpnXksaxpgS4FZgLrAemGmMWSsiT4jIZAARGSIiGcCFwKsi4rrvQ09ghYj8CswDnjTG+DxpLE7by0i/38hqOQRGV+lBrJRSTZ432zQwxnwJfFmp7JFy28uxt60qX/cz0OCGWv8y/1Mm+O0kb+j/83UoSinlEzoi/BjEZtvKTli/ST6ORCmlfEOThodKHE7aF24mO7gthET7OhyllPIJTRoe2p1dQBs5QEFEh9pPVkqpJkqThoe27D9CDEcIiIjzdShKKeUzmjQ8tHfzb7SUbMKj62c8iFJKNURe7T3VZBzZz0VLz7Nj3KO0pqGUar60puGBopzMsp3QWN8FopRSPqZJwwN79pSb/USThlKqGdOk4YHWX08r24lq57tAlFLKxzRp1KakkODCAwAUD7gSuoz1cUBKKeU7mjRqUXJ4v3s78Kx/gFQ347tSSjUPmjRqsT09o2wnMNR3gSilVAOgSaMW29PtKn17zp3l40iUUsr3NGnUYrer51TrNm19HIlSSvmeJo2jcRSTtOsLACS8pY+DUUop39OkcRRb57/FySVL7Y6uB66UUpo0anJw3y6SFt4NQMFln2mvKaWUQpNGjeZ+/IZ7OyR5lA8jUUqphkOTRg3a7fvJbty4yLeBKKVUA6JJoxpb57/FqY4lLO1wDbRpcEuVK6WUz+jU6ADLXoeFz9htZwlJR/aR5mxH4Kh7fBuXUko1MM0+aRSVOMlf9TGhJQ4Oth/DgSNFfJ3tT/bAm3i8a3tfh6eUUg1Ks08auQXFFO7eyHfOXty95hwAusSH8+opPXwcmVJKNTzNPmlE+hcTJ1kMGTSE9/sOIzoskN7ton0dllJKNUjNPmkEOQugzxQ69htFxy466lsppY6m2ScNwlvClDd9HYVSSjUK2uVWKaWUxzRpKKWU8pgmDaWUUh7TpKGUUspjmjSUUkp5TJOGUkopj2nSUEop5TFNGkoppTwmxhhfx1AnRGQfsP0EnqIlsL+OwqkvGnP90Jjrh8ZcPyrH3MkYE+/pxU0maZwoEVlhjEnxdRzHQmOuHxpz/dCY68eJxqy3p5RSSnlMk4ZSSimPadIo85qvAzgOGnP90Jjrh8ZcP04oZm3TUEop5TGtaSillPJYs08aIjJBRDaKSJqIPODreEqJyAwRyRSRNeXKWojItyKyyfUz1lUuIvKC6zWkisggH8XcQUTmich6EVkrInc09LhFJERElonIr66YH3eVJ4nIUlfM/xORIFd5sGs/zXU8sb5jLhe7v4j8IiJzGkPMIrJNRH4TkdUissJV1mD/NlxxxIjILBHZ4Pq7Pqkhxywi3V3vb+kjR0T+WKcxG2Oa7QPwBzYDnYEg4Fegl6/jcsV2KjAIWFOu7CngAdf2A8A/XNtnAl8BAgwHlvoo5rbAINd2JPA70Kshx+363RGu7UBgqSuWmcBUV/krwE2u7ZuBV1zbU4H/+fBv5C7gfWCOa79BxwxsA1pWKmuwfxuuON4CrnNtBwExDT3mcrH7A3uATnUZs89eUEN4ACcBc8vtPwg86Ou4ysWTWClpbATaurbbAhtd268Cl1R3no/j/xQ4vbHEDYQBq4Bh2MFPAZX/ToC5wEmu7QDXeeKDWBOA74HTgDmuf/qGHnN1SaPB/m0AUcDWyu9VQ465UpzjgZ/qOubmfnuqPZBebj/DVdZQtTbG7AZw/WzlKm9wr8N1C2Qg9pt7g47bdZtnNZAJfIutfR4yxpRUE5c7ZtfxbCCufiMG4DngPsDp2o+j4cdsgG9EZKWITHOVNeS/jc7APuA/rtuAb4hIOA075vKmAh+4tuss5uaeNKSassbYnaxBvQ4RiQA+Bv5ojMk52qnVlNV73MYYhzFmAPbb+1CgZ3WnuX76PGYRORvINMasLF9czakNJmaXEcaYQcBE4BYROfUo5zaEmAOwt4hfNsYMBI5gb+3UpCHEDICrPWsy8FFtp1ZTdtSYm3vSyAA6lNtPAHb5KBZP7BWRtgCun5mu8gbzOkQkEJsw3jPG/J+ruMHHDWCMOQTMx97bjRGRgGricsfsOh4NZNVvpIwAJovINuBD7C2q52jYMWOM2eX6mQnMxibohvy3kQFkGGOWuvZnYZNIQ4651ERglTFmr2u/zmJu7kljOZDs6nUShK3OfebjmI7mM+BK1/aV2DaD0vIrXD0hhgPZpVXR+iQiArwJrDfGTC93qMHGLSLxIhLj2g4FxgHrgXnAlBpiLn0tU4AfjOtmcH0xxjxojEkwxiRi/2Z/MMZcRgOOWUTCRSSydBt7v30NDfhvwxizB0gXke6uorHAuoYcczmXUHZrCuoyZl810jSUB7b3wO/Y+9gP+TqecnF9AOwGirHfBq7F3of+Htjk+tnCda4AL7pew29Aio9iHomt2qYCq12PMxty3EA/4BdXzGuAR1zlnYFlQBq2ih/sKg9x7ae5jnf28d/JaMp6TzXYmF2x/ep6rC39X2vIfxuuOAYAK1x/H58AsY0g5jDgABBdrqzOYtYR4UoppTzW3G9PKaWUOgaaNJRSSnlMk4ZSSimPadJQSinlMU0aSimlPKZJQ6laiIij0syhdTYbsogkSrmZjJVq6AJqP0WpZi/f2GlGlGr2tKah1HFyrQ/xD7HrcSwTka6u8k4i8r1rfYLvRaSjq7y1iMwWu3bHryJysuup/EXkdbHreXzjGpmOiNwuIutcz/Ohj16mUhVo0lCqdqGVbk9dXO5YjjFmKPBv7PxPuLbfNsb0A94DXnCVvwD8aIzpj53DaK2rPBl40RjTGzgEXOAqfwAY6HqeG7314pQ6FjoiXKlaiMhhY0xENeXbgNOMMVtcEzXuMcbEich+7JoExa7y3caYliKyD0gwxhSWe45E4FtjTLJr/34g0BjzFxH5GjiMnb7iE2PMYS+/VKVqpTUNpU6MqWG7pnOqU1hu20FZW+NZ2HmBBgMry81gq5TPaNJQ6sRcXO7nYtf2z9jZZwEuAxa5tr8HbgL3wk9RNT2piPgBHYwx87CLLcUAVWo7StU3/eaiVO1CXSv7lfraGFPa7TZYRJZiv4Bd4iq7HZghIvdiV3672lV+B/CaiFyLrVHchJ3JuDr+wLsiEo2difRZY9f7UMqntE1DqePkatNIMcbs93UsStUXvT2llFLKY1rTUEop5TGtaSillPKYJg2llFIe06ShlFLKY5o0lFJKeUyThlJKKY9p0lBKKeWx/w8G54SB/to/DwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTraining model:\n",
      "simplest\n",
      "0 - U:830|A:prelu|D:0.654 \n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 830)               651550    \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 830)               830       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 830)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                8310      \n",
      "=================================================================\n",
      "Total params: 660,690\n",
      "Trainable params: 660,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/50000\n",
      "9600/9600 [==============================] - 1s 58us/step - loss: 2.3005 - acc: 0.1157 - val_loss: 2.2999 - val_acc: 0.1154\n",
      "Epoch 2/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.2969 - acc: 0.1188 - val_loss: 2.2976 - val_acc: 0.1154\n",
      "Epoch 3/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.2914 - acc: 0.1280 - val_loss: 2.2888 - val_acc: 0.1175\n",
      "Epoch 4/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.2802 - acc: 0.1498 - val_loss: 2.2768 - val_acc: 0.1271\n",
      "Epoch 5/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.2624 - acc: 0.1746 - val_loss: 2.2470 - val_acc: 0.2204\n",
      "Epoch 6/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.2341 - acc: 0.2058 - val_loss: 2.2184 - val_acc: 0.2142\n",
      "Epoch 7/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 2.1992 - acc: 0.2234 - val_loss: 2.1731 - val_acc: 0.2225\n",
      "Epoch 8/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.1617 - acc: 0.2331 - val_loss: 2.1292 - val_acc: 0.2508\n",
      "Epoch 9/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.1209 - acc: 0.2474 - val_loss: 2.0879 - val_acc: 0.2825\n",
      "Epoch 10/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.0786 - acc: 0.2640 - val_loss: 2.0484 - val_acc: 0.2917\n",
      "Epoch 11/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.0422 - acc: 0.2741 - val_loss: 2.0124 - val_acc: 0.3054\n",
      "Epoch 12/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 2.0073 - acc: 0.2929 - val_loss: 1.9756 - val_acc: 0.3004\n",
      "Epoch 13/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.9733 - acc: 0.2989 - val_loss: 1.9517 - val_acc: 0.3096\n",
      "Epoch 14/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.9459 - acc: 0.3095 - val_loss: 1.9383 - val_acc: 0.3000\n",
      "Epoch 15/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.9211 - acc: 0.3114 - val_loss: 1.9023 - val_acc: 0.3233\n",
      "Epoch 16/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.9010 - acc: 0.3140 - val_loss: 1.8888 - val_acc: 0.3221\n",
      "Epoch 17/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.8851 - acc: 0.3219 - val_loss: 1.8710 - val_acc: 0.3283\n",
      "Epoch 18/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.8654 - acc: 0.3309 - val_loss: 1.8629 - val_acc: 0.3367\n",
      "Epoch 19/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.8534 - acc: 0.3306 - val_loss: 1.8673 - val_acc: 0.3171\n",
      "Epoch 20/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.8395 - acc: 0.3294 - val_loss: 1.8488 - val_acc: 0.3287\n",
      "Epoch 21/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.8258 - acc: 0.3412 - val_loss: 1.8396 - val_acc: 0.3325\n",
      "Epoch 22/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.8187 - acc: 0.3399 - val_loss: 1.8226 - val_acc: 0.3446\n",
      "Epoch 23/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.8111 - acc: 0.3443 - val_loss: 1.8203 - val_acc: 0.3292\n",
      "Epoch 24/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.8042 - acc: 0.3457 - val_loss: 1.8194 - val_acc: 0.3392\n",
      "Epoch 25/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.7964 - acc: 0.3445 - val_loss: 1.8114 - val_acc: 0.3329\n",
      "Epoch 26/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.7921 - acc: 0.3509 - val_loss: 1.8175 - val_acc: 0.3371\n",
      "Epoch 27/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.7916 - acc: 0.3484 - val_loss: 1.8042 - val_acc: 0.3350\n",
      "Epoch 28/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7813 - acc: 0.3538 - val_loss: 1.8085 - val_acc: 0.3337\n",
      "Epoch 29/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7810 - acc: 0.3545 - val_loss: 1.8004 - val_acc: 0.3379\n",
      "Epoch 30/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7742 - acc: 0.3549 - val_loss: 1.7992 - val_acc: 0.3454\n",
      "Epoch 31/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7753 - acc: 0.3527 - val_loss: 1.8007 - val_acc: 0.3325\n",
      "Epoch 32/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7712 - acc: 0.3569 - val_loss: 1.7908 - val_acc: 0.3375\n",
      "Epoch 33/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7679 - acc: 0.3602 - val_loss: 1.7931 - val_acc: 0.3388\n",
      "Epoch 34/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7666 - acc: 0.3579 - val_loss: 1.7900 - val_acc: 0.3429\n",
      "Epoch 35/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7591 - acc: 0.3597 - val_loss: 1.7900 - val_acc: 0.3429\n",
      "Epoch 36/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7578 - acc: 0.3541 - val_loss: 1.7880 - val_acc: 0.3421\n",
      "Epoch 37/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7574 - acc: 0.3620 - val_loss: 1.7848 - val_acc: 0.3454\n",
      "Epoch 38/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7569 - acc: 0.3638 - val_loss: 1.7914 - val_acc: 0.3467\n",
      "Epoch 39/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.7544 - acc: 0.3663 - val_loss: 1.7879 - val_acc: 0.3433\n",
      "Epoch 40/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.7532 - acc: 0.3584 - val_loss: 1.7848 - val_acc: 0.3437\n",
      "Epoch 41/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.7509 - acc: 0.3689 - val_loss: 1.7887 - val_acc: 0.3396\n",
      "Epoch 42/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.7477 - acc: 0.3664 - val_loss: 1.7820 - val_acc: 0.3421\n",
      "Epoch 43/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.7472 - acc: 0.3679 - val_loss: 1.7851 - val_acc: 0.3421\n",
      "Epoch 44/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.7414 - acc: 0.3693 - val_loss: 1.7832 - val_acc: 0.3446\n",
      "Epoch 45/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.7448 - acc: 0.3670 - val_loss: 1.7846 - val_acc: 0.3442\n",
      "Epoch 46/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.7401 - acc: 0.3716 - val_loss: 1.7822 - val_acc: 0.3412\n",
      "Epoch 47/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.7399 - acc: 0.3691 - val_loss: 1.7840 - val_acc: 0.3500\n",
      "Epoch 48/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.7385 - acc: 0.3682 - val_loss: 1.7831 - val_acc: 0.3433\n",
      "Epoch 49/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7349 - acc: 0.3697 - val_loss: 1.7785 - val_acc: 0.3467\n",
      "Epoch 50/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.7322 - acc: 0.3760 - val_loss: 1.7785 - val_acc: 0.3417\n",
      "Epoch 51/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7328 - acc: 0.3723 - val_loss: 1.7811 - val_acc: 0.3438\n",
      "Epoch 52/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7310 - acc: 0.3720 - val_loss: 1.7988 - val_acc: 0.3433\n",
      "Epoch 53/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7323 - acc: 0.3726 - val_loss: 1.7791 - val_acc: 0.3475\n",
      "Epoch 54/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7242 - acc: 0.3797 - val_loss: 1.7723 - val_acc: 0.3508\n",
      "Epoch 55/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7252 - acc: 0.3784 - val_loss: 1.7858 - val_acc: 0.3442\n",
      "Epoch 56/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7248 - acc: 0.3777 - val_loss: 1.7696 - val_acc: 0.3512\n",
      "Epoch 57/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7218 - acc: 0.3766 - val_loss: 1.7744 - val_acc: 0.3529\n",
      "Epoch 58/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.7211 - acc: 0.3804 - val_loss: 1.7833 - val_acc: 0.3496\n",
      "Epoch 59/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7172 - acc: 0.3807 - val_loss: 1.7727 - val_acc: 0.3463\n",
      "Epoch 60/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7177 - acc: 0.3807 - val_loss: 1.7694 - val_acc: 0.3546\n",
      "Epoch 61/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7142 - acc: 0.3807 - val_loss: 1.7699 - val_acc: 0.3554\n",
      "Epoch 62/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7104 - acc: 0.3815 - val_loss: 1.7776 - val_acc: 0.3508\n",
      "Epoch 63/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7071 - acc: 0.3837 - val_loss: 1.7731 - val_acc: 0.3537\n",
      "Epoch 64/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.7111 - acc: 0.3805 - val_loss: 1.7729 - val_acc: 0.3471\n",
      "Epoch 65/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.7110 - acc: 0.3803 - val_loss: 1.7773 - val_acc: 0.3525\n",
      "Epoch 66/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7070 - acc: 0.3806 - val_loss: 1.7649 - val_acc: 0.3512\n",
      "Epoch 67/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7050 - acc: 0.3868 - val_loss: 1.7662 - val_acc: 0.3521\n",
      "Epoch 68/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6978 - acc: 0.3869 - val_loss: 1.7632 - val_acc: 0.3521\n",
      "Epoch 69/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7001 - acc: 0.3850 - val_loss: 1.7691 - val_acc: 0.3508\n",
      "Epoch 70/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.7000 - acc: 0.3877 - val_loss: 1.7639 - val_acc: 0.3579\n",
      "Epoch 71/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6994 - acc: 0.3880 - val_loss: 1.7772 - val_acc: 0.3483\n",
      "Epoch 72/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6966 - acc: 0.3908 - val_loss: 1.7620 - val_acc: 0.3538\n",
      "Epoch 73/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6954 - acc: 0.3892 - val_loss: 1.7608 - val_acc: 0.3521\n",
      "Epoch 74/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6917 - acc: 0.3926 - val_loss: 1.7753 - val_acc: 0.3529\n",
      "Epoch 75/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6926 - acc: 0.3928 - val_loss: 1.7744 - val_acc: 0.3521\n",
      "Epoch 76/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6882 - acc: 0.3931 - val_loss: 1.7606 - val_acc: 0.3567\n",
      "Epoch 77/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6883 - acc: 0.3918 - val_loss: 1.7679 - val_acc: 0.3521\n",
      "Epoch 78/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6857 - acc: 0.3931 - val_loss: 1.7759 - val_acc: 0.3462\n",
      "Epoch 79/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.6856 - acc: 0.3926 - val_loss: 1.7604 - val_acc: 0.3550\n",
      "Epoch 80/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.6811 - acc: 0.3939 - val_loss: 1.7570 - val_acc: 0.3554\n",
      "Epoch 81/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.6820 - acc: 0.3914 - val_loss: 1.7654 - val_acc: 0.3625\n",
      "Epoch 82/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.6783 - acc: 0.3965 - val_loss: 1.7592 - val_acc: 0.3537\n",
      "Epoch 83/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.6769 - acc: 0.4001 - val_loss: 1.7580 - val_acc: 0.3538\n",
      "Epoch 84/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.6736 - acc: 0.4003 - val_loss: 1.7564 - val_acc: 0.3542\n",
      "Epoch 85/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6788 - acc: 0.3981 - val_loss: 1.7552 - val_acc: 0.3592\n",
      "Epoch 86/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6754 - acc: 0.4044 - val_loss: 1.7599 - val_acc: 0.3533\n",
      "Epoch 87/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6675 - acc: 0.4045 - val_loss: 1.7572 - val_acc: 0.3583\n",
      "Epoch 88/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6708 - acc: 0.3961 - val_loss: 1.7648 - val_acc: 0.3537\n",
      "Epoch 89/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6697 - acc: 0.3985 - val_loss: 1.7510 - val_acc: 0.3550\n",
      "Epoch 90/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6684 - acc: 0.3995 - val_loss: 1.7644 - val_acc: 0.3550\n",
      "Epoch 91/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6713 - acc: 0.3984 - val_loss: 1.7576 - val_acc: 0.3596\n",
      "Epoch 92/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6649 - acc: 0.3960 - val_loss: 1.7596 - val_acc: 0.3587\n",
      "Epoch 93/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6580 - acc: 0.4074 - val_loss: 1.7515 - val_acc: 0.3613\n",
      "Epoch 94/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6631 - acc: 0.4006 - val_loss: 1.7578 - val_acc: 0.3621\n",
      "Epoch 95/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6595 - acc: 0.4046 - val_loss: 1.7617 - val_acc: 0.3533\n",
      "Epoch 96/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6586 - acc: 0.4027 - val_loss: 1.7554 - val_acc: 0.3567\n",
      "Epoch 97/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6548 - acc: 0.4073 - val_loss: 1.7733 - val_acc: 0.3508\n",
      "Epoch 98/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6530 - acc: 0.4082 - val_loss: 1.7520 - val_acc: 0.3571\n",
      "Epoch 99/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6503 - acc: 0.4080 - val_loss: 1.7498 - val_acc: 0.3629\n",
      "Epoch 100/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6483 - acc: 0.4062 - val_loss: 1.7588 - val_acc: 0.3488\n",
      "Epoch 101/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6520 - acc: 0.4104 - val_loss: 1.7475 - val_acc: 0.3646\n",
      "Epoch 102/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6458 - acc: 0.4089 - val_loss: 1.7565 - val_acc: 0.3563\n",
      "Epoch 103/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6450 - acc: 0.4113 - val_loss: 1.7486 - val_acc: 0.3654\n",
      "Epoch 104/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6441 - acc: 0.4095 - val_loss: 1.7475 - val_acc: 0.3625\n",
      "Epoch 105/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6419 - acc: 0.4118 - val_loss: 1.7573 - val_acc: 0.3633\n",
      "Epoch 106/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6400 - acc: 0.4132 - val_loss: 1.7516 - val_acc: 0.3642\n",
      "Epoch 107/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6350 - acc: 0.4149 - val_loss: 1.7505 - val_acc: 0.3658\n",
      "Epoch 108/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6396 - acc: 0.4091 - val_loss: 1.7478 - val_acc: 0.3592\n",
      "Epoch 109/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6378 - acc: 0.4157 - val_loss: 1.7710 - val_acc: 0.3558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6353 - acc: 0.4130 - val_loss: 1.7481 - val_acc: 0.3683\n",
      "Epoch 111/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6276 - acc: 0.4200 - val_loss: 1.7483 - val_acc: 0.3633\n",
      "Epoch 112/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6307 - acc: 0.4159 - val_loss: 1.7462 - val_acc: 0.3671\n",
      "Epoch 113/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6332 - acc: 0.4146 - val_loss: 1.7551 - val_acc: 0.3558\n",
      "Epoch 114/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6251 - acc: 0.4206 - val_loss: 1.7503 - val_acc: 0.3538\n",
      "Epoch 115/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6267 - acc: 0.4148 - val_loss: 1.7467 - val_acc: 0.3633\n",
      "Epoch 116/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6196 - acc: 0.4191 - val_loss: 1.7553 - val_acc: 0.3654\n",
      "Epoch 117/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6229 - acc: 0.4218 - val_loss: 1.7523 - val_acc: 0.3587\n",
      "Epoch 118/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6233 - acc: 0.4254 - val_loss: 1.7467 - val_acc: 0.3679\n",
      "Epoch 119/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6194 - acc: 0.4185 - val_loss: 1.7518 - val_acc: 0.3633\n",
      "Epoch 120/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6186 - acc: 0.4205 - val_loss: 1.7393 - val_acc: 0.3708\n",
      "Epoch 121/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6174 - acc: 0.4241 - val_loss: 1.7463 - val_acc: 0.3667\n",
      "Epoch 122/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6162 - acc: 0.4214 - val_loss: 1.7439 - val_acc: 0.3671\n",
      "Epoch 123/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6100 - acc: 0.4316 - val_loss: 1.7698 - val_acc: 0.3592\n",
      "Epoch 124/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6152 - acc: 0.4236 - val_loss: 1.7495 - val_acc: 0.3679\n",
      "Epoch 125/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6070 - acc: 0.4291 - val_loss: 1.7367 - val_acc: 0.3725\n",
      "Epoch 126/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6086 - acc: 0.4231 - val_loss: 1.7453 - val_acc: 0.3667\n",
      "Epoch 127/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6001 - acc: 0.4310 - val_loss: 1.7413 - val_acc: 0.3688\n",
      "Epoch 128/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6000 - acc: 0.4260 - val_loss: 1.7388 - val_acc: 0.3687\n",
      "Epoch 129/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6068 - acc: 0.4310 - val_loss: 1.7586 - val_acc: 0.3658\n",
      "Epoch 130/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.5947 - acc: 0.4343 - val_loss: 1.7490 - val_acc: 0.3708\n",
      "Epoch 131/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5967 - acc: 0.4321 - val_loss: 1.7469 - val_acc: 0.3650\n",
      "Epoch 132/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.6058 - acc: 0.4258 - val_loss: 1.7445 - val_acc: 0.3600\n",
      "Epoch 133/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5964 - acc: 0.4318 - val_loss: 1.7501 - val_acc: 0.3604\n",
      "Epoch 134/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5919 - acc: 0.4349 - val_loss: 1.7365 - val_acc: 0.3629\n",
      "Epoch 135/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5951 - acc: 0.4322 - val_loss: 1.7318 - val_acc: 0.3663\n",
      "Epoch 136/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5865 - acc: 0.4351 - val_loss: 1.7464 - val_acc: 0.3683\n",
      "Epoch 137/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.5829 - acc: 0.4368 - val_loss: 1.7344 - val_acc: 0.3725\n",
      "Epoch 138/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.5808 - acc: 0.4342 - val_loss: 1.7343 - val_acc: 0.3717\n",
      "Epoch 139/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.5858 - acc: 0.4367 - val_loss: 1.7338 - val_acc: 0.3729\n",
      "Epoch 140/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.5809 - acc: 0.4375 - val_loss: 1.7397 - val_acc: 0.3654\n",
      "Epoch 141/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5777 - acc: 0.4392 - val_loss: 1.7539 - val_acc: 0.3613\n",
      "Epoch 142/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.5809 - acc: 0.4333 - val_loss: 1.7422 - val_acc: 0.3637\n",
      "Epoch 143/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.5783 - acc: 0.4366 - val_loss: 1.7325 - val_acc: 0.3733\n",
      "Epoch 144/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5780 - acc: 0.4353 - val_loss: 1.7390 - val_acc: 0.3650\n",
      "Epoch 145/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5774 - acc: 0.4349 - val_loss: 1.7337 - val_acc: 0.3738\n",
      "Epoch 146/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5750 - acc: 0.4400 - val_loss: 1.7355 - val_acc: 0.3612\n",
      "Epoch 147/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5698 - acc: 0.4414 - val_loss: 1.7410 - val_acc: 0.3679\n",
      "Epoch 148/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.5701 - acc: 0.4380 - val_loss: 1.7422 - val_acc: 0.3700\n",
      "Epoch 149/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.5670 - acc: 0.4443 - val_loss: 1.7311 - val_acc: 0.3746\n",
      "Epoch 150/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.5682 - acc: 0.4397 - val_loss: 1.7373 - val_acc: 0.3700\n",
      "Epoch 151/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.5623 - acc: 0.4403 - val_loss: 1.7397 - val_acc: 0.3687\n",
      "Epoch 152/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5622 - acc: 0.4371 - val_loss: 1.7459 - val_acc: 0.3575\n",
      "Epoch 153/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.5612 - acc: 0.4363 - val_loss: 1.7273 - val_acc: 0.3738\n",
      "Epoch 154/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5617 - acc: 0.4366 - val_loss: 1.7415 - val_acc: 0.3717\n",
      "Epoch 155/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5533 - acc: 0.4428 - val_loss: 1.7286 - val_acc: 0.3696\n",
      "Epoch 156/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5600 - acc: 0.4478 - val_loss: 1.7286 - val_acc: 0.3708\n",
      "Epoch 157/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.5561 - acc: 0.4464 - val_loss: 1.7222 - val_acc: 0.3808\n",
      "Epoch 158/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.5526 - acc: 0.4458 - val_loss: 1.7264 - val_acc: 0.3667\n",
      "Epoch 159/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.5510 - acc: 0.4517 - val_loss: 1.7291 - val_acc: 0.3738\n",
      "Epoch 160/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.5460 - acc: 0.4436 - val_loss: 1.7209 - val_acc: 0.3800\n",
      "Epoch 161/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5490 - acc: 0.4481 - val_loss: 1.7365 - val_acc: 0.3600\n",
      "Epoch 162/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5457 - acc: 0.4503 - val_loss: 1.7244 - val_acc: 0.3700\n",
      "Epoch 163/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5485 - acc: 0.4552 - val_loss: 1.7257 - val_acc: 0.3758\n",
      "Epoch 164/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5370 - acc: 0.4581 - val_loss: 1.7419 - val_acc: 0.3633\n",
      "Epoch 165/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5420 - acc: 0.4524 - val_loss: 1.7347 - val_acc: 0.3742\n",
      "Epoch 166/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5408 - acc: 0.4532 - val_loss: 1.7211 - val_acc: 0.3758\n",
      "Epoch 167/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5406 - acc: 0.4537 - val_loss: 1.7226 - val_acc: 0.3729\n",
      "Epoch 168/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.5307 - acc: 0.4566 - val_loss: 1.7253 - val_acc: 0.3683\n",
      "Epoch 169/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.5353 - acc: 0.4519 - val_loss: 1.7277 - val_acc: 0.3733\n",
      "Epoch 170/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5365 - acc: 0.4523 - val_loss: 1.7323 - val_acc: 0.3754\n",
      "Epoch 171/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5252 - acc: 0.4599 - val_loss: 1.7447 - val_acc: 0.3654\n",
      "Epoch 172/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5268 - acc: 0.4589 - val_loss: 1.7247 - val_acc: 0.3721\n",
      "Epoch 173/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5255 - acc: 0.4560 - val_loss: 1.7168 - val_acc: 0.3754\n",
      "Epoch 174/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.5233 - acc: 0.4567 - val_loss: 1.7176 - val_acc: 0.3787\n",
      "Epoch 175/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5276 - acc: 0.4545 - val_loss: 1.7170 - val_acc: 0.3746\n",
      "Epoch 176/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5257 - acc: 0.4572 - val_loss: 1.7207 - val_acc: 0.3817\n",
      "Epoch 177/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5228 - acc: 0.4571 - val_loss: 1.7256 - val_acc: 0.3796\n",
      "Epoch 178/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5172 - acc: 0.4630 - val_loss: 1.7281 - val_acc: 0.3738\n",
      "Epoch 179/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5164 - acc: 0.4630 - val_loss: 1.7213 - val_acc: 0.3817\n",
      "Epoch 180/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5182 - acc: 0.4589 - val_loss: 1.7297 - val_acc: 0.3708\n",
      "Epoch 181/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5160 - acc: 0.4573 - val_loss: 1.7186 - val_acc: 0.3804\n",
      "Epoch 182/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5120 - acc: 0.4618 - val_loss: 1.7192 - val_acc: 0.3767\n",
      "Epoch 183/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.5138 - acc: 0.4601 - val_loss: 1.7232 - val_acc: 0.3792\n",
      "Epoch 184/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5057 - acc: 0.4651 - val_loss: 1.7354 - val_acc: 0.3771\n",
      "Epoch 185/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5116 - acc: 0.4597 - val_loss: 1.7215 - val_acc: 0.3783\n",
      "Epoch 186/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5115 - acc: 0.4608 - val_loss: 1.7266 - val_acc: 0.3725\n",
      "Epoch 187/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5035 - acc: 0.4649 - val_loss: 1.7270 - val_acc: 0.3771\n",
      "Epoch 188/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4987 - acc: 0.4688 - val_loss: 1.7121 - val_acc: 0.3771\n",
      "Epoch 189/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5021 - acc: 0.4725 - val_loss: 1.7138 - val_acc: 0.3775\n",
      "Epoch 190/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5055 - acc: 0.4663 - val_loss: 1.7231 - val_acc: 0.3729\n",
      "Epoch 191/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.4964 - acc: 0.4681 - val_loss: 1.7203 - val_acc: 0.3821\n",
      "Epoch 192/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5018 - acc: 0.4671 - val_loss: 1.7182 - val_acc: 0.3733\n",
      "Epoch 193/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.4941 - acc: 0.4676 - val_loss: 1.7118 - val_acc: 0.3804\n",
      "Epoch 194/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5028 - acc: 0.4615 - val_loss: 1.7150 - val_acc: 0.3833\n",
      "Epoch 195/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4925 - acc: 0.4673 - val_loss: 1.7122 - val_acc: 0.3846\n",
      "Epoch 196/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.4941 - acc: 0.4706 - val_loss: 1.7247 - val_acc: 0.3858\n",
      "Epoch 197/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4871 - acc: 0.4724 - val_loss: 1.7129 - val_acc: 0.3829\n",
      "Epoch 198/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.4904 - acc: 0.4722 - val_loss: 1.7129 - val_acc: 0.3754\n",
      "Epoch 199/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4836 - acc: 0.4735 - val_loss: 1.7128 - val_acc: 0.3817\n",
      "Epoch 200/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4847 - acc: 0.4770 - val_loss: 1.7142 - val_acc: 0.3787\n",
      "Epoch 201/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4853 - acc: 0.4696 - val_loss: 1.7279 - val_acc: 0.3767\n",
      "Epoch 202/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4734 - acc: 0.4797 - val_loss: 1.7156 - val_acc: 0.3817\n",
      "Epoch 203/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4826 - acc: 0.4712 - val_loss: 1.7134 - val_acc: 0.3721\n",
      "Epoch 204/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4768 - acc: 0.4801 - val_loss: 1.7163 - val_acc: 0.3813\n",
      "Epoch 205/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4782 - acc: 0.4723 - val_loss: 1.7093 - val_acc: 0.3812\n",
      "Epoch 206/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4732 - acc: 0.4799 - val_loss: 1.7104 - val_acc: 0.3771\n",
      "Epoch 207/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4683 - acc: 0.4779 - val_loss: 1.7214 - val_acc: 0.3733\n",
      "Epoch 208/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4750 - acc: 0.4727 - val_loss: 1.7115 - val_acc: 0.3804\n",
      "Epoch 209/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4635 - acc: 0.4803 - val_loss: 1.7123 - val_acc: 0.3842\n",
      "Epoch 210/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4607 - acc: 0.4826 - val_loss: 1.7087 - val_acc: 0.3808\n",
      "Epoch 211/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4666 - acc: 0.4814 - val_loss: 1.7255 - val_acc: 0.3696\n",
      "Epoch 212/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4683 - acc: 0.4835 - val_loss: 1.7056 - val_acc: 0.3900\n",
      "Epoch 213/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.4621 - acc: 0.4799 - val_loss: 1.7226 - val_acc: 0.3796\n",
      "Epoch 214/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4598 - acc: 0.4836 - val_loss: 1.7287 - val_acc: 0.3775\n",
      "Epoch 215/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4615 - acc: 0.4829 - val_loss: 1.7146 - val_acc: 0.3808\n",
      "Epoch 216/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4516 - acc: 0.4886 - val_loss: 1.7176 - val_acc: 0.3821\n",
      "Epoch 217/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4639 - acc: 0.4831 - val_loss: 1.7146 - val_acc: 0.3837\n",
      "Epoch 218/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4524 - acc: 0.4889 - val_loss: 1.7064 - val_acc: 0.3863\n",
      "Epoch 219/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4544 - acc: 0.4862 - val_loss: 1.7052 - val_acc: 0.3962\n",
      "Epoch 220/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4498 - acc: 0.4867 - val_loss: 1.7092 - val_acc: 0.3850\n",
      "Epoch 221/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4421 - acc: 0.4885 - val_loss: 1.7202 - val_acc: 0.3817\n",
      "Epoch 222/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4429 - acc: 0.4881 - val_loss: 1.7019 - val_acc: 0.3988\n",
      "Epoch 223/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4465 - acc: 0.4889 - val_loss: 1.7084 - val_acc: 0.3921\n",
      "Epoch 224/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4419 - acc: 0.4886 - val_loss: 1.7083 - val_acc: 0.3879\n",
      "Epoch 225/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4375 - acc: 0.4900 - val_loss: 1.7093 - val_acc: 0.3883\n",
      "Epoch 226/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4438 - acc: 0.4955 - val_loss: 1.7108 - val_acc: 0.3904\n",
      "Epoch 227/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4426 - acc: 0.4857 - val_loss: 1.7135 - val_acc: 0.3875\n",
      "Epoch 228/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4452 - acc: 0.4907 - val_loss: 1.7089 - val_acc: 0.3921\n",
      "Epoch 229/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4388 - acc: 0.4839 - val_loss: 1.7047 - val_acc: 0.3879\n",
      "Epoch 230/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4273 - acc: 0.4936 - val_loss: 1.7190 - val_acc: 0.3838\n",
      "Epoch 231/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4260 - acc: 0.4994 - val_loss: 1.7003 - val_acc: 0.3954\n",
      "Epoch 232/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4293 - acc: 0.4952 - val_loss: 1.7225 - val_acc: 0.3896\n",
      "Epoch 233/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4321 - acc: 0.4921 - val_loss: 1.7141 - val_acc: 0.3900\n",
      "Epoch 234/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4329 - acc: 0.4953 - val_loss: 1.6991 - val_acc: 0.3937\n",
      "Epoch 235/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4210 - acc: 0.5034 - val_loss: 1.7090 - val_acc: 0.3896\n",
      "Epoch 236/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4197 - acc: 0.5000 - val_loss: 1.7047 - val_acc: 0.3896\n",
      "Epoch 237/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4249 - acc: 0.4945 - val_loss: 1.7083 - val_acc: 0.3942\n",
      "Epoch 238/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4104 - acc: 0.5037 - val_loss: 1.7159 - val_acc: 0.3833\n",
      "Epoch 239/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4109 - acc: 0.5039 - val_loss: 1.7038 - val_acc: 0.3958\n",
      "Epoch 240/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.4076 - acc: 0.5047 - val_loss: 1.7075 - val_acc: 0.3863\n",
      "Epoch 241/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.4094 - acc: 0.5060 - val_loss: 1.7006 - val_acc: 0.3975\n",
      "Epoch 242/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.4110 - acc: 0.5004 - val_loss: 1.7074 - val_acc: 0.3950\n",
      "Epoch 243/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.4076 - acc: 0.5043 - val_loss: 1.7198 - val_acc: 0.3854\n",
      "Epoch 244/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.4106 - acc: 0.5018 - val_loss: 1.7055 - val_acc: 0.3904\n",
      "Epoch 245/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.4165 - acc: 0.4989 - val_loss: 1.6955 - val_acc: 0.3983\n",
      "Epoch 246/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.4051 - acc: 0.5080 - val_loss: 1.6988 - val_acc: 0.4008\n",
      "Epoch 247/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.3913 - acc: 0.5091 - val_loss: 1.6982 - val_acc: 0.4017\n",
      "Epoch 248/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.3995 - acc: 0.5074 - val_loss: 1.7069 - val_acc: 0.3987\n",
      "Epoch 249/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.4048 - acc: 0.5075 - val_loss: 1.7110 - val_acc: 0.3883\n",
      "Epoch 250/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.3958 - acc: 0.5076 - val_loss: 1.7202 - val_acc: 0.3808\n",
      "Epoch 251/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.3935 - acc: 0.5096 - val_loss: 1.7131 - val_acc: 0.3929\n",
      "Epoch 252/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.3955 - acc: 0.5092 - val_loss: 1.6978 - val_acc: 0.3925\n",
      "Epoch 253/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3869 - acc: 0.5141 - val_loss: 1.7049 - val_acc: 0.3837\n",
      "Epoch 254/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.3912 - acc: 0.5092 - val_loss: 1.7035 - val_acc: 0.3971\n",
      "Epoch 255/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3986 - acc: 0.5090 - val_loss: 1.6944 - val_acc: 0.4029\n",
      "Epoch 256/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3781 - acc: 0.5173 - val_loss: 1.7046 - val_acc: 0.3954\n",
      "Epoch 257/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3875 - acc: 0.5164 - val_loss: 1.6935 - val_acc: 0.3988\n",
      "Epoch 258/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3797 - acc: 0.5144 - val_loss: 1.7157 - val_acc: 0.3850\n",
      "Epoch 259/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3798 - acc: 0.5167 - val_loss: 1.6918 - val_acc: 0.3942\n",
      "Epoch 260/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3728 - acc: 0.5165 - val_loss: 1.6933 - val_acc: 0.3942\n",
      "Epoch 261/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3849 - acc: 0.5132 - val_loss: 1.6914 - val_acc: 0.3950\n",
      "Epoch 262/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.3796 - acc: 0.5174 - val_loss: 1.6909 - val_acc: 0.4037\n",
      "Epoch 263/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3780 - acc: 0.5128 - val_loss: 1.7014 - val_acc: 0.3921\n",
      "Epoch 264/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3675 - acc: 0.5191 - val_loss: 1.7024 - val_acc: 0.3913\n",
      "Epoch 265/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.3666 - acc: 0.5200 - val_loss: 1.6954 - val_acc: 0.3929\n",
      "Epoch 266/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.3680 - acc: 0.5190 - val_loss: 1.6927 - val_acc: 0.4062\n",
      "Epoch 267/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.3629 - acc: 0.5234 - val_loss: 1.7012 - val_acc: 0.3967\n",
      "Epoch 268/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.3632 - acc: 0.5227 - val_loss: 1.6907 - val_acc: 0.4021\n",
      "Epoch 269/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3624 - acc: 0.5201 - val_loss: 1.6947 - val_acc: 0.4012\n",
      "Epoch 270/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3511 - acc: 0.5301 - val_loss: 1.6987 - val_acc: 0.3958\n",
      "Epoch 271/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.3616 - acc: 0.5234 - val_loss: 1.6897 - val_acc: 0.4000\n",
      "Epoch 272/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3519 - acc: 0.5273 - val_loss: 1.6891 - val_acc: 0.3954\n",
      "Epoch 273/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3627 - acc: 0.5199 - val_loss: 1.7002 - val_acc: 0.3962\n",
      "Epoch 274/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3482 - acc: 0.5295 - val_loss: 1.6968 - val_acc: 0.4021\n",
      "Epoch 275/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3523 - acc: 0.5254 - val_loss: 1.6949 - val_acc: 0.3987\n",
      "Epoch 276/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3509 - acc: 0.5270 - val_loss: 1.6882 - val_acc: 0.4071\n",
      "Epoch 277/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.3444 - acc: 0.5270 - val_loss: 1.6855 - val_acc: 0.4071\n",
      "Epoch 278/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3431 - acc: 0.5292 - val_loss: 1.6772 - val_acc: 0.4083\n",
      "Epoch 279/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.3402 - acc: 0.5325 - val_loss: 1.7101 - val_acc: 0.3975\n",
      "Epoch 280/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.3543 - acc: 0.5278 - val_loss: 1.7006 - val_acc: 0.4021\n",
      "Epoch 281/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.3496 - acc: 0.5295 - val_loss: 1.6892 - val_acc: 0.4054\n",
      "Epoch 282/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.3349 - acc: 0.5337 - val_loss: 1.6933 - val_acc: 0.4012\n",
      "Epoch 283/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.3427 - acc: 0.5293 - val_loss: 1.7052 - val_acc: 0.3942\n",
      "Epoch 284/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.3394 - acc: 0.5348 - val_loss: 1.6860 - val_acc: 0.4096\n",
      "Epoch 285/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.3419 - acc: 0.5295 - val_loss: 1.6875 - val_acc: 0.3979\n",
      "Epoch 286/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.3342 - acc: 0.5346 - val_loss: 1.6862 - val_acc: 0.4008\n",
      "Epoch 287/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 1.3290 - acc: 0.5342 - val_loss: 1.6953 - val_acc: 0.3954\n",
      "Epoch 288/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.3258 - acc: 0.5337 - val_loss: 1.6894 - val_acc: 0.4050\n",
      "Epoch 289/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.3236 - acc: 0.5385 - val_loss: 1.6972 - val_acc: 0.4008\n",
      "Epoch 290/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.3231 - acc: 0.5345 - val_loss: 1.6802 - val_acc: 0.4046\n",
      "Epoch 291/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3241 - acc: 0.5374 - val_loss: 1.6934 - val_acc: 0.3967\n",
      "Epoch 292/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3122 - acc: 0.5446 - val_loss: 1.6866 - val_acc: 0.4050\n",
      "Epoch 293/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3250 - acc: 0.5351 - val_loss: 1.7018 - val_acc: 0.4046\n",
      "Epoch 294/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.3215 - acc: 0.5366 - val_loss: 1.6904 - val_acc: 0.4025\n",
      "Epoch 295/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.3130 - acc: 0.5438 - val_loss: 1.6782 - val_acc: 0.4100\n",
      "Epoch 296/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3103 - acc: 0.5390 - val_loss: 1.7012 - val_acc: 0.3967\n",
      "Epoch 297/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3140 - acc: 0.5413 - val_loss: 1.6761 - val_acc: 0.4117\n",
      "Epoch 298/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3212 - acc: 0.5403 - val_loss: 1.7047 - val_acc: 0.3971\n",
      "Epoch 299/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3057 - acc: 0.5390 - val_loss: 1.6864 - val_acc: 0.4017\n",
      "Epoch 300/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3129 - acc: 0.5414 - val_loss: 1.6862 - val_acc: 0.4058\n",
      "Epoch 301/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3052 - acc: 0.5460 - val_loss: 1.6919 - val_acc: 0.4142\n",
      "Epoch 302/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3001 - acc: 0.5428 - val_loss: 1.6887 - val_acc: 0.4017\n",
      "Epoch 303/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2997 - acc: 0.5440 - val_loss: 1.6977 - val_acc: 0.3954\n",
      "Epoch 304/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2982 - acc: 0.5487 - val_loss: 1.6827 - val_acc: 0.4092\n",
      "Epoch 305/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2971 - acc: 0.5422 - val_loss: 1.6878 - val_acc: 0.4042\n",
      "Epoch 306/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3007 - acc: 0.5433 - val_loss: 1.6881 - val_acc: 0.4008\n",
      "Epoch 307/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.2922 - acc: 0.5495 - val_loss: 1.6798 - val_acc: 0.4071\n",
      "Epoch 308/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.2865 - acc: 0.5491 - val_loss: 1.6807 - val_acc: 0.4088\n",
      "Epoch 309/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.2925 - acc: 0.5497 - val_loss: 1.6915 - val_acc: 0.4050\n",
      "Epoch 310/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.2900 - acc: 0.5520 - val_loss: 1.6982 - val_acc: 0.4038\n",
      "Epoch 311/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.3008 - acc: 0.5506 - val_loss: 1.6884 - val_acc: 0.4042\n",
      "Epoch 312/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.2904 - acc: 0.5453 - val_loss: 1.6731 - val_acc: 0.4108\n",
      "Epoch 313/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2891 - acc: 0.5532 - val_loss: 1.6724 - val_acc: 0.4154\n",
      "Epoch 314/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2774 - acc: 0.5566 - val_loss: 1.6774 - val_acc: 0.4067\n",
      "Epoch 315/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2846 - acc: 0.5503 - val_loss: 1.6684 - val_acc: 0.4200\n",
      "Epoch 316/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2695 - acc: 0.5580 - val_loss: 1.6795 - val_acc: 0.4125\n",
      "Epoch 317/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2903 - acc: 0.5473 - val_loss: 1.6797 - val_acc: 0.4138\n",
      "Epoch 318/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2635 - acc: 0.5559 - val_loss: 1.6761 - val_acc: 0.4129\n",
      "Epoch 319/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.2651 - acc: 0.5610 - val_loss: 1.6720 - val_acc: 0.4167\n",
      "Epoch 320/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2686 - acc: 0.5576 - val_loss: 1.6686 - val_acc: 0.4208\n",
      "Epoch 321/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2682 - acc: 0.5553 - val_loss: 1.6821 - val_acc: 0.4129\n",
      "Epoch 322/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2737 - acc: 0.5582 - val_loss: 1.6658 - val_acc: 0.4167\n",
      "Epoch 323/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2688 - acc: 0.5602 - val_loss: 1.6757 - val_acc: 0.4112\n",
      "Epoch 324/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2688 - acc: 0.5584 - val_loss: 1.6655 - val_acc: 0.4204\n",
      "Epoch 325/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2625 - acc: 0.5609 - val_loss: 1.6853 - val_acc: 0.4104\n",
      "Epoch 326/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2641 - acc: 0.5556 - val_loss: 1.6806 - val_acc: 0.4133\n",
      "Epoch 327/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2620 - acc: 0.5573 - val_loss: 1.6824 - val_acc: 0.4138\n",
      "Epoch 328/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2534 - acc: 0.5634 - val_loss: 1.6964 - val_acc: 0.4058\n",
      "Epoch 329/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2567 - acc: 0.5628 - val_loss: 1.6721 - val_acc: 0.4142\n",
      "Epoch 330/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2601 - acc: 0.5621 - val_loss: 1.6790 - val_acc: 0.4171\n",
      "Epoch 331/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2515 - acc: 0.5629 - val_loss: 1.6704 - val_acc: 0.4138\n",
      "Epoch 332/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2463 - acc: 0.5686 - val_loss: 1.6858 - val_acc: 0.4108\n",
      "Epoch 333/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2578 - acc: 0.5609 - val_loss: 1.6751 - val_acc: 0.4071\n",
      "Epoch 334/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2442 - acc: 0.5736 - val_loss: 1.6786 - val_acc: 0.4175\n",
      "Epoch 335/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2516 - acc: 0.5631 - val_loss: 1.6775 - val_acc: 0.4167\n",
      "Epoch 336/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2531 - acc: 0.5649 - val_loss: 1.6682 - val_acc: 0.4225\n",
      "Epoch 337/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2473 - acc: 0.5633 - val_loss: 1.6748 - val_acc: 0.4146\n",
      "Epoch 338/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2374 - acc: 0.5749 - val_loss: 1.6778 - val_acc: 0.4142\n",
      "Epoch 339/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.2415 - acc: 0.5713 - val_loss: 1.6928 - val_acc: 0.4108\n",
      "Epoch 340/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2435 - acc: 0.5735 - val_loss: 1.6761 - val_acc: 0.4154\n",
      "Epoch 341/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2429 - acc: 0.5671 - val_loss: 1.6747 - val_acc: 0.4088\n",
      "Epoch 342/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2299 - acc: 0.5725 - val_loss: 1.6771 - val_acc: 0.4083\n",
      "Epoch 343/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2309 - acc: 0.5767 - val_loss: 1.6702 - val_acc: 0.4154\n",
      "Epoch 344/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.2314 - acc: 0.5728 - val_loss: 1.6673 - val_acc: 0.4125\n",
      "Epoch 345/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.2313 - acc: 0.5741 - val_loss: 1.6736 - val_acc: 0.4175\n",
      "Epoch 346/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.2295 - acc: 0.5768 - val_loss: 1.6751 - val_acc: 0.4171\n",
      "Epoch 347/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.2327 - acc: 0.5715 - val_loss: 1.6768 - val_acc: 0.4150\n",
      "Epoch 348/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2199 - acc: 0.5753 - val_loss: 1.6658 - val_acc: 0.4229\n",
      "Epoch 349/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2257 - acc: 0.5763 - val_loss: 1.6647 - val_acc: 0.4171\n",
      "Epoch 350/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2193 - acc: 0.5831 - val_loss: 1.6798 - val_acc: 0.4100\n",
      "Epoch 351/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.2283 - acc: 0.5784 - val_loss: 1.6631 - val_acc: 0.4233\n",
      "Epoch 352/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2252 - acc: 0.5763 - val_loss: 1.6749 - val_acc: 0.4250\n",
      "Epoch 353/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2196 - acc: 0.5828 - val_loss: 1.6782 - val_acc: 0.4200\n",
      "Epoch 354/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.2190 - acc: 0.5772 - val_loss: 1.6685 - val_acc: 0.4175\n",
      "Epoch 355/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2150 - acc: 0.5767 - val_loss: 1.6743 - val_acc: 0.4183\n",
      "Epoch 356/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2194 - acc: 0.5824 - val_loss: 1.6756 - val_acc: 0.4221\n",
      "Epoch 357/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2182 - acc: 0.5780 - val_loss: 1.6704 - val_acc: 0.4200\n",
      "Epoch 358/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2061 - acc: 0.5840 - val_loss: 1.6814 - val_acc: 0.4158\n",
      "Epoch 359/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2110 - acc: 0.5820 - val_loss: 1.6831 - val_acc: 0.4188\n",
      "Epoch 360/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2107 - acc: 0.5817 - val_loss: 1.6773 - val_acc: 0.4192\n",
      "Epoch 361/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1949 - acc: 0.5841 - val_loss: 1.6718 - val_acc: 0.4246\n",
      "Epoch 362/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1961 - acc: 0.5871 - val_loss: 1.6782 - val_acc: 0.4188\n",
      "Epoch 363/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2020 - acc: 0.5824 - val_loss: 1.6677 - val_acc: 0.4196\n",
      "Epoch 364/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2011 - acc: 0.5821 - val_loss: 1.6770 - val_acc: 0.4200\n",
      "Epoch 365/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.1927 - acc: 0.5859 - val_loss: 1.6771 - val_acc: 0.4250\n",
      "Epoch 366/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1927 - acc: 0.5893 - val_loss: 1.6663 - val_acc: 0.4229\n",
      "Epoch 367/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1971 - acc: 0.5872 - val_loss: 1.6717 - val_acc: 0.4221\n",
      "Epoch 368/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1859 - acc: 0.5834 - val_loss: 1.6687 - val_acc: 0.4196\n",
      "Epoch 369/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1995 - acc: 0.5878 - val_loss: 1.6742 - val_acc: 0.4192\n",
      "Epoch 370/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1920 - acc: 0.5882 - val_loss: 1.6856 - val_acc: 0.4196\n",
      "Epoch 371/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.1917 - acc: 0.5874 - val_loss: 1.7082 - val_acc: 0.4117\n",
      "Epoch 372/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1835 - acc: 0.5885 - val_loss: 1.6733 - val_acc: 0.4279\n",
      "Epoch 373/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1884 - acc: 0.5882 - val_loss: 1.6705 - val_acc: 0.4225\n",
      "Epoch 374/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1958 - acc: 0.5848 - val_loss: 1.6618 - val_acc: 0.4283\n",
      "Epoch 375/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1810 - acc: 0.5942 - val_loss: 1.6754 - val_acc: 0.4200\n",
      "Epoch 376/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1954 - acc: 0.5891 - val_loss: 1.6615 - val_acc: 0.4304\n",
      "Epoch 377/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1851 - acc: 0.5899 - val_loss: 1.6705 - val_acc: 0.4271\n",
      "Epoch 378/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.1752 - acc: 0.5890 - val_loss: 1.6888 - val_acc: 0.4125\n",
      "Epoch 379/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.1765 - acc: 0.5943 - val_loss: 1.6750 - val_acc: 0.4121\n",
      "Epoch 380/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1780 - acc: 0.5938 - val_loss: 1.6703 - val_acc: 0.4258\n",
      "Epoch 381/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1628 - acc: 0.5985 - val_loss: 1.6716 - val_acc: 0.4229\n",
      "Epoch 382/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1696 - acc: 0.5985 - val_loss: 1.6712 - val_acc: 0.4233\n",
      "Epoch 383/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1705 - acc: 0.5934 - val_loss: 1.6807 - val_acc: 0.4188\n",
      "Epoch 384/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1692 - acc: 0.5959 - val_loss: 1.6815 - val_acc: 0.4208\n",
      "Epoch 385/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.1759 - acc: 0.5930 - val_loss: 1.6844 - val_acc: 0.4175\n",
      "Epoch 386/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1670 - acc: 0.5997 - val_loss: 1.6826 - val_acc: 0.4158\n",
      "Epoch 387/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1627 - acc: 0.6011 - val_loss: 1.6689 - val_acc: 0.4229\n",
      "Epoch 388/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1622 - acc: 0.5976 - val_loss: 1.6781 - val_acc: 0.4313\n",
      "Epoch 389/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1617 - acc: 0.5926 - val_loss: 1.6638 - val_acc: 0.4233\n",
      "Epoch 390/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1590 - acc: 0.6009 - val_loss: 1.6711 - val_acc: 0.4246\n",
      "Epoch 391/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1652 - acc: 0.5953 - val_loss: 1.6854 - val_acc: 0.4196\n",
      "Epoch 392/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1631 - acc: 0.5921 - val_loss: 1.6673 - val_acc: 0.4300\n",
      "Epoch 393/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1547 - acc: 0.6012 - val_loss: 1.7038 - val_acc: 0.4183\n",
      "Epoch 394/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1559 - acc: 0.6019 - val_loss: 1.6749 - val_acc: 0.4246\n",
      "Epoch 395/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1454 - acc: 0.6075 - val_loss: 1.6766 - val_acc: 0.4275\n",
      "Epoch 396/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1515 - acc: 0.5994 - val_loss: 1.6862 - val_acc: 0.4233\n",
      "Epoch 397/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1457 - acc: 0.6020 - val_loss: 1.6834 - val_acc: 0.4233\n",
      "Epoch 398/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.1416 - acc: 0.6090 - val_loss: 1.6760 - val_acc: 0.4254\n",
      "Epoch 399/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1412 - acc: 0.6129 - val_loss: 1.6695 - val_acc: 0.4296\n",
      "Epoch 400/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1394 - acc: 0.6112 - val_loss: 1.6935 - val_acc: 0.4246\n",
      "Epoch 401/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1478 - acc: 0.6023 - val_loss: 1.6691 - val_acc: 0.4288\n",
      "Epoch 402/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1486 - acc: 0.6024 - val_loss: 1.6674 - val_acc: 0.4342\n",
      "Epoch 403/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1381 - acc: 0.6069 - val_loss: 1.6706 - val_acc: 0.4337\n",
      "Epoch 404/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1392 - acc: 0.6058 - val_loss: 1.6718 - val_acc: 0.4275\n",
      "Epoch 405/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1357 - acc: 0.6054 - val_loss: 1.6906 - val_acc: 0.4246\n",
      "Epoch 406/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1378 - acc: 0.6043 - val_loss: 1.6737 - val_acc: 0.4308\n",
      "Epoch 407/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1378 - acc: 0.6058 - val_loss: 1.6883 - val_acc: 0.4321\n",
      "Epoch 408/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1375 - acc: 0.6038 - val_loss: 1.6699 - val_acc: 0.4317\n",
      "Epoch 409/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1429 - acc: 0.6133 - val_loss: 1.6790 - val_acc: 0.4342\n",
      "Epoch 410/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1451 - acc: 0.6023 - val_loss: 1.6756 - val_acc: 0.4308\n",
      "Epoch 411/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1352 - acc: 0.6100 - val_loss: 1.6881 - val_acc: 0.4238\n",
      "Epoch 412/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1273 - acc: 0.6123 - val_loss: 1.6703 - val_acc: 0.4346\n",
      "Epoch 413/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1220 - acc: 0.6101 - val_loss: 1.6775 - val_acc: 0.4313\n",
      "Epoch 414/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1271 - acc: 0.6125 - val_loss: 1.6948 - val_acc: 0.4187\n",
      "Epoch 415/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1283 - acc: 0.6109 - val_loss: 1.6895 - val_acc: 0.4221\n",
      "Epoch 416/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1202 - acc: 0.6100 - val_loss: 1.6694 - val_acc: 0.4308\n",
      "Epoch 417/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1205 - acc: 0.6144 - val_loss: 1.6769 - val_acc: 0.4308\n",
      "Epoch 418/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1222 - acc: 0.6136 - val_loss: 1.6749 - val_acc: 0.4300\n",
      "Epoch 419/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1192 - acc: 0.6148 - val_loss: 1.6873 - val_acc: 0.4175\n",
      "Epoch 420/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.1160 - acc: 0.6134 - val_loss: 1.6786 - val_acc: 0.4233\n",
      "Epoch 421/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.1209 - acc: 0.6128 - val_loss: 1.6732 - val_acc: 0.4221\n",
      "Epoch 422/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.1261 - acc: 0.6106 - val_loss: 1.6819 - val_acc: 0.4313\n",
      "Epoch 423/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.1163 - acc: 0.6141 - val_loss: 1.6706 - val_acc: 0.4329\n",
      "Epoch 424/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.1195 - acc: 0.6150 - val_loss: 1.6849 - val_acc: 0.4250\n",
      "Epoch 425/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.1084 - acc: 0.6247 - val_loss: 1.6778 - val_acc: 0.4313\n",
      "Epoch 426/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.1047 - acc: 0.6149 - val_loss: 1.6771 - val_acc: 0.4242\n",
      "Epoch 427/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0999 - acc: 0.6240 - val_loss: 1.6812 - val_acc: 0.4242\n",
      "Epoch 428/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.1046 - acc: 0.6168 - val_loss: 1.6775 - val_acc: 0.4317\n",
      "Epoch 429/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1084 - acc: 0.6171 - val_loss: 1.6897 - val_acc: 0.4279\n",
      "Epoch 430/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1061 - acc: 0.6149 - val_loss: 1.6898 - val_acc: 0.4392\n",
      "Epoch 431/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1048 - acc: 0.6202 - val_loss: 1.6802 - val_acc: 0.4288\n",
      "Epoch 432/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.1071 - acc: 0.6168 - val_loss: 1.6921 - val_acc: 0.4346\n",
      "Epoch 433/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0962 - acc: 0.6208 - val_loss: 1.6875 - val_acc: 0.4321\n",
      "Epoch 434/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.0863 - acc: 0.6243 - val_loss: 1.6972 - val_acc: 0.4263\n",
      "Epoch 435/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.0969 - acc: 0.6229 - val_loss: 1.6978 - val_acc: 0.4321\n",
      "Epoch 436/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0976 - acc: 0.6217 - val_loss: 1.6738 - val_acc: 0.4300\n",
      "Epoch 437/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.1049 - acc: 0.6193 - val_loss: 1.6708 - val_acc: 0.4338\n",
      "Epoch 438/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0921 - acc: 0.6250 - val_loss: 1.6707 - val_acc: 0.4342\n",
      "Epoch 439/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0885 - acc: 0.6248 - val_loss: 1.6955 - val_acc: 0.4325\n",
      "Epoch 440/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0972 - acc: 0.6207 - val_loss: 1.6793 - val_acc: 0.4354\n",
      "Epoch 441/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0834 - acc: 0.6232 - val_loss: 1.6824 - val_acc: 0.4267\n",
      "Epoch 442/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0839 - acc: 0.6229 - val_loss: 1.6843 - val_acc: 0.4292\n",
      "Epoch 443/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.0952 - acc: 0.6214 - val_loss: 1.6926 - val_acc: 0.4288\n",
      "Epoch 444/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0827 - acc: 0.6228 - val_loss: 1.6830 - val_acc: 0.4317\n",
      "Epoch 445/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0847 - acc: 0.6285 - val_loss: 1.6742 - val_acc: 0.4338\n",
      "Epoch 446/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0723 - acc: 0.6314 - val_loss: 1.6927 - val_acc: 0.4333\n",
      "Epoch 447/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.0784 - acc: 0.6261 - val_loss: 1.6874 - val_acc: 0.4392\n",
      "Epoch 448/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0801 - acc: 0.6275 - val_loss: 1.6759 - val_acc: 0.4358\n",
      "Epoch 449/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0694 - acc: 0.6366 - val_loss: 1.6829 - val_acc: 0.4333\n",
      "Epoch 450/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0675 - acc: 0.6321 - val_loss: 1.6806 - val_acc: 0.4308\n",
      "Epoch 451/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0723 - acc: 0.6333 - val_loss: 1.6762 - val_acc: 0.4333\n",
      "Epoch 452/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.0722 - acc: 0.6253 - val_loss: 1.6839 - val_acc: 0.4321\n",
      "Epoch 453/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.0595 - acc: 0.6312 - val_loss: 1.6786 - val_acc: 0.4404\n",
      "Epoch 454/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0629 - acc: 0.6362 - val_loss: 1.6938 - val_acc: 0.4292\n",
      "Epoch 455/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.0667 - acc: 0.6235 - val_loss: 1.6816 - val_acc: 0.4350\n",
      "Epoch 456/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0607 - acc: 0.6301 - val_loss: 1.6812 - val_acc: 0.4383\n",
      "Epoch 457/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.0567 - acc: 0.6377 - val_loss: 1.6838 - val_acc: 0.4300\n",
      "Epoch 458/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.0626 - acc: 0.6406 - val_loss: 1.6765 - val_acc: 0.4371\n",
      "Epoch 459/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 1.0639 - acc: 0.6321 - val_loss: 1.6863 - val_acc: 0.4300\n",
      "Epoch 460/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0566 - acc: 0.6343 - val_loss: 1.6798 - val_acc: 0.4304\n",
      "Epoch 461/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0575 - acc: 0.6330 - val_loss: 1.6752 - val_acc: 0.4396\n",
      "Epoch 462/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0448 - acc: 0.6405 - val_loss: 1.6824 - val_acc: 0.4346\n",
      "Epoch 463/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0540 - acc: 0.6400 - val_loss: 1.6973 - val_acc: 0.4379\n",
      "Epoch 464/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0647 - acc: 0.6356 - val_loss: 1.6828 - val_acc: 0.4350\n",
      "Epoch 465/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0566 - acc: 0.6370 - val_loss: 1.6834 - val_acc: 0.4375\n",
      "Epoch 466/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0498 - acc: 0.6394 - val_loss: 1.6946 - val_acc: 0.4396\n",
      "Epoch 467/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0562 - acc: 0.6372 - val_loss: 1.7016 - val_acc: 0.4296\n",
      "Epoch 468/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0429 - acc: 0.6439 - val_loss: 1.6918 - val_acc: 0.4325\n",
      "Epoch 469/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.0406 - acc: 0.6406 - val_loss: 1.7017 - val_acc: 0.4400\n",
      "Epoch 470/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0366 - acc: 0.6419 - val_loss: 1.6857 - val_acc: 0.4338\n",
      "Epoch 471/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0469 - acc: 0.6362 - val_loss: 1.6829 - val_acc: 0.4383\n",
      "Epoch 472/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0467 - acc: 0.6376 - val_loss: 1.6893 - val_acc: 0.4263\n",
      "Epoch 473/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0422 - acc: 0.6405 - val_loss: 1.6762 - val_acc: 0.4354\n",
      "Epoch 474/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0418 - acc: 0.6432 - val_loss: 1.6921 - val_acc: 0.4425\n",
      "Epoch 475/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0430 - acc: 0.6423 - val_loss: 1.6863 - val_acc: 0.4313\n",
      "Epoch 476/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.0485 - acc: 0.6358 - val_loss: 1.6829 - val_acc: 0.4412\n",
      "Epoch 477/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0280 - acc: 0.6480 - val_loss: 1.6983 - val_acc: 0.4429\n",
      "Epoch 478/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0366 - acc: 0.6416 - val_loss: 1.7060 - val_acc: 0.4338\n",
      "Epoch 479/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0378 - acc: 0.6406 - val_loss: 1.7058 - val_acc: 0.4350\n",
      "Epoch 480/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0309 - acc: 0.6447 - val_loss: 1.7105 - val_acc: 0.4313\n",
      "Epoch 481/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0385 - acc: 0.6432 - val_loss: 1.6903 - val_acc: 0.4383\n",
      "Epoch 482/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0227 - acc: 0.6545 - val_loss: 1.7083 - val_acc: 0.4279\n",
      "Epoch 483/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0264 - acc: 0.6520 - val_loss: 1.6989 - val_acc: 0.4425\n",
      "Epoch 484/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0277 - acc: 0.6507 - val_loss: 1.6963 - val_acc: 0.4379\n",
      "Epoch 485/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.0336 - acc: 0.6441 - val_loss: 1.6967 - val_acc: 0.4346\n",
      "Epoch 486/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0173 - acc: 0.6489 - val_loss: 1.7219 - val_acc: 0.4329\n",
      "Epoch 487/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0361 - acc: 0.6472 - val_loss: 1.7115 - val_acc: 0.4358\n",
      "Epoch 488/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0304 - acc: 0.6475 - val_loss: 1.7054 - val_acc: 0.4325\n",
      "Epoch 489/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0238 - acc: 0.6475 - val_loss: 1.7040 - val_acc: 0.4346\n",
      "Epoch 490/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0192 - acc: 0.6527 - val_loss: 1.6834 - val_acc: 0.4375\n",
      "Epoch 491/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0283 - acc: 0.6437 - val_loss: 1.6994 - val_acc: 0.4388\n",
      "Epoch 492/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.0239 - acc: 0.6450 - val_loss: 1.6904 - val_acc: 0.4379\n",
      "Epoch 493/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0125 - acc: 0.6502 - val_loss: 1.7029 - val_acc: 0.4346\n",
      "Epoch 494/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0112 - acc: 0.6536 - val_loss: 1.7092 - val_acc: 0.4387\n",
      "Epoch 495/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0031 - acc: 0.6564 - val_loss: 1.7115 - val_acc: 0.4313\n",
      "Epoch 496/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.0137 - acc: 0.6535 - val_loss: 1.6999 - val_acc: 0.4408\n",
      "Epoch 497/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.0163 - acc: 0.6502 - val_loss: 1.6974 - val_acc: 0.4333\n",
      "Epoch 498/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0020 - acc: 0.6601 - val_loss: 1.7198 - val_acc: 0.4354\n",
      "Epoch 499/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 1.0065 - acc: 0.6568 - val_loss: 1.7061 - val_acc: 0.4417\n",
      "Epoch 500/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0069 - acc: 0.6568 - val_loss: 1.6959 - val_acc: 0.4388\n",
      "Epoch 501/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0010 - acc: 0.6548 - val_loss: 1.6993 - val_acc: 0.4367\n",
      "Epoch 502/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9881 - acc: 0.6532 - val_loss: 1.7052 - val_acc: 0.4387\n",
      "Epoch 503/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.0039 - acc: 0.6553 - val_loss: 1.6912 - val_acc: 0.4446\n",
      "Epoch 504/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.0141 - acc: 0.6545 - val_loss: 1.6992 - val_acc: 0.4425\n",
      "Epoch 505/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.0072 - acc: 0.6571 - val_loss: 1.7020 - val_acc: 0.4354\n",
      "Epoch 506/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 1.0014 - acc: 0.6552 - val_loss: 1.7376 - val_acc: 0.4346\n",
      "Epoch 507/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.9940 - acc: 0.6562 - val_loss: 1.7084 - val_acc: 0.4371\n",
      "Epoch 508/50000\n",
      "9600/9600 [==============================] - 0s 27us/step - loss: 0.9978 - acc: 0.6578 - val_loss: 1.7064 - val_acc: 0.4379\n",
      "Epoch 509/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 0.9949 - acc: 0.6557 - val_loss: 1.6919 - val_acc: 0.4396\n",
      "Epoch 510/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.9812 - acc: 0.6634 - val_loss: 1.6920 - val_acc: 0.4450\n",
      "Epoch 511/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9857 - acc: 0.6585 - val_loss: 1.6956 - val_acc: 0.4438\n",
      "Epoch 512/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 0.9945 - acc: 0.6597 - val_loss: 1.7048 - val_acc: 0.4363\n",
      "Epoch 513/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 0.9857 - acc: 0.6565 - val_loss: 1.7122 - val_acc: 0.4325\n",
      "Epoch 514/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.9959 - acc: 0.6558 - val_loss: 1.7117 - val_acc: 0.4383\n",
      "Epoch 515/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9765 - acc: 0.6627 - val_loss: 1.6946 - val_acc: 0.4454\n",
      "Epoch 516/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9921 - acc: 0.6586 - val_loss: 1.7157 - val_acc: 0.4392\n",
      "Epoch 517/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9670 - acc: 0.6696 - val_loss: 1.7004 - val_acc: 0.4321\n",
      "Epoch 518/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.9846 - acc: 0.6649 - val_loss: 1.6997 - val_acc: 0.4446\n",
      "Epoch 519/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.9743 - acc: 0.6690 - val_loss: 1.7054 - val_acc: 0.4437\n",
      "Epoch 520/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.9810 - acc: 0.6630 - val_loss: 1.6815 - val_acc: 0.4479\n",
      "Epoch 521/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.9754 - acc: 0.6655 - val_loss: 1.7144 - val_acc: 0.4333\n",
      "Epoch 522/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.9805 - acc: 0.6606 - val_loss: 1.7101 - val_acc: 0.4358\n",
      "Epoch 523/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9642 - acc: 0.6644 - val_loss: 1.7023 - val_acc: 0.4371\n",
      "Epoch 524/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9664 - acc: 0.6714 - val_loss: 1.7349 - val_acc: 0.4333\n",
      "Epoch 525/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9802 - acc: 0.6609 - val_loss: 1.7133 - val_acc: 0.4383\n",
      "Epoch 526/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9715 - acc: 0.6653 - val_loss: 1.7153 - val_acc: 0.4329\n",
      "Epoch 527/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9759 - acc: 0.6639 - val_loss: 1.6993 - val_acc: 0.4442\n",
      "Epoch 528/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9787 - acc: 0.6637 - val_loss: 1.7114 - val_acc: 0.4346\n",
      "Epoch 529/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9647 - acc: 0.6664 - val_loss: 1.7186 - val_acc: 0.4400\n",
      "Epoch 530/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.9680 - acc: 0.6646 - val_loss: 1.6962 - val_acc: 0.4350\n",
      "Epoch 531/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9803 - acc: 0.6599 - val_loss: 1.7251 - val_acc: 0.4358\n",
      "Epoch 532/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9582 - acc: 0.6714 - val_loss: 1.7263 - val_acc: 0.4363\n",
      "Epoch 533/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9609 - acc: 0.6742 - val_loss: 1.7205 - val_acc: 0.4429\n",
      "Epoch 534/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9645 - acc: 0.6666 - val_loss: 1.7251 - val_acc: 0.4342\n",
      "Epoch 535/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9539 - acc: 0.6747 - val_loss: 1.7185 - val_acc: 0.4338\n",
      "Epoch 536/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9709 - acc: 0.6661 - val_loss: 1.6918 - val_acc: 0.4483\n",
      "Epoch 537/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9461 - acc: 0.6773 - val_loss: 1.7212 - val_acc: 0.4421\n",
      "Epoch 538/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9492 - acc: 0.6755 - val_loss: 1.7062 - val_acc: 0.4408\n",
      "Epoch 539/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.9430 - acc: 0.6749 - val_loss: 1.7099 - val_acc: 0.4333\n",
      "Epoch 540/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9608 - acc: 0.6705 - val_loss: 1.7186 - val_acc: 0.4396\n",
      "Epoch 541/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9524 - acc: 0.6763 - val_loss: 1.6967 - val_acc: 0.4458\n",
      "Epoch 542/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9440 - acc: 0.6761 - val_loss: 1.7167 - val_acc: 0.4392\n",
      "Epoch 543/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9479 - acc: 0.6761 - val_loss: 1.7335 - val_acc: 0.4312\n",
      "Epoch 544/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.9468 - acc: 0.6708 - val_loss: 1.7268 - val_acc: 0.4425\n",
      "Epoch 545/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9378 - acc: 0.6832 - val_loss: 1.7406 - val_acc: 0.4400\n",
      "Epoch 546/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9524 - acc: 0.6714 - val_loss: 1.7400 - val_acc: 0.4337\n",
      "Epoch 547/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9438 - acc: 0.6724 - val_loss: 1.7260 - val_acc: 0.4400\n",
      "Epoch 548/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9452 - acc: 0.6759 - val_loss: 1.7244 - val_acc: 0.4392\n",
      "Epoch 549/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9508 - acc: 0.6742 - val_loss: 1.7266 - val_acc: 0.4429\n",
      "Epoch 550/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9348 - acc: 0.6779 - val_loss: 1.7322 - val_acc: 0.4346\n",
      "Epoch 551/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9506 - acc: 0.6698 - val_loss: 1.7237 - val_acc: 0.4292\n",
      "Epoch 552/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9383 - acc: 0.6760 - val_loss: 1.7235 - val_acc: 0.4408\n",
      "Epoch 553/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9342 - acc: 0.6779 - val_loss: 1.7302 - val_acc: 0.4396\n",
      "Epoch 554/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9348 - acc: 0.6780 - val_loss: 1.7168 - val_acc: 0.4425\n",
      "Epoch 555/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9380 - acc: 0.6808 - val_loss: 1.7341 - val_acc: 0.4425\n",
      "Epoch 556/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9297 - acc: 0.6817 - val_loss: 1.7327 - val_acc: 0.4288\n",
      "Epoch 557/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9384 - acc: 0.6757 - val_loss: 1.7401 - val_acc: 0.4383\n",
      "Epoch 558/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9325 - acc: 0.6779 - val_loss: 1.7329 - val_acc: 0.4421\n",
      "Epoch 559/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9271 - acc: 0.6795 - val_loss: 1.7522 - val_acc: 0.4354\n",
      "Epoch 560/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9326 - acc: 0.6766 - val_loss: 1.7242 - val_acc: 0.4404\n",
      "Epoch 561/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9131 - acc: 0.6879 - val_loss: 1.7318 - val_acc: 0.4446\n",
      "Epoch 562/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9321 - acc: 0.6784 - val_loss: 1.7268 - val_acc: 0.4425\n",
      "Epoch 563/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9207 - acc: 0.6847 - val_loss: 1.7245 - val_acc: 0.4442\n",
      "Epoch 564/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.9249 - acc: 0.6831 - val_loss: 1.7458 - val_acc: 0.4475\n",
      "Epoch 565/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9428 - acc: 0.6774 - val_loss: 1.7203 - val_acc: 0.4412\n",
      "Epoch 566/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9182 - acc: 0.6803 - val_loss: 1.7271 - val_acc: 0.4433\n",
      "Epoch 567/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.9201 - acc: 0.6821 - val_loss: 1.7358 - val_acc: 0.4367\n",
      "Epoch 568/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9178 - acc: 0.6792 - val_loss: 1.7285 - val_acc: 0.4408\n",
      "Epoch 569/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.9257 - acc: 0.6771 - val_loss: 1.7310 - val_acc: 0.4417\n",
      "Epoch 570/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9166 - acc: 0.6878 - val_loss: 1.7290 - val_acc: 0.4454\n",
      "Epoch 571/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9154 - acc: 0.6885 - val_loss: 1.7095 - val_acc: 0.4412\n",
      "Epoch 572/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9190 - acc: 0.6883 - val_loss: 1.7073 - val_acc: 0.4467\n",
      "Epoch 573/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9161 - acc: 0.6828 - val_loss: 1.7385 - val_acc: 0.4438\n",
      "Epoch 574/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9092 - acc: 0.6911 - val_loss: 1.7267 - val_acc: 0.4462\n",
      "Epoch 575/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9129 - acc: 0.6893 - val_loss: 1.7355 - val_acc: 0.4450\n",
      "Epoch 576/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.9173 - acc: 0.6797 - val_loss: 1.7341 - val_acc: 0.4417\n",
      "Epoch 577/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9057 - acc: 0.6864 - val_loss: 1.7386 - val_acc: 0.4425\n",
      "Epoch 578/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9002 - acc: 0.6903 - val_loss: 1.7442 - val_acc: 0.4417\n",
      "Epoch 579/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9092 - acc: 0.6892 - val_loss: 1.7370 - val_acc: 0.4392\n",
      "Epoch 580/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9078 - acc: 0.6950 - val_loss: 1.7197 - val_acc: 0.4437\n",
      "Epoch 581/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.8930 - acc: 0.6940 - val_loss: 1.7507 - val_acc: 0.4450\n",
      "Epoch 582/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9055 - acc: 0.6907 - val_loss: 1.7408 - val_acc: 0.4450\n",
      "Epoch 583/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9004 - acc: 0.6902 - val_loss: 1.7346 - val_acc: 0.4363\n",
      "Epoch 584/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.9166 - acc: 0.6801 - val_loss: 1.7269 - val_acc: 0.4450\n",
      "Epoch 585/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.9026 - acc: 0.6882 - val_loss: 1.7565 - val_acc: 0.4387\n",
      "Epoch 586/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.8934 - acc: 0.6958 - val_loss: 1.7365 - val_acc: 0.4442\n",
      "Val loss: 1.6918,Val acc: 0.4483\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTraining model:\n",
      "baseline\n",
      "0 - U:512|A:relu|D:0.200 \n",
      "1 - U:512|A:relu|D:0.200 \n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 2.2990 - acc: 0.1178 - val_loss: 2.2934 - val_acc: 0.1258\n",
      "Epoch 2/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 2.2468 - acc: 0.1713 - val_loss: 2.1608 - val_acc: 0.2279\n",
      "Epoch 3/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 2.1192 - acc: 0.2246 - val_loss: 2.0495 - val_acc: 0.2667\n",
      "Epoch 4/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 2.0025 - acc: 0.2779 - val_loss: 1.9362 - val_acc: 0.3050\n",
      "Epoch 5/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.8886 - acc: 0.3100 - val_loss: 1.8604 - val_acc: 0.3221\n",
      "Epoch 6/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.8518 - acc: 0.3130 - val_loss: 1.8465 - val_acc: 0.3150\n",
      "Epoch 7/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.8240 - acc: 0.3269 - val_loss: 1.8288 - val_acc: 0.3258\n",
      "Epoch 8/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.8080 - acc: 0.3273 - val_loss: 1.8301 - val_acc: 0.3212\n",
      "Epoch 9/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.8119 - acc: 0.3268 - val_loss: 1.8112 - val_acc: 0.3333\n",
      "Epoch 10/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.7972 - acc: 0.3349 - val_loss: 1.8280 - val_acc: 0.3225\n",
      "Epoch 11/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.7893 - acc: 0.3339 - val_loss: 1.8162 - val_acc: 0.3279\n",
      "Epoch 12/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7891 - acc: 0.3348 - val_loss: 1.8059 - val_acc: 0.3400\n",
      "Epoch 13/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7890 - acc: 0.3359 - val_loss: 1.8105 - val_acc: 0.3329\n",
      "Epoch 14/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.7805 - acc: 0.3370 - val_loss: 1.8122 - val_acc: 0.3367\n",
      "Epoch 15/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.7675 - acc: 0.3417 - val_loss: 1.8145 - val_acc: 0.3367\n",
      "Epoch 16/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.7682 - acc: 0.3429 - val_loss: 1.7984 - val_acc: 0.3350\n",
      "Epoch 17/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.7643 - acc: 0.3447 - val_loss: 1.8071 - val_acc: 0.3438\n",
      "Epoch 18/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.7540 - acc: 0.3483 - val_loss: 1.8069 - val_acc: 0.3421\n",
      "Epoch 19/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7546 - acc: 0.3521 - val_loss: 1.7885 - val_acc: 0.3442\n",
      "Epoch 20/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.7472 - acc: 0.3530 - val_loss: 1.7930 - val_acc: 0.3425\n",
      "Epoch 21/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.7444 - acc: 0.3566 - val_loss: 1.7880 - val_acc: 0.3433\n",
      "Epoch 22/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.7410 - acc: 0.3501 - val_loss: 1.8249 - val_acc: 0.3329\n",
      "Epoch 23/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.7408 - acc: 0.3559 - val_loss: 1.8078 - val_acc: 0.3438\n",
      "Epoch 24/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.7322 - acc: 0.3633 - val_loss: 1.7782 - val_acc: 0.3342\n",
      "Epoch 25/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.7286 - acc: 0.3612 - val_loss: 1.7742 - val_acc: 0.3517\n",
      "Epoch 26/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.7355 - acc: 0.3594 - val_loss: 1.7764 - val_acc: 0.3517\n",
      "Epoch 27/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.7216 - acc: 0.3614 - val_loss: 1.7808 - val_acc: 0.3417\n",
      "Epoch 28/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7346 - acc: 0.3556 - val_loss: 1.8480 - val_acc: 0.3267\n",
      "Epoch 29/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.7241 - acc: 0.3588 - val_loss: 1.7942 - val_acc: 0.3350\n",
      "Epoch 30/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.7136 - acc: 0.3655 - val_loss: 1.7668 - val_acc: 0.3421\n",
      "Epoch 31/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.7158 - acc: 0.3711 - val_loss: 1.7924 - val_acc: 0.3504\n",
      "Epoch 32/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7063 - acc: 0.3699 - val_loss: 1.7811 - val_acc: 0.3450\n",
      "Epoch 33/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.7127 - acc: 0.3714 - val_loss: 1.7692 - val_acc: 0.3475\n",
      "Epoch 34/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7047 - acc: 0.3678 - val_loss: 1.7765 - val_acc: 0.3479\n",
      "Epoch 35/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.7060 - acc: 0.3749 - val_loss: 1.7646 - val_acc: 0.3400\n",
      "Epoch 36/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.7073 - acc: 0.3656 - val_loss: 1.7787 - val_acc: 0.3521\n",
      "Epoch 37/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6979 - acc: 0.3701 - val_loss: 1.7662 - val_acc: 0.3571\n",
      "Epoch 38/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.6963 - acc: 0.3718 - val_loss: 1.7696 - val_acc: 0.3596\n",
      "Epoch 39/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.7015 - acc: 0.3736 - val_loss: 1.7693 - val_acc: 0.3562\n",
      "Epoch 40/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.6898 - acc: 0.3767 - val_loss: 1.7809 - val_acc: 0.3513\n",
      "Epoch 41/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6880 - acc: 0.3819 - val_loss: 1.7839 - val_acc: 0.3475\n",
      "Epoch 42/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6837 - acc: 0.3774 - val_loss: 1.7818 - val_acc: 0.3483\n",
      "Epoch 43/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.6859 - acc: 0.3757 - val_loss: 1.7897 - val_acc: 0.3563\n",
      "Epoch 44/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6883 - acc: 0.3806 - val_loss: 1.7770 - val_acc: 0.3583\n",
      "Epoch 45/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.6770 - acc: 0.3822 - val_loss: 1.7722 - val_acc: 0.3525\n",
      "Epoch 46/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.6788 - acc: 0.3821 - val_loss: 1.7623 - val_acc: 0.3454\n",
      "Epoch 47/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.6765 - acc: 0.3800 - val_loss: 1.7587 - val_acc: 0.3500\n",
      "Epoch 48/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.6756 - acc: 0.3823 - val_loss: 1.7777 - val_acc: 0.3488\n",
      "Epoch 49/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.6729 - acc: 0.3851 - val_loss: 1.7605 - val_acc: 0.3483\n",
      "Epoch 50/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.6674 - acc: 0.3882 - val_loss: 1.7693 - val_acc: 0.3521\n",
      "Epoch 51/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.6629 - acc: 0.3841 - val_loss: 1.7753 - val_acc: 0.3412\n",
      "Epoch 52/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6671 - acc: 0.3895 - val_loss: 1.7770 - val_acc: 0.3492\n",
      "Epoch 53/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.6633 - acc: 0.3877 - val_loss: 1.7821 - val_acc: 0.3450\n",
      "Epoch 54/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6626 - acc: 0.3919 - val_loss: 1.7577 - val_acc: 0.3579\n",
      "Epoch 55/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.6547 - acc: 0.3910 - val_loss: 1.7648 - val_acc: 0.3496\n",
      "Epoch 56/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.6589 - acc: 0.3881 - val_loss: 1.7741 - val_acc: 0.3588\n",
      "Epoch 57/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6446 - acc: 0.3881 - val_loss: 1.7680 - val_acc: 0.3583\n",
      "Epoch 58/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.6489 - acc: 0.3899 - val_loss: 1.7874 - val_acc: 0.3475\n",
      "Epoch 59/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.6476 - acc: 0.3962 - val_loss: 1.7499 - val_acc: 0.3521\n",
      "Epoch 60/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6363 - acc: 0.3994 - val_loss: 1.7636 - val_acc: 0.3638\n",
      "Epoch 61/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6349 - acc: 0.4004 - val_loss: 1.7622 - val_acc: 0.3588\n",
      "Epoch 62/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.6413 - acc: 0.4007 - val_loss: 1.8018 - val_acc: 0.3421\n",
      "Epoch 63/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.6407 - acc: 0.3959 - val_loss: 1.7621 - val_acc: 0.3600\n",
      "Epoch 64/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.6357 - acc: 0.3970 - val_loss: 1.7633 - val_acc: 0.3563\n",
      "Epoch 65/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.6262 - acc: 0.4015 - val_loss: 1.7612 - val_acc: 0.3629\n",
      "Epoch 66/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.6257 - acc: 0.4055 - val_loss: 1.7615 - val_acc: 0.3638\n",
      "Epoch 67/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.6298 - acc: 0.3984 - val_loss: 1.7881 - val_acc: 0.3496\n",
      "Epoch 68/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.6209 - acc: 0.4019 - val_loss: 1.7479 - val_acc: 0.3683\n",
      "Epoch 69/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.6126 - acc: 0.4101 - val_loss: 1.7591 - val_acc: 0.3613\n",
      "Epoch 70/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.6030 - acc: 0.4132 - val_loss: 1.7518 - val_acc: 0.3650\n",
      "Epoch 71/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.6007 - acc: 0.4110 - val_loss: 1.7553 - val_acc: 0.3558\n",
      "Epoch 72/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.6088 - acc: 0.4086 - val_loss: 1.7814 - val_acc: 0.3588\n",
      "Epoch 73/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.6022 - acc: 0.4150 - val_loss: 1.7631 - val_acc: 0.3588\n",
      "Epoch 74/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.6036 - acc: 0.4131 - val_loss: 1.7695 - val_acc: 0.3621\n",
      "Epoch 75/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5853 - acc: 0.4163 - val_loss: 1.7789 - val_acc: 0.3508\n",
      "Epoch 76/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5919 - acc: 0.4190 - val_loss: 1.7672 - val_acc: 0.3617\n",
      "Epoch 77/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5884 - acc: 0.4214 - val_loss: 1.7673 - val_acc: 0.3700\n",
      "Epoch 78/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.5827 - acc: 0.4246 - val_loss: 1.7823 - val_acc: 0.3617\n",
      "Epoch 79/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5775 - acc: 0.4247 - val_loss: 1.7702 - val_acc: 0.3525\n",
      "Epoch 80/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5668 - acc: 0.4299 - val_loss: 1.7676 - val_acc: 0.3646\n",
      "Epoch 81/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5670 - acc: 0.4283 - val_loss: 1.8089 - val_acc: 0.3550\n",
      "Epoch 82/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5819 - acc: 0.4265 - val_loss: 1.8021 - val_acc: 0.3525\n",
      "Epoch 83/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5659 - acc: 0.4278 - val_loss: 1.8105 - val_acc: 0.3571\n",
      "Epoch 84/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5599 - acc: 0.4309 - val_loss: 1.7548 - val_acc: 0.3654\n",
      "Epoch 85/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5447 - acc: 0.4431 - val_loss: 1.7322 - val_acc: 0.3771\n",
      "Epoch 86/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.5466 - acc: 0.4397 - val_loss: 1.7848 - val_acc: 0.3500\n",
      "Epoch 87/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.5403 - acc: 0.4366 - val_loss: 1.7425 - val_acc: 0.3708\n",
      "Epoch 88/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.5416 - acc: 0.4360 - val_loss: 1.7496 - val_acc: 0.3638\n",
      "Epoch 89/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5340 - acc: 0.4387 - val_loss: 1.7619 - val_acc: 0.3662\n",
      "Epoch 90/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5215 - acc: 0.4467 - val_loss: 1.7538 - val_acc: 0.3792\n",
      "Epoch 91/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.5276 - acc: 0.4395 - val_loss: 1.7473 - val_acc: 0.3692\n",
      "Epoch 92/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.5221 - acc: 0.4434 - val_loss: 1.7361 - val_acc: 0.3842\n",
      "Epoch 93/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.5242 - acc: 0.4451 - val_loss: 1.7675 - val_acc: 0.3658\n",
      "Epoch 94/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.5148 - acc: 0.4539 - val_loss: 1.7400 - val_acc: 0.3717\n",
      "Epoch 95/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.5155 - acc: 0.4511 - val_loss: 1.7528 - val_acc: 0.3679\n",
      "Epoch 96/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4965 - acc: 0.4576 - val_loss: 1.7643 - val_acc: 0.3746\n",
      "Epoch 97/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4968 - acc: 0.4555 - val_loss: 1.7420 - val_acc: 0.3750\n",
      "Epoch 98/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4978 - acc: 0.4651 - val_loss: 1.7696 - val_acc: 0.3687\n",
      "Epoch 99/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4917 - acc: 0.4616 - val_loss: 1.7331 - val_acc: 0.3800\n",
      "Epoch 100/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4809 - acc: 0.4615 - val_loss: 1.7420 - val_acc: 0.3825\n",
      "Epoch 101/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4795 - acc: 0.4612 - val_loss: 1.7648 - val_acc: 0.3750\n",
      "Epoch 102/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.4823 - acc: 0.4639 - val_loss: 1.7797 - val_acc: 0.3604\n",
      "Epoch 103/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.4704 - acc: 0.4650 - val_loss: 1.7935 - val_acc: 0.3587\n",
      "Epoch 104/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.4760 - acc: 0.4660 - val_loss: 1.7407 - val_acc: 0.3796\n",
      "Epoch 105/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4588 - acc: 0.4710 - val_loss: 1.7422 - val_acc: 0.3858\n",
      "Epoch 106/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.4764 - acc: 0.4680 - val_loss: 1.7744 - val_acc: 0.3679\n",
      "Epoch 107/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.4559 - acc: 0.4743 - val_loss: 1.7675 - val_acc: 0.3725\n",
      "Epoch 108/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.4525 - acc: 0.4764 - val_loss: 1.7785 - val_acc: 0.3663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.4516 - acc: 0.4773 - val_loss: 1.7716 - val_acc: 0.3788\n",
      "Epoch 110/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4515 - acc: 0.4734 - val_loss: 1.7467 - val_acc: 0.3796\n",
      "Epoch 111/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.4487 - acc: 0.4727 - val_loss: 1.7370 - val_acc: 0.3683\n",
      "Epoch 112/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4450 - acc: 0.4757 - val_loss: 1.7516 - val_acc: 0.3792\n",
      "Epoch 113/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4346 - acc: 0.4817 - val_loss: 1.7397 - val_acc: 0.3813\n",
      "Epoch 114/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4253 - acc: 0.4876 - val_loss: 1.7235 - val_acc: 0.3838\n",
      "Epoch 115/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.4268 - acc: 0.4845 - val_loss: 1.8086 - val_acc: 0.3667\n",
      "Epoch 116/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.4166 - acc: 0.4958 - val_loss: 1.7430 - val_acc: 0.3771\n",
      "Epoch 117/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.4070 - acc: 0.4969 - val_loss: 1.7517 - val_acc: 0.3596\n",
      "Epoch 118/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.4045 - acc: 0.4943 - val_loss: 1.7534 - val_acc: 0.3733\n",
      "Epoch 119/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.4030 - acc: 0.4956 - val_loss: 1.7284 - val_acc: 0.3837\n",
      "Epoch 120/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3930 - acc: 0.4984 - val_loss: 1.7637 - val_acc: 0.3750\n",
      "Epoch 121/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3942 - acc: 0.4999 - val_loss: 1.7603 - val_acc: 0.3863\n",
      "Epoch 122/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3781 - acc: 0.4994 - val_loss: 1.7094 - val_acc: 0.3925\n",
      "Epoch 123/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.3803 - acc: 0.4988 - val_loss: 1.7560 - val_acc: 0.3837\n",
      "Epoch 124/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.3632 - acc: 0.5187 - val_loss: 1.7512 - val_acc: 0.3912\n",
      "Epoch 125/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.3669 - acc: 0.5081 - val_loss: 1.7528 - val_acc: 0.3737\n",
      "Epoch 126/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.3593 - acc: 0.5089 - val_loss: 1.7417 - val_acc: 0.3796\n",
      "Epoch 127/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.3629 - acc: 0.5101 - val_loss: 1.7566 - val_acc: 0.3862\n",
      "Epoch 128/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3615 - acc: 0.5133 - val_loss: 1.7571 - val_acc: 0.3758\n",
      "Epoch 129/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.3647 - acc: 0.5108 - val_loss: 1.7440 - val_acc: 0.3850\n",
      "Epoch 130/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3433 - acc: 0.5147 - val_loss: 1.7542 - val_acc: 0.3858\n",
      "Epoch 131/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.3437 - acc: 0.5126 - val_loss: 1.7475 - val_acc: 0.3837\n",
      "Epoch 132/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3277 - acc: 0.5265 - val_loss: 1.7685 - val_acc: 0.3879\n",
      "Epoch 133/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.3330 - acc: 0.5201 - val_loss: 1.7545 - val_acc: 0.3958\n",
      "Epoch 134/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3300 - acc: 0.5235 - val_loss: 1.7440 - val_acc: 0.3958\n",
      "Epoch 135/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3271 - acc: 0.5282 - val_loss: 1.7392 - val_acc: 0.3975\n",
      "Epoch 136/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3095 - acc: 0.5288 - val_loss: 1.7637 - val_acc: 0.3958\n",
      "Epoch 137/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.3018 - acc: 0.5335 - val_loss: 1.7237 - val_acc: 0.3942\n",
      "Epoch 138/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.2957 - acc: 0.5331 - val_loss: 1.7519 - val_acc: 0.3942\n",
      "Epoch 139/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 1.2877 - acc: 0.5418 - val_loss: 1.7596 - val_acc: 0.3946\n",
      "Epoch 140/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2926 - acc: 0.5385 - val_loss: 1.7655 - val_acc: 0.3892\n",
      "Epoch 141/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.2864 - acc: 0.5443 - val_loss: 1.7317 - val_acc: 0.3967\n",
      "Epoch 142/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.2846 - acc: 0.5390 - val_loss: 1.7733 - val_acc: 0.3933\n",
      "Epoch 143/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2790 - acc: 0.5420 - val_loss: 1.7377 - val_acc: 0.3996\n",
      "Epoch 144/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.2700 - acc: 0.5472 - val_loss: 1.7758 - val_acc: 0.3971\n",
      "Epoch 145/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.2578 - acc: 0.5536 - val_loss: 1.8257 - val_acc: 0.3804\n",
      "Epoch 146/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.2475 - acc: 0.5582 - val_loss: 1.7383 - val_acc: 0.4067\n",
      "Epoch 147/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2444 - acc: 0.5595 - val_loss: 1.8032 - val_acc: 0.3888\n",
      "Epoch 148/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.2490 - acc: 0.5551 - val_loss: 1.7888 - val_acc: 0.3967\n",
      "Epoch 149/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.2356 - acc: 0.5620 - val_loss: 1.7786 - val_acc: 0.3912\n",
      "Epoch 150/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.2337 - acc: 0.5588 - val_loss: 1.7358 - val_acc: 0.4046\n",
      "Epoch 151/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.2265 - acc: 0.5642 - val_loss: 1.7517 - val_acc: 0.4033\n",
      "Epoch 152/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2240 - acc: 0.5661 - val_loss: 1.7572 - val_acc: 0.3992\n",
      "Epoch 153/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.2085 - acc: 0.5761 - val_loss: 1.7575 - val_acc: 0.3971\n",
      "Epoch 154/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.2180 - acc: 0.5724 - val_loss: 1.7530 - val_acc: 0.4054\n",
      "Epoch 155/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.2006 - acc: 0.5741 - val_loss: 1.7492 - val_acc: 0.4063\n",
      "Epoch 156/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1971 - acc: 0.5794 - val_loss: 1.7574 - val_acc: 0.4062\n",
      "Epoch 157/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1856 - acc: 0.5810 - val_loss: 1.7906 - val_acc: 0.3958\n",
      "Epoch 158/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.1895 - acc: 0.5763 - val_loss: 1.7335 - val_acc: 0.4142\n",
      "Epoch 159/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.1764 - acc: 0.5841 - val_loss: 1.7672 - val_acc: 0.3950\n",
      "Epoch 160/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.1822 - acc: 0.5828 - val_loss: 1.8106 - val_acc: 0.3896\n",
      "Epoch 161/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.1671 - acc: 0.5898 - val_loss: 1.7697 - val_acc: 0.4075\n",
      "Epoch 162/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1605 - acc: 0.5882 - val_loss: 1.7593 - val_acc: 0.4083\n",
      "Epoch 163/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.1537 - acc: 0.6014 - val_loss: 1.7838 - val_acc: 0.4017\n",
      "Epoch 164/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.1535 - acc: 0.5901 - val_loss: 1.7791 - val_acc: 0.4042\n",
      "Epoch 165/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.1645 - acc: 0.5906 - val_loss: 1.7505 - val_acc: 0.4146\n",
      "Epoch 166/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.1403 - acc: 0.5985 - val_loss: 1.7687 - val_acc: 0.4075\n",
      "Epoch 167/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.1199 - acc: 0.6101 - val_loss: 1.7861 - val_acc: 0.4100\n",
      "Epoch 168/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1219 - acc: 0.6026 - val_loss: 1.7506 - val_acc: 0.4121\n",
      "Epoch 169/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.1177 - acc: 0.6097 - val_loss: 1.7750 - val_acc: 0.3958\n",
      "Epoch 170/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.1129 - acc: 0.6095 - val_loss: 1.7949 - val_acc: 0.4025\n",
      "Epoch 171/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 1.1023 - acc: 0.6144 - val_loss: 1.7868 - val_acc: 0.4108\n",
      "Epoch 172/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0993 - acc: 0.6160 - val_loss: 1.7836 - val_acc: 0.4217\n",
      "Epoch 173/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.1016 - acc: 0.6101 - val_loss: 1.7726 - val_acc: 0.4071\n",
      "Epoch 174/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.1090 - acc: 0.6077 - val_loss: 1.7639 - val_acc: 0.4096\n",
      "Epoch 175/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0740 - acc: 0.6218 - val_loss: 1.8099 - val_acc: 0.4112\n",
      "Epoch 176/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 1.0874 - acc: 0.6217 - val_loss: 1.7815 - val_acc: 0.4088\n",
      "Epoch 177/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0814 - acc: 0.6246 - val_loss: 1.7734 - val_acc: 0.4079\n",
      "Epoch 178/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0632 - acc: 0.6286 - val_loss: 1.7798 - val_acc: 0.4154\n",
      "Epoch 179/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.0583 - acc: 0.6293 - val_loss: 1.8072 - val_acc: 0.4171\n",
      "Epoch 180/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 1.0595 - acc: 0.6326 - val_loss: 1.8170 - val_acc: 0.4050\n",
      "Epoch 181/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 1.0542 - acc: 0.6377 - val_loss: 1.8005 - val_acc: 0.4104\n",
      "Epoch 182/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0306 - acc: 0.6369 - val_loss: 1.7960 - val_acc: 0.4150\n",
      "Epoch 183/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 1.0331 - acc: 0.6348 - val_loss: 1.8411 - val_acc: 0.4154\n",
      "Epoch 184/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 1.0313 - acc: 0.6408 - val_loss: 1.8003 - val_acc: 0.4183\n",
      "Epoch 185/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 1.0109 - acc: 0.6507 - val_loss: 1.7962 - val_acc: 0.4146\n",
      "Epoch 186/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 1.0116 - acc: 0.6495 - val_loss: 1.8391 - val_acc: 0.4150\n",
      "Epoch 187/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.0062 - acc: 0.6453 - val_loss: 1.8104 - val_acc: 0.4175\n",
      "Epoch 188/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 1.0090 - acc: 0.6483 - val_loss: 1.8394 - val_acc: 0.4121\n",
      "Epoch 189/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.0153 - acc: 0.6480 - val_loss: 1.8376 - val_acc: 0.4242\n",
      "Epoch 190/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.9941 - acc: 0.6568 - val_loss: 1.7972 - val_acc: 0.4242\n",
      "Epoch 191/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.9785 - acc: 0.6642 - val_loss: 1.8058 - val_acc: 0.4308\n",
      "Epoch 192/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 1.0027 - acc: 0.6503 - val_loss: 1.8044 - val_acc: 0.4204\n",
      "Epoch 193/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.9880 - acc: 0.6569 - val_loss: 1.8163 - val_acc: 0.4283\n",
      "Epoch 194/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.9608 - acc: 0.6684 - val_loss: 1.8116 - val_acc: 0.4275\n",
      "Epoch 195/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.9664 - acc: 0.6665 - val_loss: 1.8187 - val_acc: 0.4196\n",
      "Epoch 196/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9590 - acc: 0.6708 - val_loss: 1.8383 - val_acc: 0.4225\n",
      "Epoch 197/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9495 - acc: 0.6756 - val_loss: 1.8623 - val_acc: 0.4125\n",
      "Epoch 198/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9484 - acc: 0.6736 - val_loss: 1.8251 - val_acc: 0.4200\n",
      "Epoch 199/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9467 - acc: 0.6707 - val_loss: 1.8820 - val_acc: 0.4200\n",
      "Epoch 200/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.9397 - acc: 0.6781 - val_loss: 1.8382 - val_acc: 0.4175\n",
      "Epoch 201/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9346 - acc: 0.6824 - val_loss: 1.8330 - val_acc: 0.4217\n",
      "Epoch 202/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.9269 - acc: 0.6807 - val_loss: 1.9596 - val_acc: 0.4133\n",
      "Epoch 203/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.9265 - acc: 0.6797 - val_loss: 1.8868 - val_acc: 0.4279\n",
      "Epoch 204/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.9041 - acc: 0.6880 - val_loss: 1.8583 - val_acc: 0.4250\n",
      "Epoch 205/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.9068 - acc: 0.6899 - val_loss: 1.8891 - val_acc: 0.4213\n",
      "Epoch 206/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.9132 - acc: 0.6818 - val_loss: 1.8346 - val_acc: 0.4229\n",
      "Epoch 207/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.8939 - acc: 0.6868 - val_loss: 1.8655 - val_acc: 0.4275\n",
      "Epoch 208/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.8779 - acc: 0.6961 - val_loss: 1.8730 - val_acc: 0.4183\n",
      "Epoch 209/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.8938 - acc: 0.6884 - val_loss: 1.8686 - val_acc: 0.4304\n",
      "Epoch 210/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.8821 - acc: 0.6970 - val_loss: 1.9276 - val_acc: 0.4196\n",
      "Epoch 211/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.9104 - acc: 0.6833 - val_loss: 1.9587 - val_acc: 0.4142\n",
      "Epoch 212/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.8775 - acc: 0.7008 - val_loss: 1.8891 - val_acc: 0.4242\n",
      "Epoch 213/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.8778 - acc: 0.6968 - val_loss: 1.9257 - val_acc: 0.4146\n",
      "Epoch 214/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.8500 - acc: 0.7080 - val_loss: 1.8902 - val_acc: 0.4312\n",
      "Epoch 215/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.8469 - acc: 0.7080 - val_loss: 1.8695 - val_acc: 0.4317\n",
      "Epoch 216/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.8654 - acc: 0.7023 - val_loss: 1.8691 - val_acc: 0.4246\n",
      "Epoch 217/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.8551 - acc: 0.6986 - val_loss: 1.9347 - val_acc: 0.4179\n",
      "Epoch 218/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.8519 - acc: 0.7086 - val_loss: 1.8773 - val_acc: 0.4275\n",
      "Epoch 219/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 0.8507 - acc: 0.7062 - val_loss: 1.8646 - val_acc: 0.4263\n",
      "Epoch 220/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 0.8338 - acc: 0.7152 - val_loss: 1.8892 - val_acc: 0.4208\n",
      "Epoch 221/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.8321 - acc: 0.7103 - val_loss: 1.9516 - val_acc: 0.4129\n",
      "Epoch 222/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.8374 - acc: 0.7110 - val_loss: 1.8892 - val_acc: 0.4308\n",
      "Epoch 223/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.8122 - acc: 0.7134 - val_loss: 1.8921 - val_acc: 0.4338\n",
      "Epoch 224/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 0.8048 - acc: 0.7191 - val_loss: 1.9328 - val_acc: 0.4271\n",
      "Epoch 225/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.8245 - acc: 0.7174 - val_loss: 1.8726 - val_acc: 0.4213\n",
      "Epoch 226/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.8071 - acc: 0.7215 - val_loss: 1.8961 - val_acc: 0.4225\n",
      "Epoch 227/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7880 - acc: 0.7294 - val_loss: 1.9630 - val_acc: 0.4325\n",
      "Epoch 228/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.8052 - acc: 0.7185 - val_loss: 1.9178 - val_acc: 0.4387\n",
      "Epoch 229/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7897 - acc: 0.7302 - val_loss: 1.9261 - val_acc: 0.4350\n",
      "Epoch 230/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 0.7872 - acc: 0.7339 - val_loss: 1.9115 - val_acc: 0.4254\n",
      "Epoch 231/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 0.7845 - acc: 0.7285 - val_loss: 1.9261 - val_acc: 0.4217\n",
      "Epoch 232/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 0.7731 - acc: 0.7330 - val_loss: 1.9581 - val_acc: 0.4321\n",
      "Epoch 233/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.7795 - acc: 0.7265 - val_loss: 1.9324 - val_acc: 0.4287\n",
      "Epoch 234/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7842 - acc: 0.7251 - val_loss: 1.9396 - val_acc: 0.4379\n",
      "Epoch 235/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.7551 - acc: 0.7380 - val_loss: 1.9749 - val_acc: 0.4267\n",
      "Epoch 236/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.7634 - acc: 0.7355 - val_loss: 1.9559 - val_acc: 0.4383\n",
      "Epoch 237/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7687 - acc: 0.7341 - val_loss: 1.9544 - val_acc: 0.4329\n",
      "Epoch 238/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.7497 - acc: 0.7423 - val_loss: 1.8986 - val_acc: 0.4350\n",
      "Epoch 239/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.7365 - acc: 0.7477 - val_loss: 1.9582 - val_acc: 0.4321\n",
      "Epoch 240/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7422 - acc: 0.7440 - val_loss: 1.9471 - val_acc: 0.4354\n",
      "Epoch 241/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.7272 - acc: 0.7484 - val_loss: 1.9679 - val_acc: 0.4383\n",
      "Epoch 242/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.7319 - acc: 0.7436 - val_loss: 2.0031 - val_acc: 0.4350\n",
      "Epoch 243/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7195 - acc: 0.7504 - val_loss: 2.0128 - val_acc: 0.4317\n",
      "Epoch 244/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7392 - acc: 0.7457 - val_loss: 2.0021 - val_acc: 0.4246\n",
      "Epoch 245/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7290 - acc: 0.7469 - val_loss: 1.9330 - val_acc: 0.4404\n",
      "Epoch 246/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7227 - acc: 0.7520 - val_loss: 1.9568 - val_acc: 0.4367\n",
      "Epoch 247/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.7008 - acc: 0.7590 - val_loss: 2.0001 - val_acc: 0.4300\n",
      "Epoch 248/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7153 - acc: 0.7537 - val_loss: 2.0036 - val_acc: 0.4321\n",
      "Epoch 249/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7080 - acc: 0.7541 - val_loss: 2.0357 - val_acc: 0.4229\n",
      "Epoch 250/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.7094 - acc: 0.7584 - val_loss: 2.0280 - val_acc: 0.4296\n",
      "Epoch 251/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.7086 - acc: 0.7523 - val_loss: 2.0214 - val_acc: 0.4379\n",
      "Epoch 252/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6682 - acc: 0.7767 - val_loss: 1.9928 - val_acc: 0.4350\n",
      "Epoch 253/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6796 - acc: 0.7676 - val_loss: 2.0471 - val_acc: 0.4375\n",
      "Epoch 254/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.6754 - acc: 0.7706 - val_loss: 2.0451 - val_acc: 0.4229\n",
      "Epoch 255/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.6962 - acc: 0.7604 - val_loss: 2.0693 - val_acc: 0.4308\n",
      "Epoch 256/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 0.6843 - acc: 0.7656 - val_loss: 2.0405 - val_acc: 0.4229\n",
      "Epoch 257/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 0.6480 - acc: 0.7773 - val_loss: 2.0817 - val_acc: 0.4233\n",
      "Epoch 258/50000\n",
      "9600/9600 [==============================] - 0s 41us/step - loss: 0.6799 - acc: 0.7662 - val_loss: 2.0139 - val_acc: 0.4362\n",
      "Epoch 259/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 0.6925 - acc: 0.7588 - val_loss: 2.1024 - val_acc: 0.4258\n",
      "Epoch 260/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.6555 - acc: 0.7768 - val_loss: 2.0731 - val_acc: 0.4304\n",
      "Epoch 261/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6544 - acc: 0.7695 - val_loss: 2.0758 - val_acc: 0.4233\n",
      "Epoch 262/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6659 - acc: 0.7707 - val_loss: 2.0693 - val_acc: 0.4333\n",
      "Epoch 263/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.6556 - acc: 0.7720 - val_loss: 2.0655 - val_acc: 0.4317\n",
      "Epoch 264/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6477 - acc: 0.7773 - val_loss: 2.0540 - val_acc: 0.4429\n",
      "Epoch 265/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.6445 - acc: 0.7799 - val_loss: 2.0616 - val_acc: 0.4333\n",
      "Epoch 266/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.6356 - acc: 0.7812 - val_loss: 2.0727 - val_acc: 0.4429\n",
      "Epoch 267/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6289 - acc: 0.7796 - val_loss: 2.0692 - val_acc: 0.4312\n",
      "Epoch 268/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6671 - acc: 0.7711 - val_loss: 2.0802 - val_acc: 0.4188\n",
      "Epoch 269/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6306 - acc: 0.7819 - val_loss: 2.1110 - val_acc: 0.4358\n",
      "Epoch 270/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.6509 - acc: 0.7756 - val_loss: 2.0971 - val_acc: 0.4350\n",
      "Epoch 271/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.6404 - acc: 0.7806 - val_loss: 2.0797 - val_acc: 0.4325\n",
      "Epoch 272/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6075 - acc: 0.7939 - val_loss: 2.0602 - val_acc: 0.4329\n",
      "Epoch 273/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.6206 - acc: 0.7899 - val_loss: 2.1374 - val_acc: 0.4267\n",
      "Epoch 274/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 0.6135 - acc: 0.7873 - val_loss: 2.1115 - val_acc: 0.4471\n",
      "Epoch 275/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.6058 - acc: 0.7919 - val_loss: 2.1468 - val_acc: 0.4350\n",
      "Epoch 276/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6051 - acc: 0.7906 - val_loss: 2.1104 - val_acc: 0.4279\n",
      "Epoch 277/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.6154 - acc: 0.7895 - val_loss: 2.1966 - val_acc: 0.4362\n",
      "Epoch 278/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.5845 - acc: 0.8022 - val_loss: 2.1403 - val_acc: 0.4400\n",
      "Epoch 279/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 0.5781 - acc: 0.8041 - val_loss: 2.1519 - val_acc: 0.4367\n",
      "Epoch 280/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.6036 - acc: 0.7900 - val_loss: 2.1823 - val_acc: 0.4263\n",
      "Epoch 281/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.5815 - acc: 0.8033 - val_loss: 2.1202 - val_acc: 0.4404\n",
      "Epoch 282/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 0.5844 - acc: 0.7951 - val_loss: 2.1816 - val_acc: 0.4250\n",
      "Epoch 283/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 34us/step - loss: 0.5941 - acc: 0.7985 - val_loss: 2.1391 - val_acc: 0.4400\n",
      "Epoch 284/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 0.5917 - acc: 0.7975 - val_loss: 2.1057 - val_acc: 0.4387\n",
      "Epoch 285/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.5674 - acc: 0.8034 - val_loss: 2.1169 - val_acc: 0.4458\n",
      "Epoch 286/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.5861 - acc: 0.8008 - val_loss: 2.1451 - val_acc: 0.4308\n",
      "Epoch 287/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.5861 - acc: 0.8025 - val_loss: 2.1296 - val_acc: 0.4329\n",
      "Epoch 288/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.5711 - acc: 0.8025 - val_loss: 2.1784 - val_acc: 0.4400\n",
      "Epoch 289/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.5598 - acc: 0.8068 - val_loss: 2.2872 - val_acc: 0.4200\n",
      "Epoch 290/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 0.5741 - acc: 0.8030 - val_loss: 2.1759 - val_acc: 0.4346\n",
      "Epoch 291/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 0.5600 - acc: 0.8089 - val_loss: 2.1452 - val_acc: 0.4400\n",
      "Epoch 292/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.5504 - acc: 0.8109 - val_loss: 2.1749 - val_acc: 0.4354\n",
      "Epoch 293/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.5593 - acc: 0.8074 - val_loss: 2.2158 - val_acc: 0.4417\n",
      "Epoch 294/50000\n",
      "9600/9600 [==============================] - 0s 36us/step - loss: 0.5580 - acc: 0.8063 - val_loss: 2.1728 - val_acc: 0.4400\n",
      "Epoch 295/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.5353 - acc: 0.8139 - val_loss: 2.2208 - val_acc: 0.4346\n",
      "Epoch 296/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.5724 - acc: 0.8020 - val_loss: 2.1633 - val_acc: 0.4358\n",
      "Epoch 297/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.5398 - acc: 0.8161 - val_loss: 2.2102 - val_acc: 0.4383\n",
      "Epoch 298/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.5505 - acc: 0.8110 - val_loss: 2.2348 - val_acc: 0.4371\n",
      "Epoch 299/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.5422 - acc: 0.8153 - val_loss: 2.2084 - val_acc: 0.4450\n",
      "Epoch 300/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 0.5207 - acc: 0.8195 - val_loss: 2.1914 - val_acc: 0.4346\n",
      "Epoch 301/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.5136 - acc: 0.8250 - val_loss: 2.2814 - val_acc: 0.4387\n",
      "Epoch 302/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.5249 - acc: 0.8203 - val_loss: 2.2426 - val_acc: 0.4412\n",
      "Epoch 303/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.5206 - acc: 0.8215 - val_loss: 2.2208 - val_acc: 0.4233\n",
      "Epoch 304/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.5272 - acc: 0.8200 - val_loss: 2.2754 - val_acc: 0.4296\n",
      "Epoch 305/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.5356 - acc: 0.8155 - val_loss: 2.2417 - val_acc: 0.4363\n",
      "Epoch 306/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.5404 - acc: 0.8123 - val_loss: 2.2355 - val_acc: 0.4437\n",
      "Epoch 307/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.5167 - acc: 0.8240 - val_loss: 2.1978 - val_acc: 0.4413\n",
      "Epoch 308/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.5203 - acc: 0.8193 - val_loss: 2.3690 - val_acc: 0.4229\n",
      "Epoch 309/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.5170 - acc: 0.8230 - val_loss: 2.2640 - val_acc: 0.4425\n",
      "Epoch 310/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.5120 - acc: 0.8239 - val_loss: 2.2811 - val_acc: 0.4346\n",
      "Epoch 311/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.5041 - acc: 0.8282 - val_loss: 2.2599 - val_acc: 0.4404\n",
      "Epoch 312/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.5014 - acc: 0.8273 - val_loss: 2.2614 - val_acc: 0.4404\n",
      "Epoch 313/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.4986 - acc: 0.8324 - val_loss: 2.2827 - val_acc: 0.4342\n",
      "Epoch 314/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 0.5054 - acc: 0.8277 - val_loss: 2.2561 - val_acc: 0.4396\n",
      "Epoch 315/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 0.4975 - acc: 0.8295 - val_loss: 2.3291 - val_acc: 0.4358\n",
      "Epoch 316/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.5103 - acc: 0.8225 - val_loss: 2.2802 - val_acc: 0.4396\n",
      "Epoch 317/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4924 - acc: 0.8301 - val_loss: 2.3000 - val_acc: 0.4479\n",
      "Epoch 318/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4916 - acc: 0.8312 - val_loss: 2.2770 - val_acc: 0.4429\n",
      "Epoch 319/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.4861 - acc: 0.8325 - val_loss: 2.3247 - val_acc: 0.4412\n",
      "Epoch 320/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.4895 - acc: 0.8310 - val_loss: 2.2759 - val_acc: 0.4483\n",
      "Epoch 321/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.4669 - acc: 0.8398 - val_loss: 2.3336 - val_acc: 0.4487\n",
      "Epoch 322/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4747 - acc: 0.8345 - val_loss: 2.3166 - val_acc: 0.4471\n",
      "Epoch 323/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 0.4756 - acc: 0.8372 - val_loss: 2.2733 - val_acc: 0.4383\n",
      "Epoch 324/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.4932 - acc: 0.8321 - val_loss: 2.2683 - val_acc: 0.4487\n",
      "Epoch 325/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4745 - acc: 0.8386 - val_loss: 2.2965 - val_acc: 0.4396\n",
      "Epoch 326/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4809 - acc: 0.8332 - val_loss: 2.3154 - val_acc: 0.4346\n",
      "Epoch 327/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4756 - acc: 0.8358 - val_loss: 2.2803 - val_acc: 0.4367\n",
      "Epoch 328/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4917 - acc: 0.8290 - val_loss: 2.3215 - val_acc: 0.4350\n",
      "Epoch 329/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.4614 - acc: 0.8383 - val_loss: 2.3001 - val_acc: 0.4513\n",
      "Epoch 330/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 0.4512 - acc: 0.8462 - val_loss: 2.3765 - val_acc: 0.4312\n",
      "Epoch 331/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.4509 - acc: 0.8470 - val_loss: 2.4456 - val_acc: 0.4158\n",
      "Epoch 332/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4882 - acc: 0.8330 - val_loss: 2.3365 - val_acc: 0.4375\n",
      "Epoch 333/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4594 - acc: 0.8464 - val_loss: 2.3685 - val_acc: 0.4413\n",
      "Epoch 334/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4668 - acc: 0.8410 - val_loss: 2.3545 - val_acc: 0.4400\n",
      "Epoch 335/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4645 - acc: 0.8382 - val_loss: 2.4222 - val_acc: 0.4358\n",
      "Epoch 336/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4499 - acc: 0.8451 - val_loss: 2.3487 - val_acc: 0.4342\n",
      "Epoch 337/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4441 - acc: 0.8441 - val_loss: 2.4379 - val_acc: 0.4392\n",
      "Epoch 338/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4401 - acc: 0.8506 - val_loss: 2.3673 - val_acc: 0.4375\n",
      "Epoch 339/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4299 - acc: 0.8519 - val_loss: 2.3430 - val_acc: 0.4367\n",
      "Epoch 340/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4379 - acc: 0.8475 - val_loss: 2.4554 - val_acc: 0.4338\n",
      "Epoch 341/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4379 - acc: 0.8489 - val_loss: 2.4065 - val_acc: 0.4421\n",
      "Epoch 342/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4515 - acc: 0.8429 - val_loss: 2.4177 - val_acc: 0.4379\n",
      "Epoch 343/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4379 - acc: 0.8507 - val_loss: 2.3936 - val_acc: 0.4408\n",
      "Epoch 344/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4248 - acc: 0.8555 - val_loss: 2.4193 - val_acc: 0.4446\n",
      "Epoch 345/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4506 - acc: 0.8470 - val_loss: 2.4319 - val_acc: 0.4375\n",
      "Epoch 346/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4373 - acc: 0.8492 - val_loss: 2.4553 - val_acc: 0.4313\n",
      "Epoch 347/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4585 - acc: 0.8436 - val_loss: 2.4116 - val_acc: 0.4483\n",
      "Epoch 348/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4431 - acc: 0.8489 - val_loss: 2.4386 - val_acc: 0.4400\n",
      "Epoch 349/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4214 - acc: 0.8542 - val_loss: 2.3880 - val_acc: 0.4387\n",
      "Epoch 350/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4391 - acc: 0.8457 - val_loss: 2.3632 - val_acc: 0.4300\n",
      "Epoch 351/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4439 - acc: 0.8419 - val_loss: 2.4778 - val_acc: 0.4437\n",
      "Epoch 352/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4248 - acc: 0.8546 - val_loss: 2.4552 - val_acc: 0.4392\n",
      "Epoch 353/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.4353 - acc: 0.8506 - val_loss: 2.4121 - val_acc: 0.4346\n",
      "Epoch 354/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.4311 - acc: 0.8541 - val_loss: 2.3763 - val_acc: 0.4325\n",
      "Epoch 355/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4248 - acc: 0.8566 - val_loss: 2.4513 - val_acc: 0.4446\n",
      "Epoch 356/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4237 - acc: 0.8566 - val_loss: 2.4511 - val_acc: 0.4521\n",
      "Epoch 357/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4404 - acc: 0.8506 - val_loss: 2.4229 - val_acc: 0.4342\n",
      "Epoch 358/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.4095 - acc: 0.8583 - val_loss: 2.4451 - val_acc: 0.4392\n",
      "Epoch 359/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 0.4226 - acc: 0.8546 - val_loss: 2.4644 - val_acc: 0.4400\n",
      "Epoch 360/50000\n",
      "9600/9600 [==============================] - 0s 39us/step - loss: 0.4026 - acc: 0.8630 - val_loss: 2.4264 - val_acc: 0.4471\n",
      "Epoch 361/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4376 - acc: 0.8467 - val_loss: 2.4311 - val_acc: 0.4425\n",
      "Epoch 362/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.4259 - acc: 0.8521 - val_loss: 2.4643 - val_acc: 0.4363\n",
      "Epoch 363/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.3948 - acc: 0.8655 - val_loss: 2.5161 - val_acc: 0.4337\n",
      "Epoch 364/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 0.4273 - acc: 0.8510 - val_loss: 2.4794 - val_acc: 0.4442\n",
      "Epoch 365/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.4349 - acc: 0.8493 - val_loss: 2.4712 - val_acc: 0.4462\n",
      "Epoch 366/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 0.4337 - acc: 0.8497 - val_loss: 2.5561 - val_acc: 0.4200\n",
      "Epoch 367/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4018 - acc: 0.8655 - val_loss: 2.4272 - val_acc: 0.4396\n",
      "Epoch 368/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.3942 - acc: 0.8675 - val_loss: 2.5275 - val_acc: 0.4392\n",
      "Epoch 369/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.4096 - acc: 0.8578 - val_loss: 2.4816 - val_acc: 0.4379\n",
      "Epoch 370/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.4039 - acc: 0.8605 - val_loss: 2.4467 - val_acc: 0.4425\n",
      "Epoch 371/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4059 - acc: 0.8646 - val_loss: 2.4673 - val_acc: 0.4346\n",
      "Epoch 372/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 0.3971 - acc: 0.8630 - val_loss: 2.4958 - val_acc: 0.4367\n",
      "Epoch 373/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.4050 - acc: 0.8573 - val_loss: 2.5236 - val_acc: 0.4296\n",
      "Epoch 374/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3895 - acc: 0.8652 - val_loss: 2.5053 - val_acc: 0.4454\n",
      "Epoch 375/50000\n",
      "9600/9600 [==============================] - 0s 30us/step - loss: 0.4211 - acc: 0.8518 - val_loss: 2.5175 - val_acc: 0.4271\n",
      "Epoch 376/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.4061 - acc: 0.8567 - val_loss: 2.5008 - val_acc: 0.4321\n",
      "Epoch 377/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3957 - acc: 0.8610 - val_loss: 2.5229 - val_acc: 0.4383\n",
      "Epoch 378/50000\n",
      "9600/9600 [==============================] - 0s 40us/step - loss: 0.3988 - acc: 0.8624 - val_loss: 2.5413 - val_acc: 0.4342\n",
      "Epoch 379/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 0.4117 - acc: 0.8601 - val_loss: 2.5032 - val_acc: 0.4279\n",
      "Epoch 380/50000\n",
      "9600/9600 [==============================] - 0s 38us/step - loss: 0.4261 - acc: 0.8515 - val_loss: 2.4656 - val_acc: 0.4425\n",
      "Epoch 381/50000\n",
      "9600/9600 [==============================] - 0s 37us/step - loss: 0.4008 - acc: 0.8617 - val_loss: 2.5625 - val_acc: 0.4317\n",
      "Epoch 382/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.4027 - acc: 0.8602 - val_loss: 2.5003 - val_acc: 0.4379\n",
      "Epoch 383/50000\n",
      "9600/9600 [==============================] - 0s 34us/step - loss: 0.3669 - acc: 0.8779 - val_loss: 2.5565 - val_acc: 0.4279\n",
      "Epoch 384/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.3710 - acc: 0.8735 - val_loss: 2.5424 - val_acc: 0.4350\n",
      "Epoch 385/50000\n",
      "9600/9600 [==============================] - 0s 31us/step - loss: 0.3818 - acc: 0.8688 - val_loss: 2.5237 - val_acc: 0.4408\n",
      "Epoch 386/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3822 - acc: 0.8707 - val_loss: 2.5821 - val_acc: 0.4396\n",
      "Epoch 387/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3567 - acc: 0.8814 - val_loss: 2.5767 - val_acc: 0.4342\n",
      "Epoch 388/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3801 - acc: 0.8705 - val_loss: 2.5150 - val_acc: 0.4396\n",
      "Epoch 389/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3720 - acc: 0.8714 - val_loss: 2.6526 - val_acc: 0.4354\n",
      "Epoch 390/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3421 - acc: 0.8857 - val_loss: 2.6744 - val_acc: 0.4304\n",
      "Epoch 391/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3580 - acc: 0.8744 - val_loss: 2.6081 - val_acc: 0.4283\n",
      "Epoch 392/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3799 - acc: 0.8677 - val_loss: 2.5529 - val_acc: 0.4367\n",
      "Epoch 393/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.3579 - acc: 0.8803 - val_loss: 2.7390 - val_acc: 0.4267\n",
      "Epoch 394/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3764 - acc: 0.8734 - val_loss: 2.6319 - val_acc: 0.4404\n",
      "Epoch 395/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3747 - acc: 0.8700 - val_loss: 2.6377 - val_acc: 0.4338\n",
      "Epoch 396/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.3719 - acc: 0.8711 - val_loss: 2.6082 - val_acc: 0.4363\n",
      "Epoch 397/50000\n",
      "9600/9600 [==============================] - 0s 35us/step - loss: 0.3624 - acc: 0.8765 - val_loss: 2.5440 - val_acc: 0.4412\n",
      "Epoch 398/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.3606 - acc: 0.8767 - val_loss: 2.5194 - val_acc: 0.4412\n",
      "Epoch 399/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.3621 - acc: 0.8781 - val_loss: 2.6709 - val_acc: 0.4271\n",
      "Epoch 400/50000\n",
      "9600/9600 [==============================] - 0s 33us/step - loss: 0.3724 - acc: 0.8695 - val_loss: 2.6061 - val_acc: 0.4325\n",
      "Epoch 401/50000\n",
      "9600/9600 [==============================] - 0s 32us/step - loss: 0.3552 - acc: 0.8784 - val_loss: 2.5947 - val_acc: 0.4404\n",
      "Epoch 402/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3720 - acc: 0.8741 - val_loss: 2.6122 - val_acc: 0.4304\n",
      "Epoch 403/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3560 - acc: 0.8753 - val_loss: 2.6925 - val_acc: 0.4229\n",
      "Epoch 404/50000\n",
      "9600/9600 [==============================] - 0s 29us/step - loss: 0.3455 - acc: 0.8798 - val_loss: 2.6459 - val_acc: 0.4379\n",
      "Epoch 405/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.3654 - acc: 0.8772 - val_loss: 2.5623 - val_acc: 0.4358\n",
      "Epoch 406/50000\n",
      "9600/9600 [==============================] - 0s 28us/step - loss: 0.3709 - acc: 0.8751 - val_loss: 2.6130 - val_acc: 0.4442\n",
      "Val loss: 2.4511,Val acc: 0.4521\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTraining model:\n",
      "best\n",
      "0 - U:830|A:prelu|D:0.654 \n",
      "1 - U:782|A:tanh|D:0.166 \n",
      "2 - U:28|A:elu|D:0.062 \n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 830)               651550    \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 830)               830       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 830)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 782)               649842    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 782)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 28)                21924     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                290       \n",
      "=================================================================\n",
      "Total params: 1,324,436\n",
      "Trainable params: 1,324,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9600 samples, validate on 2400 samples\n",
      "Epoch 1/50000\n",
      "9600/9600 [==============================] - 1s 67us/step - loss: 2.2994 - acc: 0.1154 - val_loss: 2.2978 - val_acc: 0.1179\n",
      "Epoch 2/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 2.2673 - acc: 0.1487 - val_loss: 2.1836 - val_acc: 0.2254\n",
      "Epoch 3/50000\n",
      "9600/9600 [==============================] - 1s 58us/step - loss: 2.1453 - acc: 0.2109 - val_loss: 2.0517 - val_acc: 0.2750\n",
      "Epoch 4/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 2.0472 - acc: 0.2549 - val_loss: 1.9290 - val_acc: 0.3013\n",
      "Epoch 5/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.9614 - acc: 0.2804 - val_loss: 1.9126 - val_acc: 0.2817\n",
      "Epoch 6/50000\n",
      "9600/9600 [==============================] - 0s 52us/step - loss: 1.9013 - acc: 0.3033 - val_loss: 1.9034 - val_acc: 0.2887\n",
      "Epoch 7/50000\n",
      "9600/9600 [==============================] - 1s 61us/step - loss: 1.8854 - acc: 0.3042 - val_loss: 1.8361 - val_acc: 0.3221\n",
      "Epoch 8/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.8659 - acc: 0.3122 - val_loss: 1.8253 - val_acc: 0.3242\n",
      "Epoch 9/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.8648 - acc: 0.3108 - val_loss: 1.8336 - val_acc: 0.3196\n",
      "Epoch 10/50000\n",
      "9600/9600 [==============================] - 1s 56us/step - loss: 1.8539 - acc: 0.3119 - val_loss: 1.8375 - val_acc: 0.3121\n",
      "Epoch 11/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.8441 - acc: 0.3174 - val_loss: 1.8286 - val_acc: 0.3250\n",
      "Epoch 12/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.8396 - acc: 0.3127 - val_loss: 1.8391 - val_acc: 0.3104\n",
      "Epoch 13/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.8386 - acc: 0.3140 - val_loss: 1.8515 - val_acc: 0.3042\n",
      "Epoch 14/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.8296 - acc: 0.3199 - val_loss: 1.8014 - val_acc: 0.3388\n",
      "Epoch 15/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.8209 - acc: 0.3294 - val_loss: 1.8140 - val_acc: 0.3342\n",
      "Epoch 16/50000\n",
      "9600/9600 [==============================] - 0s 52us/step - loss: 1.8273 - acc: 0.3156 - val_loss: 1.8243 - val_acc: 0.3221\n",
      "Epoch 17/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.8275 - acc: 0.3232 - val_loss: 1.8020 - val_acc: 0.3321\n",
      "Epoch 18/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.8201 - acc: 0.3276 - val_loss: 1.8116 - val_acc: 0.3429\n",
      "Epoch 19/50000\n",
      "9600/9600 [==============================] - 1s 57us/step - loss: 1.8195 - acc: 0.3226 - val_loss: 1.7978 - val_acc: 0.3358\n",
      "Epoch 20/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.8020 - acc: 0.3295 - val_loss: 1.7931 - val_acc: 0.3404\n",
      "Epoch 21/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.8126 - acc: 0.3311 - val_loss: 1.8056 - val_acc: 0.3333\n",
      "Epoch 22/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.7987 - acc: 0.3349 - val_loss: 1.8254 - val_acc: 0.3208\n",
      "Epoch 23/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.8011 - acc: 0.3333 - val_loss: 1.7983 - val_acc: 0.3342\n",
      "Epoch 24/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.7939 - acc: 0.3357 - val_loss: 1.7849 - val_acc: 0.3450\n",
      "Epoch 25/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.7946 - acc: 0.3316 - val_loss: 1.8116 - val_acc: 0.3179\n",
      "Epoch 26/50000\n",
      "9600/9600 [==============================] - 1s 57us/step - loss: 1.7871 - acc: 0.3349 - val_loss: 1.7821 - val_acc: 0.3463\n",
      "Epoch 27/50000\n",
      "9600/9600 [==============================] - 1s 65us/step - loss: 1.7849 - acc: 0.3372 - val_loss: 1.7869 - val_acc: 0.3442\n",
      "Epoch 28/50000\n",
      "9600/9600 [==============================] - 1s 63us/step - loss: 1.7873 - acc: 0.3392 - val_loss: 1.7762 - val_acc: 0.3467\n",
      "Epoch 29/50000\n",
      "9600/9600 [==============================] - 1s 56us/step - loss: 1.7716 - acc: 0.3460 - val_loss: 1.7800 - val_acc: 0.3371\n",
      "Epoch 30/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.7838 - acc: 0.3384 - val_loss: 1.8030 - val_acc: 0.3362\n",
      "Epoch 31/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.7713 - acc: 0.3466 - val_loss: 1.7790 - val_acc: 0.3488\n",
      "Epoch 32/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.7680 - acc: 0.3459 - val_loss: 1.7786 - val_acc: 0.3392\n",
      "Epoch 33/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.7732 - acc: 0.3415 - val_loss: 1.7861 - val_acc: 0.3500\n",
      "Epoch 34/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.7735 - acc: 0.3465 - val_loss: 1.7840 - val_acc: 0.3408\n",
      "Epoch 35/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.7705 - acc: 0.3465 - val_loss: 1.7725 - val_acc: 0.3488\n",
      "Epoch 36/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.7773 - acc: 0.3436 - val_loss: 1.7849 - val_acc: 0.3463\n",
      "Epoch 37/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.7628 - acc: 0.3542 - val_loss: 1.7752 - val_acc: 0.3521\n",
      "Epoch 38/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.7544 - acc: 0.3549 - val_loss: 1.7808 - val_acc: 0.3392\n",
      "Epoch 39/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.7674 - acc: 0.3545 - val_loss: 1.7694 - val_acc: 0.3492\n",
      "Epoch 40/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.7615 - acc: 0.3533 - val_loss: 1.8066 - val_acc: 0.3246\n",
      "Epoch 41/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.7544 - acc: 0.3565 - val_loss: 1.7709 - val_acc: 0.3504\n",
      "Epoch 42/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.7552 - acc: 0.3528 - val_loss: 1.8003 - val_acc: 0.3371\n",
      "Epoch 43/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.7509 - acc: 0.3546 - val_loss: 1.7756 - val_acc: 0.3554\n",
      "Epoch 44/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.7493 - acc: 0.3581 - val_loss: 1.7612 - val_acc: 0.3467\n",
      "Epoch 45/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.7484 - acc: 0.3549 - val_loss: 1.7882 - val_acc: 0.3458\n",
      "Epoch 46/50000\n",
      "9600/9600 [==============================] - 1s 52us/step - loss: 1.7546 - acc: 0.3530 - val_loss: 1.7859 - val_acc: 0.3475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.7361 - acc: 0.3599 - val_loss: 1.7729 - val_acc: 0.3458\n",
      "Epoch 48/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.7507 - acc: 0.3557 - val_loss: 1.7913 - val_acc: 0.3400\n",
      "Epoch 49/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.7488 - acc: 0.3592 - val_loss: 1.7620 - val_acc: 0.3521\n",
      "Epoch 50/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.7396 - acc: 0.3604 - val_loss: 1.7665 - val_acc: 0.3625\n",
      "Epoch 51/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.7519 - acc: 0.3582 - val_loss: 1.7615 - val_acc: 0.3621\n",
      "Epoch 52/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.7344 - acc: 0.3612 - val_loss: 1.7669 - val_acc: 0.3400\n",
      "Epoch 53/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.7332 - acc: 0.3558 - val_loss: 1.7594 - val_acc: 0.3579\n",
      "Epoch 54/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.7349 - acc: 0.3576 - val_loss: 1.7703 - val_acc: 0.3442\n",
      "Epoch 55/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.7453 - acc: 0.3608 - val_loss: 1.7904 - val_acc: 0.3442\n",
      "Epoch 56/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.7362 - acc: 0.3676 - val_loss: 1.8015 - val_acc: 0.3412\n",
      "Epoch 57/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.7355 - acc: 0.3597 - val_loss: 1.7557 - val_acc: 0.3529\n",
      "Epoch 58/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.7354 - acc: 0.3592 - val_loss: 1.7712 - val_acc: 0.3592\n",
      "Epoch 59/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.7306 - acc: 0.3582 - val_loss: 1.7678 - val_acc: 0.3433\n",
      "Epoch 60/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.7255 - acc: 0.3646 - val_loss: 1.7668 - val_acc: 0.3517\n",
      "Epoch 61/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.7179 - acc: 0.3671 - val_loss: 1.7543 - val_acc: 0.3504\n",
      "Epoch 62/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.7267 - acc: 0.3732 - val_loss: 1.7631 - val_acc: 0.3608\n",
      "Epoch 63/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.7231 - acc: 0.3698 - val_loss: 1.7669 - val_acc: 0.3496\n",
      "Epoch 64/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.7232 - acc: 0.3674 - val_loss: 1.7733 - val_acc: 0.3525\n",
      "Epoch 65/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.7193 - acc: 0.3689 - val_loss: 1.7762 - val_acc: 0.3517\n",
      "Epoch 66/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.7159 - acc: 0.3705 - val_loss: 1.7682 - val_acc: 0.3496\n",
      "Epoch 67/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.7106 - acc: 0.3738 - val_loss: 1.7645 - val_acc: 0.3496\n",
      "Epoch 68/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.7189 - acc: 0.3709 - val_loss: 1.7970 - val_acc: 0.3412\n",
      "Epoch 69/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.7157 - acc: 0.3698 - val_loss: 1.7604 - val_acc: 0.3487\n",
      "Epoch 70/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.7103 - acc: 0.3709 - val_loss: 1.7682 - val_acc: 0.3454\n",
      "Epoch 71/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.7143 - acc: 0.3755 - val_loss: 1.7567 - val_acc: 0.3529\n",
      "Epoch 72/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.7046 - acc: 0.3701 - val_loss: 1.7571 - val_acc: 0.3479\n",
      "Epoch 73/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.7065 - acc: 0.3752 - val_loss: 1.7519 - val_acc: 0.3617\n",
      "Epoch 74/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.7029 - acc: 0.3738 - val_loss: 1.8062 - val_acc: 0.3396\n",
      "Epoch 75/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.7159 - acc: 0.3733 - val_loss: 1.7653 - val_acc: 0.3500\n",
      "Epoch 76/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.6973 - acc: 0.3795 - val_loss: 1.7708 - val_acc: 0.3558\n",
      "Epoch 77/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.6978 - acc: 0.3826 - val_loss: 1.7477 - val_acc: 0.3521\n",
      "Epoch 78/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.6941 - acc: 0.3781 - val_loss: 1.7493 - val_acc: 0.3533\n",
      "Epoch 79/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.6966 - acc: 0.3758 - val_loss: 1.7537 - val_acc: 0.3592\n",
      "Epoch 80/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.7014 - acc: 0.3792 - val_loss: 1.7460 - val_acc: 0.3483\n",
      "Epoch 81/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.6962 - acc: 0.3772 - val_loss: 1.7450 - val_acc: 0.3625\n",
      "Epoch 82/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.6852 - acc: 0.3870 - val_loss: 1.7494 - val_acc: 0.3667\n",
      "Epoch 83/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.6930 - acc: 0.3855 - val_loss: 1.7597 - val_acc: 0.3625\n",
      "Epoch 84/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.6926 - acc: 0.3833 - val_loss: 1.7532 - val_acc: 0.3558\n",
      "Epoch 85/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.6799 - acc: 0.3861 - val_loss: 1.7474 - val_acc: 0.3575\n",
      "Epoch 86/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.6866 - acc: 0.3828 - val_loss: 1.7592 - val_acc: 0.3579\n",
      "Epoch 87/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.6778 - acc: 0.3892 - val_loss: 1.7405 - val_acc: 0.3687\n",
      "Epoch 88/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.6776 - acc: 0.3839 - val_loss: 1.7453 - val_acc: 0.3633\n",
      "Epoch 89/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.6850 - acc: 0.3851 - val_loss: 1.7438 - val_acc: 0.3663\n",
      "Epoch 90/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.6744 - acc: 0.3898 - val_loss: 1.7480 - val_acc: 0.3638\n",
      "Epoch 91/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.6646 - acc: 0.3926 - val_loss: 1.7429 - val_acc: 0.3613\n",
      "Epoch 92/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.6811 - acc: 0.3892 - val_loss: 1.7378 - val_acc: 0.3671\n",
      "Epoch 93/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.6731 - acc: 0.3922 - val_loss: 1.7774 - val_acc: 0.3483\n",
      "Epoch 94/50000\n",
      "9600/9600 [==============================] - 1s 55us/step - loss: 1.6783 - acc: 0.3853 - val_loss: 1.7369 - val_acc: 0.3667\n",
      "Epoch 95/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.6706 - acc: 0.3878 - val_loss: 1.7540 - val_acc: 0.3633\n",
      "Epoch 96/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.6555 - acc: 0.3964 - val_loss: 1.7340 - val_acc: 0.3683\n",
      "Epoch 97/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.6666 - acc: 0.3922 - val_loss: 1.7350 - val_acc: 0.3692\n",
      "Epoch 98/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.6609 - acc: 0.3941 - val_loss: 1.7485 - val_acc: 0.3683\n",
      "Epoch 99/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.6619 - acc: 0.3960 - val_loss: 1.7253 - val_acc: 0.3617\n",
      "Epoch 100/50000\n",
      "9600/9600 [==============================] - 0s 52us/step - loss: 1.6583 - acc: 0.3927 - val_loss: 1.7303 - val_acc: 0.3746\n",
      "Epoch 101/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.6504 - acc: 0.3985 - val_loss: 1.7266 - val_acc: 0.3758\n",
      "Epoch 102/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.6571 - acc: 0.3964 - val_loss: 1.7293 - val_acc: 0.3708\n",
      "Epoch 103/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.6452 - acc: 0.3986 - val_loss: 1.7481 - val_acc: 0.3617\n",
      "Epoch 104/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.6529 - acc: 0.3941 - val_loss: 1.7253 - val_acc: 0.3721\n",
      "Epoch 105/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.6562 - acc: 0.3980 - val_loss: 1.7255 - val_acc: 0.3742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.6508 - acc: 0.4026 - val_loss: 1.7373 - val_acc: 0.3596\n",
      "Epoch 107/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.6443 - acc: 0.4000 - val_loss: 1.7258 - val_acc: 0.3721\n",
      "Epoch 108/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.6510 - acc: 0.3980 - val_loss: 1.7278 - val_acc: 0.3787\n",
      "Epoch 109/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.6491 - acc: 0.3943 - val_loss: 1.7387 - val_acc: 0.3708\n",
      "Epoch 110/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.6474 - acc: 0.3997 - val_loss: 1.7260 - val_acc: 0.3746\n",
      "Epoch 111/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.6382 - acc: 0.4002 - val_loss: 1.7346 - val_acc: 0.3713\n",
      "Epoch 112/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.6339 - acc: 0.4034 - val_loss: 1.7258 - val_acc: 0.3733\n",
      "Epoch 113/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.6352 - acc: 0.4016 - val_loss: 1.7304 - val_acc: 0.3808\n",
      "Epoch 114/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.6336 - acc: 0.4026 - val_loss: 1.7376 - val_acc: 0.3738\n",
      "Epoch 115/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.6286 - acc: 0.4113 - val_loss: 1.7753 - val_acc: 0.3613\n",
      "Epoch 116/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.6263 - acc: 0.4068 - val_loss: 1.7164 - val_acc: 0.3800\n",
      "Epoch 117/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.6237 - acc: 0.4119 - val_loss: 1.7317 - val_acc: 0.3662\n",
      "Epoch 118/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.6285 - acc: 0.4031 - val_loss: 1.7157 - val_acc: 0.3783\n",
      "Epoch 119/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.6140 - acc: 0.4108 - val_loss: 1.7361 - val_acc: 0.3708\n",
      "Epoch 120/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.6224 - acc: 0.4062 - val_loss: 1.7290 - val_acc: 0.3821\n",
      "Epoch 121/50000\n",
      "9600/9600 [==============================] - 1s 54us/step - loss: 1.6200 - acc: 0.4085 - val_loss: 1.7219 - val_acc: 0.3817\n",
      "Epoch 122/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.6188 - acc: 0.4119 - val_loss: 1.7344 - val_acc: 0.3654\n",
      "Epoch 123/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.6289 - acc: 0.4066 - val_loss: 1.7418 - val_acc: 0.3671\n",
      "Epoch 124/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.6224 - acc: 0.4126 - val_loss: 1.7456 - val_acc: 0.3696\n",
      "Epoch 125/50000\n",
      "9600/9600 [==============================] - 1s 56us/step - loss: 1.6025 - acc: 0.4186 - val_loss: 1.7303 - val_acc: 0.3696\n",
      "Epoch 126/50000\n",
      "9600/9600 [==============================] - 1s 55us/step - loss: 1.6100 - acc: 0.4125 - val_loss: 1.7510 - val_acc: 0.3604\n",
      "Epoch 127/50000\n",
      "9600/9600 [==============================] - 0s 52us/step - loss: 1.6073 - acc: 0.4149 - val_loss: 1.7130 - val_acc: 0.3813\n",
      "Epoch 128/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.6053 - acc: 0.4178 - val_loss: 1.7423 - val_acc: 0.3721\n",
      "Epoch 129/50000\n",
      "9600/9600 [==============================] - 1s 57us/step - loss: 1.6021 - acc: 0.4117 - val_loss: 1.7303 - val_acc: 0.3738\n",
      "Epoch 130/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.6041 - acc: 0.4166 - val_loss: 1.7450 - val_acc: 0.3646\n",
      "Epoch 131/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.6028 - acc: 0.4109 - val_loss: 1.7153 - val_acc: 0.3808\n",
      "Epoch 132/50000\n",
      "9600/9600 [==============================] - 1s 52us/step - loss: 1.5977 - acc: 0.4177 - val_loss: 1.7336 - val_acc: 0.3675\n",
      "Epoch 133/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.6064 - acc: 0.4126 - val_loss: 1.7207 - val_acc: 0.3679\n",
      "Epoch 134/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.5996 - acc: 0.4188 - val_loss: 1.7159 - val_acc: 0.3792\n",
      "Epoch 135/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.5952 - acc: 0.4213 - val_loss: 1.7383 - val_acc: 0.3688\n",
      "Epoch 136/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.5920 - acc: 0.4196 - val_loss: 1.7130 - val_acc: 0.3829\n",
      "Epoch 137/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.5904 - acc: 0.4215 - val_loss: 1.7242 - val_acc: 0.3758\n",
      "Epoch 138/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.5894 - acc: 0.4226 - val_loss: 1.7143 - val_acc: 0.3804\n",
      "Epoch 139/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.5897 - acc: 0.4213 - val_loss: 1.7083 - val_acc: 0.3792\n",
      "Epoch 140/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.5836 - acc: 0.4292 - val_loss: 1.7150 - val_acc: 0.3796\n",
      "Epoch 141/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.5864 - acc: 0.4248 - val_loss: 1.7096 - val_acc: 0.3812\n",
      "Epoch 142/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.5843 - acc: 0.4294 - val_loss: 1.7330 - val_acc: 0.3842\n",
      "Epoch 143/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.5701 - acc: 0.4281 - val_loss: 1.7136 - val_acc: 0.3854\n",
      "Epoch 144/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.5840 - acc: 0.4320 - val_loss: 1.7201 - val_acc: 0.3771\n",
      "Epoch 145/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.5843 - acc: 0.4217 - val_loss: 1.7184 - val_acc: 0.3854\n",
      "Epoch 146/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.5690 - acc: 0.4283 - val_loss: 1.7020 - val_acc: 0.3871\n",
      "Epoch 147/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.5637 - acc: 0.4368 - val_loss: 1.6942 - val_acc: 0.3937\n",
      "Epoch 148/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.5695 - acc: 0.4348 - val_loss: 1.7106 - val_acc: 0.3871\n",
      "Epoch 149/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.5768 - acc: 0.4256 - val_loss: 1.7032 - val_acc: 0.3896\n",
      "Epoch 150/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.5720 - acc: 0.4336 - val_loss: 1.7109 - val_acc: 0.3854\n",
      "Epoch 151/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5590 - acc: 0.4390 - val_loss: 1.7081 - val_acc: 0.3854\n",
      "Epoch 152/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5731 - acc: 0.4290 - val_loss: 1.7131 - val_acc: 0.3904\n",
      "Epoch 153/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5640 - acc: 0.4302 - val_loss: 1.7059 - val_acc: 0.3862\n",
      "Epoch 154/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5681 - acc: 0.4320 - val_loss: 1.7307 - val_acc: 0.3729\n",
      "Epoch 155/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5620 - acc: 0.4330 - val_loss: 1.6980 - val_acc: 0.3883\n",
      "Epoch 156/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.5623 - acc: 0.4309 - val_loss: 1.7186 - val_acc: 0.3775\n",
      "Epoch 157/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.5624 - acc: 0.4341 - val_loss: 1.6987 - val_acc: 0.3863\n",
      "Epoch 158/50000\n",
      "9600/9600 [==============================] - 1s 62us/step - loss: 1.5498 - acc: 0.4355 - val_loss: 1.7445 - val_acc: 0.3729\n",
      "Epoch 159/50000\n",
      "9600/9600 [==============================] - 1s 57us/step - loss: 1.5614 - acc: 0.4294 - val_loss: 1.6822 - val_acc: 0.3846\n",
      "Epoch 160/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.5556 - acc: 0.4402 - val_loss: 1.7019 - val_acc: 0.3913\n",
      "Epoch 161/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.5502 - acc: 0.4370 - val_loss: 1.6966 - val_acc: 0.3875\n",
      "Epoch 162/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5463 - acc: 0.4438 - val_loss: 1.7106 - val_acc: 0.3833\n",
      "Epoch 163/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.5442 - acc: 0.4432 - val_loss: 1.7061 - val_acc: 0.3833\n",
      "Epoch 164/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.5385 - acc: 0.4450 - val_loss: 1.7170 - val_acc: 0.3879\n",
      "Epoch 165/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.5452 - acc: 0.4349 - val_loss: 1.6883 - val_acc: 0.3962\n",
      "Epoch 166/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5420 - acc: 0.4414 - val_loss: 1.6953 - val_acc: 0.3963\n",
      "Epoch 167/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.5274 - acc: 0.4445 - val_loss: 1.7079 - val_acc: 0.3900\n",
      "Epoch 168/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.5371 - acc: 0.4429 - val_loss: 1.6921 - val_acc: 0.3942\n",
      "Epoch 169/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.5369 - acc: 0.4435 - val_loss: 1.7020 - val_acc: 0.3983\n",
      "Epoch 170/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5369 - acc: 0.4446 - val_loss: 1.7154 - val_acc: 0.3921\n",
      "Epoch 171/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5389 - acc: 0.4462 - val_loss: 1.6946 - val_acc: 0.3992\n",
      "Epoch 172/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5281 - acc: 0.4478 - val_loss: 1.7003 - val_acc: 0.3900\n",
      "Epoch 173/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.5263 - acc: 0.4500 - val_loss: 1.6833 - val_acc: 0.3987\n",
      "Epoch 174/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.5224 - acc: 0.4465 - val_loss: 1.6913 - val_acc: 0.3950\n",
      "Epoch 175/50000\n",
      "9600/9600 [==============================] - 1s 65us/step - loss: 1.5047 - acc: 0.4562 - val_loss: 1.7033 - val_acc: 0.3979\n",
      "Epoch 176/50000\n",
      "9600/9600 [==============================] - 1s 65us/step - loss: 1.5222 - acc: 0.4456 - val_loss: 1.6822 - val_acc: 0.4017\n",
      "Epoch 177/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.5280 - acc: 0.4440 - val_loss: 1.6840 - val_acc: 0.3958\n",
      "Epoch 178/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5177 - acc: 0.4542 - val_loss: 1.7050 - val_acc: 0.3921\n",
      "Epoch 179/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5194 - acc: 0.4461 - val_loss: 1.6988 - val_acc: 0.3917\n",
      "Epoch 180/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5162 - acc: 0.4499 - val_loss: 1.7090 - val_acc: 0.3854\n",
      "Epoch 181/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5147 - acc: 0.4484 - val_loss: 1.7331 - val_acc: 0.3829\n",
      "Epoch 182/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.5235 - acc: 0.4464 - val_loss: 1.6845 - val_acc: 0.3917\n",
      "Epoch 183/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.5006 - acc: 0.4597 - val_loss: 1.6837 - val_acc: 0.3967\n",
      "Epoch 184/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.5085 - acc: 0.4545 - val_loss: 1.6787 - val_acc: 0.3987\n",
      "Epoch 185/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.5048 - acc: 0.4611 - val_loss: 1.7067 - val_acc: 0.3854\n",
      "Epoch 186/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.5038 - acc: 0.4546 - val_loss: 1.6985 - val_acc: 0.3962\n",
      "Epoch 187/50000\n",
      "9600/9600 [==============================] - 1s 55us/step - loss: 1.5050 - acc: 0.4546 - val_loss: 1.7749 - val_acc: 0.3837\n",
      "Epoch 188/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.5025 - acc: 0.4565 - val_loss: 1.7032 - val_acc: 0.3937\n",
      "Epoch 189/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.5061 - acc: 0.4632 - val_loss: 1.7170 - val_acc: 0.3925\n",
      "Epoch 190/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.4999 - acc: 0.4570 - val_loss: 1.7001 - val_acc: 0.3946\n",
      "Epoch 191/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.4927 - acc: 0.4575 - val_loss: 1.7125 - val_acc: 0.3958\n",
      "Epoch 192/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.4869 - acc: 0.4680 - val_loss: 1.6937 - val_acc: 0.3946\n",
      "Epoch 193/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.4826 - acc: 0.4672 - val_loss: 1.6966 - val_acc: 0.3992\n",
      "Epoch 194/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.4812 - acc: 0.4665 - val_loss: 1.6773 - val_acc: 0.4046\n",
      "Epoch 195/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.4771 - acc: 0.4619 - val_loss: 1.6893 - val_acc: 0.4037\n",
      "Epoch 196/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.4899 - acc: 0.4618 - val_loss: 1.7131 - val_acc: 0.3975\n",
      "Epoch 197/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.4778 - acc: 0.4678 - val_loss: 1.6860 - val_acc: 0.3971\n",
      "Epoch 198/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.4765 - acc: 0.4689 - val_loss: 1.6988 - val_acc: 0.3962\n",
      "Epoch 199/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.4734 - acc: 0.4701 - val_loss: 1.6926 - val_acc: 0.3992\n",
      "Epoch 200/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.4717 - acc: 0.4669 - val_loss: 1.6888 - val_acc: 0.3975\n",
      "Epoch 201/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.4670 - acc: 0.4748 - val_loss: 1.7049 - val_acc: 0.3921\n",
      "Epoch 202/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.4727 - acc: 0.4692 - val_loss: 1.6945 - val_acc: 0.4050\n",
      "Epoch 203/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.4700 - acc: 0.4667 - val_loss: 1.7090 - val_acc: 0.3971\n",
      "Epoch 204/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.4565 - acc: 0.4755 - val_loss: 1.6780 - val_acc: 0.4021\n",
      "Epoch 205/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.4733 - acc: 0.4630 - val_loss: 1.7081 - val_acc: 0.3887\n",
      "Epoch 206/50000\n",
      "9600/9600 [==============================] - 1s 59us/step - loss: 1.4790 - acc: 0.4632 - val_loss: 1.7019 - val_acc: 0.4008\n",
      "Epoch 207/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.4738 - acc: 0.4648 - val_loss: 1.6697 - val_acc: 0.4083\n",
      "Epoch 208/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4574 - acc: 0.4770 - val_loss: 1.6875 - val_acc: 0.4075\n",
      "Epoch 209/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4562 - acc: 0.4719 - val_loss: 1.7132 - val_acc: 0.3913\n",
      "Epoch 210/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4576 - acc: 0.4774 - val_loss: 1.6779 - val_acc: 0.3983\n",
      "Epoch 211/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4485 - acc: 0.4770 - val_loss: 1.6981 - val_acc: 0.4046\n",
      "Epoch 212/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4623 - acc: 0.4728 - val_loss: 1.6846 - val_acc: 0.4025\n",
      "Epoch 213/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.4510 - acc: 0.4774 - val_loss: 1.6829 - val_acc: 0.4050\n",
      "Epoch 214/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4514 - acc: 0.4719 - val_loss: 1.7356 - val_acc: 0.3971\n",
      "Epoch 215/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4502 - acc: 0.4717 - val_loss: 1.6748 - val_acc: 0.4029\n",
      "Epoch 216/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.4501 - acc: 0.4781 - val_loss: 1.6956 - val_acc: 0.4012\n",
      "Epoch 217/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.4444 - acc: 0.4811 - val_loss: 1.6909 - val_acc: 0.3979\n",
      "Epoch 218/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4349 - acc: 0.4824 - val_loss: 1.7028 - val_acc: 0.4025\n",
      "Epoch 219/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.4331 - acc: 0.4852 - val_loss: 1.7003 - val_acc: 0.3862\n",
      "Epoch 220/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.4487 - acc: 0.4781 - val_loss: 1.7140 - val_acc: 0.4046\n",
      "Epoch 221/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.4286 - acc: 0.4849 - val_loss: 1.6946 - val_acc: 0.4025\n",
      "Epoch 222/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.4371 - acc: 0.4858 - val_loss: 1.6857 - val_acc: 0.4029\n",
      "Epoch 223/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.4336 - acc: 0.4866 - val_loss: 1.6782 - val_acc: 0.4079\n",
      "Epoch 224/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.4147 - acc: 0.4918 - val_loss: 1.6953 - val_acc: 0.3954\n",
      "Epoch 225/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.4200 - acc: 0.4855 - val_loss: 1.6964 - val_acc: 0.4042\n",
      "Epoch 226/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.4221 - acc: 0.4916 - val_loss: 1.7028 - val_acc: 0.4083\n",
      "Epoch 227/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.4174 - acc: 0.4945 - val_loss: 1.6656 - val_acc: 0.4129\n",
      "Epoch 228/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.4322 - acc: 0.4820 - val_loss: 1.6668 - val_acc: 0.4150\n",
      "Epoch 229/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.4231 - acc: 0.4864 - val_loss: 1.6790 - val_acc: 0.4183\n",
      "Epoch 230/50000\n",
      "9600/9600 [==============================] - 0s 52us/step - loss: 1.4216 - acc: 0.4860 - val_loss: 1.6840 - val_acc: 0.4054\n",
      "Epoch 231/50000\n",
      "9600/9600 [==============================] - 1s 55us/step - loss: 1.4126 - acc: 0.4894 - val_loss: 1.6802 - val_acc: 0.4092\n",
      "Epoch 232/50000\n",
      "9600/9600 [==============================] - 1s 57us/step - loss: 1.4104 - acc: 0.4952 - val_loss: 1.7405 - val_acc: 0.3917\n",
      "Epoch 233/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.4315 - acc: 0.4886 - val_loss: 1.6835 - val_acc: 0.3983\n",
      "Epoch 234/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.4107 - acc: 0.4906 - val_loss: 1.6800 - val_acc: 0.4050\n",
      "Epoch 235/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.4162 - acc: 0.4881 - val_loss: 1.6698 - val_acc: 0.4183\n",
      "Epoch 236/50000\n",
      "9600/9600 [==============================] - 1s 58us/step - loss: 1.3946 - acc: 0.4974 - val_loss: 1.6839 - val_acc: 0.4088\n",
      "Epoch 237/50000\n",
      "9600/9600 [==============================] - 1s 61us/step - loss: 1.4002 - acc: 0.4968 - val_loss: 1.6866 - val_acc: 0.4137\n",
      "Epoch 238/50000\n",
      "9600/9600 [==============================] - 1s 55us/step - loss: 1.3922 - acc: 0.4916 - val_loss: 1.6999 - val_acc: 0.3946\n",
      "Epoch 239/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.3987 - acc: 0.4927 - val_loss: 1.6684 - val_acc: 0.4196\n",
      "Epoch 240/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.3936 - acc: 0.5046 - val_loss: 1.6712 - val_acc: 0.4175\n",
      "Epoch 241/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.4050 - acc: 0.4937 - val_loss: 1.6960 - val_acc: 0.4104\n",
      "Epoch 242/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.3952 - acc: 0.4958 - val_loss: 1.6867 - val_acc: 0.4138\n",
      "Epoch 243/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.3869 - acc: 0.4981 - val_loss: 1.6864 - val_acc: 0.4083\n",
      "Epoch 244/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.3807 - acc: 0.5061 - val_loss: 1.6829 - val_acc: 0.4167\n",
      "Epoch 245/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.3919 - acc: 0.4968 - val_loss: 1.6782 - val_acc: 0.4113\n",
      "Epoch 246/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.3794 - acc: 0.5039 - val_loss: 1.6921 - val_acc: 0.4079\n",
      "Epoch 247/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.3818 - acc: 0.5056 - val_loss: 1.6769 - val_acc: 0.4175\n",
      "Epoch 248/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.3970 - acc: 0.4977 - val_loss: 1.6844 - val_acc: 0.4196\n",
      "Epoch 249/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.3852 - acc: 0.5062 - val_loss: 1.6739 - val_acc: 0.4200\n",
      "Epoch 250/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3670 - acc: 0.5139 - val_loss: 1.6720 - val_acc: 0.4187\n",
      "Epoch 251/50000\n",
      "9600/9600 [==============================] - 0s 52us/step - loss: 1.3717 - acc: 0.5058 - val_loss: 1.6844 - val_acc: 0.4108\n",
      "Epoch 252/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.3714 - acc: 0.5095 - val_loss: 1.7096 - val_acc: 0.4071\n",
      "Epoch 253/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3733 - acc: 0.5005 - val_loss: 1.7058 - val_acc: 0.4129\n",
      "Epoch 254/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3763 - acc: 0.5068 - val_loss: 1.6792 - val_acc: 0.4138\n",
      "Epoch 255/50000\n",
      "9600/9600 [==============================] - 1s 52us/step - loss: 1.3621 - acc: 0.5091 - val_loss: 1.6713 - val_acc: 0.4125\n",
      "Epoch 256/50000\n",
      "9600/9600 [==============================] - 1s 58us/step - loss: 1.3531 - acc: 0.5132 - val_loss: 1.6620 - val_acc: 0.4246\n",
      "Epoch 257/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.3671 - acc: 0.5122 - val_loss: 1.6534 - val_acc: 0.4300\n",
      "Epoch 258/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.3645 - acc: 0.5074 - val_loss: 1.6672 - val_acc: 0.4200\n",
      "Epoch 259/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.3588 - acc: 0.5125 - val_loss: 1.6746 - val_acc: 0.4108\n",
      "Epoch 260/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.3450 - acc: 0.5177 - val_loss: 1.6674 - val_acc: 0.4192\n",
      "Epoch 261/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.3631 - acc: 0.5126 - val_loss: 1.6911 - val_acc: 0.4142\n",
      "Epoch 262/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3590 - acc: 0.5121 - val_loss: 1.6831 - val_acc: 0.4246\n",
      "Epoch 263/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.3430 - acc: 0.5151 - val_loss: 1.6578 - val_acc: 0.4171\n",
      "Epoch 264/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3372 - acc: 0.5218 - val_loss: 1.7099 - val_acc: 0.4083\n",
      "Epoch 265/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3427 - acc: 0.5222 - val_loss: 1.6941 - val_acc: 0.4213\n",
      "Epoch 266/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3430 - acc: 0.5236 - val_loss: 1.6938 - val_acc: 0.4267\n",
      "Epoch 267/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.3466 - acc: 0.5157 - val_loss: 1.6712 - val_acc: 0.4221\n",
      "Epoch 268/50000\n",
      "9600/9600 [==============================] - 1s 62us/step - loss: 1.3392 - acc: 0.5231 - val_loss: 1.7272 - val_acc: 0.4154\n",
      "Epoch 269/50000\n",
      "9600/9600 [==============================] - 1s 57us/step - loss: 1.3272 - acc: 0.5192 - val_loss: 1.6747 - val_acc: 0.4125\n",
      "Epoch 270/50000\n",
      "9600/9600 [==============================] - 1s 58us/step - loss: 1.3370 - acc: 0.5203 - val_loss: 1.6921 - val_acc: 0.4242\n",
      "Epoch 271/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.3250 - acc: 0.5256 - val_loss: 1.6713 - val_acc: 0.4300\n",
      "Epoch 272/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3266 - acc: 0.5234 - val_loss: 1.6749 - val_acc: 0.4279\n",
      "Epoch 273/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3411 - acc: 0.5264 - val_loss: 1.6916 - val_acc: 0.4217\n",
      "Epoch 274/50000\n",
      "9600/9600 [==============================] - 1s 54us/step - loss: 1.3435 - acc: 0.5181 - val_loss: 1.6954 - val_acc: 0.4163\n",
      "Epoch 275/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.3264 - acc: 0.5166 - val_loss: 1.6751 - val_acc: 0.4275\n",
      "Epoch 276/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.3200 - acc: 0.5228 - val_loss: 1.6770 - val_acc: 0.4225\n",
      "Epoch 277/50000\n",
      "9600/9600 [==============================] - 0s 52us/step - loss: 1.3241 - acc: 0.5238 - val_loss: 1.6901 - val_acc: 0.4192\n",
      "Epoch 278/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.3333 - acc: 0.5195 - val_loss: 1.6824 - val_acc: 0.4250\n",
      "Epoch 279/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.3000 - acc: 0.5380 - val_loss: 1.6988 - val_acc: 0.4146\n",
      "Epoch 280/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.3165 - acc: 0.5249 - val_loss: 1.6534 - val_acc: 0.4275\n",
      "Epoch 281/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.3110 - acc: 0.5274 - val_loss: 1.6706 - val_acc: 0.4250\n",
      "Epoch 282/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3203 - acc: 0.5233 - val_loss: 1.6761 - val_acc: 0.4200\n",
      "Epoch 283/50000\n",
      "9600/9600 [==============================] - 1s 56us/step - loss: 1.3170 - acc: 0.5284 - val_loss: 1.6454 - val_acc: 0.4321\n",
      "Epoch 284/50000\n",
      "9600/9600 [==============================] - 1s 54us/step - loss: 1.2989 - acc: 0.5378 - val_loss: 1.6708 - val_acc: 0.4300\n",
      "Epoch 285/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.3162 - acc: 0.5290 - val_loss: 1.6528 - val_acc: 0.4321\n",
      "Epoch 286/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.2960 - acc: 0.5365 - val_loss: 1.6869 - val_acc: 0.4179\n",
      "Epoch 287/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.3105 - acc: 0.5284 - val_loss: 1.6780 - val_acc: 0.4233\n",
      "Epoch 288/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.2998 - acc: 0.5370 - val_loss: 1.6726 - val_acc: 0.4246\n",
      "Epoch 289/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.3008 - acc: 0.5299 - val_loss: 1.6702 - val_acc: 0.4258\n",
      "Epoch 290/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.2977 - acc: 0.5381 - val_loss: 1.6730 - val_acc: 0.4075\n",
      "Epoch 291/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.2856 - acc: 0.5383 - val_loss: 1.7057 - val_acc: 0.4179\n",
      "Epoch 292/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.2960 - acc: 0.5363 - val_loss: 1.6452 - val_acc: 0.4258\n",
      "Epoch 293/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.2948 - acc: 0.5384 - val_loss: 1.6685 - val_acc: 0.4313\n",
      "Epoch 294/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.3041 - acc: 0.5372 - val_loss: 1.6531 - val_acc: 0.4271\n",
      "Epoch 295/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.2817 - acc: 0.5406 - val_loss: 1.6782 - val_acc: 0.4279\n",
      "Epoch 296/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.2732 - acc: 0.5414 - val_loss: 1.6784 - val_acc: 0.4304\n",
      "Epoch 297/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.2896 - acc: 0.5417 - val_loss: 1.6707 - val_acc: 0.4342\n",
      "Epoch 298/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.2974 - acc: 0.5346 - val_loss: 1.6702 - val_acc: 0.4229\n",
      "Epoch 299/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.2768 - acc: 0.5442 - val_loss: 1.6444 - val_acc: 0.4379\n",
      "Epoch 300/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.2769 - acc: 0.5435 - val_loss: 1.6903 - val_acc: 0.4287\n",
      "Epoch 301/50000\n",
      "9600/9600 [==============================] - 0s 52us/step - loss: 1.2815 - acc: 0.5444 - val_loss: 1.7320 - val_acc: 0.4154\n",
      "Epoch 302/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.2737 - acc: 0.5380 - val_loss: 1.6847 - val_acc: 0.4254\n",
      "Epoch 303/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.2550 - acc: 0.5532 - val_loss: 1.6834 - val_acc: 0.4333\n",
      "Epoch 304/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.2721 - acc: 0.5395 - val_loss: 1.6817 - val_acc: 0.4229\n",
      "Epoch 305/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.2808 - acc: 0.5376 - val_loss: 1.6829 - val_acc: 0.4246\n",
      "Epoch 306/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.2702 - acc: 0.5479 - val_loss: 1.6584 - val_acc: 0.4408\n",
      "Epoch 307/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.2661 - acc: 0.5429 - val_loss: 1.6686 - val_acc: 0.4321\n",
      "Epoch 308/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.2668 - acc: 0.5523 - val_loss: 1.6828 - val_acc: 0.4312\n",
      "Epoch 309/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2569 - acc: 0.5483 - val_loss: 1.6628 - val_acc: 0.4342\n",
      "Epoch 310/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.2704 - acc: 0.5460 - val_loss: 1.6846 - val_acc: 0.4292\n",
      "Epoch 311/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2459 - acc: 0.5525 - val_loss: 1.6629 - val_acc: 0.4308\n",
      "Epoch 312/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2332 - acc: 0.5641 - val_loss: 1.7137 - val_acc: 0.4263\n",
      "Epoch 313/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2489 - acc: 0.5590 - val_loss: 1.6881 - val_acc: 0.4292\n",
      "Epoch 314/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2503 - acc: 0.5510 - val_loss: 1.6745 - val_acc: 0.4300\n",
      "Epoch 315/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.2462 - acc: 0.5519 - val_loss: 1.6697 - val_acc: 0.4283\n",
      "Epoch 316/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2532 - acc: 0.5503 - val_loss: 1.6918 - val_acc: 0.4400\n",
      "Epoch 317/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2526 - acc: 0.5513 - val_loss: 1.6628 - val_acc: 0.4392\n",
      "Epoch 318/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2272 - acc: 0.5613 - val_loss: 1.7032 - val_acc: 0.4196\n",
      "Epoch 319/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2393 - acc: 0.5560 - val_loss: 1.6926 - val_acc: 0.4329\n",
      "Epoch 320/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2276 - acc: 0.5611 - val_loss: 1.6615 - val_acc: 0.4408\n",
      "Epoch 321/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2413 - acc: 0.5546 - val_loss: 1.7115 - val_acc: 0.4358\n",
      "Epoch 322/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2285 - acc: 0.5593 - val_loss: 1.6955 - val_acc: 0.4475\n",
      "Epoch 323/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2483 - acc: 0.5510 - val_loss: 1.6684 - val_acc: 0.4392\n",
      "Epoch 324/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2473 - acc: 0.5513 - val_loss: 1.6852 - val_acc: 0.4333\n",
      "Epoch 325/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2350 - acc: 0.5617 - val_loss: 1.6830 - val_acc: 0.4333\n",
      "Epoch 326/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2195 - acc: 0.5620 - val_loss: 1.6722 - val_acc: 0.4317\n",
      "Epoch 327/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2147 - acc: 0.5614 - val_loss: 1.6777 - val_acc: 0.4417\n",
      "Epoch 328/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2282 - acc: 0.5649 - val_loss: 1.6467 - val_acc: 0.4362\n",
      "Epoch 329/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2464 - acc: 0.5528 - val_loss: 1.7002 - val_acc: 0.4346\n",
      "Epoch 330/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2440 - acc: 0.5563 - val_loss: 1.6722 - val_acc: 0.4358\n",
      "Epoch 331/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2277 - acc: 0.5611 - val_loss: 1.6837 - val_acc: 0.4321\n",
      "Epoch 332/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2194 - acc: 0.5630 - val_loss: 1.6818 - val_acc: 0.4400\n",
      "Epoch 333/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2171 - acc: 0.5693 - val_loss: 1.6992 - val_acc: 0.4267\n",
      "Epoch 334/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2034 - acc: 0.5696 - val_loss: 1.7054 - val_acc: 0.4204\n",
      "Epoch 335/50000\n",
      "9600/9600 [==============================] - 0s 52us/step - loss: 1.2208 - acc: 0.5655 - val_loss: 1.6797 - val_acc: 0.4333\n",
      "Epoch 336/50000\n",
      "9600/9600 [==============================] - 1s 52us/step - loss: 1.1988 - acc: 0.5725 - val_loss: 1.6994 - val_acc: 0.4350\n",
      "Epoch 337/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2114 - acc: 0.5655 - val_loss: 1.6617 - val_acc: 0.4450\n",
      "Epoch 338/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.2183 - acc: 0.5651 - val_loss: 1.6791 - val_acc: 0.4463\n",
      "Epoch 339/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.1954 - acc: 0.5683 - val_loss: 1.7114 - val_acc: 0.4383\n",
      "Epoch 340/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2051 - acc: 0.5748 - val_loss: 1.6690 - val_acc: 0.4408\n",
      "Epoch 341/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.2108 - acc: 0.5655 - val_loss: 1.6897 - val_acc: 0.4317\n",
      "Epoch 342/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.1897 - acc: 0.5710 - val_loss: 1.7133 - val_acc: 0.4233\n",
      "Epoch 343/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.2004 - acc: 0.5675 - val_loss: 1.7034 - val_acc: 0.4325\n",
      "Epoch 344/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.2074 - acc: 0.5695 - val_loss: 1.6859 - val_acc: 0.4379\n",
      "Epoch 345/50000\n",
      "9600/9600 [==============================] - 0s 42us/step - loss: 1.2016 - acc: 0.5721 - val_loss: 1.6872 - val_acc: 0.4358\n",
      "Epoch 346/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.2013 - acc: 0.5695 - val_loss: 1.7151 - val_acc: 0.4325\n",
      "Epoch 347/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.1932 - acc: 0.5734 - val_loss: 1.6982 - val_acc: 0.4375\n",
      "Epoch 348/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.1839 - acc: 0.5781 - val_loss: 1.7001 - val_acc: 0.4313\n",
      "Epoch 349/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.1893 - acc: 0.5748 - val_loss: 1.6821 - val_acc: 0.4412\n",
      "Epoch 350/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.1812 - acc: 0.5749 - val_loss: 1.7403 - val_acc: 0.4254\n",
      "Epoch 351/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.2054 - acc: 0.5666 - val_loss: 1.6899 - val_acc: 0.4288\n",
      "Epoch 352/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.2018 - acc: 0.5751 - val_loss: 1.7194 - val_acc: 0.4383\n",
      "Epoch 353/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.1884 - acc: 0.5735 - val_loss: 1.7114 - val_acc: 0.4337\n",
      "Epoch 354/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.1803 - acc: 0.5741 - val_loss: 1.6852 - val_acc: 0.4404\n",
      "Epoch 355/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.1741 - acc: 0.5825 - val_loss: 1.6640 - val_acc: 0.4521\n",
      "Epoch 356/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.1736 - acc: 0.5794 - val_loss: 1.7160 - val_acc: 0.4279\n",
      "Epoch 357/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.1979 - acc: 0.5678 - val_loss: 1.6898 - val_acc: 0.4354\n",
      "Epoch 358/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.1911 - acc: 0.5775 - val_loss: 1.7107 - val_acc: 0.4358\n",
      "Epoch 359/50000\n",
      "9600/9600 [==============================] - 1s 54us/step - loss: 1.1769 - acc: 0.5766 - val_loss: 1.6844 - val_acc: 0.4433\n",
      "Epoch 360/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.1638 - acc: 0.5827 - val_loss: 1.6834 - val_acc: 0.4337\n",
      "Epoch 361/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.1942 - acc: 0.5697 - val_loss: 1.6715 - val_acc: 0.4379\n",
      "Epoch 362/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.1796 - acc: 0.5839 - val_loss: 1.6662 - val_acc: 0.4437\n",
      "Epoch 363/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.1794 - acc: 0.5782 - val_loss: 1.6875 - val_acc: 0.4354\n",
      "Epoch 364/50000\n",
      "9600/9600 [==============================] - 0s 43us/step - loss: 1.1782 - acc: 0.5728 - val_loss: 1.7196 - val_acc: 0.4425\n",
      "Epoch 365/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.1438 - acc: 0.5904 - val_loss: 1.7026 - val_acc: 0.4350\n",
      "Epoch 366/50000\n",
      "9600/9600 [==============================] - 0s 44us/step - loss: 1.1566 - acc: 0.5825 - val_loss: 1.7296 - val_acc: 0.4329\n",
      "Epoch 367/50000\n",
      "9600/9600 [==============================] - 1s 54us/step - loss: 1.1742 - acc: 0.5807 - val_loss: 1.6857 - val_acc: 0.4421\n",
      "Epoch 368/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.1696 - acc: 0.5931 - val_loss: 1.7307 - val_acc: 0.4400\n",
      "Epoch 369/50000\n",
      "9600/9600 [==============================] - 1s 53us/step - loss: 1.1852 - acc: 0.5794 - val_loss: 1.6946 - val_acc: 0.4338\n",
      "Epoch 370/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.1638 - acc: 0.5876 - val_loss: 1.7358 - val_acc: 0.4338\n",
      "Epoch 371/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.1560 - acc: 0.5887 - val_loss: 1.6962 - val_acc: 0.4437\n",
      "Epoch 372/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.1561 - acc: 0.5868 - val_loss: 1.6958 - val_acc: 0.4446\n",
      "Epoch 373/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.1499 - acc: 0.5917 - val_loss: 1.6852 - val_acc: 0.4467\n",
      "Epoch 374/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.1488 - acc: 0.5873 - val_loss: 1.7012 - val_acc: 0.4454\n",
      "Epoch 375/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.1461 - acc: 0.5938 - val_loss: 1.6707 - val_acc: 0.4521\n",
      "Epoch 376/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.1428 - acc: 0.5947 - val_loss: 1.6948 - val_acc: 0.4333\n",
      "Epoch 377/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.1500 - acc: 0.5908 - val_loss: 1.6767 - val_acc: 0.4450\n",
      "Epoch 378/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.1474 - acc: 0.5948 - val_loss: 1.6805 - val_acc: 0.4421\n",
      "Epoch 379/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.1578 - acc: 0.5826 - val_loss: 1.6969 - val_acc: 0.4433\n",
      "Epoch 380/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.1229 - acc: 0.6033 - val_loss: 1.6905 - val_acc: 0.4375\n",
      "Epoch 381/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.1332 - acc: 0.5986 - val_loss: 1.7398 - val_acc: 0.4421\n",
      "Epoch 382/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.1431 - acc: 0.5897 - val_loss: 1.7237 - val_acc: 0.4267\n",
      "Epoch 383/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.1374 - acc: 0.5989 - val_loss: 1.6974 - val_acc: 0.4313\n",
      "Epoch 384/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.1435 - acc: 0.5930 - val_loss: 1.6803 - val_acc: 0.4463\n",
      "Epoch 385/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.1443 - acc: 0.5919 - val_loss: 1.7020 - val_acc: 0.4387\n",
      "Epoch 386/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.1569 - acc: 0.5864 - val_loss: 1.7596 - val_acc: 0.4300\n",
      "Epoch 387/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.1151 - acc: 0.6008 - val_loss: 1.6795 - val_acc: 0.4463\n",
      "Epoch 388/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.1342 - acc: 0.5962 - val_loss: 1.6831 - val_acc: 0.4479\n",
      "Epoch 389/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.1141 - acc: 0.6055 - val_loss: 1.7105 - val_acc: 0.4446\n",
      "Epoch 390/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.1179 - acc: 0.6011 - val_loss: 1.6878 - val_acc: 0.4492\n",
      "Epoch 391/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.1038 - acc: 0.6019 - val_loss: 1.7264 - val_acc: 0.4379\n",
      "Epoch 392/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.1237 - acc: 0.6006 - val_loss: 1.7580 - val_acc: 0.4233\n",
      "Epoch 393/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.1318 - acc: 0.5962 - val_loss: 1.6972 - val_acc: 0.4475\n",
      "Epoch 394/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.1220 - acc: 0.6021 - val_loss: 1.7187 - val_acc: 0.4379\n",
      "Epoch 395/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.1136 - acc: 0.6034 - val_loss: 1.7018 - val_acc: 0.4487\n",
      "Epoch 396/50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.1231 - acc: 0.6005 - val_loss: 1.6780 - val_acc: 0.4412\n",
      "Epoch 397/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.1146 - acc: 0.6071 - val_loss: 1.7127 - val_acc: 0.4392\n",
      "Epoch 398/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.1144 - acc: 0.6023 - val_loss: 1.7234 - val_acc: 0.4417\n",
      "Epoch 399/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.1191 - acc: 0.5964 - val_loss: 1.7105 - val_acc: 0.4342\n",
      "Epoch 400/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.1172 - acc: 0.6001 - val_loss: 1.6994 - val_acc: 0.4367\n",
      "Epoch 401/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.1114 - acc: 0.6035 - val_loss: 1.7197 - val_acc: 0.4496\n",
      "Epoch 402/50000\n",
      "9600/9600 [==============================] - 0s 45us/step - loss: 1.1047 - acc: 0.6017 - val_loss: 1.7099 - val_acc: 0.4504\n",
      "Epoch 403/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.1146 - acc: 0.5967 - val_loss: 1.6675 - val_acc: 0.4542\n",
      "Epoch 404/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.1162 - acc: 0.6031 - val_loss: 1.7068 - val_acc: 0.4533\n",
      "Epoch 405/50000\n",
      "9600/9600 [==============================] - 0s 49us/step - loss: 1.1034 - acc: 0.6067 - val_loss: 1.7013 - val_acc: 0.4412\n",
      "Epoch 406/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.0934 - acc: 0.6146 - val_loss: 1.6897 - val_acc: 0.4475\n",
      "Epoch 407/50000\n",
      "9600/9600 [==============================] - 0s 50us/step - loss: 1.1053 - acc: 0.6053 - val_loss: 1.6925 - val_acc: 0.4504\n",
      "Epoch 408/50000\n",
      "9600/9600 [==============================] - 0s 48us/step - loss: 1.0950 - acc: 0.6098 - val_loss: 1.7064 - val_acc: 0.4538\n",
      "Epoch 409/50000\n",
      "9600/9600 [==============================] - 0s 47us/step - loss: 1.0962 - acc: 0.6053 - val_loss: 1.7595 - val_acc: 0.4325\n",
      "Epoch 410/50000\n",
      "9600/9600 [==============================] - 0s 46us/step - loss: 1.1093 - acc: 0.6036 - val_loss: 1.7611 - val_acc: 0.4367\n",
      "Epoch 411/50000\n",
      "9600/9600 [==============================] - 0s 51us/step - loss: 1.0998 - acc: 0.6047 - val_loss: 1.7280 - val_acc: 0.4533\n",
      "Epoch 412/50000\n",
      "6016/9600 [=================>............] - ETA: 0s - loss: 1.0872 - acc: 0.6084"
     ]
    }
   ],
   "source": [
    "logreg = Cromosome([])\n",
    "simplest = Cromosome([Layer(830, 'prelu', 0.654)])\n",
    "baseline = Cromosome([Layer(512, 'relu', 0.2), Layer(512, 'relu', 0.2)])\n",
    "best = Cromosome([Layer(830, 'prelu', 0.654), Layer(782, 'tanh', 0.166), Layer(28, 'elu', 0.062)])\n",
    "\n",
    "models = {'logreg':logreg, 'simplest':simplest, 'baseline':baseline, 'best':best}\n",
    "datasets = ['MB', 'MBI', 'MRB', 'MRD', 'MRDBI']\n",
    "results = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(\"-\"*10 + \"  DATASET %s  \" % dataset + \"-\"*10)\n",
    "    # Load data\n",
    "    dm = DataManager(dataset, clases=classes, folder_var_mnist=folder)\n",
    "    data = dm.load_data()\n",
    "    fitness = Fitness.get_instance()\n",
    "    fitness.set_params(data, verbose=verbose, reduce_plateau=redu_plat, \n",
    "                       epochs=epochs, early_stop=early_stop)\n",
    "    for tag, model in models.items():\n",
    "        if dataset != 'MRDBI' and tag!='logreg':\n",
    "            continue\n",
    "        print(\"\\n\\tTraining model:\")\n",
    "        print(tag)\n",
    "        print(model, end='\\n\\n')\n",
    "        score = model.fitness()\n",
    "        results[(model.__repr__(), dataset)] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
