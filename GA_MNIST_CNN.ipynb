{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from time import time\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import  Model\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, PReLU, LeakyReLU\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from time import time\n",
    "import time as T\n",
    "import traceback\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from GA.geneticAlgorithm import GenerationalGA\n",
    "from GA.parentSelector.parentSelector import RandomParentSelector, LinealOrder, TournamentSelection\n",
    "from GA.parentSelector.parentSelector import WheelSelection, LinealOrderII\n",
    "from utils.datamanager import DataManager\n",
    "#import tensorflow as tf\n",
    "\n",
    "class Layer(object):\n",
    "    def cross(self, other_layer):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def mutate(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def compare(self, other_layer):\n",
    "        raise self.__repr__() == other_layer.__repr__()\n",
    "\n",
    "    def self_copy(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def random_layer(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __repr__(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class NNLayer(Layer):\n",
    "    def __init__(self, units=128, activation='relu', dropout=0):\n",
    "        self.type = 'NN'\n",
    "        self.posible_activations = ['relu', 'sigmoid', 'tanh', 'elu', 'prelu', 'leakyreLu']\n",
    "        assert activation in self.posible_activations\n",
    "        \n",
    "        # parameters\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.units = units\n",
    "        \n",
    "        self.units_lim = 1024\n",
    "        self.units_prob = 0.2\n",
    "        self.act_prob = 0.2\n",
    "        self.drop_prob = 0.2\n",
    "\n",
    "    def cross(self, other_layer):\n",
    "        assert self.type == other_layer.type\n",
    "        new_units = self.cross_units(other_layer.units)\n",
    "        new_activation = self.cross_activation(other_layer.activation)\n",
    "        new_dropout = self.cross_dropout(other_layer.dropout)\n",
    "        return NNLayer(new_units, new_activation, new_dropout)\n",
    "\n",
    "    def cross_activation(self, other_activation):\n",
    "        if np.random.rand() > 0.5:\n",
    "            return self.activation\n",
    "        return other_activation\n",
    "\n",
    "    def cross_dropout(self, other_dropout):\n",
    "        b = np.random.rand()\n",
    "        return self.dropout * (1 - b) + b * other_dropout\n",
    "\n",
    "    def cross_units(self, other_units):\n",
    "        b = np.random.rand()\n",
    "        return int(self.units * (1 - b) + other_units * b)\n",
    "\n",
    "    def mutate(self):\n",
    "        aleatory = np.random.rand(4)\n",
    "        if aleatory[0] < self.units_prob:\n",
    "            self.units = np.random.randint(1, self.units_lim)\n",
    "        if aleatory[1] < self.act_prob:\n",
    "            self.activation = random.choice(self.posible_activations)\n",
    "        if aleatory[2] < self.drop_prob:\n",
    "            self.dropout = np.random.rand()\n",
    "\n",
    "    '''\n",
    "    def compare(self, other_layer):\n",
    "        if self.units != other_layer.units:\n",
    "            return False\n",
    "        if self.activation != other_layer.activation:\n",
    "            return False\n",
    "        if self.dropout != other_layer.dropout:\n",
    "            return False\n",
    "        return True\n",
    "    '''\n",
    "\n",
    "    def self_copy(self):\n",
    "        return NNLayer(self.units, self.activation, self.dropout)\n",
    "\n",
    "    def random_layer(self):\n",
    "        units = np.random.randint(1, self.units_lim)\n",
    "        act = random.choice(self.posible_activations)\n",
    "        drop = np.random.rand()\n",
    "        return NNLayer(units, act, drop)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"%s|U:%d|A:%s|D:%0.3f\" % (self.type, self.units, self.activation, self.dropout)\n",
    "    \n",
    "class CNNLayer(object):\n",
    "    def __init__(self, filters=32, kernel_size=(3,3), activation='relu', dropout=0, maxpool=True):\n",
    "        self.type = 'CNN'\n",
    "        self.posible_activations = ['relu', 'sigmoid', 'tanh', 'elu', 'prelu', 'leakyreLu']\n",
    "        assert activation in self.posible_activations\n",
    "        \n",
    "        # Parameters\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.filters = filters\n",
    "        self.k_size = kernel_size\n",
    "        self.maxpool = True\n",
    "        \n",
    "        self.filters_lim = 1024\n",
    "        self.k_lim = 9\n",
    "        self.k_prob = 0.2\n",
    "        self.filter_prob = 0.2\n",
    "        self.act_prob = 0.2\n",
    "        self.drop_prob = 0.2\n",
    "        self.maxpool_prob = 0.1\n",
    "\n",
    "    def cross(self, other_layer):\n",
    "        new_filters = self.cross_filters(other_layer.filters)\n",
    "        new_ksize = self.cross_kernel(other_layer.k_size)\n",
    "        new_activation = self.cross_activation(other_layer.activation)\n",
    "        new_dropout = self.cross_dropout(other_layer.dropout)\n",
    "        new_maxpool = self.cross_maxpool(other_layer.maxpool)\n",
    "        return CNNLayer(new_filters, new_ksize, new_activation, new_dropout, new_maxpool)\n",
    "    \n",
    "    def cross_kernel(self, )\n",
    "    \n",
    "    def cross_maxpool(self, other_maxpool):\n",
    "        return random.choice([self.maxpool, other_maxpool])\n",
    "\n",
    "    def cross_activation(self, other_activation):\n",
    "        return random.choice([self.activation, other_activation])\n",
    "    \n",
    "    def cross_dropout(self, other_dropout):\n",
    "        b = np.random.rand()\n",
    "        return self.dropout * (1 - b) + b * other_dropout\n",
    "\n",
    "    def cross_filters(self, other_filters):\n",
    "        b = np.random.rand()\n",
    "        return int(self.filters * (1 - b) + other_filters * b)\n",
    "\n",
    "    def mutate(self):\n",
    "        aleatory = np.random.rand(6)\n",
    "        if aleatory[0] < self.filter_prob:\n",
    "            self.filters = np.random.randint(0, self.filters_lim)\n",
    "        if aleatory[1] < self.act_prob:\n",
    "            self.activation = random.choice(self.posible_activations)\n",
    "        if aleatory[2] < self.drop_prob:\n",
    "            self.dropout = np.random.rand()\n",
    "        if aleatory[3] < self.k_prob:\n",
    "            self.k_size = (self.k_size[0], np.random.randint(1, self.k_lim + 1))\n",
    "        if aleatory[4] < self.k_prob:\n",
    "            self.k_size = (np.random.randint(1, self.k_lim + 1), self.k_size[1])\n",
    "        if aleatory[5] < self.maxpool_prob:\n",
    "            self.maxpool = random.choice([True, False])\n",
    "    '''\n",
    "    def compare(self, other_layer):\n",
    "        if self.filters != other_layer.filters:\n",
    "            return False\n",
    "        if self.activation != other_layer.activation:\n",
    "            return False\n",
    "        if self.dropout != other_layer.dropout:\n",
    "            return False\n",
    "        if self.k_size != other_layer.k_size:\n",
    "            return False\n",
    "        return True\n",
    "    '''\n",
    "\n",
    "    def self_copy(self):\n",
    "        return CNNLayer(self.filters, self.k_size, self.activation, self.dropout, self.maxpool)\n",
    "\n",
    "    def random_layer(self):\n",
    "        filters = np.random.randint(1, self.filters_lim)\n",
    "        k_size = tuple(np.random.randint(1, self.k_lim + 1, size=(2,)))\n",
    "        act = random.choice(self.posible_activations)\n",
    "        drop = np.random.rand()\n",
    "        maxpool = random.choice([True, False])\n",
    "        return CNNLayer(filters, k_size, act, drop, maxpool)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"%s|F:%d|K:(%d,%d)|A:%s|D:%0.3f|M:%d\" % (self.type, self.filters, self.k_size[0], self.k_size[1],\n",
    "                                         self.activation, self.dropout, self.maxpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN|F:32|K:(3,3)|A:relu|D:0.968|M:1\n",
      "CNN|F:32|K:(3,3)|A:elu|D:0.968|M:1\n",
      "CNN|F:32|K:(3,3)|A:elu|D:0.968|M:1\n",
      "CNN|F:32|K:(3,3)|A:elu|D:0.968|M:1\n",
      "CNN|F:32|K:(3,3)|A:relu|D:0.968|M:1\n",
      "CNN|F:32|K:(5,3)|A:elu|D:0.968|M:1\n",
      "CNN|F:32|K:(5,8)|A:sigmoid|D:0.968|M:1\n",
      "CNN|F:342|K:(5,5)|A:sigmoid|D:0.968|M:1\n",
      "CNN|F:342|K:(5,5)|A:relu|D:0.968|M:0\n",
      "CNN|F:342|K:(5,5)|A:relu|D:0.792|M:1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CNNLayer' object has no attribute 'cross_kernel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-534792090d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-8bb288b01044>\u001b[0m in \u001b[0;36mcross\u001b[0;34m(self, other_layer)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mnew_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_filters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mnew_ksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mnew_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mnew_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CNNLayer' object has no attribute 'cross_kernel'"
     ]
    }
   ],
   "source": [
    "a = CNNLayer()\n",
    "for i in range(10):\n",
    "    a.mutate()\n",
    "    print(a)\n",
    "print(a.cross(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(673, (9, 8), 'relu', 0, ['/bin/bash: self.maxpool: orden no encontrada'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.filters, a.k_size, a.activation, a.dropout, a.maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cromosome(object):\n",
    "\n",
    "    def __init__(self, layers=[], fit=None):\n",
    "        assert type(layers) == list\n",
    "        self.n_layers = len(layers)\n",
    "        self.n_cnn_layers = self.count_cnn_layers(layers)\n",
    "        self.n_nn_layers = self.n_layers - self.n_cnn_layers\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.max_nn_layers = 5\n",
    "        self.max_cnn_layers = 5\n",
    "        \n",
    "        self.grow_prob = 0.1\n",
    "        self.decrese_prob = 0.1\n",
    "        self.evaluator = Fitness.get_instance()\n",
    "        \n",
    "    def count_cnn_layers(self, layers):\n",
    "        c = 0\n",
    "        for l in layers:\n",
    "            if l.type == 'CNN':\n",
    "                c += 1\n",
    "        return c\n",
    "\n",
    "    def set_fitness(self, fit):\n",
    "        self.evaluator = fit\n",
    "\n",
    "    def random_indiv(self):\n",
    "        nn_layers = np.random.randint(0, self.max_nn_layers)\n",
    "        cnn_layers = np.random.randint(0, self.max_cnn_layers)\n",
    "        layers = [NNLayer().random_layer() for i in range(nn_layers)]\n",
    "        layers += [CNNLayer().random_layer() for i in range(cnn_layers)]\n",
    "        return Cromosome(layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def simple_indiv():\n",
    "        return Cromosome([Layer()])\n",
    "\n",
    "    def cross(self, other_cromosome):\n",
    "        new_layers = []\n",
    "\n",
    "        if self.n_layers == 0:\n",
    "            return other_cromosome\n",
    "\n",
    "        n_intersection = np.random.randint(0, self.n_layers)\n",
    "        for i in range(self.n_layers):\n",
    "            if i < n_intersection or i >= other_cromosome.n_layers:\n",
    "                new_layers.append(self.layers[i].self_copy())\n",
    "            else:\n",
    "                try:\n",
    "                    new_layers.append(self.layers[i].cross(other_cromosome.layers[i - n_intersection]))\n",
    "                except IndexError:\n",
    "                    print(\"Problem with index %d\" % i)\n",
    "                    print(\"Intersection point at %d\" % n_intersection)\n",
    "                    print(len(self.layers), self.layers)\n",
    "                    print(len(other_cromosome.layers), other_cromosome.layers)\n",
    "                    print(len(new_layers), new_layers)\n",
    "                    raise IndexError\n",
    "        return Cromosome(new_layers)\n",
    "\n",
    "    def mutate(self):\n",
    "        for i in range(self.n_layers):\n",
    "            self.layers[i].mutate()\n",
    "        if np.random.rand() < self.grow_prob:\n",
    "            if np.random.rand() < 0.5 and self.n_nn_layers < self.nn_max_layers:\n",
    "            self.layers.append(Layer().random_layer())\n",
    "            self.n_layers = len(self.layers)\n",
    "\n",
    "    def equals(self, other_cromosome):\n",
    "        if self.n_layers != other_cromosome.n_layers:\n",
    "            return False\n",
    "        for i in range(self.n_layers):\n",
    "            if not self.layers[i].compare(other_cromosome.layers[i]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def __repr__(self):\n",
    "        rep = \"\"\n",
    "        for i in range(self.n_layers):\n",
    "            rep += \"%d - %s \\n\" % (i, self.layers[i])\n",
    "        return rep\n",
    "\n",
    "    def fitness(self):\n",
    "        return self.evaluator.calc(self)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
