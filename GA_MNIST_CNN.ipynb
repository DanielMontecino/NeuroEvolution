{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import time as T\n",
    "from time import time\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import  Model\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, PReLU, LeakyReLU\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from time import time\n",
    "import time as T\n",
    "import traceback\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from GA.geneticAlgorithm import GenerationalGA\n",
    "from GA.parentSelector.parentSelector import RandomParentSelector, LinealOrder, TournamentSelection\n",
    "from GA.parentSelector.parentSelector import WheelSelection, LinealOrderII\n",
    "from utils.datamanager import DataManager\n",
    "#import tensorflow as tf\n",
    "\n",
    "class Layer(object):\n",
    "    def cross(self, other_layer):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def mutate(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def compare(self, other_layer):\n",
    "        raise self.__repr__() == other_layer.__repr__()\n",
    "\n",
    "    def self_copy(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def random_layer(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __repr__(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class NNLayer(Layer):\n",
    "    def __init__(self, units=128, activation='relu', dropout=0):\n",
    "        self.type = 'NN'\n",
    "        self.posible_activations = ['relu', 'sigmoid', 'tanh', 'elu', 'prelu', 'leakyreLu']\n",
    "        assert activation in self.posible_activations\n",
    "        \n",
    "        # parameters\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.units = units\n",
    "        \n",
    "        self.units_lim = 1024\n",
    "        self.units_prob = 0.2\n",
    "        self.act_prob = 0.2\n",
    "        self.drop_prob = 0.2\n",
    "\n",
    "    def cross(self, other_layer):\n",
    "        assert self.type == other_layer.type\n",
    "        new_units = self.cross_units(other_layer.units)\n",
    "        new_activation = self.cross_activation(other_layer.activation)\n",
    "        new_dropout = self.cross_dropout(other_layer.dropout)\n",
    "        return NNLayer(new_units, new_activation, new_dropout)\n",
    "\n",
    "    def cross_activation(self, other_activation):\n",
    "        if np.random.rand() > 0.5:\n",
    "            return self.activation\n",
    "        return other_activation\n",
    "\n",
    "    def cross_dropout(self, other_dropout):\n",
    "        b = np.random.rand()\n",
    "        return self.dropout * (1 - b) + b * other_dropout\n",
    "\n",
    "    def cross_units(self, other_units):\n",
    "        b = np.random.rand()\n",
    "        return int(self.units * (1 - b) + other_units * b)\n",
    "\n",
    "    def mutate(self):\n",
    "        aleatory = np.random.rand(4)\n",
    "        if aleatory[0] < self.units_prob:\n",
    "            self.units = np.random.randint(1, self.units_lim)\n",
    "        if aleatory[1] < self.act_prob:\n",
    "            self.activation = random.choice(self.posible_activations)\n",
    "        if aleatory[2] < self.drop_prob:\n",
    "            self.dropout = np.random.rand()\n",
    "\n",
    "    '''\n",
    "    def compare(self, other_layer):\n",
    "        if self.units != other_layer.units:\n",
    "            return False\n",
    "        if self.activation != other_layer.activation:\n",
    "            return False\n",
    "        if self.dropout != other_layer.dropout:\n",
    "            return False\n",
    "        return True\n",
    "    '''\n",
    "\n",
    "    def self_copy(self):\n",
    "        return NNLayer(self.units, self.activation, self.dropout)\n",
    "\n",
    "    def random_layer(self):\n",
    "        units = np.random.randint(1, self.units_lim)\n",
    "        act = random.choice(self.posible_activations)\n",
    "        drop = np.random.rand()\n",
    "        return NNLayer(units, act, drop)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"%s|U:%d|A:%s|D:%0.3f\" % (self.type, self.units, self.activation, self.dropout)\n",
    "    \n",
    "class CNNLayer(object):\n",
    "    def __init__(self, filters=32, kernel_size=(3,3), activation='relu', dropout=0, maxpool=True):\n",
    "        self.type = 'CNN'\n",
    "        self.posible_activations = ['relu', 'sigmoid', 'tanh', 'elu', 'prelu', 'leakyreLu']\n",
    "        assert activation in self.posible_activations\n",
    "        \n",
    "        # Parameters\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.filters = filters\n",
    "        self.k_size = kernel_size\n",
    "        self.maxpool = maxpool\n",
    "        \n",
    "        self.filters_lim = 1024\n",
    "        self.k_lim = 9\n",
    "        self.k_prob = 0.2\n",
    "        self.filter_prob = 0.2\n",
    "        self.act_prob = 0.2\n",
    "        self.drop_prob = 0.2\n",
    "        self.maxpool_prob = 0.1\n",
    "\n",
    "    def cross(self, other_layer):\n",
    "        new_filters = self.cross_filters(other_layer.filters)\n",
    "        new_ksize = self.cross_kernel(other_layer.k_size)\n",
    "        new_activation = self.cross_activation(other_layer.activation)\n",
    "        new_dropout = self.cross_dropout(other_layer.dropout)\n",
    "        new_maxpool = self.cross_maxpool(other_layer.maxpool)\n",
    "        return CNNLayer(new_filters, new_ksize, new_activation, new_dropout, new_maxpool)\n",
    "    \n",
    "    def cross_kernel(self, other_kernel):\n",
    "        b = np.random.rand(2)\n",
    "        kh = int(self.k_size[0] * b[0] + (1 - b[0]) * other_kernel[0])\n",
    "        kw = int(self.k_size[1] * b[1] + (1 - b[1]) * other_kernel[1])\n",
    "        return (kh, kw)\n",
    "    \n",
    "    def cross_maxpool(self, other_maxpool):\n",
    "        return random.choice([self.maxpool, other_maxpool])\n",
    "\n",
    "    def cross_activation(self, other_activation):\n",
    "        return random.choice([self.activation, other_activation])\n",
    "    \n",
    "    def cross_dropout(self, other_dropout):\n",
    "        b = np.random.rand()\n",
    "        return self.dropout * (1 - b) + b * other_dropout\n",
    "\n",
    "    def cross_filters(self, other_filters):\n",
    "        b = np.random.rand()\n",
    "        return int(self.filters * (1 - b) + other_filters * b)\n",
    "\n",
    "    def mutate(self):\n",
    "        aleatory = np.random.rand(6)\n",
    "        if aleatory[0] < self.filter_prob:\n",
    "            self.filters = np.random.randint(0, self.filters_lim)\n",
    "        if aleatory[1] < self.act_prob:\n",
    "            self.activation = random.choice(self.posible_activations)\n",
    "        if aleatory[2] < self.drop_prob:\n",
    "            self.dropout = np.random.rand()\n",
    "        if aleatory[3] < self.k_prob:\n",
    "            self.k_size = (self.k_size[0], np.random.randint(1, self.k_lim + 1))\n",
    "        if aleatory[4] < self.k_prob:\n",
    "            self.k_size = (np.random.randint(1, self.k_lim + 1), self.k_size[1])\n",
    "        if aleatory[5] < self.maxpool_prob:\n",
    "            self.maxpool = random.choice([True, False])\n",
    "    '''\n",
    "    def compare(self, other_layer):\n",
    "        if self.filters != other_layer.filters:\n",
    "            return False\n",
    "        if self.activation != other_layer.activation:\n",
    "            return False\n",
    "        if self.dropout != other_layer.dropout:\n",
    "            return False\n",
    "        if self.k_size != other_layer.k_size:\n",
    "            return False\n",
    "        return True\n",
    "    '''\n",
    "\n",
    "    def self_copy(self):\n",
    "        return CNNLayer(self.filters, self.k_size, self.activation, self.dropout, self.maxpool)\n",
    "\n",
    "    def random_layer(self):\n",
    "        filters = np.random.randint(1, self.filters_lim)\n",
    "        k_size = tuple(np.random.randint(1, self.k_lim + 1, size=(2,)))\n",
    "        act = random.choice(self.posible_activations)\n",
    "        drop = np.random.rand()\n",
    "        maxpool = random.choice([True, False])\n",
    "        return CNNLayer(filters, k_size, act, drop, maxpool)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"%s|F:%d|K:(%d,%d)|A:%s|D:%0.3f|M:%d\" % (self.type, self.filters, self.k_size[0], self.k_size[1],\n",
    "                                         self.activation, self.dropout, self.maxpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cromosome(object):\n",
    "\n",
    "    def __init__(self, cnn_layers=[], nn_layers=[], fit=None):\n",
    "        assert type(cnn_layers) == list\n",
    "        assert type(nn_layers)  == list\n",
    "        self.cnn_layers = cnn_layers\n",
    "        self.nn_layers = nn_layers\n",
    "        self.n_cnn = len(cnn_layers)\n",
    "        self.n_nn  = len(nn_layers)\n",
    "        \n",
    "        self.max_cnn = 3\n",
    "        self.max_nn = 3\n",
    "        \n",
    "        self.grow_prob = 0.1\n",
    "        self.decrese_prob = 0.1\n",
    "        self.fit = None\n",
    "        self.evaluator = Fitness.get_instance()\n",
    "\n",
    "    def set_fitness(self, fit):\n",
    "        self.evaluator = fit\n",
    "\n",
    "    def random_indiv(self):\n",
    "        n_cnn = np.random.randint(0, self.max_cnn)\n",
    "        n_nn = np.random.randint(0, self.max_nn)\n",
    "        cnn_layers = [CNNLayer().random_layer() for i in range(n_cnn)]\n",
    "        nn_layers  = [ NNLayer().random_layer() for i in range(n_nn)]\n",
    "        return Cromosome(cnn_layers, nn_layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def simple_indiv():\n",
    "        return Cromosome([Layer()])\n",
    "    \n",
    "    def cross(self, other_chromosome):\n",
    "        new_cnn_layers = self.cross_layers(self.cnn_layers, other_chromosome.cnn_layers)\n",
    "        new_nn_layers  = self.cross_layers( self.nn_layers, other_chromosome.nn_layers)\n",
    "        return Cromosome(new_cnn_layers, new_nn_layers)\n",
    "\n",
    "    def cross_layers(self,this_layers, other_layers):\n",
    "        new_layers = []\n",
    "\n",
    "        if -len(other_layers) + 1 >= len(this_layers):\n",
    "            return [l.self_copy() for l in this_layers]\n",
    "\n",
    "        t = np.random.randint(-len(other_layers) + 1, len(this_layers))\n",
    "        print(t)\n",
    "        for i in range(len(this_layers)):\n",
    "            j = i - t\n",
    "            if j < 0 or j >= len(other_layers):\n",
    "                new_layers.append(this_layers[i].self_copy())\n",
    "            else:\n",
    "                new_layers.append(this_layers[i].cross(other_layers[j]))\n",
    "        \n",
    "        return new_layers\n",
    "\n",
    "    def mutate(self):\n",
    "        self.mutate_layers(self.cnn_layers, self.max_cnn)\n",
    "        self.mutate_layers(self.nn_layers, self.max_nn)\n",
    "        self.n_cnn = len(self.cnn_layers)\n",
    "        self.n_nn = len(self.nn_layers)\n",
    "        \n",
    "    ### TODO: Allow to the empty cromosomes to grow up\n",
    "    def mutate_layers(self, this_layers, max_layers):\n",
    "        for i in range(len(this_layers)):\n",
    "            this_layers[i].mutate()\n",
    "        if np.random.rand() < self.grow_prob and len(this_layers) < max_layers and len(this_layers)>0:\n",
    "            this_layers.append(this_layers[0].random_layer())\n",
    "        elif np.random.rand() < self.decrese_prob and len(this_layers) > 0:\n",
    "            this_layers.pop()\n",
    "        \n",
    "\n",
    "    def equals(self, other_cromosome):\n",
    "        return self.__repr__() == other_cromosome.__repr__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        rep = \"\"\n",
    "        for l in self.cnn_layers + self.nn_layers:\n",
    "            rep += \"%s\\n\" % (l)\n",
    "        return rep\n",
    "\n",
    "    def fitness(self, test=False):\n",
    "        return self.evaluator.calc(self, test=test)\n",
    "    \n",
    "class Fitness:\n",
    "    __instance = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_instance():\n",
    "        \"\"\" Static access method. \"\"\"\n",
    "        if Fitness.__instance == None:\n",
    "            Fitness()\n",
    "        return Fitness.__instance\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Virtually private constructor. \"\"\"\n",
    "        if Fitness.__instance != None:\n",
    "            raise Exception(\"This class is a singleton!\")\n",
    "        else:\n",
    "            Fitness.__instance = self\n",
    "\n",
    "    def set_params(self, data, batch_size=128, epochs=100, early_stop=True, reduce_plateau=True, verbose=1,\n",
    "                  reset=True, test=False):\n",
    "        self.reset = reset\n",
    "        self.test =test\n",
    "        self.time = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.early_stop = early_stop\n",
    "        self.reduce_plateu = reduce_plateau\n",
    "        self.verb = verbose\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test), (self.x_val, self.y_val) = data\n",
    "        self.num_clases = self.y_train.shape[1]\n",
    "        self.callbacks = []\n",
    "        if self.early_stop and keras.__version__=='2.2.4':\n",
    "            #self.run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "            self.callbacks.append(EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True))\n",
    "        elif self.early_stop:\n",
    "            self.callbacks.append(EarlyStopping(monitor='val_acc', patience=10))\n",
    "        if self.reduce_plateu:\n",
    "            self.callbacks.append(ReduceLROnPlateau(monitor='val_acc', factor=0.2, \n",
    "                                                    patience=5, verbose=self.verb))\n",
    "        return self\n",
    "\n",
    "    def calc(self, chromosome, test=False):\n",
    "        try:\n",
    "            ti = time()\n",
    "            keras.backend.clear_session()\n",
    "            model = self.decode(chromosome)\n",
    "            h = model.fit(self.x_train, self.y_train,\n",
    "                              batch_size=self.batch_size,\n",
    "                              epochs=self.epochs,\n",
    "                              verbose=self.verb,\n",
    "                              validation_data=(self.x_val, self.y_val),\n",
    "                              callbacks=self.callbacks)\n",
    "            \n",
    "            if test:\n",
    "                score = model.evaluate(self.x_test, self.y_test, verbose=0)\n",
    "            else:\n",
    "                score = model.evaluate(self.x_val, self.y_val, verbose=0)\n",
    "        except Exception as e:\n",
    "            score = [1 / self.num_clases, 1. / self.num_clases]\n",
    "            print(\"Some Error with gen:\")\n",
    "            print(chromosome)\n",
    "            logging.error(traceback.format_exc())\n",
    "            keras.backend.clear_session()\n",
    "            T.sleep(5)\n",
    "        if self.verb and score[0] > 0:\n",
    "            dataset = ['Val', 'Test'][test]\n",
    "            print('%s loss: %0.4f,%s acc: %0.4f' % (dataset, score[0], dataset, score[1]))\n",
    "            self.show_result(h, 'acc')\n",
    "            self.show_result(h, 'loss')\n",
    "        self.time += T.time() - ti\n",
    "        return score[1]        \n",
    "        \n",
    "\n",
    "    def decode(self, chromosome):\n",
    "\n",
    "        inp = Input(shape=(28, 28, 1))\n",
    "        x   = Activation('linear', name='linear')(inp)\n",
    "        \n",
    "        for i in range(chromosome.n_cnn):\n",
    "            act = chromosome.cnn_layers[i].activation\n",
    "            filters = chromosome.cnn_layers[i].filters\n",
    "            ksize = chromosome.cnn_layers[i].k_size\n",
    "            if act in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
    "                x = Conv2D(filters, ksize, activation=act)(x)\n",
    "            elif act == 'prelu':\n",
    "                x = Conv2D(filters, ksize)(x)\n",
    "                x = PReLU()(x)\n",
    "            else:\n",
    "                x = Conv2D(filters, ksize)(x)\n",
    "                x = LeakyReLU()(x)\n",
    "            x = Dropout(chromosome.cnn_layers[i].dropout)(x)\n",
    "            if chromosome.cnn_layers[i].maxpool:\n",
    "                x = MaxPooling2D()(x)\n",
    "            \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        for i in range(chromosome.n_nn):\n",
    "            act = chromosome.nn_layers[i].activation\n",
    "            if act in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
    "                x = Dense(chromosome.nn_layers[i].units, activation=act)(x)\n",
    "            elif act == 'prelu':\n",
    "                x = Dense(chromosome.nn_layers[i].units)(x)\n",
    "                x = PReLU()(x)\n",
    "            else:\n",
    "                x = Dense(chromosome.nn_layers[i].units)(x)\n",
    "                x = LeakyReLU()(x)\n",
    "            x = Dropout(chromosome.nn_layers[i].dropout)(x)\n",
    "        x = Dense(self.num_clases, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        if self.verb:\n",
    "            model.summary()\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "                      #options = self.run_opts)\n",
    "        return model\n",
    "\n",
    "    def show_result(self, history, metric='acc'):\n",
    "        epochs = np.linspace(0, len(history.history['acc']) - 1, len(history.history['acc']))\n",
    "        plt.plot(epochs, history.history['val_%s' % metric], label='validation')\n",
    "        plt.plot(epochs, history.history[metric], label='train')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(metric)\n",
    "        plt.show()\n",
    "\n",
    "    def calc_mean(self, chromosome, iters=5):\n",
    "        f = []\n",
    "        ti = time()\n",
    "        for i in range(iters):\n",
    "            f.append(self.calc(chromosome))\n",
    "        print(\"Acc: %0.3f\" % np.mean(f), np.std(f), np.max(f))\n",
    "        print(\"Time elapsed: %0.3f\" % (time() - ti))\n",
    "        \n",
    "    def fitness_N_models(self, c1, c2):\n",
    "        from keras.layers.core import Activation\n",
    "        def decode_C(chromosome, inp, name=''):\n",
    "            x = Flatten()(inp)\n",
    "            for i in range(chromosome.n_layers):\n",
    "                act = chromosome.layers[i].activation\n",
    "                if act in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
    "                    x = Dense(chromosome.layers[i].units, activation=act)(x)\n",
    "                elif act == 'prelu':\n",
    "                    x = Dense(chromosome.layers[i].units)(x)\n",
    "                    x = PReLU()(x)\n",
    "                else:\n",
    "                    x = Dense(chromosome.layers[i].units)(x)\n",
    "                    x = LeakyReLU()(x)\n",
    "                x = Dropout(chromosome.layers[i].dropout)(x)\n",
    "            x = Dense(self.num_clases, activation='softmax', name=name)(x)\n",
    "            return x\n",
    "        \n",
    "        inputs = Input(shape=(28, 28, 1))\n",
    "        model = Model(inputs=inputs, outputs=[decode_C(c1, inputs,'x1'), decode_C(c2, inputs,'x2')],\n",
    "                        name=\"all_net\")\n",
    "        losses = {'x1':\"categorical_crossentropy\", 'x2':\"categorical_crossentropy\"}\n",
    "        metrics = {'x1': 'accuracy',\n",
    "                   'x2': 'accuracy'}\n",
    "        model.compile(optimizer=Adam(), loss=losses, metrics=metrics)\n",
    "        model.summary()\n",
    "        model.fit(self.x_train, [self.y_train, self.y_train],\n",
    "                  batch_size=self.batch_size,\n",
    "                  epochs=self.epochs,\n",
    "                  verbose=self.verb,\n",
    "                  validation_data=(self.x_val, [self.y_val, self.y_val]))\n",
    "                  #callbacks=self.callbacks)\n",
    "        score = model.evaluate(self.x_val, [self.y_val, self.y_val], verbose=1)\n",
    "        return score\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l = CNNLayer(32, (3,3), 'relu', 0, False)\n",
    "l2 = CNNLayer(64, (3,3), 'relu', 0.25, True)\n",
    "l3 = NNLayer(128, 'relu', 0.5)\n",
    "c = Cromosome([l, l2], [l3])\n",
    "\n",
    "ps = {'random':RandomParentSelector(), 'lineal':LinealOrder(), 'wheel':WheelSelection(), \n",
    "      'tournament':TournamentSelection(5)}\n",
    "\n",
    "# genetic algorithm params:\n",
    "parents_selector_key = 'wheel'\n",
    "num_parents = 0.3\n",
    "generations = 40\n",
    "population = 15\n",
    "train_time = 48\n",
    "\n",
    "# Fitness params\n",
    "epochs = 75\n",
    "batch_size = 256\n",
    "maximize_fit = True\n",
    "verbose = 0\n",
    "redu_plat = False\n",
    "early_stop = True\n",
    "\n",
    "# dataset params:\n",
    "dataset = 'mnist'\n",
    "classes = []\n",
    "\n",
    "p = ps[parents_selector_key]\n",
    "\n",
    "# Load data\n",
    "dm = DataManager(dataset, clases=classes)\n",
    "data = dm.load_data()\n",
    "fitness = Fitness.get_instance()\n",
    "fitness.set_params(data, verbose=verbose, reduce_plateau=redu_plat, \n",
    "                   epochs=epochs, early_stop=early_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_all = time()\n",
    "generational = GenerationalGA(num_parents=num_parents, chromosome=c, parent_selector=p, generations=generations,\n",
    "                              num_population=population, crossover_prob=0.5, mutation_prob=0.7,\n",
    "                              maximize_fitness=maximize_fit, training_hours=train_time)\n",
    "winner, best_fit, ranking = generational.evolve()\n",
    "print(\"Total elapsed time: %0.3f\" % (time() - ti_all))\n",
    "print(\"Total training time: %0.3f\" % fitness.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
