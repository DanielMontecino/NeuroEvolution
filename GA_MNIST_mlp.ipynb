{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from GA.geneticAlgorithm import GenerationalGA\n",
    "from GA.parentSelector.parentSelector import RandomParentSelector, LinealOrder, TournamentSelection\n",
    "from GA.parentSelector.parentSelector import WheelSelection, LinealOrderII\n",
    "from utils.datamanager import DataManager\n",
    "from utils.codificication_mlp import Layer, Cromosome, Fitness\n",
    "\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "class ParameterSensibilation(object):\n",
    "    \n",
    "    def __init__(self,chrom, cross_validation=False, iters=5, act=True, drop=True,\n",
    "                 units=True, layers=True, delta=False):\n",
    "        self.cross_val = cross_validation\n",
    "        self.iters = iters\n",
    "        self.act = act\n",
    "        self.drop = drop\n",
    "        self.units = units\n",
    "        self.layers = layers\n",
    "        self.chrom = chrom\n",
    "        self.levels = 2\n",
    "        self.delta = delta\n",
    "        \n",
    "        \n",
    "    def start_tests(self):\n",
    "        print(\"Testing Baseline\")\n",
    "        self.baseline_data = self.test_single(self.chrom)\n",
    "        all_fits = []\n",
    "        if self.act:\n",
    "            all_fits.append(self.activation_test(self.chrom))\n",
    "        if self.drop:\n",
    "            all_fits.append(self.dropout_test(self.chrom, self.delta))\n",
    "        if self.units:\n",
    "            all_fits.append(self.units_test(self.chrom, self.delta))\n",
    "        if self.layers:\n",
    "            all_fits.append(self.layer_test(self.chrom))\n",
    "        return all_fits\n",
    "        \n",
    "    def test_single(self, new_chrom):\n",
    "        fits = np.ones(5)\n",
    "        print(new_chrom, end='')\n",
    "        if self.cross_val:\n",
    "            fits = new_chrom.cross_val(exclude_first=False)\n",
    "        else:\n",
    "            fits = [new_chrom.fitness() for i in range(self.iters)]\n",
    "        print(\"Fitness: %0.4f (%0.4f)\" % (np.mean(fits), np.std(fits)))\n",
    "        return fits\n",
    "    \n",
    "    \n",
    "    def test_samples(self, new_chroms):\n",
    "        for new_chrom in new_chroms:\n",
    "            fits = self.test_single(new_chrom)\n",
    "            t_value, p_value = stats.ttest_ind(self.baseline_data, fits)\n",
    "            print(\"t = %0.4f, p = %0.4f\\n\" % (t_value, p_value))\n",
    "        return fits\n",
    "        \n",
    "    \n",
    "    def activation_test(self, chrom, crossval=True):\n",
    "        print(\"\\nActivation test:\\n\")\n",
    "        new_chroms = []\n",
    "        all_relu = chrom.self_copy()\n",
    "        for n in range(len(chrom.layers)):\n",
    "            new_chrom = chrom.self_copy()\n",
    "            new_chrom.layers[n].activation = 'relu'\n",
    "            new_chroms.append(new_chrom)\n",
    "            all_relu.layers[n].activation = 'relu'\n",
    "        new_chroms.append(all_relu)\n",
    "        return self.test_samples(new_chroms)\n",
    "\n",
    "\n",
    "    def dropout_test(self, chrom, crossval=False, delta=False):\n",
    "\n",
    "        def get_drop(d, i):\n",
    "            if i < 0:\n",
    "                return d - d * (2 ** i)\n",
    "            else:\n",
    "                return d + (1 - d) * (0.5 ** (i + 1))\n",
    "\n",
    "        print(\"\\nDropout test\\n\")\n",
    "        new_chroms = [chrom.self_copy() for i in range(len(chrom.layers))]\n",
    "        if delta:\n",
    "            new_chroms = [chrom.self_copy() for i in range(2 * self.levels)]\n",
    "        dropout_zero = chrom.self_copy()\n",
    "        dropout_02 = chrom.self_copy()\n",
    "        for n in range(len(chrom.layers)):\n",
    "            dropout_zero.layers[n].dropout = 0\n",
    "            dropout_02.layers[n].dropout = 0.2\n",
    "            if delta:\n",
    "                for i in range(len(new_chroms)):\n",
    "                    d = new_chroms[i].layers[n].dropout\n",
    "                    new_chroms[i].layers[n].dropout = get_drop(d, i - self.levels)\n",
    "            else:\n",
    "                new_chroms[n].layers[n].dropout = 0.2\n",
    "        new_chroms.append(dropout_zero)\n",
    "        new_chroms.append(dropout_02)\n",
    "        return self.test_samples(new_chroms)\n",
    "\n",
    "    \n",
    "    def layer_test(self, chrom):\n",
    "        print(\"\\nLayer test\\n\")\n",
    "        new_chroms = [chrom.self_copy()]\n",
    "        for i in range(len(chrom.layers)):\n",
    "            original_chrom = new_chroms[-1].self_copy()\n",
    "            new_layers = original_chrom.layers\n",
    "            new_layers.pop()\n",
    "            new_chroms.append(Cromosome(new_layers))\n",
    "        return self.test_samples(new_chroms)\n",
    "\n",
    "\n",
    "    def units_test(self, chrom, delta=True):\n",
    "        def get_units(d, i):\n",
    "            if i < 0:\n",
    "                return int(d * (1 + i * 0.2))\n",
    "            else:\n",
    "                return int(d * (1 + (i + 1) * 0.2))\n",
    "\n",
    "        print(\"\\nUnits test\\n\")\n",
    "        new_chroms = [chrom.self_copy() for i in range(len(chrom.layers))]\n",
    "        if delta:\n",
    "            new_chroms = [chrom.self_copy() for i in range(2 * self.levels)]\n",
    "        \n",
    "        units_512 = chrom.self_copy()\n",
    "        for n in range(len(chrom.layers)):\n",
    "            units_512.layers[n].units = 512\n",
    "            if delta:\n",
    "                for i in range(2 * self.levels):\n",
    "                    d = new_chroms[i].layers[n].units\n",
    "                    new_chroms[i].layers[n].units = get_units(d, i - self.levels)\n",
    "            else:\n",
    "                new_chroms[n].layers[n].units = 512\n",
    "        new_chroms.append(units_512)\n",
    "        return self.test_samples(new_chroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1) train samples\n",
      "(12000, 28, 28, 1) validation samples\n",
      "(10000, 28, 28, 1) test samples\n"
     ]
    }
   ],
   "source": [
    "l = Layer(512, 'relu', 0.2)\n",
    "l2 = Layer(512, 'relu', 0.2)\n",
    "benchm = Cromosome([l, l2])\n",
    "\n",
    "ps = {'random':RandomParentSelector(), 'lineal':LinealOrder(), 'wheel':WheelSelection(), \n",
    "      'tournament':TournamentSelection(5)}\n",
    "\n",
    "# dataset params:\n",
    "dataset = 'mnist'\n",
    "classes = []\n",
    "\n",
    "# genetic algorithm params:\n",
    "parents_selector_key = 'wheel'\n",
    "num_parents = 0.3\n",
    "generations = 40\n",
    "population = 15\n",
    "train_time = 10\n",
    "\n",
    "# Fitness params\n",
    "epochs = 75\n",
    "batch_size = 128\n",
    "maximize_fit = True\n",
    "verbose = 0\n",
    "redu_plat = False\n",
    "early_stop = True\n",
    "\n",
    "# Load data\n",
    "dm = DataManager(dataset, clases=classes)\n",
    "data = dm.load_data()\n",
    "fitness = Fitness.get_instance()\n",
    "fitness.set_params(data, batch_size=batch_size, verbose=verbose, reduce_plateau=redu_plat, \n",
    "                   epochs=epochs, early_stop=early_stop)\n",
    "p = ps[parents_selector_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_all = time()\n",
    "generational = GenerationalGA(num_parents=num_parents, chromosome=benchm, parent_selector=p,\n",
    "                              generations=generations, num_population=population, crossover_prob=0.5,\n",
    "                              mutation_prob=0.7, maximize_fitness=maximize_fit, training_hours=train_time)\n",
    "winner, best_fit, ranking = generational.evolve()\n",
    "print(\"Total elapsed time: %0.3f\" % (time() - ti_all))\n",
    "print(\"Total training time: %0.3f\" % fitness.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner = Cromosome([Layer(830, 'prelu',0.654), Layer(782, 'tanh', 0.166), Layer(28, 'elu', 0.062)])\n",
    "benchm = Cromosome([Layer(512, 'relu', 0.2), Layer(512, 'relu', 0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Baseline\n",
      "0 - U:830|A:prelu|D:0.654 \n",
      "Fitness: 0.9840 (0.0006)\n",
      "\n",
      "Activation test:\n",
      "\n",
      "0 - U:830|A:relu|D:0.654 \n",
      "Fitness: 0.9841 (0.0007)\n",
      "t = -0.1443, p = 0.8888\n",
      "\n",
      "0 - U:830|A:relu|D:0.654 \n",
      "Fitness: 0.9835 (0.0005)\n",
      "t = 1.2805, p = 0.2362\n",
      "\n",
      "\n",
      "Dropout test\n",
      "\n",
      "0 - U:830|A:prelu|D:0.200 \n",
      "Fitness: 0.9831 (0.0003)\n",
      "t = 2.7809, p = 0.0239\n",
      "\n",
      "0 - U:830|A:prelu|D:0.000 \n",
      "Fitness: 0.9842 (0.0005)\n",
      "t = -0.4491, p = 0.6653\n",
      "\n",
      "0 - U:830|A:prelu|D:0.200 \n",
      "Fitness: 0.9827 (0.0008)\n",
      "t = 2.6370, p = 0.0299\n",
      "\n",
      "\n",
      "Units test\n",
      "\n",
      "0 - U:498|A:prelu|D:0.654 \n",
      "Fitness: 0.9836 (0.0003)\n",
      "t = 1.1070, p = 0.3005\n",
      "\n",
      "0 - U:664|A:prelu|D:0.654 \n",
      "Fitness: 0.9835 (0.0006)\n",
      "t = 1.1767, p = 0.2731\n",
      "\n",
      "0 - U:996|A:prelu|D:0.654 \n",
      "Fitness: 0.9845 (0.0003)\n",
      "t = -1.2430, p = 0.2490\n",
      "\n",
      "0 - U:1162|A:prelu|D:0.654 \n",
      "Fitness: 0.9843 (0.0004)\n",
      "t = -0.8619, p = 0.4139\n",
      "\n",
      "0 - U:512|A:prelu|D:0.654 \n",
      "Fitness: 0.9836 (0.0004)\n",
      "t = 1.0839, p = 0.3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ps = ParameterSensibilation(Cromosome([Layer(830, 'prelu', 0.654)]), \n",
    "                            drop=True, layers=False, act=True, iters=10, delta=True)\n",
    "fits = ps.start_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Baseline\n",
      "0 - U:830|A:prelu|D:0.654 \n",
      "1 - U:782|A:tanh|D:0.166 \n",
      "2 - U:28|A:elu|D:0.062 \n",
      "Fitness: 0.9838 (0.0006)\n",
      "\n",
      "Units test\n",
      "\n",
      "0 - U:512|A:prelu|D:0.654 \n",
      "1 - U:782|A:tanh|D:0.166 \n",
      "2 - U:28|A:elu|D:0.062 \n",
      "Fitness: 0.9826 (0.0007)\n",
      "t = 2.4607, p = 0.0393\n",
      "\n",
      "0 - U:830|A:prelu|D:0.654 \n",
      "1 - U:512|A:tanh|D:0.166 \n",
      "2 - U:28|A:elu|D:0.062 \n",
      "Fitness: 0.9842 (0.0007)\n",
      "t = -0.9141, p = 0.3874\n",
      "\n",
      "0 - U:830|A:prelu|D:0.654 \n",
      "1 - U:782|A:tanh|D:0.166 \n",
      "2 - U:512|A:elu|D:0.062 \n",
      "Fitness: 0.9845 (0.0004)\n",
      "t = -1.9158, p = 0.0917\n",
      "\n",
      "0 - U:512|A:prelu|D:0.654 \n",
      "1 - U:512|A:tanh|D:0.166 \n",
      "2 - U:512|A:elu|D:0.062 \n",
      "Fitness: 0.9828 (0.0007)\n",
      "t = 1.9620, p = 0.0854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ps = ParameterSensibilation(winner, act=False, drop=False, layers=True, units=False, iters=5)\n",
    "ps.start_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness.calc_mean(winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness.calc_mean(benchm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4166666666666667"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1500/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "%%z\n%matplotlib inline       \n%%\n\nclass Layer(object):\n    def __init__(self, units=128, activation = 'relu', dropout = 0):\n        self.units = units\n        self.posible_activations = ['relu', 'sigmoid', 'tanh', 'elu', 'prelu', 'leakyreLu']\n        assert activation in self.posible_activations\n        self.activation = activation\n        self.dropout = dropout\n        self.units_lim = 1024\n        self.units_prob = 0.2\n        self.act_prob = 0.2\n        self.drop_prob = 0.2\n        \n    def cross(self, other_layer):\n        new_units = self.cross_units(other_layer.units)\n        new_activation = self.cross_activation(other_layer.activation)\n        new_dropout = self.cross_dropout(other_layer.dropout)\n        return Layer(new_units, new_activation, new_dropout)\n    \n    def cross_activation(self, other_activation):\n        if np.random.rand() > 0.5:\n            return self.activation\n        return other_activation\n    \n    def cross_dropout(self, other_dropout):\n        b = np.random.rand()\n        return self.dropout * (1 - b) + b * other_dropout\n    \n    def cross_units(self, other_units):\n        b = np.random.rand()\n        return int(self.units * (1 - b) + other_units * b)\n    \n    def mutate(self):\n        aleatory = np.random.rand(4)\n        if aleatory[0] < self.units_prob:\n            self.units = np.random.randint(0, self.units_lim)\n        if aleatory[1] < self.act_prob:\n            self.activation = random.choice(self.posible_activations)\n        if aleatory[2] < self.drop_prob:\n            self.dropout = np.random.rand()\n            \n    def compare(self, other_layer):\n        if self.units != other_layer.units:\n            return False\n        if self.activation != other_layer.activation:\n            return False\n        if self.dropout != other_layer.dropout:\n            return False\n        return True\n    \n    def self_copy(self):\n        return Layer(self.units, self.activation, self.dropout)\n    \n    def random_layer(self):\n        units = np.random.randint(0, self.units_lim)\n        act = random.choice(self.posible_activations)\n        drop = np.random.rand()\n        return Layer(units, act, drop)\n    \n    def __repr__(self):\n        return \"U:%d|A:%s|D:%0.3f\" % (self.units,self.activation, self.dropout)\n\n            \nclass Cromosome(object):\n    \n    def __init__(self, layers = []):\n        assert type(layers)==list\n        self.n_layers = len(layers)\n        self.layers = layers\n        self.max_layers = 10\n        self.layer_prob = 0.1\n        \n    def cross(self, other_cromosome):\n        new_layers = []\n        \n        if self.n_layers==0:\n            return other_cromosome\n        '''\n        elif other_cromosome.n_layers==0:\n            return self\n        '''\n        \n        n_intersection = np.random.randint(0, self.n_layers)\n        for i in range(self.n_layers):\n            if i<n_intersection or i>=other_cromosome.n_layers:\n                new_layers.append(self.layers[i].self_copy())\n            else:\n                try:\n                    new_layers.append(self.layers[i].cross(other_cromosome.layers[i - n_intersection]))\n                except IndexError:\n                    print(\"Problem with index %d\" % i)\n                    print(\"Intersection point at %d\" % n_intersection)\n                    print(len(self.layers), self.layers)\n                    print(len(other_cromosome.layers), other_cromosome.layers)\n                    print(len(new_layers), new_layers)\n                    raise IndexError\n        return Cromosome(new_layers)\n    \n    def mutate(self):\n        for i in range(self.n_layers):\n            self.layers[i].mutate()\n        if np.random.rand() < self.layer_prob and self.n_layers<self.max_layers:\n            self.layers.append(Layer().random_layer())\n            self.n_layers = len(self.layers)\n            \n    def compare(self, other_cromosome):\n        if self.n_layers != other_cromosome.n_layers:\n            return False\n        for i in range(self.n_layers):\n            if not self.layers[i].compare(other_cromosome.layers[i]):\n                return False\n        return True\n    \n    def __repr__(self):\n        rep = \"\"\n        for i in range(self.n_layers):\n            rep += \"%d - %s \\n\" % (i, self.layers[i])\n        return rep\n    \n\nclass GeneticAlgorithm(object):\n    \n    def __init__(self,fitness_obj, generations=70, num_population=20, num_parents=0.3, mutation_prob=0.7):\n        self.num_generations = generations\n        self.pop_size = num_population\n        self.prob_muta = mutation_prob\n        if type(num_parents)==int:\n            self.num_parents = num_parents\n        else:\n            self.num_parents = int(self.pop_size * num_parents)\n        self.posible_activations = ['relu', 'sigmoid', 'tanh', 'elu', 'prelu', 'leakyreLu']\n        self.Fitness = fitness_obj\n        self.offspring_size = self.pop_size - self.num_parents\n        self.history = np.empty((self.pop_size, self.num_generations + 1))\n        self.history_fitness = {}\n        self.fitness_reutilization = 0\n        \n    def create_random_indiv(self):\n        n_layers = np.random.randint(0,2)\n        layers = []\n        for i in range(n_layers):\n            units = np.random.randint(0,512)\n            act = random.choice(self.posible_activations)\n            drop = np.random.rand()\n            layers.append(Layer(units, act, drop))\n        return Cromosome(layers)\n    \n    def create_simple_indiv(self):\n        return Cromosome([])\n    \n    def initial_population(self):\n        population = []\n        for i in range(0, self.pop_size):\n            population.append(self.create_simple_indiv())\n        return population\n    \n    def rank(self, population):\n        fitness_result = {}\n        for i in range(self.pop_size):\n            gen = \"%s\" % population[i]\n            if not gen in self.history_fitness.keys():\n                self.history_fitness[gen] = self.Fitness.calc(population[i])\n            else:\n                self.fitness_reutilization += 1\n            fitness_result[i] = self.history_fitness[gen]\n        return sorted(fitness_result.items(), key = operator.itemgetter(1), reverse = True)\n    \n    def select_mating_pool(self, population, rank):\n        parents = []\n        for i in range(self.num_parents):\n            parent_num = rank[i][0]\n            parents.append(population[parent_num])\n        return parents\n    \n    def crossover(self, parents, offspring_size):\n        offspring = []\n        for k in range(offspring_size):\n            p1 = np.random.randint(0, len(parents) - 1)\n            p2 = np.random.randint(p1 + 1, len(parents))\n            parent1 = parents[p1]\n            parent2 = parents[p2]\n            #parent1 = random.choice(parents)\n            #parent2 = random.choice(parents)\n            offspring.append(parent1.cross(parent2))\n        return offspring\n    \n    def mutation(self, offspring_crossover):\n        for crom in offspring_crossover:\n            crom.mutate()\n        return offspring_crossover\n    \n    def actualize_history(self, generation, rank):\n        for i in range(len(rank)):\n            self.history[i, generation] = rank[i][1]\n    \n    def show_history(self):\n        x = np.linspace(0, self.num_generations, self.num_generations + 1)\n        mean = np.mean(self.history, axis=0)\n        max_ = np.max(self.history, axis=0)\n        min_ = np.min(self.history, axis=0)\n        plt.plot(x, mean, label=\"mean\", color='r', lw=1)\n        plt.plot(x, max_, label='max', color='b', lw=1)\n        plt.plot(x, min_, label='min', color='g', lw=1)\n        plt.legend()\n        plt.xlabel(\"num generation\")\n        plt.ylabel('Fitness')\n        plt.show()\n    \n    def evolve(self, show=True):\n        population = self.initial_population()\n        for generation in range(self.num_generations + 1):\n            ranking = self.rank(population)\n            self.actualize_history(generation, ranking)\n            if self.num_generations<=10 and show:\n                print(\"%d) best fit: %0.3f\" % (generation + 1, ranking[0][1]))\n            elif show and (generation % int(self.num_generations / 10) == 0):\n                print(\"%d) best fit: %0.3f\" % (generation + 1, ranking[0][1]))\n            if generation == self.num_generations:\n                break\n\n            # Selecting the best parents in the population for mating.\n            parents = self.select_mating_pool(population, ranking)\n\n            # Generating next generation using crossover.\n            offspring_crossover = self.crossover(parents, self.offspring_size)\n\n            # Adding some variations to the offsrping using mutation.\n            offspring_mutation = self.mutation(offspring_crossover)\n\n            # Creating the new population based on the parents and offspring.\n            population[0:self.num_parents] = parents\n            population[self.num_parents:] = offspring_mutation\n            \n        ranking = self.rank(population)\n        win_idx = ranking[0][0]\n        best_fit = ranking[0][1]\n        winner = population[win_idx]\n        if show:\n            print(\"Best Gen -> \", winner)\n            print(\"With Fitness: %0.3f\" % best_fit)\n            print(\"Number of reutilization fitness: %d\" % self.fitness_reutilization)\n            self.show_history()\n        return winner, best_fit, ranking\n    \n\nclass ParentSelection(object):\n    def __init__(self, mode):\n        self.mode = mode\n        \n    def linear_order(self, rank, ):\n        rank = dict(rank)\n        idxs = list(rank.keys())\n        fitness = list(rank.values())\n        probs = np.linspace(len(idxs), 1, len(idxs))\n        probs /= np.sum(probs)\n        \n        winner_idx = self.wheel_selection(probs)\n        \n    def wheel_selection(self, probs, num_selections=1):\n        if np.sum(probs) != 1:\n            print(\"normalizing probs\")\n            probs /= np.sum(probs)\n            \n        cumsum = np.cumsum(probs)\n        bullets = np.random.rand(num_selections)\n        winners = [np.argmax(cumsum>bullets[i]) for i in range(num_selections)]\n        return winners\n    \ndef parent_selction(rank, num_parents, selection_type):\n    rank = dict(rank)\n    idxs = list(rank.keys())\n    fitness = list(rank.values())\n    \n    def rank_probs(idxs):\n        probs = np.linspace(len(idxs), 1, len(idxs))\n        probs /= np.sum(probs)\n        return probs\n    \n    def fitness_probs(fitness):\n        probs = fitness / np.sum(fitness)\n        return probs\n    \ndef linear_selection_without_probs(rank, num_parents):\n    rank = dict(rank)\n    idxs = list(rank.keys())\n    fitness = list(rank.values())\n    valid_idxs = idxs[:num_parents]\n    num_offspring = len(idxs) - len(valid_idxs)\n    parents = []\n    for i in range(num_offspring):\n        parent_1 = random.choice(valid_idxs)\n        parent_2 = random.choice(valid_idxs)\n        while parent_1 == parent_2:\n            parent_2 = random.choice(valid_idxs)\n        parents.append((parent_1, parent_2))\n    \ndef linear_order_with_probs(rank, num_parents):\n    rank = dict(rank)\n    idxs = list(rank.keys())\n    fitness = list(rank.values())\n    \n    probs = np.linspace(len(idxs), 1, len(idxs))\n    num_offspring = len(idxs) - num_parents\n    parents_1 = random.choices(idxs, weights=probs, k=num_parents)\n    parents_2 = random.choices(idxs, weights=probs, k=num_parents)\n    parents = []\n    for i in range(num_offspring):\n        while parents_1[i] == parents_2[i]:\n            parents_2[i] = random.choice(idxs)\n        parents.append((parents_1[i], parents_2[i]))\n    return parents\n        \n\n    \nclass Fitness_str():\n    \n    def __init__(self, crom_objective):\n        self.crom = crom_objective\n        self.str = \"%s\" % self.crom\n        \n    def calc(self, crom):\n        C_str = \"%s\" % crom\n        min_lenght = min(len(C_str), len(self.str))\n        max_lenght = max(len(C_str), len(self.str))\n        f = max_lenght - min_lenght\n        for i in range(min_lenght):\n            f += self.str[i] != C_str[i]\n        return -f\n    \n\n        "
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
